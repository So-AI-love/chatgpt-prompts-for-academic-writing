{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/So-AI-love/chatgpt-prompts-for-academic-writing/blob/main/NoteBook/ChatDev_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Communicative Agents for Software Development\n",
        "\n",
        "https://github.com/OpenBMB/ChatDev"
      ],
      "metadata": {
        "id": "PDvXCooLMtst"
      },
      "id": "PDvXCooLMtst"
    },
    {
      "cell_type": "markdown",
      "source": [
        "![enter image description here](https://i.stack.imgur.com/nORyw.jpg)"
      ],
      "metadata": {
        "id": "GBrp6O0KM42b"
      },
      "id": "GBrp6O0KM42b"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "  # Mount Google Drive\n",
        "if not os.path.isdir('/content/drive'):\n",
        "   # If not, mount the drive\n",
        "     drive.mount('/content/drive')\n",
        "else:\n",
        "     print(\"Drive is already mounted.\")\n",
        "\n",
        "dst = '/content/drive/MyDrive/ChatGPT_Paper_wrting/ChatDev_projec'\n",
        "if not os.path.exists(dst):\n",
        "   os.makedirs(dst)\n",
        "\n",
        "os.chdir(dst)\n",
        "print ( 'current directory is :', os. getcwd())"
      ],
      "metadata": {
        "id": "LypJ6L9RwaM2",
        "outputId": "54216ae1-a076-4feb-f8ab-af908bb99061",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LypJ6L9RwaM2",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive is already mounted.\n",
            "current directory is : /content/drive/MyDrive/ChatGPT_Paper_wrting/ChatDev_projec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/OpenBMB/ChatDev.git"
      ],
      "metadata": {
        "id": "vJYsSBgtMt6-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24a5c492-a4c4-499e-b51c-b66ddd2ba7d1"
      },
      "id": "vJYsSBgtMt6-",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ChatDev' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install conda"
      ],
      "metadata": {
        "id": "2v7dsRxSNjKQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ae73785-b80d-4ce6-fa00-f83216ab5c03"
      },
      "id": "2v7dsRxSNjKQ",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package conda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda create -n ChatDev_conda_env python=3.9 -y\n",
        "!conda activate ChatDev_conda_env"
      ],
      "metadata": {
        "id": "IDhB_ZN7NdoM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0adb5a81-ad9c-4e55-c3bf-302b707ccd0c"
      },
      "id": "IDhB_ZN7NdoM",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: conda: command not found\n",
            "/bin/bash: line 1: conda: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ChatDev\n",
        "!pip3 install -r requirements.txt"
      ],
      "metadata": {
        "id": "LLd6MBw7NsaT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d752b893-4671-4839-edc2-4f657c9dd80c"
      },
      "id": "LLd6MBw7NsaT",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ChatGPT_Paper_wrting/ChatDev_projec/ChatDev\n",
            "Requirement already satisfied: colorama==0.4.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.4.6)\n",
            "Collecting Flask==2.3.2 (from -r requirements.txt (line 2))\n",
            "  Using cached Flask-2.3.2-py3-none-any.whl (96 kB)\n",
            "Collecting Flask-SocketIO==5.3.4 (from -r requirements.txt (line 3))\n",
            "  Using cached Flask_SocketIO-5.3.4-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-metadata==6.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (6.8.0)\n",
            "Requirement already satisfied: numpy==1.24.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.24.3)\n",
            "Collecting openai==0.27.8 (from -r requirements.txt (line 6))\n",
            "  Using cached openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "Requirement already satisfied: regex==2023.6.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (2023.6.3)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.31.0)\n",
            "Requirement already satisfied: tenacity==8.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (8.2.2)\n",
            "Collecting tiktoken==0.4.0 (from -r requirements.txt (line 10))\n",
            "  Using cached tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "Requirement already satisfied: virtualenv==20.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (20.23.0)\n",
            "Requirement already satisfied: Werkzeug==2.3.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.3.6)\n",
            "Requirement already satisfied: Markdown==3.4.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (3.4.4)\n",
            "Requirement already satisfied: Pillow==10.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (10.1.0)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask==2.3.2->-r requirements.txt (line 2)) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask==2.3.2->-r requirements.txt (line 2)) (2.1.2)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask==2.3.2->-r requirements.txt (line 2)) (8.1.7)\n",
            "Collecting blinker>=1.6.2 (from Flask==2.3.2->-r requirements.txt (line 2))\n",
            "  Using cached blinker-1.7.0-py3-none-any.whl (13 kB)\n",
            "Collecting python-socketio>=5.0.2 (from Flask-SocketIO==5.3.4->-r requirements.txt (line 3))\n",
            "  Using cached python_socketio-5.10.0-py3-none-any.whl (74 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata==6.8.0->-r requirements.txt (line 4)) (3.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8->-r requirements.txt (line 6)) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8->-r requirements.txt (line 6)) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->-r requirements.txt (line 8)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->-r requirements.txt (line 8)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->-r requirements.txt (line 8)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->-r requirements.txt (line 8)) (2023.11.17)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from virtualenv==20.23.0->-r requirements.txt (line 11)) (0.3.8)\n",
            "Requirement already satisfied: filelock<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from virtualenv==20.23.0->-r requirements.txt (line 11)) (3.13.1)\n",
            "Requirement already satisfied: platformdirs<4,>=3.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv==20.23.0->-r requirements.txt (line 11)) (3.11.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from Werkzeug==2.3.6->-r requirements.txt (line 12)) (2.1.3)\n",
            "Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from python-socketio>=5.0.2->Flask-SocketIO==5.3.4->-r requirements.txt (line 3)) (0.22.1)\n",
            "Collecting python-engineio>=4.8.0 (from python-socketio>=5.0.2->Flask-SocketIO==5.3.4->-r requirements.txt (line 3))\n",
            "  Using cached python_engineio-4.8.0-py3-none-any.whl (56 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 6)) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 6)) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 6)) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 6)) (4.0.3)\n",
            "Collecting simple-websocket>=0.10.0 (from python-engineio>=4.8.0->python-socketio>=5.0.2->Flask-SocketIO==5.3.4->-r requirements.txt (line 3))\n",
            "  Using cached simple_websocket-1.0.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: wsproto in /usr/local/lib/python3.10/dist-packages (from simple-websocket>=0.10.0->python-engineio>=4.8.0->python-socketio>=5.0.2->Flask-SocketIO==5.3.4->-r requirements.txt (line 3)) (1.2.0)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto->simple-websocket>=0.10.0->python-engineio>=4.8.0->python-socketio>=5.0.2->Flask-SocketIO==5.3.4->-r requirements.txt (line 3)) (0.14.0)\n",
            "Installing collected packages: blinker, tiktoken, simple-websocket, Flask, python-engineio, openai, python-socketio, Flask-SocketIO\n",
            "  Attempting uninstall: blinker\n",
            "    Found existing installation: blinker 1.4\n",
            "\u001b[31mERROR: Cannot uninstall 'blinker'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip uninstall openai -y\n",
        "\n",
        "!pip3 install openai==0.28 tiktoken tenacity"
      ],
      "metadata": {
        "id": "3JKXhs5GP3G9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b639308b-384b-4f6b-dd84-41b478ff22b3"
      },
      "id": "3JKXhs5GP3G9",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: openai 0.28.0\n",
            "Uninstalling openai-0.28.0:\n",
            "  Successfully uninstalled openai-0.28.0\n",
            "Collecting openai==0.28\n",
            "  Using cached openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (8.2.2)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title (Please insert your request to be done by this code at below form:👇👇)\n",
        "Topic = \"PersonalityInteractions\" # @param {type:\"string\"}\n",
        "PARAGRAPH = \"Use game theory to understand how different personality types (Dark Triad, Dark Tetrad, Dark Empathy) might interact within a society \\u003CINFO> PowerPoint\" # @param {type:\"string\"}\n",
        "role = \"startup Entrepreneur\"# @param {type:\"string\"}\n",
        "\n",
        "\n",
        "Your_Email = \"hh@gmail.com\" # @param {type:\"string\"}\n",
        "\n",
        "openai_api = \"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\" # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "#!export OPENAI_API_KEY = openai_api\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = openai_api #'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'"
      ],
      "metadata": {
        "id": "6dGOPiCyOzRx"
      },
      "id": "6dGOPiCyOzRx",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface\n",
        "!sudo apt install git-lfs\n",
        "!git lfs install"
      ],
      "metadata": {
        "id": "-AecMpQ5lKP4",
        "outputId": "418bb920-5c7a-41e0-d9c6-862991a60768",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-AecMpQ5lKP4",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface in /usr/local/lib/python3.10/dist-packages (0.0.1)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 16 not upgraded.\n",
            "Updated git hooks.\n",
            "Git LFS initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!huggingface-cli login --token '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'\n",
        "!git init\n",
        "!git add .\n",
        "!git commit -am \"test\"\n",
        "!git remote add space https://huggingface.co/spaces/your_HF_USERNAME/your_SPACE_NAME\n",
        "!git push --force space main"
      ],
      "metadata": {
        "id": "rwbieSlIlCLt",
        "outputId": "927e1e57-c97e-4fe1-d388-dee8e3f378c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "rwbieSlIlCLt",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n",
            "Reinitialized existing Git repository in /content/ChatDev/WareHouse/chatdev2huggingface_DefaultOrganization_20231212154538/.git/\n",
            "Author identity unknown\n",
            "\n",
            "*** Please tell me who you are.\n",
            "\n",
            "Run\n",
            "\n",
            "  git config --global user.email \"you@example.com\"\n",
            "  git config --global user.name \"Your Name\"\n",
            "\n",
            "to set your account's default identity.\n",
            "Omit --global to set the identity only in this repository.\n",
            "\n",
            "fatal: unable to auto-detect email address (got 'root@cefbd09ecbf2.(none)')\n",
            "error: remote space already exists.\n",
            "error: src refspec main does not match any\n",
            "\u001b[31merror: failed to push some refs to 'https://huggingface.co/spaces/SoSa123456/Auto-Business-Plan-maker'\n",
            "\u001b[m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "https://www.phind.com/search?cache=esnrf1bblvwbp4q4sp3drbs6\n",
        "\n",
        "Based on your project description and the search results, it seems like you want to generate a PowerPoint presentation from the results of your simulation using the ChatDev software.\n",
        "\n",
        "According to the ChatDev documentation, you can specify the product modality as PowerPoint in the task description. You can do this by adding `<INFO> PowerPoint` at the end of your task description.\n",
        "\n",
        "Here's how you can update the command:\n",
        "\n",
        "```bash\n",
        "python3 run.py --task \"Use game theory to understand how different personality types (Dark Triad, Dark Tetrad, Dark Empathy) might interact within a society <INFO> PowerPoint\" --name \"PersonalityInteractions\"\n",
        "```\n",
        "\n",
        "This command will initiate the building of your software with the task description being the application of game theory to understand the interactions of different personality types and the final product modality being PowerPoint. The project name is \"PersonalityInteractions\".\n",
        "\n",
        "Remember to replace `\"PersonalityInteractions\"` with your desired project name. Also, you need to make sure that you have defined the roles and behaviors of the personality types in your project configuration.\n",
        "\n",
        "This command will create a corresponding folder in the WareHouse directory, which will contain all the files and documents related to the software, configuration files of the company responsible for this software, a comprehensive log detailing the software's building process, and the initial prompt used to create this software [Source 1](https://github.com/OpenBMB/ChatDev).\n",
        "\n",
        "After the software is built and run, you should be able to find a PowerPoint file in the WareHouse directory under the specific project folder, such as `project_name_DefaultOrganization_timestamp`. This PowerPoint file will contain the results of your simulation [Source 1](https://github.com/OpenBMB/ChatDev)."
      ],
      "metadata": {
        "id": "D3OrVwWOvOf7"
      },
      "id": "D3OrVwWOvOf7"
    },
    {
      "cell_type": "code",
      "source": [
        "#!python3 run.py --task \"[description_of_your_idea]\" --name \"[project_name]\"\n",
        "\n",
        "#!python3 run.py --task \"theory to understand how different personality types (Dark Triad, Dark Tetrad, Dark Empathy) might interact within a society <INFO> PowerPoint\" --name \"PersonalityInteractions\""
      ],
      "metadata": {
        "id": "fvanVNknPQAP"
      },
      "id": "fvanVNknPQAP",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ChatDev\n",
        "TOPIC = 'business_plan_chatgpt'\n",
        "PARAGRAPH= 'creat one beautiful one website page with description about the AutoGPT for writing business  plan and by using langchain python module and its feature like website or saving result as pdf and docx and sending the documents by one predefined email content and send it as email to user . Also Openai ChatGP pyhton program as webpage which be run in Huggingface  space by docker file and recive the openai API and the the two topic and description variable and then act like AutoGPT  but  for writing the Business Plan report with around 10 prompt and then results must be saved as standard business plan with title , subtitle and numbering the results of the 10 prompt, so the official form of final repost is important and it must be in the form of pdf and doc saved and the Huggingface face mist have one email form to send this pdf and doc file to the given email of user'\n",
        "!python3 run.py --task '{PARAGRAPH}' --name '{TOPIC}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPdqUwuWjNv0",
        "outputId": "da7894a6-2f94-4d7a-9ef5-43c38ea28977"
      },
      "id": "OPdqUwuWjNv0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ChatDev\n",
            "**[Preprocessing]**\n",
            "\n",
            "**ChatDev Starts** (20231212193222)\n",
            "\n",
            "**Timestamp**: 20231212193222\n",
            "\n",
            "**config_path**: /content/ChatDev/CompanyConfig/Default/ChatChainConfig.json\n",
            "\n",
            "**config_phase_path**: /content/ChatDev/CompanyConfig/Default/PhaseConfig.json\n",
            "\n",
            "**config_role_path**: /content/ChatDev/CompanyConfig/Default/RoleConfig.json\n",
            "\n",
            "**task_prompt**: creat one beautiful one website page with description about the AutoGPT for writing business  plan and by using langchain python module and its feature like website or saving result as pdf and docx and sending the documents by one predefined email content and send it as email to user . Also Openai ChatGP pyhton program as webpage which be run in Huggingface  space by docker file and recive the openai API and the the two topic and description variable and then act like AutoGPT  but  for writing the Business Plan report with around 10 prompt and then results must be saved as standard business plan with title , subtitle and numbering the results of the 10 prompt, so the official form of final repost is important and it must be in the form of pdf and doc saved and the Huggingface face mist have one email form to send this pdf and doc file to the given email of user\n",
            "\n",
            "**project_name**: business_plan_chatgpt\n",
            "\n",
            "**Log File**: /content/ChatDev/WareHouse/business_plan_chatgpt_DefaultOrganization_20231212193222.log\n",
            "\n",
            "**ChatDevConfig**:\n",
            "ChatEnvConfig.clear_structure: True\n",
            "ChatEnvConfig.git_management: False\n",
            "ChatEnvConfig.gui_design: True\n",
            "ChatEnvConfig.incremental_develop: False\n",
            "\n",
            "\n",
            "**ChatGPTConfig**:\n",
            "ChatGPTConfig(temperature=0.2, top_p=1.0, n=1, stream=False, stop=None, max_tokens=None, presence_penalty=0.0, frequency_penalty=0.0, logit_bias={}, user='')\n",
            "\n",
            "\n",
            "\n",
            "System: **[chatting]**\n",
            "\n",
            "| Parameter | Value |\n",
            "| --- | --- |\n",
            "| **task_prompt** | creat one beautiful one website page with description about the AutoGPT for writing business  plan and by using langchain python module and its feature like website or saving result as pdf and docx and sending the documents by one predefined email content and send it as email to user . Also Openai ChatGP pyhton program as webpage which be run in Huggingface  space by docker file and recive the openai API and the the two topic and description variable and then act like AutoGPT  but  for writing the Business Plan report with around 10 prompt and then results must be saved as standard business plan with title , subtitle and numbering the results of the 10 prompt, so the official form of final repost is important and it must be in the form of pdf and doc saved and the Huggingface face mist have one email form to send this pdf and doc file to the given email of user |\n",
            "| **need_reflect** | True |\n",
            "| **assistant_role_name** | Chief Product Officer |\n",
            "| **user_role_name** | Chief Executive Officer |\n",
            "| **phase_prompt** | ChatDev has made products in the following form before: Image: can present information in line chart, bar chart, flow chart, cloud chart, Gantt chart, etc. Document: can present information via .docx files. PowerPoint: can present information via .pptx files. Excel: can present information via .xlsx files. PDF: can present information via .pdf files. Website: can present personal resume, tutorial, products, or ideas, via .html files. Application: can implement visualized game, software, tool, etc, via python. Dashboard: can display a panel visualizing real-time information. Mind Map: can represent ideas, with related concepts arranged around a core concept. As the {assistant_role}, to satisfy the new user's demand and the product should be realizable, you should keep discussing with me to decide which product modality do we want the product to be? Note that we must ONLY discuss the product modality and do not discuss anything else! Once we all have expressed our opinion(s) and agree with the results of the discussion unanimously, any of us must actively terminate the discussion by replying with only one line, which starts with a single word , followed by our final product modality without any other words, e.g., \" PowerPoint\". |\n",
            "| **phase_name** | DemandAnalysis |\n",
            "| **assistant_role_prompt** | {chatdev_prompt} You are Chief Product Officer. we are both working at ChatDev. We share a common interest in collaborating to successfully complete a task assigned by a new customer. You are responsible for all product-related matters in ChatDev. Usually includes product design, product strategy, product vision, product innovation, project management and product marketing. Here is a new customer's task: {task}. To complete the task, you must write a response that appropriately solves the requested instruction based on your expertise and customer's needs. |\n",
            "| **user_role_prompt** | {chatdev_prompt} You are Chief Executive Officer. Now, we are both working at ChatDev and we share a common interest in collaborating to successfully complete a task assigned by a new customer. Your main responsibilities include being an active decision-maker on users' demands and other key policy issues, leader, manager, and executor. Your decision-making role involves high-level decisions about policy and strategy; and your communicator role can involve speaking to the organization's management and employees. Here is a new customer's task: {task}. To complete the task, I will give you one or more instructions, and you must help me to write a specific solution that appropriately solves the requested instruction based on your expertise and my needs. |\n",
            "| **chat_turn_limit** | 10 |\n",
            "| **placeholders** | {} |\n",
            "| **model_type** | ModelType.GPT_3_5_TURBO |\n",
            "\n",
            "System: **[RolePlaying]**\n",
            "\n",
            "| Parameter | Value |\n",
            "| --- | --- |\n",
            "| **assistant_role_name** | Chief Product Officer |\n",
            "| **user_role_name** | Chief Executive Officer |\n",
            "| **assistant_role_prompt** | {chatdev_prompt} You are Chief Product Officer. we are both working at ChatDev. We share a common interest in collaborating to successfully complete a task assigned by a new customer. You are responsible for all product-related matters in ChatDev. Usually includes product design, product strategy, product vision, product innovation, project management and product marketing. Here is a new customer's task: {task}. To complete the task, you must write a response that appropriately solves the requested instruction based on your expertise and customer's needs. |\n",
            "| **user_role_prompt** | {chatdev_prompt} You are Chief Executive Officer. Now, we are both working at ChatDev and we share a common interest in collaborating to successfully complete a task assigned by a new customer. Your main responsibilities include being an active decision-maker on users' demands and other key policy issues, leader, manager, and executor. Your decision-making role involves high-level decisions about policy and strategy; and your communicator role can involve speaking to the organization's management and employees. Here is a new customer's task: {task}. To complete the task, I will give you one or more instructions, and you must help me to write a specific solution that appropriately solves the requested instruction based on your expertise and my needs. |\n",
            "| **task_prompt** | creat one beautiful one website page with description about the AutoGPT for writing business  plan and by using langchain python module and its feature like website or saving result as pdf and docx and sending the documents by one predefined email content and send it as email to user . Also Openai ChatGP pyhton program as webpage which be run in Huggingface  space by docker file and recive the openai API and the the two topic and description variable and then act like AutoGPT  but  for writing the Business Plan report with around 10 prompt and then results must be saved as standard business plan with title , subtitle and numbering the results of the 10 prompt, so the official form of final repost is important and it must be in the form of pdf and doc saved and the Huggingface face mist have one email form to send this pdf and doc file to the given email of user |\n",
            "| **with_task_specify** | False |\n",
            "| **model_type** | ModelType.GPT_3_5_TURBO |\n",
            "\n",
            "Chief Executive Officer: **[Start Chat]**\n",
            "\n",
            "[ChatDev is a software company powered by multiple intelligent agents, such as chief executive officer, chief human resources officer, chief product officer, chief technology officer, etc, with a multi-agent organizational structure and the mission of \"changing the digital world through programming\".\n",
            "You are Chief Product Officer. we are both working at ChatDev. We share a common interest in collaborating to successfully complete a task assigned by a new customer.\n",
            "You are responsible for all product-related matters in ChatDev. Usually includes product design, product strategy, product vision, product innovation, project management and product marketing.\n",
            "Here is a new customer's task: creat one beautiful one website page with description about the AutoGPT for writing business  plan and by using langchain python module and its feature like website or saving result as pdf and docx and sending the documents by one predefined email content and send it as email to user . Also Openai ChatGP pyhton program as webpage which be run in Huggingface  space by docker file and recive the openai API and the the two topic and description variable and then act like AutoGPT  but  for writing the Business Plan report with around 10 prompt and then results must be saved as standard business plan with title , subtitle and numbering the results of the 10 prompt, so the official form of final repost is important and it must be in the form of pdf and doc saved and the Huggingface face mist have one email form to send this pdf and doc file to the given email of user.\n",
            "To complete the task, you must write a response that appropriately solves the requested instruction based on your expertise and customer's needs.]\n",
            "\n",
            "ChatDev has made products in the following form before:\n",
            "\n",
            "Image: can present information in line chart, bar chart, flow chart, cloud chart, Gantt chart, etc.\n",
            "\n",
            "Document: can present information via .docx files.\n",
            "\n",
            "PowerPoint: can present information via .pptx files.\n",
            "\n",
            "Excel: can present information via .xlsx files.\n",
            "\n",
            "PDF: can present information via .pdf files.\n",
            "\n",
            "Website: can present personal resume, tutorial, products, or ideas, via .html files.\n",
            "\n",
            "Application: can implement visualized game, software, tool, etc, via python.\n",
            "\n",
            "Dashboard: can display a panel visualizing real-time information.\n",
            "\n",
            "Mind Map: can represent ideas, with related concepts arranged around a core concept.\n",
            "\n",
            "As the Chief Product Officer, to satisfy the new user's demand and the product should be realizable, you should keep discussing with me to decide which product modality do we want the product to be?\n",
            "\n",
            "Note that we must ONLY discuss the product modality and do not discuss anything else! Once we all have expressed our opinion(s) and agree with the results of the discussion unanimously, any of us must actively terminate the discussion by replying with only one line, which starts with a single word <INFO>, followed by our final product modality without any other words, e.g., \"<INFO> PowerPoint\".\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "src = '/content/ChatDev/WareHouse/'\n",
        "\n",
        "scr2 = f'{src}'+'/chatdev2huggingface_DefaultOrganization_20231212154538'\n",
        "%cd '{scr2}'\n",
        "!pwd\n",
        "!ls\n",
        "\n",
        "!python3 -m venv env\n",
        "!source env/bin/activate\n",
        "!pip3 install -r requirements.txt\n",
        "!python3 '{scr2}/'main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gccm9EZGUgKj",
        "outputId": "440a44e3-f45f-43ee-aa89-b188cf1f91d1"
      },
      "id": "Gccm9EZGUgKj",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ChatDev/WareHouse/chatdev2huggingface_DefaultOrganization_20231212154538\n",
            "/content/ChatDev/WareHouse/chatdev2huggingface_DefaultOrganization_20231212154538\n",
            "chat_app.py\t\t\t\t\t\t    env\t\tPhaseConfig.json\n",
            "ChatChainConfig.json\t\t\t\t\t    main.py\trequirements.txt\n",
            "chatdev2huggingface_DefaultOrganization_20231212154538.log  manual.md\tRoleConfig.json\n",
            "chatdev2huggingface.prompt\t\t\t\t    message.py\n",
            "chat_window.py\t\t\t\t\t\t    meta.txt\n",
            "Collecting requests==2.25.1 (from -r requirements.txt (line 1))\n",
            "  Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tkinter==8.6 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tkinter==8.6\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pwd\n",
        "!python3 '{scr2}/'main.py"
      ],
      "metadata": {
        "id": "fnLQ15g-wluo",
        "outputId": "32b8573b-bd46-4526-a80e-250b37a541a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "fnLQ15g-wluo",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ChatDev/WareHouse/chatdev2huggingface_DefaultOrganization_20231212154538\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dst = '/content/drive/MyDrive/ChatGPT_Paper_wrting/ChatDev'\n",
        "if not os.path.exists(dst):\n",
        "   os.makedirs(dst)\n",
        "!cp -r '{src}' '{dst}'\n",
        "\n",
        "#src = '/content/ChatDev/ChatDev/WareHouse/PersonalityInteractions_DefaultOrganization_20231212111412'\n",
        "\n",
        "import shutil\n",
        "#shutil.copytree(src, dst)"
      ],
      "metadata": {
        "id": "lrjMzdKmyzIB"
      },
      "id": "lrjMzdKmyzIB",
      "execution_count": 41,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}