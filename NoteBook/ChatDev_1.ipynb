{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/So-AI-love/chatgpt-prompts-for-academic-writing/blob/main/NoteBook/ChatDev_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Communicative Agents for Software Development\n",
        "\n",
        "https://github.com/OpenBMB/ChatDev"
      ],
      "metadata": {
        "id": "PDvXCooLMtst"
      },
      "id": "PDvXCooLMtst"
    },
    {
      "cell_type": "markdown",
      "source": [
        "![enter image description here](https://i.stack.imgur.com/nORyw.jpg)"
      ],
      "metadata": {
        "id": "GBrp6O0KM42b"
      },
      "id": "GBrp6O0KM42b"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "  # Mount Google Drive\n",
        "if not os.path.isdir('/content/drive'):\n",
        "   # If not, mount the drive\n",
        "     drive.mount('/content/drive')\n",
        "else:\n",
        "     print(\"Drive is already mounted.\")\n",
        "\n",
        "dst = '/content/drive/MyDrive/ChatGPT_Paper_wrting/ChatDev_projec'\n",
        "if not os.path.exists(dst):\n",
        "   os.makedirs(dst)\n",
        "\n",
        "os.chdir(dst)\n",
        "print ( 'current directory is :', os. getcwd())"
      ],
      "metadata": {
        "id": "LypJ6L9RwaM2",
        "outputId": "4d281797-fcbd-407f-832e-199ba680c03e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LypJ6L9RwaM2",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive is already mounted.\n",
            "current directory is : /content/drive/MyDrive/ChatGPT_Paper_wrting/ChatDev_projec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/OpenBMB/ChatDev.git"
      ],
      "metadata": {
        "id": "vJYsSBgtMt6-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6230b4c4-66d1-4802-adeb-d5016966dbdd"
      },
      "id": "vJYsSBgtMt6-",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ChatDev' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install conda"
      ],
      "metadata": {
        "id": "2v7dsRxSNjKQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6dda362-d4ab-4900-818d-009084b82ac1"
      },
      "id": "2v7dsRxSNjKQ",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package conda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda create -n ChatDev_conda_env python=3.9 -y\n",
        "!conda activate ChatDev_conda_env"
      ],
      "metadata": {
        "id": "IDhB_ZN7NdoM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b087d5c9-12b6-4d98-81d4-de63958b6e7d"
      },
      "id": "IDhB_ZN7NdoM",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: conda: command not found\n",
            "/bin/bash: line 1: conda: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ChatDev\n",
        "!pip3 install -r requirements.txt"
      ],
      "metadata": {
        "id": "LLd6MBw7NsaT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdc3034d-3941-4f5e-cebb-59adb75e7e4a"
      },
      "id": "LLd6MBw7NsaT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ChatGPT_Paper_wrting/ChatDev_projec/ChatDev\n",
            "Requirement already satisfied: colorama==0.4.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.4.6)\n",
            "Collecting Flask==2.3.2 (from -r requirements.txt (line 2))\n",
            "  Using cached Flask-2.3.2-py3-none-any.whl (96 kB)\n",
            "Collecting Flask-SocketIO==5.3.4 (from -r requirements.txt (line 3))\n",
            "  Using cached Flask_SocketIO-5.3.4-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-metadata==6.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (6.8.0)\n",
            "Requirement already satisfied: numpy==1.24.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.24.3)\n",
            "Collecting openai==0.27.8 (from -r requirements.txt (line 6))\n",
            "  Using cached openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "Requirement already satisfied: regex==2023.6.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (2023.6.3)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.31.0)\n",
            "Requirement already satisfied: tenacity==8.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (8.2.2)\n",
            "Collecting tiktoken==0.4.0 (from -r requirements.txt (line 10))\n",
            "  Using cached tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "Collecting virtualenv==20.23.0 (from -r requirements.txt (line 11))\n",
            "  Using cached virtualenv-20.23.0-py3-none-any.whl (3.3 MB)\n",
            "Requirement already satisfied: Werkzeug==2.3.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.3.6)\n",
            "Requirement already satisfied: Markdown==3.4.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (3.4.4)\n",
            "Requirement already satisfied: Pillow==10.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (10.1.0)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask==2.3.2->-r requirements.txt (line 2)) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask==2.3.2->-r requirements.txt (line 2)) (2.1.2)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask==2.3.2->-r requirements.txt (line 2)) (8.1.7)\n",
            "Collecting blinker>=1.6.2 (from Flask==2.3.2->-r requirements.txt (line 2))\n",
            "  Using cached blinker-1.7.0-py3-none-any.whl (13 kB)\n",
            "Collecting python-socketio>=5.0.2 (from Flask-SocketIO==5.3.4->-r requirements.txt (line 3))\n",
            "  Using cached python_socketio-5.10.0-py3-none-any.whl (74 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata==6.8.0->-r requirements.txt (line 4)) (3.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8->-r requirements.txt (line 6)) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8->-r requirements.txt (line 6)) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->-r requirements.txt (line 8)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->-r requirements.txt (line 8)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->-r requirements.txt (line 8)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->-r requirements.txt (line 8)) (2023.11.17)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from virtualenv==20.23.0->-r requirements.txt (line 11)) (0.3.8)\n",
            "Requirement already satisfied: filelock<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from virtualenv==20.23.0->-r requirements.txt (line 11)) (3.13.1)\n",
            "Requirement already satisfied: platformdirs<4,>=3.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv==20.23.0->-r requirements.txt (line 11)) (3.11.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from Werkzeug==2.3.6->-r requirements.txt (line 12)) (2.1.3)\n",
            "Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from python-socketio>=5.0.2->Flask-SocketIO==5.3.4->-r requirements.txt (line 3)) (0.22.1)\n",
            "Collecting python-engineio>=4.8.0 (from python-socketio>=5.0.2->Flask-SocketIO==5.3.4->-r requirements.txt (line 3))\n",
            "  Using cached python_engineio-4.8.0-py3-none-any.whl (56 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 6)) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 6)) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 6)) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 6)) (4.0.3)\n",
            "Collecting simple-websocket>=0.10.0 (from python-engineio>=4.8.0->python-socketio>=5.0.2->Flask-SocketIO==5.3.4->-r requirements.txt (line 3))\n",
            "  Using cached simple_websocket-1.0.0-py3-none-any.whl (13 kB)\n",
            "Collecting wsproto (from simple-websocket>=0.10.0->python-engineio>=4.8.0->python-socketio>=5.0.2->Flask-SocketIO==5.3.4->-r requirements.txt (line 3))\n",
            "  Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto->simple-websocket>=0.10.0->python-engineio>=4.8.0->python-socketio>=5.0.2->Flask-SocketIO==5.3.4->-r requirements.txt (line 3)) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install openai==0.28 tiktoken tenacity"
      ],
      "metadata": {
        "id": "3JKXhs5GP3G9"
      },
      "id": "3JKXhs5GP3G9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # @title (Please insert your request to be done by this code at below form:ðŸ‘‡ðŸ‘‡)\n",
        "Topic = \"Enhancing Iran's Cognitive Immune System Against Dark Triad Forces: A Study by Nathanael Hadson and Brainstorming Iranian Light Triad Forces\" # @param {type:\"string\"}\n",
        "PARAGRAPH = \"# Using ChatGPT for a Project on Enhancing Iran's Cognitive Immune System Against Dark Triad Forces  In this post, we will explore how to use the ChatGPT model to assist in creating a project aimed at enhancing Iran's cognitive immune system against Dark Triad forces. The project will focus on the study by Nathanael Hadson, which suggests that certain activities can reduce the traits of the Dark Triad over a period of four months.  ## The Dark Triad Traits  The Dark Triad traits are deeply ingrained in the psyche and highly resistant to change. These traits are associated with manipulative, exploitative behaviors, and a lack of empathy. People with these traits are often seen as dangerous due to their tendency to exploit others and their disregard for the well-being of others.  ## The Study by Nathanael Hadson  In a study conducted by Nathanael Hadson, a psychologist at SMU, it was found that certain activities can reduce the traits of the Dark Triad over a period of four months. The study found that tasks designed to make someone more agreeable also effectively reduced a trio of negative personality traits known as the \\\"Dark Triad\\\" -- Machiavellianism, narcissism, and psychopathy.  ## The Activities to Reduce Dark Triad Traits  Specifically, practicing activities like \\\"donating money to a charity that you would normally spend on yourself\\\" or \\\"talking to a stranger and asking them about themselves\\\" decreased all three Dark Triad traits. This was the case even for people who said they wanted to increase their dark traits, not diminish them.  ## Using ChatGPT for the Project  ChatGPT can be a valuable tool in creating this project. It can assist in brainstorming ideas, generating code snippets, and providing guidance on best practices. Here are a few prompts that could be used with ChatGPT:  1. \\\"Can you suggest ways to implement the activities suggested by the study by Nathanael Hadson in a digital platform?\\\" 2. \\\"Can you provide a code snippet for a feature that encourages users to donate to charities?\\\" 3. \\\"Can you suggest a way to encourage users to engage in meaningful conversations with others?\\\" 4. \\\"Can you provide a code snippet for a feature that promotes kindness and empathy?\\\" 5. \\\"Can you suggest a way to foster diversity and inclusion on the platform?\\\"  Remember, ChatGPT is a tool to assist in the development process, and the code suggestions it provides may need to be refined and tested. Always corroborate its explanations against other resources and use its code examples for learning, not plagiarizing solutions [Source 4](https://dev.to/evergrowingdev/how-to-use-chatgpt-for-learning-to-code-with-examples-39e7).  ## Conclusion  While the Dark Triad traits are deeply ingrained and resistant to change, the study by Nathanael Hadson suggests that certain activities can help reduce these traits over time. In the context of Iran, these findings could be particularly relevant and could potentially contribute to the development of a cognitive immune system against the forces of the Dark Triad. ChatGPT can be a powerful tool in this journey, assisting in the creation of a project that promotes empathy, kindness, and cooperation.\" # @param {type:\"string\"}\n",
        "role = \"startup Entrepreneur\"# @param {type:\"string\"}\n",
        "\n",
        "\n",
        "Your_Email = \"hh@gmail.com\" # @param {type:\"string\"}\n",
        "\n",
        "openai_api = \"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\" # @param {type:\"string\"}\n",
        "\n",
        "#PARAGRAPH = '\n",
        "#!export OPENAI_API_KEY = openai_api\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = openai_api #'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'"
      ],
      "metadata": {
        "id": "6dGOPiCyOzRx"
      },
      "id": "6dGOPiCyOzRx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface\n",
        "!sudo apt install git-lfs\n",
        "!git lfs install"
      ],
      "metadata": {
        "id": "-AecMpQ5lKP4"
      },
      "id": "-AecMpQ5lKP4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!huggingface-cli login --token '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'\n",
        "\n",
        "!git remote add space https://huggingface.co/spaces/your_HF_USERNAME/your_SPACE_NAME\n",
        "!git push --force space main"
      ],
      "metadata": {
        "id": "rwbieSlIlCLt"
      },
      "id": "rwbieSlIlCLt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "https://www.phind.com/search?cache=esnrf1bblvwbp4q4sp3drbs6\n",
        "\n",
        "Based on your project description and the search results, it seems like you want to generate a PowerPoint presentation from the results of your simulation using the ChatDev software.\n",
        "\n",
        "According to the ChatDev documentation, you can specify the product modality as PowerPoint in the task description. You can do this by adding `<INFO> PowerPoint` at the end of your task description.\n",
        "\n",
        "Here's how you can update the command:\n",
        "\n",
        "```bash\n",
        "python3 run.py --task \"Use game theory to understand how different personality types (Dark Triad, Dark Tetrad, Dark Empathy) might interact within a society <INFO> PowerPoint\" --name \"PersonalityInteractions\"\n",
        "```\n",
        "\n",
        "This command will initiate the building of your software with the task description being the application of game theory to understand the interactions of different personality types and the final product modality being PowerPoint. The project name is \"PersonalityInteractions\".\n",
        "\n",
        "Remember to replace `\"PersonalityInteractions\"` with your desired project name. Also, you need to make sure that you have defined the roles and behaviors of the personality types in your project configuration.\n",
        "\n",
        "This command will create a corresponding folder in the WareHouse directory, which will contain all the files and documents related to the software, configuration files of the company responsible for this software, a comprehensive log detailing the software's building process, and the initial prompt used to create this software [Source 1](https://github.com/OpenBMB/ChatDev).\n",
        "\n",
        "After the software is built and run, you should be able to find a PowerPoint file in the WareHouse directory under the specific project folder, such as `project_name_DefaultOrganization_timestamp`. This PowerPoint file will contain the results of your simulation [Source 1](https://github.com/OpenBMB/ChatDev)."
      ],
      "metadata": {
        "id": "D3OrVwWOvOf7"
      },
      "id": "D3OrVwWOvOf7"
    },
    {
      "cell_type": "code",
      "source": [
        "#!python3 run.py --task \"[description_of_your_idea]\" --name \"[project_name]\"\n",
        "\n",
        "#!python3 run.py --task \"theory to understand how different personality types (Dark Triad, Dark Tetrad, Dark Empathy) might interact within a society <INFO> PowerPoint\" --name \"PersonalityInteractions\""
      ],
      "metadata": {
        "id": "fvanVNknPQAP"
      },
      "id": "fvanVNknPQAP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ChatDev\n",
        "#TOPIC = 'business plan chatgpt'\n",
        "#PARAGRAPH= 'creat one Openai ChatGP pyhton program as webpage which be run in Huggingface  space by docker file and recive the openai API and the the two topic and description variable and then act like AutoGPT  but  for writing the Business Plan report with around 10 prompt and then results must be saved as standard business plan with title , subtitle and numbering the results of the 10 prompt, so the official form of final repost is important and it must be in the form of pdf and doc saved and the Huggingface face mist have one email form to send this pdf and doc file to the given email of user'\n",
        "!python3 run.py --task f'{PARAGRAPH}' --name f'{TOPIC}'"
      ],
      "metadata": {
        "id": "OPdqUwuWjNv0"
      },
      "id": "OPdqUwuWjNv0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dst = '/content/drive/MyDrive/ChatGPT_Paper_wrting/ChatDev'\n",
        "if not os.path.exists(dst):\n",
        "   os.makedirs(dst)\n",
        "!cp -r '{src}' '{dst}'\n",
        "\n",
        "#src = '/content/ChatDev/ChatDev/WareHouse/PersonalityInteractions_DefaultOrganization_20231212111412'\n",
        "\n",
        "import shutil\n",
        "#shutil.copytree(src, dst)"
      ],
      "metadata": {
        "id": "lrjMzdKmyzIB"
      },
      "id": "lrjMzdKmyzIB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "src = '/content/ChatDev/WareHouse/'\n",
        "\n",
        "scr2 = f'{src}'+'/chatdev2huggingface_DefaultOrganization_20231212154538'\n",
        "%cd '{scr2}'\n",
        "!pwd\n",
        "!ls\n",
        "\n",
        "!python3 -m venv env\n",
        "!source env/bin/activate\n",
        "!pip3 install -r requirements.txt\n",
        "!python3 '{scr2}/'main.py"
      ],
      "metadata": {
        "id": "Gccm9EZGUgKj"
      },
      "id": "Gccm9EZGUgKj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pwd\n",
        "!python3 '{scr2}/'main.py"
      ],
      "metadata": {
        "id": "fnLQ15g-wluo"
      },
      "id": "fnLQ15g-wluo",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}