{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/So-AI-love/chatgpt-prompts-for-academic-writing/blob/main/NoteBook/ChatDev_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Communicative Agents for Software Development\n",
        "\n",
        "https://github.com/OpenBMB/ChatDev"
      ],
      "metadata": {
        "id": "PDvXCooLMtst"
      },
      "id": "PDvXCooLMtst"
    },
    {
      "cell_type": "markdown",
      "source": [
        "![enter image description here](https://i.stack.imgur.com/nORyw.jpg)"
      ],
      "metadata": {
        "id": "GBrp6O0KM42b"
      },
      "id": "GBrp6O0KM42b"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "  # Mount Google Drive\n",
        "if not os.path.isdir('/content/drive'):\n",
        "   # If not, mount the drive\n",
        "     drive.mount('/content/drive')\n",
        "else:\n",
        "     print(\"Drive is already mounted.\")\n",
        "\n",
        "dst = '/content/drive/MyDrive/ChatGPT_Paper_wrting/ChatDev_projec'\n",
        "if not os.path.exists(dst):\n",
        "   os.makedirs(dst)\n",
        "\n",
        "os.chdir(dst)\n",
        "print ( 'current directory is :', os. getcwd())"
      ],
      "metadata": {
        "id": "LypJ6L9RwaM2",
        "outputId": "996333db-7c19-488c-e47b-0aa1c7a2cc5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LypJ6L9RwaM2",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive is already mounted.\n",
            "current directory is : /content/drive/MyDrive/ChatGPT_Paper_wrting/ChatDev_projec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/OpenBMB/ChatDev.git"
      ],
      "metadata": {
        "id": "vJYsSBgtMt6-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaaaf4bb-5a6b-45b3-db61-5080d1edc838"
      },
      "id": "vJYsSBgtMt6-",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ChatDev' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install conda"
      ],
      "metadata": {
        "id": "2v7dsRxSNjKQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a56a3df-c3a7-41e6-eb22-3e40aa2d3a6f"
      },
      "id": "2v7dsRxSNjKQ",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package conda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda create -n ChatDev_conda_env python=3.9 -y\n",
        "!conda activate ChatDev_conda_env"
      ],
      "metadata": {
        "id": "IDhB_ZN7NdoM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c54fab0-9708-49ca-859c-29e639a71239"
      },
      "id": "IDhB_ZN7NdoM",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: conda: command not found\n",
            "/bin/bash: line 1: conda: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ChatDev\n",
        "!pip3 install -r requirements.txt"
      ],
      "metadata": {
        "id": "LLd6MBw7NsaT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58b6dbd9-870f-4f77-f362-d4578c3a363a"
      },
      "id": "LLd6MBw7NsaT",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ChatGPT_Paper_wrting/ChatDev_projec/ChatDev\n",
            "Requirement already satisfied: colorama==0.4.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.4.6)\n",
            "Collecting Flask==2.3.2 (from -r requirements.txt (line 2))\n",
            "  Using cached Flask-2.3.2-py3-none-any.whl (96 kB)\n",
            "Collecting Flask-SocketIO==5.3.4 (from -r requirements.txt (line 3))\n",
            "  Using cached Flask_SocketIO-5.3.4-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-metadata==6.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (6.8.0)\n",
            "Requirement already satisfied: numpy==1.24.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.24.3)\n",
            "Collecting openai==0.27.8 (from -r requirements.txt (line 6))\n",
            "  Using cached openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "Requirement already satisfied: regex==2023.6.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (2023.6.3)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.31.0)\n",
            "Requirement already satisfied: tenacity==8.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (8.2.2)\n",
            "Collecting tiktoken==0.4.0 (from -r requirements.txt (line 10))\n",
            "  Using cached tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "Collecting virtualenv==20.23.0 (from -r requirements.txt (line 11))\n",
            "  Using cached virtualenv-20.23.0-py3-none-any.whl (3.3 MB)\n",
            "Requirement already satisfied: Werkzeug==2.3.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.3.6)\n",
            "Requirement already satisfied: Markdown==3.4.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (3.4.4)\n",
            "Requirement already satisfied: Pillow==10.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (10.1.0)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask==2.3.2->-r requirements.txt (line 2)) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask==2.3.2->-r requirements.txt (line 2)) (2.1.2)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask==2.3.2->-r requirements.txt (line 2)) (8.1.7)\n",
            "Collecting blinker>=1.6.2 (from Flask==2.3.2->-r requirements.txt (line 2))\n",
            "  Using cached blinker-1.7.0-py3-none-any.whl (13 kB)\n",
            "Collecting python-socketio>=5.0.2 (from Flask-SocketIO==5.3.4->-r requirements.txt (line 3))\n",
            "  Using cached python_socketio-5.10.0-py3-none-any.whl (74 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata==6.8.0->-r requirements.txt (line 4)) (3.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8->-r requirements.txt (line 6)) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8->-r requirements.txt (line 6)) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->-r requirements.txt (line 8)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->-r requirements.txt (line 8)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->-r requirements.txt (line 8)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->-r requirements.txt (line 8)) (2023.11.17)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from virtualenv==20.23.0->-r requirements.txt (line 11)) (0.3.8)\n",
            "Requirement already satisfied: filelock<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from virtualenv==20.23.0->-r requirements.txt (line 11)) (3.13.1)\n",
            "Requirement already satisfied: platformdirs<4,>=3.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv==20.23.0->-r requirements.txt (line 11)) (3.11.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from Werkzeug==2.3.6->-r requirements.txt (line 12)) (2.1.3)\n",
            "Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from python-socketio>=5.0.2->Flask-SocketIO==5.3.4->-r requirements.txt (line 3)) (0.22.1)\n",
            "Collecting python-engineio>=4.8.0 (from python-socketio>=5.0.2->Flask-SocketIO==5.3.4->-r requirements.txt (line 3))\n",
            "  Using cached python_engineio-4.8.0-py3-none-any.whl (56 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 6)) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 6)) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 6)) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8->-r requirements.txt (line 6)) (4.0.3)\n",
            "Collecting simple-websocket>=0.10.0 (from python-engineio>=4.8.0->python-socketio>=5.0.2->Flask-SocketIO==5.3.4->-r requirements.txt (line 3))\n",
            "  Using cached simple_websocket-1.0.0-py3-none-any.whl (13 kB)\n",
            "Collecting wsproto (from simple-websocket>=0.10.0->python-engineio>=4.8.0->python-socketio>=5.0.2->Flask-SocketIO==5.3.4->-r requirements.txt (line 3))\n",
            "  Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto->simple-websocket>=0.10.0->python-engineio>=4.8.0->python-socketio>=5.0.2->Flask-SocketIO==5.3.4->-r requirements.txt (line 3)) (0.14.0)\n",
            "Installing collected packages: wsproto, virtualenv, blinker, tiktoken, simple-websocket, Flask, python-engineio, openai, python-socketio, Flask-SocketIO\n",
            "  Attempting uninstall: blinker\n",
            "    Found existing installation: blinker 1.4\n",
            "\u001b[31mERROR: Cannot uninstall 'blinker'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install openai==0.28 tiktoken tenacity"
      ],
      "metadata": {
        "id": "3JKXhs5GP3G9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c312816-4ba2-4403-d688-72efe5e5f000"
      },
      "id": "3JKXhs5GP3G9",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (8.2.2)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # @title (Please insert your request to be done by this code at below form:👇👇)\n",
        "Topic = \"PersonalityInteractions\" # @param {type:\"string\"}\n",
        "PARAGRAPH = \"Use game theory to understand how different personality types (Dark Triad, Dark Tetrad, Dark Empathy) might interact within a society \\u003CINFO> PowerPoint\" # @param {type:\"string\"}\n",
        "role = \"startup Entrepreneur\"# @param {type:\"string\"}\n",
        "\n",
        "\n",
        "Your_Email = \"hh@gmail.com\" # @param {type:\"string\"}\n",
        "\n",
        "openai_api = \"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\" # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "#!export OPENAI_API_KEY = openai_api\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = openai_api #'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'"
      ],
      "metadata": {
        "id": "6dGOPiCyOzRx"
      },
      "id": "6dGOPiCyOzRx",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface\n",
        "!sudo apt install git-lfs\n",
        "!git lfs install"
      ],
      "metadata": {
        "id": "-AecMpQ5lKP4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04eae198-3bf3-46df-bd1d-0fcb8cd9c6ec"
      },
      "id": "-AecMpQ5lKP4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting huggingface\n",
            "  Downloading huggingface-0.0.1-py3-none-any.whl (2.5 kB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!huggingface-cli login --token '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'\n",
        "\n",
        "!git remote add space https://huggingface.co/spaces/your_HF_USERNAME/your_SPACE_NAME\n",
        "!git push --force space main"
      ],
      "metadata": {
        "id": "rwbieSlIlCLt"
      },
      "id": "rwbieSlIlCLt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "https://www.phind.com/search?cache=esnrf1bblvwbp4q4sp3drbs6\n",
        "\n",
        "Based on your project description and the search results, it seems like you want to generate a PowerPoint presentation from the results of your simulation using the ChatDev software.\n",
        "\n",
        "According to the ChatDev documentation, you can specify the product modality as PowerPoint in the task description. You can do this by adding `<INFO> PowerPoint` at the end of your task description.\n",
        "\n",
        "Here's how you can update the command:\n",
        "\n",
        "```bash\n",
        "python3 run.py --task \"Use game theory to understand how different personality types (Dark Triad, Dark Tetrad, Dark Empathy) might interact within a society <INFO> PowerPoint\" --name \"PersonalityInteractions\"\n",
        "```\n",
        "\n",
        "This command will initiate the building of your software with the task description being the application of game theory to understand the interactions of different personality types and the final product modality being PowerPoint. The project name is \"PersonalityInteractions\".\n",
        "\n",
        "Remember to replace `\"PersonalityInteractions\"` with your desired project name. Also, you need to make sure that you have defined the roles and behaviors of the personality types in your project configuration.\n",
        "\n",
        "This command will create a corresponding folder in the WareHouse directory, which will contain all the files and documents related to the software, configuration files of the company responsible for this software, a comprehensive log detailing the software's building process, and the initial prompt used to create this software [Source 1](https://github.com/OpenBMB/ChatDev).\n",
        "\n",
        "After the software is built and run, you should be able to find a PowerPoint file in the WareHouse directory under the specific project folder, such as `project_name_DefaultOrganization_timestamp`. This PowerPoint file will contain the results of your simulation [Source 1](https://github.com/OpenBMB/ChatDev)."
      ],
      "metadata": {
        "id": "D3OrVwWOvOf7"
      },
      "id": "D3OrVwWOvOf7"
    },
    {
      "cell_type": "code",
      "source": [
        "#!python3 run.py --task \"[description_of_your_idea]\" --name \"[project_name]\"\n",
        "\n",
        "#!python3 run.py --task \"theory to understand how different personality types (Dark Triad, Dark Tetrad, Dark Empathy) might interact within a society <INFO> PowerPoint\" --name \"PersonalityInteractions\""
      ],
      "metadata": {
        "id": "fvanVNknPQAP"
      },
      "id": "fvanVNknPQAP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ChatDev\n",
        "TOPIC = 'business plan chatgpt'\n",
        "#PARAGRAPH= 'creat one Openai ChatGP pyhton program as webpage which be run in Huggingface  space by docker file and recive the openai API and the the two topic and description variable and then act like AutoGPT  but  for writing the Business Plan report with around 10 prompt and then results must be saved as standard business plan with title , subtitle and numbering the results of the 10 prompt, so the official form of final repost is important and it must be in the form of pdf and doc saved and the Huggingface face mist have one email form to send this pdf and doc file to the given email of user'\n",
        "PARAGRAPH= '''\n",
        "IF possible update this code :(\" import os\n",
        "from dotenv import load_dotenv\n",
        "from docx import Document\n",
        "import pdfkit\n",
        "import openai\n",
        "from retry import retry\n",
        "\n",
        "class ChatGP:\n",
        "    def __init__(self):\n",
        "        load_dotenv()\n",
        "        self.api_key = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "    def update_prompt(self, prompt, main_variables):\n",
        "        # Replace variables in the prompt with corresponding values from main_variables\n",
        "        for variable, value in main_variables.items():\n",
        "            prompt = prompt.replace(f\"{{{variable}}}\", value)\n",
        "        return prompt\n",
        "\n",
        "    def generate_business_plan(self, topic, description, main_variables_0):\n",
        "        prompts = {\n",
        "            \"business_plan\": [\n",
        "                \"1. Executive Summary:\\nProvide a brief overview of the business.\",\n",
        "                \"2. Company Description:\\nDescribe the company, its history, and its mission.\",\n",
        "                \"3. Market Analysis:\\nAnalyze the target market and the competition.\",\n",
        "                \"4. Organization and Management:\\nDescribe the company's structure and key personnel.\",\n",
        "                \"5. Product or Service Line:\\nDetail the products or services offered by the company.\",\n",
        "                \"6. Marketing and Sales Strategy:\\nExplain the marketing and sales strategies of the company.\",\n",
        "                \"7. Funding Request:\\nProvide details about the funding request, including the amount and use of funds.\",\n",
        "                \"8. Financial Projections:\\nProvide financial projections for the company.\",\n",
        "                \"9. Appendix:\\nInclude any additional information or documents that support the business plan.\",\n",
        "                \"10. Conclusion:\\nSummarize the key points of the business plan.\"\n",
        "            ],\n",
        "            \"problem_solving\": [\n",
        "                f\"What are the key aspects of {main_variables_0['TOPIC']} that need to be addressed?\",\n",
        "                f\"Create a mind map of the main elements of {main_variables_0['TOPIC']} and how they are interconnected.\",\n",
        "                f\"Write down ideas on sticky notes about how to improve {main_variables_0['TOPIC']}. Then, group these ideas based on common themes.\",\n",
        "                f\"Take turns sharing ideas on how to improve {main_variables_0['TOPIC']}. Make sure everyone has a chance to contribute.\",\n",
        "                f\"Think of ways to create the problem in {main_variables_0['TOPIC']}. This will help you understand how to solve it.\",\n",
        "                f\"Apply the SCAMPER method to existing solutions or situations in {main_variables_0['TOPIC']}. This will spark new ideas.\",\n",
        "                f\"Assemble a diverse group of people from various backgrounds and disciplines to tackle {main_variables_0['TOPIC']}. This will ensure a more rounded and innovative solution.\",\n",
        "                f\"Envision a future state where {main_variables_0['TOPIC']} has been solved successfully. Starting from this endpoint, work backward to identify the series of events and decisions that led to that future.\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        results = {}\n",
        "        for category, category_prompts in prompts.items():\n",
        "            for prompt in category_prompts:\n",
        "                # Update the prompt with variables\n",
        "                updated_prompt = self.update_prompt(prompt, main_variables_0)\n",
        "\n",
        "                if category == \"business_plan\":\n",
        "                    response = self.generate_response(updated_prompt, topic, description)\n",
        "                elif category == \"problem_solving\":\n",
        "                    response = self.generate_response(updated_prompt, main_variables_0['TOPIC'], description)\n",
        "                results[updated_prompt] = response\n",
        "\n",
        "        self.save_business_plan(results)\n",
        "        return results\n",
        "\n",
        "    @retry\n",
        "    def generate_response(self, prompt, topic, description):\n",
        "        openai.api_key = self.api_key\n",
        "        response = openai.Completion.create(\n",
        "            engine='text-davinci-003',\n",
        "            prompt=f\"{prompt} {topic} {description}\",\n",
        "            max_tokens=2048,\n",
        "            top_p=1.0,\n",
        "            frequency_penalty=0.0,\n",
        "            presence_penalty=0.0\n",
        "        )\n",
        "        return response.choices[0].text.strip()\n",
        "\n",
        "    def save_business_plan(self, results):\n",
        "        dir = os.getcwd()\n",
        "\n",
        "        for prompt, content in results.items():\n",
        "            repo_name = prompt.split(\":\")[0].strip()\n",
        "            file_name = f\"{dir}/{repo_name.replace(' ', '_').lower()}_business_plan.docx\"\n",
        "\n",
        "            doc = Document()\n",
        "            doc.add_heading(prompt, level=1)\n",
        "            doc.add_paragraph(content)\n",
        "            doc.save(file_name)\n",
        "\n",
        "            pdf_file_name = file_name.replace('.docx', '.pdf')\n",
        "            pdfkit.from_file(file_name, pdf_file_name)\n",
        "\n",
        "# Example usage:\n",
        "TOPIC = \"{TOPIC}\"\n",
        "RESEARCH_DOMAIN = \"{RESEARCH_DOMAIN}\"\n",
        "# ... (other variables)\n",
        "\n",
        "main_variables_0 = {\n",
        "    'TOPIC': TOPIC,\n",
        "    'RESEARCH_DOMAIN': RESEARCH_DOMAIN,\n",
        "    # ... (other variables)\n",
        "}\n",
        "\n",
        "chat_gp = ChatGP()\n",
        "results = chat_gp.generate_business_plan(\"business_plan\", \"Topic\", \"Description\", main_variables_0) \"\n",
        "\n",
        "busing the langchain python module ( https://python.langchain.com/docs/get_started/introduction ) and for this action :( please use the langchain pyhton module as webpage which be run in Huggingface space by some of its option  like pdf or docx saving and emailing file and recive the openai API and the the two topic and description variable and then act like AutoGPT  but  for writing the Business Plan report with around 10 prompt and then results must be saved as standard business plan with title , subtitle and numbering the results of the 10 prompt, so the official form of final repost is important and it must be in the form of pdf and doc saved and the Huggingface face mist have one email form to send this pdf and doc file to the given email of user\n",
        "'''\n",
        "\n",
        "!python3 run.py --task '{PARAGRAPH}' --name '{TOPIC}'"
      ],
      "metadata": {
        "id": "OPdqUwuWjNv0"
      },
      "id": "OPdqUwuWjNv0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "src = '/content/ChatDev/WareHouse/'\n",
        "\n",
        "scr2 = f'{src}'+'/chatdev2huggingface_DefaultOrganization_20231212154538'\n",
        "%cd '{scr2}'\n",
        "!pwd\n",
        "!ls\n",
        "\n",
        "!python3 -m venv env\n",
        "!source env/bin/activate\n",
        "!pip3 install -r requirements.txt\n",
        "!python3 '{scr2}/'main.py"
      ],
      "metadata": {
        "id": "Gccm9EZGUgKj"
      },
      "id": "Gccm9EZGUgKj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pwd\n",
        "!python3 '{scr2}/'main.py"
      ],
      "metadata": {
        "id": "fnLQ15g-wluo"
      },
      "id": "fnLQ15g-wluo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dst = '/content/drive/MyDrive/ChatGPT_Paper_wrting/ChatDev'\n",
        "if not os.path.exists(dst):\n",
        "   os.makedirs(dst)\n",
        "!cp -r '{src}' '{dst}'\n",
        "\n",
        "#src = '/content/ChatDev/ChatDev/WareHouse/PersonalityInteractions_DefaultOrganization_20231212111412'\n",
        "\n",
        "import shutil\n",
        "#shutil.copytree(src, dst)"
      ],
      "metadata": {
        "id": "lrjMzdKmyzIB"
      },
      "id": "lrjMzdKmyzIB",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}