{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/So-AI-love/chatgpt-prompts-for-academic-writing/blob/main/diffusers_doc/en/quicktour.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De-XfrCPbuPM"
      },
      "source": [
        "# Quicktour"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOmeMkzQbuPg"
      },
      "source": [
        "Diffusion models are trained to denoise random Gaussian noise step-by-step to generate a sample of interest, such as an image or audio. This has sparked a tremendous amount of interest in generative AI, and you have probably seen examples of diffusion generated images on the internet. ðŸ§¨ Diffusers is a library aimed at making diffusion models widely accessible to everyone.\n",
        "\n",
        "Whether you're a developer or an everyday user, this quicktour will introduce you to ðŸ§¨ Diffusers and help you get up and generating quickly! There are three main components of the library to know about:\n",
        "\n",
        "* The [DiffusionPipeline](https://huggingface.co/docs/diffusers/main/en/api/pipelines/overview#diffusers.DiffusionPipeline) is a high-level end-to-end class designed to rapidly generate samples from pretrained diffusion models for inference.\n",
        "* Popular pretrained [model](https://huggingface.co/docs/diffusers/main/en/./api/models) architectures and modules that can be used as building blocks for creating diffusion systems.\n",
        "* Many different [schedulers](https://huggingface.co/docs/diffusers/main/en/./api/schedulers/overview) - algorithms that control how noise is added for training, and how to generate denoised images during inference.\n",
        "\n",
        "The quicktour will show you how to use the [DiffusionPipeline](https://huggingface.co/docs/diffusers/main/en/api/pipelines/overview#diffusers.DiffusionPipeline) for inference, and then walk you through how to combine a model and scheduler to replicate what's happening inside the [DiffusionPipeline](https://huggingface.co/docs/diffusers/main/en/api/pipelines/overview#diffusers.DiffusionPipeline).\n",
        "\n",
        "<Tip>\n",
        "\n",
        "The quicktour is a simplified version of the introductory ðŸ§¨ Diffusers [notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb) to help you get started quickly. If you want to learn more about ðŸ§¨ Diffusers goal, design philosophy, and additional details about it's core API, check out the notebook!\n",
        "\n",
        "</Tip>\n",
        "\n",
        "Before you begin, make sure you have all the necessary libraries installed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CLLdbMmAbuPq"
      },
      "outputs": [],
      "source": [
        "# uncomment to install the necessary libraries in Colab\n",
        "#!pip install --upgrade diffusers accelerate transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_6BMk0sbuP1"
      },
      "source": [
        "- [ðŸ¤— Accelerate](https://huggingface.co/docs/accelerate/index) speeds up model loading for inference and training.\n",
        "- [ðŸ¤— Transformers](https://huggingface.co/docs/transformers/index) is required to run the most popular diffusion models, such as [Stable Diffusion](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/overview)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GJx4tqUbuP5"
      },
      "source": [
        "## DiffusionPipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_QH5E9BbuP8"
      },
      "source": [
        "The [DiffusionPipeline](https://huggingface.co/docs/diffusers/main/en/api/pipelines/overview#diffusers.DiffusionPipeline) is the easiest way to use a pretrained diffusion system for inference. It is an end-to-end system containing the model and the scheduler. You can use the [DiffusionPipeline](https://huggingface.co/docs/diffusers/main/en/api/pipelines/overview#diffusers.DiffusionPipeline) out-of-the-box for many tasks. Take a look at the table below for some supported tasks, and for a complete list of supported tasks, check out the [ðŸ§¨ Diffusers Summary](https://huggingface.co/docs/diffusers/main/en/./api/pipelines/overview#diffusers-summary) table.\n",
        "\n",
        "| **Task**                     | **Description**                                                                                              | **Pipeline**\n",
        "|------------------------------|--------------------------------------------------------------------------------------------------------------|-----------------|\n",
        "| Unconditional Image Generation          | generate an image from Gaussian noise | [unconditional_image_generation](https://huggingface.co/docs/diffusers/main/en/./using-diffusers/unconditional_image_generation) |\n",
        "| Text-Guided Image Generation | generate an image given a text prompt | [conditional_image_generation](https://huggingface.co/docs/diffusers/main/en/./using-diffusers/conditional_image_generation) |\n",
        "| Text-Guided Image-to-Image Translation     | adapt an image guided by a text prompt | [img2img](https://huggingface.co/docs/diffusers/main/en/./using-diffusers/img2img) |\n",
        "| Text-Guided Image-Inpainting          | fill the masked part of an image given the image, the mask and a text prompt | [inpaint](https://huggingface.co/docs/diffusers/main/en/./using-diffusers/inpaint) |\n",
        "| Text-Guided Depth-to-Image Translation | adapt parts of an image guided by a text prompt while preserving structure via depth estimation | [depth2img](https://huggingface.co/docs/diffusers/main/en/./using-diffusers/depth2img) |\n",
        "\n",
        "Start by creating an instance of a [DiffusionPipeline](https://huggingface.co/docs/diffusers/main/en/api/pipelines/overview#diffusers.DiffusionPipeline) and specify which pipeline checkpoint you would like to download.\n",
        "You can use the [DiffusionPipeline](https://huggingface.co/docs/diffusers/main/en/api/pipelines/overview#diffusers.DiffusionPipeline) for any [checkpoint](https://huggingface.co/models?library=diffusers&sort=downloads) stored on the Hugging Face Hub.\n",
        "In this quicktour, you'll load the [`stable-diffusion-v1-5`](https://huggingface.co/runwayml/stable-diffusion-v1-5) checkpoint for text-to-image generation.\n",
        "\n",
        "<Tip warning={true}>\n",
        "\n",
        "For [Stable Diffusion](https://huggingface.co/CompVis/stable-diffusion) models, please carefully read the [license](https://huggingface.co/spaces/CompVis/stable-diffusion-license) first before running the model. ðŸ§¨ Diffusers implements a [`safety_checker`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/safety_checker.py) to prevent offensive or harmful content, but the model's improved image generation capabilities can still produce potentially harmful content.\n",
        "\n",
        "</Tip>\n",
        "\n",
        "Load the model with the [from_pretrained()](https://huggingface.co/docs/diffusers/main/en/api/pipelines/overview#diffusers.DiffusionPipeline.from_pretrained) method:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade diffusers accelerate transformers"
      ],
      "metadata": {
        "id": "6dhuMeElcDqN",
        "outputId": "ac5b6170-d819-44b9-e3ad-16b6f45961fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (0.24.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.25.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.36.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.19.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.23.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->diffusers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->diffusers) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKQyawJrbuQD"
      },
      "outputs": [],
      "source": [
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "pipeline = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtVk7fv4buQJ"
      },
      "source": [
        "The [DiffusionPipeline](https://huggingface.co/docs/diffusers/main/en/api/pipelines/overview#diffusers.DiffusionPipeline) downloads and caches all modeling, tokenization, and scheduling components. You'll see that the Stable Diffusion pipeline is composed of the [UNet2DConditionModel](https://huggingface.co/docs/diffusers/main/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel) and [PNDMScheduler](https://huggingface.co/docs/diffusers/main/en/api/schedulers/pndm#diffusers.PNDMScheduler) among other things:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgGlyADYbuQN"
      },
      "outputs": [],
      "source": [
        "pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xNf2w8abuQW"
      },
      "source": [
        "We strongly recommend running the pipeline on a GPU because the model consists of roughly 1.4 billion parameters.\n",
        "You can move the generator object to a GPU, just like you would in PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-JDFZLTbuQa"
      },
      "outputs": [],
      "source": [
        "pipeline.to(\"cuda\") #\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax0S9H08buQe"
      },
      "source": [
        "Now you can pass a text prompt to the `pipeline` to generate an image, and then access the denoised image. By default, the image output is wrapped in a [`PIL.Image`](https://pillow.readthedocs.io/en/stable/reference/Image.html?highlight=image#the-image-class) object."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Text = \"\"\"\n",
        "Pitch Deck For:\n",
        "\n",
        "Unleashing the Light: Managing the Dark Triad through Dialogue and Charity\n",
        "\n",
        "1. Identify key aspects of startup pitch deck.\n",
        "\n",
        "\n",
        "The key aspects of Dark Triad that need to be addressed in the context of managing it through conversation and charity are:\n",
        "\n",
        "1. Understanding the traits: It is important to have a clear understanding of the three traits that make up the Dark Triad - Machiavellianism, narcissism, and psychopathy. Each of these traits has its own characteristics and can manifest in different ways. Understanding these traits can help in identifying them and managing them effectively.\n",
        "\n",
        "2. Self-awareness: Self-awareness is crucial in managing the Dark Triad. It involves being aware of one's own thoughts, feelings, and behaviors and how they may be influenced by these traits. This can help in recognizing when these traits are being triggered and taking steps to manage them.\n",
        "\n",
        "3. Communication skills: Effective communication is key in managing the Dark Triad. This includes being able to express oneself clearly and assertively, as well as actively listening to others. Good communication skills can help in resolving conflicts and building positive relationships.\n",
        "\n",
        "4. Empathy: Empathy is the ability to understand and share the feelings of others. It can help in managing the Dark Triad by promoting understanding and compassion towards others, rather than manipulating or exploiting them.\n",
        "\n",
        "5. Mindfulness: Practicing mindfulness can help in managing the Dark Triad by increasing self-awareness and promoting a non-judgmental attitude towards oneself and others. It can also help in managing impulsive and destructive behaviors.\n",
        "\n",
        "6. Charity and altruism: Engaging in charitable work and acts of kindness can help in managing the Dark Triad by promoting empathy and compassion towards others. It can also help in shifting the focus from self-centeredness to the well-being of others.\n",
        "\n",
        "7. Seeking professional help: In some cases, managing the Dark Triad may require seeking professional help. A therapist or counselor can provide support and guidance in managing these traits and developing healthier coping mechanisms.\n",
        "\n",
        "In conclusion, managing the Dark Triad through conversation and charity involves a combination of self-awareness, effective communication, empathy, mindfulness, and seeking professional help when needed. It is an ongoing process that requires effort and dedication, but can ultimately lead to healthier and more fulfilling relationships.\n",
        "2. Create a mind map of startup elements.\n",
        "\n",
        "\n",
        "Main Elements of Dark Triad:\n",
        "1. Machiavellianism\n",
        "2. Narcissism\n",
        "3. Psychopathy\n",
        "\n",
        "Management through Conversation and Charity:\n",
        "1. Dialogue and communication\n",
        "2. Empathy and understanding\n",
        "3. Self-reflection and self-awareness\n",
        "4. Giving back to others\n",
        "5. Building positive relationships\n",
        "6. Promoting altruistic behavior\n",
        "7. Encouraging selflessness\n",
        "8. Fostering a sense of community\n",
        "9. Promoting emotional intelligence\n",
        "10. Encouraging self-control and self-regulation\n",
        "\n",
        "Interconnectedness:\n",
        "1. Dialogue and communication can help manage Machiavellianism by promoting honest and open communication, reducing manipulation and deceitful behavior.\n",
        "2. Empathy and understanding can help manage narcissism by promoting a sense of empathy and compassion towards others, reducing self-centeredness and grandiosity.\n",
        "3. Self-reflection and self-awareness can help manage psychopathy by promoting introspection and recognition of one's own actions and their impact on others, reducing impulsive and callous behavior.\n",
        "4. Giving back to others through charity work can help manage all three traits by promoting a sense of altruism and selflessness, reducing selfish and exploitative behavior.\n",
        "5. Building positive relationships can help manage all three traits by promoting healthy and supportive connections, reducing isolation and mistrust.\n",
        "6. Promoting emotional intelligence can help manage all three traits by promoting self-awareness and regulation of emotions, reducing impulsivity and aggression.\n",
        "7. Encouraging self-control and self-regulation can help manage all three traits by promoting self-discipline and restraint, reducing impulsive and destructive behavior.\n",
        "8. Fostering a sense of community can help manage all three traits by promoting a sense of belonging and connection, reducing feelings of alienation and detachment.\n",
        "9. Promoting altruistic behavior can help manage all three traits by promoting acts of kindness and generosity, reducing self-centered and manipulative behavior.\n",
        "10. Encouraging selflessness can help manage all three traits by promoting a focus on the needs and well-being of others, reducing selfish and exploitative behavior.\n",
        "3. Brainstorm ideas for startup improvement.\n",
        "\n",
        "\n",
        "- Implementing a system for self-reflection and self-awareness to recognize and manage dark traits\n",
        "- Encouraging open and honest communication within the group to address and resolve conflicts\n",
        "- Organizing group therapy sessions to discuss and understand the root causes of dark traits\n",
        "- Incorporating mindfulness and meditation practices to promote empathy and compassion\n",
        "- Collaborating with charities and volunteering opportunities to promote altruism and giving back to the community\n",
        "- Educating individuals on the negative impact of the Dark Triad and the benefits of managing these traits\n",
        "- Providing resources and support for individuals to seek professional help for managing dark traits\n",
        "- Creating a safe and non-judgmental environment for individuals to share their struggles and seek support from others\n",
        "- Encouraging positive reinforcement and recognition for individuals who demonstrate positive changes in managing their dark traits\n",
        "- Promoting self-care and self-love to combat feelings of worthlessness and insecurity that may contribute to dark traits\n",
        "- Developing a mentorship program where individuals with strong light traits can guide and support those struggling with dark traits.\n",
        "4. Share ideas for startup improvement.\n",
        " Here are some ideas to improve Dark Triad and its management through conversation and charity:\n",
        "\n",
        "1. Promote self-awareness and reflection: One way to improve Dark Triad traits is to encourage individuals to become more self-aware and reflect on their behavior and actions. This can be done through regular self-reflection exercises, therapy, or even journaling. By understanding their own tendencies towards Machiavellianism, narcissism, and psychopathy, individuals can work towards managing these traits better.\n",
        "\n",
        "2. Encourage empathy and perspective-taking: One of the key characteristics of the Dark Triad is a lack of empathy and concern for others. By promoting empathy and perspective-taking, individuals can learn to understand and consider the feelings and perspectives of others. This can be done through volunteering or participating in charitable activities that involve interacting with people from different backgrounds.\n",
        "\n",
        "3. Foster open and honest communication: Communication is key in managing the Dark Triad traits. By fostering open and honest communication, individuals can learn to express their thoughts and feelings in a healthy and constructive manner. This can also help in building trust and understanding among individuals, leading to better management of the Dark Triad.\n",
        "\n",
        "4. Educate about the consequences of Dark Triad behavior: Many individuals with Dark Triad traits may not be aware of the negative impact their behavior can have on others. By educating them about the consequences of their actions, they may be more motivated to work on managing their traits. This can be done through workshops, seminars, or even through personal discussions.\n",
        "\n",
        "5. Encourage self-reflection and accountability: It's important for individuals with Dark Triad traits to take responsibility for their actions and their impact on others. By encouraging self-reflection and accountability, individuals can learn to recognize when their behavior is influenced by their Dark Triad traits and take steps to manage them.\n",
        "\n",
        "6. Promote positive role models: Role models can have a significant influence on individuals, especially those with Dark Triad traits. By promoting positive role models who exhibit healthy and ethical behavior, individuals can learn to emulate these traits and manage their own Dark Triad tendencies.\n",
        "\n",
        "7. Provide support and resources: Managing the Dark Triad traits can be challenging, and individuals may need support and resources to do so effectively. This can include access to therapy, support groups, or even online resources that provide information and strategies for managing these traits.\n",
        "\n",
        "8. Encourage self-care and stress management: Individuals with Dark Triad traits may be more prone to stress and burnout due to their tendencies towards manipulation and exploitation. Encouraging self-care and stress management techniques can help individuals cope with these challenges and prevent them from resorting to their Dark Triad traits.\n",
        "\n",
        "9. Address underlying issues: It's important to recognize that the Dark Triad traits may stem from underlying issues such as past trauma or low self-esteem. By addressing these underlying issues, individuals can work towards managing their Dark Triad traits more effectively.\n",
        "\n",
        "10. Promote a culture of accountability and ethical behavior: In order to effectively manage the Dark Triad, it's important to create a culture of accountability and ethical behavior. This can be done by setting clear expectations and consequences for unethical behavior and promoting a culture of transparency and fairness.\n",
        "5. Identify startup problems for solutions.\n",
        "  One way to create the problem in Dark Triad is through manipulation and deceit. People with these traits are skilled at manipulating others to get what they want, often at the expense of others. This can create a toxic and unhealthy dynamic in relationships and conversations. To manage this, engaging in open and honest communication can help. By being transparent and direct, it becomes harder for individuals with Dark Triad traits to manipulate and deceive others. Additionally, practicing empathy and actively listening can help in managing these traits. By understanding the perspective of others and showing genuine care and concern, it can counteract the selfish and manipulative tendencies of the Dark Triad.  Another way to create the problem is through grandiosity and self-centeredness. People with narcissistic traits often have an inflated sense of self-importance and believe they are superior to others. This can lead to a lack of empathy and disregard for others' feelings and needs. To manage this, engaging in charitable work can help. By focusing on helping others and giving back to the community, it can help individuals with narcissistic traits develop a sense of humility and perspective. Additionally, engaging in conversations that challenge their beliefs and encourage self-reflection can also be beneficial.  Lastly, psychopathy can create problems in relationships and conversations through a lack of remorse and empathy, as well as impulsive and manipulative behavior. To manage this, it's important to establish clear boundaries and consequences for harmful behavior. Engaging in conversations that address the impact of their actions on others and encouraging them to take responsibility for their behavior can also help manage these traits. Additionally, engaging in charity work that focuses on helping those who have been hurt by psychopathic behavior can also be beneficial.  In conclusion, managing the Dark Triad traits of Machiavellianism, narcissism, and psychopathy can be challenging, but through open and honest communication, empathy, self-reflection, and charitable work, it is possible to create a healthier and more positive dynamic in relationships and conversations. By addressing the core of darkness and promoting the vulnerability of light, we can work towards a more compassionate and understanding society.\n",
        "6. Apply SCAMPER method to startup.\n",
        "\n",
        "\n",
        "S - Substitute: Instead of using the trolling system to instill the idea of worthlessness in others, substitute it with positive reinforcement and empathy. This can be achieved through active listening and understanding the perspectives of others.\n",
        "\n",
        "C - Combine: Combine the concept of dialogue and charity with mindfulness techniques to help individuals become more aware of their thoughts and actions. This can help them recognize and manage their dark traits.\n",
        "\n",
        "A - Adapt: Adapt the conversation and charity approach to different situations and individuals. For example, in a workplace setting, the focus can be on promoting teamwork and collaboration, while in a personal setting, the focus can be on building healthy relationships.\n",
        "\n",
        "M - Modify: Modify the conversation and charity approach to include education and awareness about the Dark Triad. This can help individuals understand the impact of their actions and work towards managing their traits.\n",
        "\n",
        "P - Put to another use: Instead of using the trolling system to harm others, put it to use in a positive way by using it as a tool for self-reflection and growth. This can help individuals recognize their dark traits and work towards improving themselves.\n",
        "\n",
        "E - Eliminate: Eliminate the use of the trolling system and other negative methods to manage the Dark Triad. Instead, focus on promoting positive behaviors and actions through conversation and charity.\n",
        "\n",
        "R - Rearrange: Rearrange the focus of conversation and charity from solely managing the Dark Triad to also promoting positive traits and behaviors. This can help individuals develop a more balanced and healthy personality.\n",
        "\n",
        "By applying the SCAMPER method, we can come up with new and innovative ways to manage the Dark Triad through conversation and charity. This can help individuals recognize and manage their dark traits, leading to healthier relationships and a more positive impact on society.\n",
        "7. Assemble diverse team for startup.\n",
        "  The group should consist of individuals from various backgrounds, such as psychology, sociology, philosophy, and neuroscience, to provide a diverse perspective on the topic. It is also essential to include individuals who have personal experience with the Dark Triad, whether as a victim or as someone who has exhibited these traits in the past. This will provide a more personal and empathetic understanding of the issue.  The group should also include individuals from different cultures and demographics to ensure a global perspective on the topic. This will help in understanding how the Dark Triad manifests in different societies and how it can be managed in a culturally sensitive manner.  The goal of the group would be to have open and honest discussions about the Dark Triad and its impact on individuals and society. The group can also brainstorm and come up with innovative ways to promote dialogue and charity as a means of managing these traits. This can include creating awareness campaigns, organizing charity events, and developing educational materials.  It is also crucial for the group to collaborate with existing organizations and initiatives that focus on mental health and promoting positive traits in individuals. This will help in creating a more comprehensive approach to managing the Dark Triad.  Overall, the group should aim to raise awareness about the Dark Triad and its management through dialogue and charity. By bringing together a diverse group of individuals, we can create a more holistic and effective approach to tackling this issue.\n",
        "8. Envision successful startup future.\n",
        "\n",
        "\n",
        "In this future state, the management of the Dark Triad has been successfully addressed through the use of conversation and charity. This approach has been proven effective through a study conducted in 2023, which found that engaging in these activities for four months can help manage the traits of Machiavellianism, narcissism, and psychopathy.\n",
        "\n",
        "To achieve this success, various methods have been brainstormed and implemented to promote dialogue and charitable work. One of the key factors in this approach is the recognition of the trolling system, which uses the core of darkness to devalue others and promote self-centeredness. By understanding and addressing this system, individuals are able to shift towards more productive and empathetic conversations.\n",
        "\n",
        "However, it is also important to acknowledge that the vulnerability and unconscious induction of the core of darkness can hinder the progress of conversation and charity. This process, which can be triggered by trauma or other factors, can be compared to hypnotism and can prevent individuals from fully engaging in dialogue and charitable work.\n",
        "\n",
        "To address this issue, studies and conceptual views of the Dark Triad model have been extensively discussed. This includes the concept of the memetic code and the idea of a conceptual life, or memplex, related to the Dark and Light Triad in the human species. By studying the vulnerability of light features against the Dark Triad, researchers have been able to strengthen conceptual life and promote healthier behaviors.\n",
        "\n",
        "As a result, new codes and models have been developed to address the Dark Triad and promote positive behaviors. These codes and models have been continuously refined and improved upon, leading to the successful management of the Dark Triad through conversation and charity.\n",
        "\n",
        "Looking back, it is clear that this future state was achieved through a series of events and decisions. It started with the recognition of the trolling system and the understanding of its impact on conversations. This led to the development of new codes and models, which were continuously improved upon through research and discussions. Finally, by promoting dialogue and charity, individuals were able to manage the traits of the Dark Triad and create a more empathetic and understanding society.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "odjX4XUidYBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ0Qo48rbuQg"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "image = pipeline(\"one pitch tech report weblog cover photo with no text in image for :\"+Text).images[0] #\"An image of a squirrel in Picasso style\").images[0]\n",
        "image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYvH3TXabuQm"
      },
      "outputs": [],
      "source": [
        "image.save(\"image_of_squirrel_painting.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#There are some others example codes at this Huggingface model page:\n",
        "https://huggingface.co/kandinsky-community/kandinsky-2-2-decoder\n",
        "\n",
        "```python\n",
        "from diffusers import AutoPipelineForImage2Image\n",
        "import torch\n",
        "\n",
        "pipe = AutoPipelineForImage2Image.from_pretrained(\"kandinsky-community/kandinsky-2-2-decoder\", torch_dtype=torch.float16)\n",
        "pipe.enable_model_cpu_offload()\n",
        "\n",
        "prompt = \"A fantasy landscape, Cinematic lighting\"\n",
        "negative_prompt = \"low quality, bad quality\"\n",
        "\n",
        "image = pipe(prompt=prompt, image=original_image, strength=0.3, height=768, width=768).images[0]\n",
        "\n",
        "out.images[0].save(\"fantasy_land.png\")\n",
        "```"
      ],
      "metadata": {
        "id": "Viu4azdbgauf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers transformers accelerate"
      ],
      "metadata": {
        "id": "KAwbraD3hMxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import AutoPipelineForImage2Image\n",
        "import torch\n",
        "\n",
        "pipe = AutoPipelineForImage2Image.from_pretrained(\"kandinsky-community/kandinsky-2-2-decoder\", torch_dtype=torch.float16)\n",
        "pipe.enable_model_cpu_offload()"
      ],
      "metadata": {
        "id": "DHD5as_cgyrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from diffusers.utils import load_image\n",
        "\n",
        "original_image = load_image(\n",
        "    \"https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main\" \"/kandinsky/cat.png\"\n",
        ")\n",
        "original_image =  load_image(\n",
        "    \"https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main\" \"/kandinsky/starry_night.jpeg\"\n",
        ")\n",
        "prompt = \"portrait of a young women, blue eyes, cinematic is describing this pith deck file:\"+Text\n",
        "negative_prompt = \"low quality, bad quality, no text in picture and verbal content\"\n",
        "\n",
        "image = pipe(prompt=prompt, image=original_image, strength=0.3, height=768, width=768).images[0]\n",
        "image"
      ],
      "metadata": {
        "id": "V82sapSGiSWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"portrait of a young women, blue eyes, cinematic is describing this pith deck file:\"+Text\n",
        "negative_prompt = \"low quality, bad quality, no text in picture and verbal content\"\n",
        "\n",
        "image = pipe(prompt=prompt, negative_prompt=negative_prompt,image=original_image, prior_guidance_scale =1.0, height=768, width=768).images[0]\n",
        "image.save(\"portrait.png\")\n",
        "image"
      ],
      "metadata": {
        "id": "GV_XSbv-sC4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import AutoPipelineForText2Image\n",
        "import torch\n",
        "\n",
        "pipe = AutoPipelineForText2Image.from_pretrained(\"kandinsky-community/kandinsky-2-2-decoder\", torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "T6MysZZChqr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import KandinskyV22PriorPipeline, KandinskyV22Pipeline\n",
        "from diffusers.utils import load_image\n",
        "import PIL\n",
        "\n",
        "import torch\n",
        "\n",
        "pipe_prior = KandinskyV22PriorPipeline.from_pretrained(\n",
        "    \"kandinsky-community/kandinsky-2-2-prior\", torch_dtype=torch.float16\n",
        ")\n",
        "pipe_prior.to(\"cuda\")\n",
        "\n",
        "img1 = load_image(\n",
        "    \"https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main\" \"/kandinsky/cat.png\"\n",
        ")\n",
        "\n",
        "img2 = load_image(\n",
        "    \"https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main\" \"/kandinsky/starry_night.jpeg\"\n",
        ")\n",
        "\n",
        "# add all the conditions we want to interpolate, can be either text or image\n",
        "images_texts = [\"a woman is describing the pitch deck file with this content\"+ Text, img1, img2]\n",
        "\n",
        "# specify the weights for each condition in images_texts\n",
        "weights = [0.3, 0.3, 0.4]\n",
        "\n",
        "# We can leave the prompt empty\n",
        "prompt = \"\"\n",
        "prior_out = pipe_prior.interpolate(images_texts, weights)\n",
        "\n",
        "pipe = KandinskyV22Pipeline.from_pretrained(\"kandinsky-community/kandinsky-2-2-decoder\", torch_dtype=torch.float16)\n",
        "pipe.to(\"cuda\")\n",
        "\n",
        "image = pipe(**prior_out, height=768, width=768).images[0]\n",
        "\n",
        "image.save(\"starry_cat.png\")\n",
        "image"
      ],
      "metadata": {
        "id": "P8E2BRcni4r8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYoh7oC2buQo"
      },
      "source": [
        "### Local pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc83goS0buQq"
      },
      "source": [
        "You can also use the pipeline locally. The only difference is you need to download the weights first:\n",
        "\n",
        "```bash\n",
        "!git lfs install\n",
        "!git clone https://huggingface.co/runwayml/stable-diffusion-v1-5\n",
        "```\n",
        "\n",
        "Then load the saved weights into the pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "#!git clone https://huggingface.co/runwayml/stable-diffusion-v1-5"
      ],
      "metadata": {
        "id": "exN8fq9uea6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lLy7KSlbuQs"
      },
      "outputs": [],
      "source": [
        "pipeline = DiffusionPipeline.from_pretrained(\"./stable-diffusion-v1-5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll0LeI4fbuQw"
      },
      "source": [
        "Now you can run the pipeline as you would in the section above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCmq0GLnbuQy"
      },
      "source": [
        "### Swapping schedulers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pectm0bwbuQz"
      },
      "source": [
        "Different schedulers come with different denoising speeds and quality trade-offs. The best way to find out which one works best for you is to try them out! One of the main features of ðŸ§¨ Diffusers is to allow you to easily switch between schedulers. For example, to replace the default [PNDMScheduler](https://huggingface.co/docs/diffusers/main/en/api/schedulers/pndm#diffusers.PNDMScheduler) with the [EulerDiscreteScheduler](https://huggingface.co/docs/diffusers/main/en/api/schedulers/euler#diffusers.EulerDiscreteScheduler), load it with the [from_config()](https://huggingface.co/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin.from_config) method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxJtZyCJbuQ2"
      },
      "outputs": [],
      "source": [
        "from diffusers import EulerDiscreteScheduler\n",
        "\n",
        "pipeline = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n",
        "pipeline.scheduler = EulerDiscreteScheduler.from_config(pipeline.scheduler.config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpMHju8mbuQ5"
      },
      "source": [
        "Try generating an image with the new scheduler and see if you notice a difference!\n",
        "\n",
        "In the next section, you'll take a closer look at the components - the model and scheduler - that make up the [DiffusionPipeline](https://huggingface.co/docs/diffusers/main/en/api/pipelines/overview#diffusers.DiffusionPipeline) and learn how to use these components to generate an image of a cat."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_fEhY-gbuQ7"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7k9LP1ybuQ9"
      },
      "source": [
        "Most models take a noisy sample, and at each timestep it predicts the *noise residual* (other models learn to predict the previous sample directly or the velocity or [`v-prediction`](https://github.com/huggingface/diffusers/blob/5e5ce13e2f89ac45a0066cb3f369462a3cf1d9ef/src/diffusers/schedulers/scheduling_ddim.py#L110)), the difference between a less noisy image and the input image. You can mix and match models to create other diffusion systems.\n",
        "\n",
        "Models are initiated with the [from_pretrained()](https://huggingface.co/docs/diffusers/main/en/api/models/overview#diffusers.ModelMixin.from_pretrained) method which also locally caches the model weights so it is faster the next time you load the model. For the quicktour, you'll load the [UNet2DModel](https://huggingface.co/docs/diffusers/main/en/api/models/unet2d#diffusers.UNet2DModel), a basic unconditional image generation model with a checkpoint trained on cat images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCp79H3obuQ_"
      },
      "outputs": [],
      "source": [
        "from diffusers import UNet2DModel\n",
        "\n",
        "repo_id = \"google/ddpm-cat-256\"\n",
        "model = UNet2DModel.from_pretrained(repo_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bSAKud1buRC"
      },
      "source": [
        "To access the model parameters, call `model.config`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgaWOOmfbuRE"
      },
      "outputs": [],
      "source": [
        "model.config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5eKEvITbuRH"
      },
      "source": [
        "The model configuration is a ðŸ§Š frozen ðŸ§Š dictionary, which means those parameters can't be changed after the model is created. This is intentional and ensures that the parameters used to define the model architecture at the start remain the same, while other parameters can still be adjusted during inference.\n",
        "\n",
        "Some of the most important parameters are:\n",
        "\n",
        "* `sample_size`: the height and width dimension of the input sample.\n",
        "* `in_channels`: the number of input channels of the input sample.\n",
        "* `down_block_types` and `up_block_types`: the type of down- and upsampling blocks used to create the UNet architecture.\n",
        "* `block_out_channels`: the number of output channels of the downsampling blocks; also used in reverse order for the number of input channels of the upsampling blocks.\n",
        "* `layers_per_block`: the number of ResNet blocks present in each UNet block.\n",
        "\n",
        "To use the model for inference, create the image shape with random Gaussian noise. It should have a `batch` axis because the model can receive multiple random noises, a `channel` axis corresponding to the number of input channels, and a `sample_size` axis for the height and width of the image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SkpjGo-buRI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "noisy_sample = torch.randn(1, model.config.in_channels, model.config.sample_size, model.config.sample_size)\n",
        "noisy_sample.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKXQgrm3buRL"
      },
      "source": [
        "For inference, pass the noisy image to the model and a `timestep`. The `timestep` indicates how noisy the input image is, with more noise at the beginning and less at the end. This helps the model determine its position in the diffusion process, whether it is closer to the start or the end. Use the `sample` method to get the model output:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bD2og2pWbuRN"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    noisy_residual = model(sample=noisy_sample, timestep=2).sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRchfDzXbuRP"
      },
      "source": [
        "To generate actual examples though, you'll need a scheduler to guide the denoising process. In the next section, you'll learn how to couple a model with a scheduler."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thEEOOjIbuRR"
      },
      "source": [
        "## Schedulers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGJ1WH-nbuRT"
      },
      "source": [
        "Schedulers manage going from a noisy sample to a less noisy sample given the model output - in this case, it is the `noisy_residual`.\n",
        "\n",
        "<Tip>\n",
        "\n",
        "ðŸ§¨ Diffusers is a toolbox for building diffusion systems. While the [DiffusionPipeline](https://huggingface.co/docs/diffusers/main/en/api/pipelines/overview#diffusers.DiffusionPipeline) is a convenient way to get started with a pre-built diffusion system, you can also choose your own model and scheduler components separately to build a custom diffusion system.\n",
        "\n",
        "</Tip>\n",
        "\n",
        "For the quicktour, you'll instantiate the [DDPMScheduler](https://huggingface.co/docs/diffusers/main/en/api/schedulers/ddpm#diffusers.DDPMScheduler) with it's [from_config()](https://huggingface.co/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin.from_config) method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-eEA3u3buRV"
      },
      "outputs": [],
      "source": [
        "from diffusers import DDPMScheduler\n",
        "\n",
        "scheduler = DDPMScheduler.from_config(repo_id)\n",
        "scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn0XDSS2buRX"
      },
      "source": [
        "<Tip>\n",
        "\n",
        "ðŸ’¡ Notice how the scheduler is instantiated from a configuration. Unlike a model, a scheduler does not have trainable weights and is parameter-free!\n",
        "\n",
        "</Tip>\n",
        "\n",
        "Some of the most important parameters are:\n",
        "\n",
        "* `num_train_timesteps`: the length of the denoising process or in other words, the number of timesteps required to process random Gaussian noise into a data sample.\n",
        "* `beta_schedule`: the type of noise schedule to use for inference and training.\n",
        "* `beta_start` and `beta_end`: the start and end noise values for the noise schedule.\n",
        "\n",
        "To predict a slightly less noisy image, pass the following to the scheduler's [step()](https://huggingface.co/docs/diffusers/main/en/api/schedulers/ddpm#diffusers.DDPMScheduler.step) method: model output, `timestep`, and current `sample`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfWRm0ccbuRZ"
      },
      "outputs": [],
      "source": [
        "less_noisy_sample = scheduler.step(model_output=noisy_residual, timestep=2, sample=noisy_sample).prev_sample\n",
        "less_noisy_sample.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfaIS3avbuRc"
      },
      "source": [
        "The `less_noisy_sample` can be passed to the next `timestep` where it'll get even less noisier! Let's bring it all together now and visualize the entire denoising process.\n",
        "\n",
        "First, create a function that postprocesses and displays the denoised image as a `PIL.Image`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DG_mew7XbuR2"
      },
      "outputs": [],
      "source": [
        "import PIL.Image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def display_sample(sample, i):\n",
        "    image_processed = sample.cpu().permute(0, 2, 3, 1)\n",
        "    image_processed = (image_processed + 1.0) * 127.5\n",
        "    image_processed = image_processed.numpy().astype(np.uint8)\n",
        "\n",
        "    image_pil = PIL.Image.fromarray(image_processed[0])\n",
        "    display(f\"Image at step {i}\")\n",
        "    display(image_pil)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRSF62oLbuR4"
      },
      "source": [
        "To speed up the denoising process, move the input and model to a GPU:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryOPkkqzbuR7"
      },
      "outputs": [],
      "source": [
        "model.to(\"cuda\")\n",
        "noisy_sample = noisy_sample.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL-RaYFHbuR9"
      },
      "source": [
        "Now create a denoising loop that predicts the residual of the less noisy sample, and computes the less noisy sample with the scheduler:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IVyKtEXbuR_"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "\n",
        "sample = noisy_sample\n",
        "\n",
        "for i, t in enumerate(tqdm.tqdm(scheduler.timesteps)):\n",
        "    # 1. predict noise residual\n",
        "    with torch.no_grad():\n",
        "        residual = model(sample, t).sample\n",
        "\n",
        "    # 2. compute less noisy image and set x_t -> x_t-1\n",
        "    sample = scheduler.step(residual, t, sample).prev_sample\n",
        "\n",
        "    # 3. optionally look at image\n",
        "    if (i + 1) % 50 == 0:\n",
        "        display_sample(sample, i + 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh4oT1Y1buSC"
      },
      "source": [
        "Sit back and watch as a cat is generated from nothing but noise! ðŸ˜»\n",
        "\n",
        "<div class=\"flex justify-center\">\n",
        "    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/diffusion-quicktour.png\"/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sEsn_8JbuSF"
      },
      "source": [
        "## Next steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRCB09sSbuSH"
      },
      "source": [
        "Hopefully you generated some cool images with ðŸ§¨ Diffusers in this quicktour! For your next steps, you can:\n",
        "\n",
        "* Train or finetune a model to generate your own images in the [training](https://huggingface.co/docs/diffusers/main/en/./tutorials/basic_training) tutorial.\n",
        "* See example official and community [training or finetuning scripts](https://github.com/huggingface/diffusers/tree/main/examples#-diffusers-examples) for a variety of use cases.\n",
        "* Learn more about loading, accessing, changing and comparing schedulers in the [Using different Schedulers](https://huggingface.co/docs/diffusers/main/en/./using-diffusers/schedulers) guide.\n",
        "* Explore prompt engineering, speed and memory optimizations, and tips and tricks for generating higher quality images with the [Stable Diffusion](https://huggingface.co/docs/diffusers/main/en/./stable_diffusion) guide.\n",
        "* Dive deeper into speeding up ðŸ§¨ Diffusers with guides on [optimized PyTorch on a GPU](https://huggingface.co/docs/diffusers/main/en/./optimization/fp16), and inference guides for running [Stable Diffusion on Apple Silicon (M1/M2)](https://huggingface.co/docs/diffusers/main/en/./optimization/mps) and [ONNX Runtime](https://huggingface.co/docs/diffusers/main/en/./optimization/onnx)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}