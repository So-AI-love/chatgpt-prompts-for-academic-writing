{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/So-AI-love/chatgpt-prompts-for-academic-writing/blob/main/Auto_Making/API_4_2_big_sumerized_Game_Theory_Activitist_Analyser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AcaGPT MVP\n",
        "\n",
        "The gosl of this project is Creating something like AutoGPT but in the field of Academic Papers wrting.\n",
        "\n",
        "\n",
        "For example the MVP Lage has been made by this AI free website maker :\n",
        "\n",
        "https://acagpt.site.live/editv2/"
      ],
      "metadata": {
        "id": "qnaAEEnpFyLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "  # Mount Google Drive\n",
        "if not os.path.isdir('/content/drive'):\n",
        "   # If not, mount the drive\n",
        "     drive.mount('/content/drive')\n",
        "else:\n",
        "     print(\"Drive is already mounted.\")"
      ],
      "metadata": {
        "id": "6GjtEabAJCXo",
        "outputId": "40acc5de-8a96-4d25-89cc-e7a770b1f166",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive is already mounted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vt7VN_fmGT3E",
        "outputId": "f1ee7631-febc-448c-ffdd-a0de985f37b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.3.7)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (0.15.0)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.12.0)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (2.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install backoff\n",
        "!pip install docx2pdf\n",
        "!pip install python-docx\n",
        "!pip install django\n",
        "\n",
        "\n",
        "!pip install tenacity\n",
        "!pip install tiktoken\n",
        "\n",
        "# SETUP COLAB for run Streamlit\n",
        "!npm install localtunnel\n",
        "\n",
        "!pip install -q dl-translate\n",
        "!curl ipv4.icanhazip.com\n",
        "\n",
        "#!pip install youtube-dl\n",
        "#!apt install python3-distutils\n",
        "!pip install mega.py\n",
        "!apt install python3-distutils  -y\n",
        "\n",
        "#!pip install googletrans==4.0.0-rc1\n",
        "\n",
        "!pip install httpcore==0.15.0 httpx pymongo googletrans\n",
        "!pip install httpx==0.24.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install libreoffice\n",
        "#!sudo apt-get install abiword\n",
        "!sudo apt install libreoffice-writer"
      ],
      "metadata": {
        "id": "AUeIF57v21gq",
        "outputId": "461bf82f-221d-4528-96ca-9b961ac0a11a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 229 kB in 1s (189 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libreoffice is already the newest version (1:7.3.7-0ubuntu0.22.04.3).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " megacmd : Depends: libc-ares2 (>= 1.11.0~rc1) but it is not going to be installed\n",
            "           Depends: libcrypto++6 but it is not installable\n",
            "           Depends: libmediainfo0v5 (>= 0.7.56) but it is not going to be installed\n",
            "           Depends: libssl1.1 (>= 1.1.0) but it is not installable\n",
            "           Depends: libzen0v5 (>= 0.4.31-2~) but it is not going to be installed\n",
            "E: Unmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libreoffice-writer is already the newest version (1:7.3.7-0ubuntu0.22.04.3).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " megacmd : Depends: libc-ares2 (>= 1.11.0~rc1) but it is not going to be installed\n",
            "           Depends: libcrypto++6 but it is not installable\n",
            "           Depends: libmediainfo0v5 (>= 0.7.56) but it is not going to be installed\n",
            "           Depends: libssl1.1 (>= 1.1.0) but it is not installable\n",
            "           Depends: libzen0v5 (>= 0.4.31-2~) but it is not going to be installed\n",
            "\u001b[1;31mE: \u001b[0mUnmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Goal adding ðŸ™ðŸ‘‡ðŸŒ¸"
      ],
      "metadata": {
        "id": "Jl9PPovDuhlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# @title (Please insert your request to be done by this code at below form:ðŸ‘‡ðŸ‘‡)\n",
        "Topic = \"Benefit of Brainstorming techniques for Leveraging ChatGPT for Social Movement Analysis: A Free and Open-Source Approach\" # @param {type:\"string\"}\n",
        "person = \"unknown person \" # @param {type:\"string\"}\n",
        "movement = \"middle east femenism movment \" # @param {type:\"string\"}\n",
        "\n",
        "# Define the analysis method\n",
        "analysis_method = \"brainstorming method on Social Identity Model of Collective Action analyser\" # @param {type:\"string\"}\n",
        "\n",
        "# Define the role of ChatGPT\n",
        "chatgpt_role = \"ChatGPT can generate a comprehensive analysis based on the input prompts, utilizing its language model trained on a diverse range of internet text.\" # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "PARAGRAPH = f\"Doing {chatgpt_role} for {TOPIC} to estimate effect of Personality of {person} on the social movment of :{movement} \" # @param {type:\"string\"}\n",
        "role = \"brainstorming for social movements analyser\"# @param {type:\"string\"}\n",
        "\n",
        "\n",
        "Your_Email = \"hh@gmail.com\" # @param {type:\"string\"}\n",
        "\n",
        "openai_api = \"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\" # @param {type:\"string\"}\n",
        "\n",
        "TOPIC_0 = f\"Analyze the current situation in the Islamic Republic of Iran and the challenges faced by resistance forces. And Identify effective strategies used by resistance movements to navigate challenging political environments.\"\n",
        "TOPIC_0 = f\"Could you provide more insights into the challenges faced by the opposition groups in Iran and how they could overcome these challenges to effectively organize resistance against the Islamic Republic?\"\n",
        "\n",
        "Question=Topic\n",
        "#PASSWORD =  # @param {type:\"string\"}\n",
        "if not (Question == \"\"):\n",
        "\n",
        "    TOPIC  = Question\n",
        "\n",
        "else:\n",
        "    TOPIC  = TOPIC_0\n",
        "\n",
        "    print(\"Please Input your Mega IDs.\")\n",
        "# @markdown *After signing\n",
        "print ('Your question is:',TOPIC)# has done successfully\")\n",
        "main_variables_0 = {\n",
        "   'TOPIC': TOPIC,\n",
        "   'PARAGRAPH':PARAGRAPH,\n",
        "    'role':role\n",
        "}\n",
        "\n",
        "# Define the prompts\n",
        "prompts_1 = [\n",
        "f\"suggest one report Title wich is related to {role} in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "\n",
        "   f\"As a President Election Analyser, analyze how the personality traits of {person} as described by the Myers-Briggs Type Indicator (MBTI) framework affected the team dynamics and the success of the {movement} using the {analysis_method}. {chatgpt_role}\",\n",
        "   f\"As a Terrorism and Game Theory Analyser, evaluate how the Big Five personality traits of {person} contributed to the effectiveness of the team in the {movement} using the {analysis_method}. {chatgpt_role}\",\n",
        "   f\"As a President Election Analyser, examine how the personality traits of {person} influenced the team's performance and the outcomes of the {movement} using the {analysis_method}. {chatgpt_role}\",\n",
        "   f\"As a Terrorism and Game Theory Analyser, assess how the team-building structures developed by {person} contributed to the success of the {movement} using the {analysis_method}. {chatgpt_role}\",\n",
        "   f\"As a President Election Analyser, discuss how the personality traits and team-building structures of {person} affected the social identity of the team and influenced the success of the {movement} using the {analysis_method}. {chatgpt_role}\",\n",
        "   f\"As a President Election Analyser, find the best method of analysis for this task. {chatgpt_role}\"\n",
        "]\n",
        "prompt_Word_Topic_1 = [\n",
        "  f\"suggest one report Title wich is related to {role} in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "\n",
        "\n",
        "  \"1.Analyze personality traits impact on team dynamics.\",\n",
        "  \"2.Evaluate personality traits contribution to team effectiveness.\",\n",
        "  \"3.Examine personality traits influence on team performance.\",\n",
        "  \"4.Assess team-building structures contribution to success.\",\n",
        "  \"5.Discuss traits and structures impact on social identity.\",\n",
        "  \"6.Find best method of analysis for this task.\"\n",
        "]"
      ],
      "metadata": {
        "id": "6sB-CWjFBf5u",
        "outputId": "52360297-b44d-450f-e98a-398854b4be0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your question is: Benefit of Brainstorming techniques for Leveraging ChatGPT for Social Movement Analysis: A Free and Open-Source Approach\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Description Prompts\n",
        "prompts_old = [\n",
        "f\"suggest one report Title wich is related to {role} in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "\n",
        " f\"1. {role}, suggest a report title related to {role} in less than 15 words, based on the topic: {TOPIC} and the description: {PARAGRAPH}.\",\n",
        " f\"2. {role}, as a President Election Analyser, analyze how the personality traits of {person} as described by the Myers-Briggs Type Indicator (MBTI) framework affected the team dynamics and the success of the {movement} using the {analysis_method}. {chatgpt_role}\",\n",
        " f\"3. {role}, as a Terrorism and Game Theory Analyser, evaluate how the Big Five personality traits of {person} contributed to the effectiveness of the team in the {movement} using the {analysis_method}. {chatgpt_role}\",\n",
        " f\"4. {role}, as a President Election Analyser, examine how the personality traits of {person} influenced the team's performance and the outcomes of the {movement} using the {analysis_method}. {chatgpt_role}\",\n",
        " f\"5. {role}, as a Terrorism and Game Theory Analyser, assess how the team-building structures developed by {person} contributed to the success of the {movement} using the {analysis_method}. {chatgpt_role}\",\n",
        " f\"6. {role}, as a President Election Analyser, discuss how the personality traits and team-building structures of {person} affected the social identity of the team and influenced the success of the {movement} using the {analysis_method}. {chatgpt_role}\",\n",
        " f\"7. {role}, as a President Election Analyser, find the best method of analysis for this task. {chatgpt_role}\",\n",
        " f\"8. Compare the results of the first method of analysis with the second method.\",\n",
        " f\"9. Analyze the differences and similarities in the results.\",\n",
        " f\"10. Discuss the implications of these differences and similarities.\"\n",
        "]\n",
        "\n",
        "# Description\n",
        "prompt_Word_Topic = [\n",
        "f\"suggest one report Title wich is related to {role} in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "\n",
        " \"1. Suggesting a report title.\",\n",
        " \"2. Analyzing personality traits impact on team dynamics.\",\n",
        " \"3. Evaluating personality traits contribution to team effectiveness.\",\n",
        " \"4. Examining personality traits influence on team performance.\",\n",
        " \"5. Assessing team-building structures contribution to success.\",\n",
        " \"6. Discussing traits and structures impact on social identity.\",\n",
        " \"7. Finding the best method of analysis for this task.\",\n",
        " \"8. Comparing the results of the first method of analysis with the second method.\",\n",
        " \"9. Analyzing the differences and similarities in the results.\",\n",
        " \"10. Discussing the implications of these differences and similarities.\"\n",
        "]"
      ],
      "metadata": {
        "id": "aYc2di0VHf8J"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the improved structure of prompts\n",
        "prompts = [\n",
        "f\"suggest one report Title wich is related to {role} in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "\n",
        " f\"1. Introduction: The role of {role} is crucial in {TOPIC}. The personality traits of {person} as described by the Myers-Briggs Type Indicator (MBTI) framework can significantly affect the team dynamics and the success of the {movement}.\",\n",
        " f\"2. Task: Analyze how the personality traits of {person} affected the team dynamics and the success of the {movement} using the {analysis_method}.\",\n",
        " f\"3. Conclusion: After analyzing the personality traits of {person}, what are your conclusions about their impact on the team dynamics and the success of the {movement}?\",\n",
        " f\"4. Introduction: As a President Election Analyser, you need to understand the personality traits of {person} as described by the Myers-Briggs Type Indicator (MBTI) framework.\",\n",
        " f\"5. Task: Analyze how the personality traits of {person} affected the team dynamics and the success of the {movement} using the {analysis_method}.\",\n",
        " f\"6. Conclusion: After analyzing the personality traits of {person}, what are your conclusions about their impact on the team dynamics and the success of the {movement}?\",\n",
        " f\"7. Introduction: As a Terrorism and Game Theory Analyser, you need to understand the Big Five personality traits of {person}.\",\n",
        " f\"8. Task: Evaluate how the Big Five personality traits of {person} contributed to the effectiveness of the team in the {movement} using the {analysis_method}.\",\n",
        " f\"9. Conclusion: After evaluating the Big Five personality traits of {person}, what are your conclusions about their contribution to the effectiveness of the team in the {movement}?\",\n",
        " f\"10. Introduction: As a President Election Analyser, you need to understand the personality traits of {person}.\",\n",
        " f\"11. Task: Examine how the personality traits of {person} influenced the team's performance and the outcomes of the {movement} using the {analysis_method}.\",\n",
        " f\"12. Conclusion: After examining the personality traits of {person}, what are your conclusions about their influence on the team's performance and the outcomes of the {movement}?\",\n",
        " f\"13. Introduction: As a Terrorism and Game Theory Analyser, you need to understand the team-building structures developed by {person}.\",\n",
        " f\"14. Task: Assess how the team-building structures developed by {person} contributed to the success of the {movement} using the {analysis_method}.\",\n",
        " f\"15. Conclusion: After assessing the team-building structures developed by {person}, what are your conclusions about their contribution to the success of the {movement}?\",\n",
        " f\"16. Introduction: As a President Election Analyser, you need to understand the personality traits and team-building structures of {person}.\",\n",
        " f\"17. Task: Discuss how the personality traits and team-building structures of {person} affected the social identity of the team and influenced the success of the {movement} using the {analysis_method}.\",\n",
        " f\"18. Conclusion: After discussing the personality traits and team-building structures of {person}, what are your conclusions about their impact on the social identity of the team and their influence on the success of the {movement}?\",\n",
        " f\"19. Introduction: As a President Election Analyser, you need to find the best method of analysis for this task.\",\n",
        " f\"20. Task: Find the best method of analysis for this task.\",\n",
        " f\"21. Conclusion: After finding the best method of analysis for this task, what are your conclusions about its effectiveness in analyzing the personality traits and team-building structures of {person}?\",\n",
        "]\n",
        "\n",
        "# Define the description for each line of the prompt\n",
        "prompt_Word_Topic = [\n",
        "f\"suggest one report Title wich is related to {role} in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "\n",
        " \"Introduction: Role and topic\",\n",
        " \"Impact of personality traits\",\n",
        " \"Task: Analysis\",\n",
        " \"Conclusion: Analysis\",\n",
        " \"Introduction: Role and personality traits\",\n",
        " \"Task: Analysis\",\n",
        " \"Conclusion: Analysis\",\n",
        " \"Introduction: Role and Big Five traits\",\n",
        " \"Task: Evaluation\",\n",
        " \"Conclusion: Evaluation\",\n",
        " \"Introduction: Role and personality traits\",\n",
        " \"Task: Examination\",\n",
        " \"Conclusion: Examination\",\n",
        " \"Introduction: Role and team-building structures\",\n",
        " \"Task: Assessment\",\n",
        " \"Conclusion: Assessment\",\n",
        " \"Introduction: Role and traits and structures\",\n",
        " \"Task: Discussion\",\n",
        " \"Conclusion: Discussion\",\n",
        " \"Introduction: Role and analysis method\",\n",
        " \"Task: Analysis method\",\n",
        " \"Conclusion: Analysis method\",\n",
        "]"
      ],
      "metadata": {
        "id": "mRUjS2FFSV9x"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title .\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of changes in the type of violence that continues in the aftermath of violence\"\n",
        "#TOPIC =f\"stop the WarDark Triad and Light Triad in the Middle East: A Critical Examination of their Influence and Impact on Iran\"+TOPIC\n",
        "\n",
        "#TOPIC = f\"If possible read this post ( https://www.geeky-gadgets.com/chatgpt-brainstorming-prompts/ ) and suggest  one python block code 10 prompt in the for on ( prompt=[The suggested prompt based of [var1] ). The prompt must have 10 line and at least three necessary value like TOPIC , FIELD_SUDY,and the third vale is your optional . Also you can have more variable or prompt for doing this post main goal which is brainstorming for one topic based of ChatGPT promptimg. This would be ChatGPT cheat sheet prompting.\"\n",
        "TOPIC = main_variables_0.get('TOPIC', 'Default Value')\n",
        "print ('TOPIC IS :', TOPIC)\n",
        "\n",
        "folder_chatGPT = \"/content/ChatGPT_academic_paper\"\n",
        "#openai_api_0 = \"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\"\n",
        "#openai_api = \"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\"\n",
        "global TOPIC_CLASS\n",
        "class TOPIC_CLASS:\n",
        "    def __init__(self):\n",
        "        self.perviuse_try_numner = 0\n",
        "        self.perviuse_content = ['fist step']\n",
        "        self.topic= TOPIC\n",
        "TP= TOPIC_CLASS()\n",
        "#TOPIC = f\" \""
      ],
      "metadata": {
        "id": "I484Df8ONQVI",
        "outputId": "eb824908-27fb-4527-a1d4-cdcf4c7ae82d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TOPIC IS : Benefit of Brainstorming techniques for Leveraging ChatGPT for Social Movement Analysis: A Free and Open-Source Approach\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Funstions for saving as PDF and DOCX :\n",
        "ðŸ‘‡ðŸŒ±"
      ],
      "metadata": {
        "id": "lI5PG0BNPrPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install libreoffice\n",
        "#!sudo apt-get install abiword\n",
        "!sudo apt install libreoffice-writer"
      ],
      "metadata": {
        "id": "XDBHbtajP03B",
        "outputId": "abf13548-0e2c-4bef-9922-c15ec931d879",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libreoffice is already the newest version (1:7.3.7-0ubuntu0.22.04.3).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " megacmd : Depends: libc-ares2 (>= 1.11.0~rc1) but it is not going to be installed\n",
            "           Depends: libcrypto++6 but it is not installable\n",
            "           Depends: libmediainfo0v5 (>= 0.7.56) but it is not going to be installed\n",
            "           Depends: libssl1.1 (>= 1.1.0) but it is not installable\n",
            "           Depends: libzen0v5 (>= 0.4.31-2~) but it is not going to be installed\n",
            "E: Unmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libreoffice-writer is already the newest version (1:7.3.7-0ubuntu0.22.04.3).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " megacmd : Depends: libc-ares2 (>= 1.11.0~rc1) but it is not going to be installed\n",
            "           Depends: libcrypto++6 but it is not installable\n",
            "           Depends: libmediainfo0v5 (>= 0.7.56) but it is not going to be installed\n",
            "           Depends: libssl1.1 (>= 1.1.0) but it is not installable\n",
            "           Depends: libzen0v5 (>= 0.4.31-2~) but it is not going to be installed\n",
            "\u001b[1;31mE: \u001b[0mUnmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "W2xiQx_camiB"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "def convert_docx_to_pdf0(docx_path, pdf_path):\n",
        "  subprocess.call(['abiword', '--to=pdf', docx_path, '--to-dir', pdf_path])\n",
        "\n",
        "def convert_docx_to_pdf(docx_path, pdf_path):\n",
        " command = ['libreoffice', '--headless', '--convert-to', 'pdf', '--outdir', pdf_path, docx_path]\n",
        " subprocess.call(command)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "\n",
        "def add_text_with_bold(paragraph, text,p):\n",
        "   parts = text.split('**')\n",
        "   #doc.style('normal')\n",
        "   #p.style = doc.styles['Normal']\n",
        "\n",
        "   for i in range(len(parts)):\n",
        "       if i % 2 == 0:\n",
        "           p.add_run(parts[i])\n",
        "       else:\n",
        "           run = p.add_run(parts[i])\n",
        "           run.bold = True\n",
        "\n",
        "   return paragraph\n",
        "\n",
        "#add_text_with_bold(doc, 'This is some **bold** text',p)"
      ],
      "metadata": {
        "id": "xWvptzlbCPxk"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import subprocess\n",
        "from docx import Document\n",
        "from django.utils.text import slugify\n",
        "\n",
        "\n",
        "def save_academic_paper(topic, prompt_my):\n",
        "  global docx_path,Pdf_Dir\n",
        "\n",
        "  # Define the path to the folder in Google Drive\n",
        "  folder_path = r\"/content/drive/My Drive/ChatGPT_Paper_wrting/Bussiness_Plane/\"\n",
        "\n",
        "  # Mount Google Drive\n",
        "  if not os.path.isdir('/content/drive'):\n",
        "   # If not, mount the drive\n",
        "     drive.mount('/content/drive')\n",
        "  else:\n",
        "     print(\"Drive is already mounted.\")\n",
        "\n",
        "  Pdf_Dir= r\"/content/drive/My Drive/ChatGPT_Paper_wrting/Bussiness_Plane/\"\n",
        "  docx_path= f\"{folder_path}\"+\"FM\"+f\"{topic}.docx\"\n",
        "  # Check if the folder exists\n",
        "  if not os.path.exists(folder_path):\n",
        "  # If the folder doesn't exist, create it\n",
        "    os.mkdir(folder_path)\n",
        "\n",
        "\n",
        "  # Replace spaces in the topic with underscores\n",
        "  #topic = topic[:12].replace(\" \", \"_\")\n",
        "  topic = slugify(topic)\n",
        "\n",
        "  # Define the path to the DOCX file in the folder\n",
        "\n",
        "\n",
        "  # Check if the DOCX file exists\n",
        "  if os.path.isfile(docx_path):\n",
        "    # If the DOCX file exists, open it\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"#+str(random.randint(0,9))+\".docx\"\n",
        "    doc = Document(docx_path)\n",
        "  else:\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"\n",
        "    #print(docx_path)\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "    doc = Document()\n",
        "\n",
        "  # Add the generated text to the document\n",
        "  #doc.add_paragraph(prompt_my)\n",
        "  doc = add_text_with_bold(doc,0,prompt_my)\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Convert the DOCX file to a PDF\n",
        "  convert_docx_to_pdf(docx_path,Pdf_Dir)\n",
        "  return docx_path,Pdf_Dir"
      ],
      "metadata": {
        "id": "wTIqVCsP17gq"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from google.colab import drive\n",
        "import os , random\n",
        "import subprocess\n",
        "from docx import Document\n",
        "from django.utils.text import slugify\n",
        "from docx.shared import Pt\n",
        "\n",
        "Repost_Type_Title = 'Game Theory ACT Analysis '\n",
        "Repost_Type = 'Game_Theory_ACT_Model'\n",
        "  # Mount Google Drive\n",
        "if not os.path.isdir('/content/drive'):\n",
        "   # If not, mount the drive\n",
        "     drive.mount('/content/drive')\n",
        "else:\n",
        "     print(\"Drive is already mounted.\")\n",
        "\n",
        "\n",
        "def save_academic_paper_with_prompt_Tile(topic, prompt_my,contnet,try_number):\n",
        "  global docx_path,Pdf_Dir\n",
        "\n",
        "\n",
        "  # Define the path to the folder in Google Drive\n",
        "  folder_path = r\"/content/drive/My Drive/ChatGPT_Paper_wrting/\"+f\"{Repost_Type}/Title/\"\n",
        "\n",
        "\n",
        "  Pdf_Dir = folder_path# r\"/content/drive/My Drive/ChatGPT_Paper_wrting/{Repost_Type}/Title/\"\n",
        "\n",
        "  topic = slugify(topic[:21])\n",
        "  docx_path= f\"{folder_path}\"+f\"{Repost_Type}_T_\"+f\"{topic}.docx\"\n",
        "\n",
        "  # Check if the folder exists\n",
        "  if not os.path.exists(folder_path):\n",
        "  # If the folder doesn't exist, create it\n",
        "    os.makedirs(folder_path)\n",
        "\n",
        "\n",
        "  # Replace spaces in the topic with underscores\n",
        "  #topic = topic[:12].replace(\" \", \"_\")\n",
        "  #topic = slugify(topic)\n",
        "\n",
        "  # Define the path to the DOCX file in the folder\n",
        "\n",
        "  # Check if the DOCX file exists\n",
        "  if os.path.isfile(docx_path):\n",
        "\n",
        "    if try_number == 0 :\n",
        "\n",
        "       topic = topic+str(random.randint(0,100))#os.remove(docx_path)\n",
        "       docx_path= f\"{folder_path}\"+f\"{Repost_Type}_T_\"+f\"{topic}.docx\"\n",
        "       if os.path.isfile(docx_path):\n",
        "          try:\n",
        "             os.remove (docx_path.replace('docx','pdf'))\n",
        "             os.remove (docx_path)#\n",
        "\n",
        "          except:\n",
        "             print (\"the file for saving Exist and some error happened\")\n",
        "       doc = Document()\n",
        "\n",
        "    else :\n",
        "\n",
        "    # If the DOCX file exists, open it\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"#+str(random.randint(0,9))+\".docx\"\n",
        "       doc = Document(docx_path)\n",
        "\n",
        "\n",
        "    # Add the generated text to the document\n",
        "    p = doc.add_paragraph()#prompt_my)\n",
        "    # Add the generated text to the document\n",
        "    # Add the generated text to the document\n",
        "    p.style = doc.styles['Subtitle']\n",
        "\n",
        "    font = p.style.font\n",
        "    font.name = 'Arial'\n",
        "    font.size = Pt(15)\n",
        "    p = add_text_with_bold(doc,prompt_my,p)\n",
        "\n",
        "    #p.style = doc.styles['Subtitle']\n",
        "\n",
        "  else:\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"\n",
        "    #print(docx_path)\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "    doc = Document()\n",
        "\n",
        "    # Add the generated text to the document\n",
        "    p = doc.add_paragraph()#prompt_my)\n",
        "    # Add the generated text to the document\n",
        "    # Add the generated text to the document\n",
        "    p.style = doc.styles['Title']\n",
        "\n",
        "\n",
        "    p = add_text_with_bold(doc, f\"{Repost_Type_Title} For:\"+prompt_my,p)\n",
        "    p.style = doc.styles['Title']\n",
        "\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Revert the style of the paragraph back to 'Normal'\n",
        "  p = doc.add_paragraph()#contnet)\n",
        "  p.style = doc.styles['Normal']\n",
        "\n",
        "  p = add_text_with_bold(doc,contnet,p)\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Convert the DOCX file to a PDF\n",
        "  convert_docx_to_pdf(docx_path,Pdf_Dir)\n",
        "  return docx_path,Pdf_Dir\n",
        "\n",
        "def save_academic_paper_with_prompt(topic, prompt_my,contnet,try_number):\n",
        "  global docx_path,Pdf_Dir\n",
        "\n",
        "\n",
        "  # Define the path to the folder in Google Drive\n",
        "  folder_path = r\"/content/drive/My Drive/ChatGPT_Paper_wrting/\"+f\"{Repost_Type}/Prompt/\"\n",
        "\n",
        "\n",
        "  Pdf_Dir = folder_path# r\"/content/drive/My Drive/ChatGPT_Paper_wrting/\"+f\"{Repost_Type}/Prompt/\"\n",
        "  topic = slugify(topic[:21])\n",
        "  docx_path= f\"{folder_path}\"+f\"{Repost_Type}_PR_\"+f\"{topic}.docx\"\n",
        "\n",
        "\n",
        "  # Check if the folder exists\n",
        "  if not os.path.exists(folder_path):\n",
        "  # If the folder doesn't exist, create it\n",
        "    os.makedirs(folder_path)\n",
        "\n",
        "\n",
        "  # Replace spaces in the topic with underscores\n",
        "  #topic = topic[:12].replace(\" \", \"_\")\n",
        "  #topic = slugify(topic)\n",
        "\n",
        "  # Define the path to the DOCX file in the folder\n",
        "\n",
        "\n",
        "    # If the DOCX file exists, open it\n",
        "  if try_number == 0 :\n",
        "       try:\n",
        "          os.remove(docx_path)\n",
        "          os.romove (docx_path.replace('docx','pdf'))\n",
        "       except:\n",
        "          pass\n",
        "\n",
        "  # Check if the DOCX file exists\n",
        "  if os.path.isfile(docx_path):\n",
        "    # If the DOCX file exists, open it\n",
        "        #docx_path = f\"{folder_path}{topic}.docx\"#+str(random.randint(0,9))+\".docx\"\n",
        "    if try_number == 0 :\n",
        "\n",
        "       topic = topic+str(random.randint(0,100))#os.remove(docx_path)\n",
        "       docx_path= f\"{folder_path}\"+f\"{Repost_Type}_PR_\"+f\"{topic}.docx\"\n",
        "       if os.path.isfile(docx_path):\n",
        "          try:\n",
        "             os.remove (docx_path.replace('docx','pdf'))\n",
        "             os.remove (docx_path)#\n",
        "\n",
        "          except:\n",
        "             print (\"the file for saving Exist and some error happened\")\n",
        "       doc = Document()\n",
        "\n",
        "\n",
        "    else :\n",
        "\n",
        "    # If the DOCX file exists, open it\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"#+str(random.randint(0,9))+\".docx\"\n",
        "       doc = Document(docx_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Add the generated text to the document\n",
        "    p = doc.add_paragraph(prompt_my)\n",
        "    # Add the generated text to the document\n",
        "    # Add the generated text to the document\n",
        "    p.style = doc.styles['Subtitle']\n",
        "\n",
        "    font = p.style.font\n",
        "    font.name = 'Arial'\n",
        "    font.size = Pt(15)\n",
        "    p = add_text_with_bold(doc,prompt_my,p)\n",
        "    p.style = doc.styles['Subtitle']\n",
        "\n",
        "  else:\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"\n",
        "    #print(docx_path)\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "    doc = Document()\n",
        "\n",
        "    # Add the generated text to the document\n",
        "    p = doc.add_paragraph()#prompt_my)\n",
        "    # Add the generated text to the document\n",
        "    # Add the generated text to the document\n",
        "    p.style = doc.styles['Title']\n",
        "    p = add_text_with_bold(doc,f\"{Repost_Type_Title} For:\"+ prompt_my,p)\n",
        "\n",
        "    p.style = doc.styles['Title']\n",
        "\n",
        "  #p = add_text_with_bold(doc,prompt_my,p)  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Revert the style of the paragraph back to 'Normal'\n",
        "  p = doc.add_paragraph()#contnet)\n",
        "  p.style = doc.styles['Normal']\n",
        "\n",
        "  p = add_text_with_bold(doc,contnet,p) # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Convert the DOCX file to a PDF\n",
        "  convert_docx_to_pdf(docx_path,Pdf_Dir)\n",
        "  return docx_path,Pdf_Dir\n",
        "\n",
        "#save_academic_paper_with_prompt_Tile('title','**prmpt_mt** is ','contetn',0)\n",
        "#save_academic_paper_with_prompt('title','**prmpt_mt**','content ',0)"
      ],
      "metadata": {
        "id": "FXS5P81E2rId",
        "outputId": "3c368e90-5480-4407-aba4-2edad22a2c30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive is already mounted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# @title\n",
        "# conect to [Mega.z](https://mega.nz/) cloud for storage files based ot this page:\n",
        "\n",
        "https://colab.research.google.com/github/sudo-ken/Mega-to-Google-Drive/blob/master/Transfer_files_from_Mega_to_Google_Drive.ipynb#scrollTo=Vgh1xlQYGZCO"
      ],
      "metadata": {
        "id": "x7XWsP_amNqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# %cd '/content/'\n",
        "# !git clone https://github.com/jeroenmeulenaar/python3-mega.git\n",
        "# !(cd python3-mega; pip install urlobject pycrypto)\n",
        "\n",
        "# import os\n",
        "# os.chdir('python3-mega')\n",
        "# from mega import Mega\n",
        "# os.chdir('../')\n",
        "# m = Mega.from_ephemeral()\n",
        "\n",
        "# !git clone https://github.com/odwyersoftware/mega.py\n",
        "# %cd mega.py\n",
        "# !python setup.py install\n",
        "%cd '/content/'\n",
        "\n",
        "!rm -rf '/content/yoloOnGoogleColab'\n",
        "#!git clone https://github.com/CAR-Driving/yoloOnGoogleColab"
      ],
      "metadata": {
        "id": "L436PiVNmQog",
        "outputId": "d1409a70-0f66-427e-eddd-ebc66abc409e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# @markdown <center><h3>Input Your Mega ID</h3></center><br>\n",
        "from functools import wraps\n",
        "import errno\n",
        "import os\n",
        "import signal\n",
        "import subprocess\n",
        "import shlex\n",
        "\n",
        "\n",
        "class TimeoutError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "def timeout(seconds=10, error_message=os.strerror(errno.ETIME)):\n",
        "    def decorator(func):\n",
        "        def _handle_timeout(signum, frame):\n",
        "            raise TimeoutError(error_message)\n",
        "\n",
        "        def wrapper(*args, **kwargs):\n",
        "            signal.signal(signal.SIGALRM, _handle_timeout)\n",
        "            signal.alarm(seconds)\n",
        "            try:\n",
        "                result = func(*args, **kwargs)\n",
        "            finally:\n",
        "                signal.alarm(0)\n",
        "            return result\n",
        "\n",
        "        return wraps(func)(wrapper)\n",
        "\n",
        "    return decorator\n",
        "\n",
        "\n",
        "if not os.path.exists(\"/root/.ipython/ocr.py\"):\n",
        "    from subprocess import run\n",
        "    from shlex import split\n",
        "\n",
        "    shellCmd = \"wget -qq https://raw.githubusercontent.com/biplobsd/OneClickRun/master/res/ocr.py \\\n",
        "                    -O /root/.ipython/ocr.py\"\n",
        "    run(split(shellCmd))\n",
        "from ocr import runSh\n",
        "\n",
        "@timeout(10)\n",
        "def runShT(args):\n",
        "    return runSh(args, output=True)\n",
        "\n",
        "\n",
        "# MEGAcmd installing\n",
        "if not os.path.exists(\"/usr/bin/mega-cmd\"):\n",
        "    print(\"Installing MEGA ...\")\n",
        "    runSh('sudo apt-get -y update')\n",
        "    runSh('sudo apt-get -y install libmms0 libc-ares2 libc6 libcrypto++6 libgcc1 libmediainfo0v5 libpcre3 libpcrecpp0v5 libssl1.1 libstdc++6 libzen0v5 zlib1g apt-transport-https')\n",
        "    runSh('sudo curl -sL -o /var/cache/apt/archives/MEGAcmd.deb https://mega.nz/linux/MEGAsync/Debian_9.0/amd64/megacmd-Debian_9.0_amd64.deb', output=True)\n",
        "    runSh('sudo dpkg -i /var/cache/apt/archives/MEGAcmd.deb', output=True)\n",
        "    print(\"MEGA is installed.\")\n",
        "else:\n",
        "    !pkill mega-cmd\n",
        "\n",
        "# INPUT YOUR MEGA ID\n",
        "\n",
        "USERNAME = 'kayeyoc231@llubed.com'  # @param {type:\"string\"}\n",
        "PASSWORD = \"ss123456\"  # @param {type:\"string\"}\n",
        "if not (USERNAME == \"\" or PASSWORD == \"\"):\n",
        "    try:\n",
        "        runShT(f\"mega-login {USERNAME} {PASSWORD}\")\n",
        "        print (\"megazn login has done successfully\")\n",
        "    except TimeoutError:\n",
        "        runSh('mega-whoami', output=True)\n",
        "else:\n",
        "    print(\"Please Input your Mega IDs.\")\n",
        "# @markdown *After signing in, use the above cell(Main Cell) to transfer files from Mega to GDrive using the transfer quota of your Mega Pro Account*"
      ],
      "metadata": {
        "id": "uqYuzvYFoMIM",
        "outputId": "0d7ee6bc-4ebe-4b10-9e76-fcf432c96faf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Initiating MEGAcmd server in background. Log: /root/.megaCmd/megacmdserver.log]\n",
            "Unable to connect to service: error=2\n",
            "Please ensure mega-cmd-server is running\n",
            "Failed to create socket for registering for state changes\n",
            "megazn login has done successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#!rm -rf '/content/ChatGPT_academic_paper'\n",
        "!mkdir '/content/ChatGPT_academic_paper'\n",
        "%cd '/content/ChatGPT_academic_paper'\n",
        "!echo 't' >> t.txt\n",
        "\n",
        "from subprocess import Popen, PIPE\n",
        "import shlex\n",
        "import errno, os\n",
        "\n",
        "from subprocess import Popen, PIPE\n",
        "import shlex\n",
        "from ocr import runSh\n",
        "import re\n",
        "from distutils.dir_util import copy_tree\n",
        "\n",
        "# copy subdirectory example\n",
        "fromDirectory = '/content/ChatGPT_academic_paper/'\n",
        "toDirectory = '/content/gdrive/My Drive/yolo_car_database/'\n",
        "\n",
        "runSh('mega-cd /' )\n",
        "runSh(' mega-mkdir ChatGPT_academic_paper ')\n",
        "runSh(' mega-ls ')\n",
        "runSh('mega-cd ChatGPT_academic_paper ')\n",
        "\n",
        "# copy_tree(fromDirectory, toDirectory)\n",
        "def uplaod_mega_nz(root,cloude='mega',title1=''):\n",
        "  if (cloude=='mega'):\n",
        "  #  from mega import Mega\n",
        "  #  mega = Mega()\n",
        "  #  email = 'woraqofa@ivyandmarj.com'\n",
        "  #  password = 'feripas800@wgraj.com'\n",
        "  #  m = mega.login(email, password)\n",
        "  #  # login using a temporary anonymous account\n",
        "  #  m = mega.login()\n",
        "  #  quota = m.get_quota()\n",
        "  #  # specify unit output kilo, mega, gig, else bytes will output\n",
        "  #  space = m.get_storage_space(kilo=True)\n",
        "  #  m.create_folder('yolo_car_database/'+title1+'/')\n",
        "  #  folder = m.find('yolo_car_database/'+title1+'/')\n",
        "   # m.upload('myfile.doc', folder[0])\n",
        "  #  run_command('mega-cd ~ && mega-mkdir Yolo_car_database && mega-cd Yolo_car_database && mega-put '+ root+'/* . ')\n",
        "\n",
        "   runSh('mega-cd ChatGPT_academic_paper' + title1 + '/')\n",
        "   runSh('mega-put '+ root+' . ')\n",
        "   runSh(' mega-ls')\n",
        "\n",
        "   for path, subdirs, files in os.walk( root):\n",
        "      for name in files:\n",
        "        print (files)\n",
        "          # m.upload(os.path.join(path, name), folder[0])\n",
        "   # public_exported_web_link = m.export('myfile.doc')\n",
        "   # public_exported_web_link = m.export('my_mega_folder/my_sub_folder_to_share')\n",
        "\n",
        "  if (cloude=='google_drive'):\n",
        "     run_command('mkdir '+root+'/')\n",
        "     for path, subdirs, files in os.walk( root):\n",
        "      for name in files:\n",
        "        # print ('cp -r \"'+os.path.join(path, name)+'\" '+'\"/content/gdrive/My Drive/ChatGPT_academic_paper/' + title1 + '/\"')\n",
        "        # print (os.path.join(path, change_name(name)))\n",
        "        # os.rename(os.path.join(path, name), os.path.join(path, change_name(name)))\n",
        "        run_command('cp -r  \"'+os.path.join(path, name)+'\" '+'\"/content/gdrive/My Drive/ChatGPT_academic_paper/' + title1 + '/\"')\n",
        "     try:\n",
        "        copy_tree(root,'/content/gdrive/My Drive/ChatGPT_academic_paper/' + title1 + '/')\n",
        "     except OSError as e: # this would be \"except OSError, e:\" before Python 2.6\n",
        "        if e.errno != errno.ENOENT: # errno.ENOENT = no such file or directory\n",
        "            # raise #\n",
        "            i=0\n",
        "def change_file_name(root):\n",
        "  for path, subdirs, files in os.walk( root):\n",
        "      for name in files:\n",
        "        print ('filename is: \"'+os.path.join(path, name))\n",
        "        print (os.path.join(path, change_name(name)))\n",
        "        os.rename(os.path.join(path, name), os.path.join(path, change_name(name)))\n",
        "\n",
        "def run_command(cmd):\n",
        "    with Popen(shlex.split(cmd), stdout=PIPE, bufsize=1, universal_newlines=False) as p:\n",
        "        while True:\n",
        "            line = p.stdout.readline()\n",
        "            if not line:\n",
        "                break\n",
        "            print(line)\n",
        "        exit_code = p.poll()\n",
        "    return exit_code\n",
        "def change_name(name):\n",
        "    name_file = ''.join(name)\n",
        "    name_file = name_file.replace(\" \", \"_\")\n",
        "    name_file = name_file.replace(\"'\", \"_\")\n",
        "    name_file = name_file.replace(\"\\n\", \"\")\n",
        "    name_file = name_file.replace(\"\\t\", \"\")\n",
        "    name_file = name_file.replace(\"!\", \"\")\n",
        "    name_file = name_file.replace(\"-\", \"\")\n",
        "    name_file = name_file.replace(\"$\", \"\")\n",
        "    name_file = re.sub(r'[\\\\/*?:\"<>|]',\"\",name_file)\n",
        "    return name_file\n",
        "def MegaZN_upload_file(command):\n",
        "    # command_title=re.split('([^a-zA-Z0-9])',command)\n",
        "    command_title_1 = re.split('([^a-zA-Z0-9])', command)\n",
        "    command_title = ''.join(command_title_1)\n",
        "    command_title=change_name(command_title)\n",
        "\n",
        "\n",
        "    # call_args = ' youtube-dl --match-title ' + ' \"'+command_title_1[0]+ '\" ' + '\"ytsearch10\":'+'\"'+command+ '\" '+\"--external-downloader-args   '-ss 00:00:03 -t 00:03:08' --write-info-json --write-annotation --write-thumbnail --write-sub -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4'\"\n",
        "    #call_args = ' youtube-dl --match-title ' + ' \"'+command_title_1[0]+ '\" ' + '\"ytsearch100\":'+'\"'+command+ '\" '+\"--playlist-end 3  --external-downloader-args   '-ss 00:00:03 -t 00:03:08' --write-info-json --write-annotation --write-thumbnail --write-sub -f 'best[ext=mp4,height<=1080]+best[filesize<100M]' \"\n",
        "\n",
        "    # call_args = call_args.split() # because call takes a list of strings\n",
        "    # print (call_args)\n",
        "    # call(call_args)\n",
        "    # os.chdir(\"/content/yolo_car_database\")\n",
        "    # run_command('cd \"/content/yolo_car_database\"')\n",
        "    # run_command(call_args)\n",
        "    # os.system(\"cp --recursive '/content/yolo_car_database' '/content/gdrive/My Drive/yolo_car_databe\")\n",
        "    # os.system('pwd && ls ')\n",
        "    # copy_tree(fromDirectory, toDirectory)\n",
        "    # p = Popen(shlex.split(call_args), bufsize=1, universal_newlines=True)\n",
        "    run_command('mkdir /content/ChatGPT_academic_paper/'+command_title)\n",
        "\n",
        "    os.chdir( '/content/ChatGPT_academic_paper/'+command_title+'/')\n",
        "    #run_command(call_args)\n",
        "    # copy_tree('/content/yolo_car_database/'+command_title+'/', '/content/gdrive/My Drive/yolo_car_database/'+command_title+'/')\n",
        "    change_file_name('/content/ChatGPT_academic_paper/'+command_title+'/')\n",
        "    uplaod_mega_nz('/content/ChatGPT_academic_paper/'+command_title+'/','mega',command_title)\n",
        "    try:\n",
        "        # call(call_args)\n",
        "        # run_command('mkdir /content/yolo_car_database/'+command_title)\n",
        "        # os.chdir( '/content/yolo_car_database/'+command_title+'/')\n",
        "        # run_command(call_args)\n",
        "        # copy_tree('/content/yolo_car_database/'+command_title+'/', toDirectory)\n",
        "\n",
        "        # print (call_args)\n",
        "        pp=0\n",
        "\n",
        "    except OSError as e: # this would be \"except OSError, e:\" before Python 2.6\n",
        "        if e.errno != errno.ENOENT: # errno.ENOENT = no such file or directory\n",
        "            raise # re-raise exception if a different error occurred\n",
        "\n",
        "    # return p.poll()\n",
        "\n",
        "# !wget https://github.com/spectrico/car-make-model-classifier-yolo3-python/blob/master/labels.txt\n",
        "\n",
        "i=0\n",
        "#for line in open('/content/yoloOnGoogleColab/car_type_label.txt','r').readlines():\n",
        "    #print (line)\n",
        "    #try:\n",
        "      #Youtube_download_video(line)\n",
        "\n",
        "    #except OSError as e: # this would be \"except OSError, e:\" before Python 2.6\n",
        "        #if e.errno != errno.ENOENT: # errno.ENOENT = no such file or directory\n",
        "            #i=1 # re-raise exception if a different error occurred\n",
        "    #i=i+1\n",
        "# !cp '/content/yolo_car_database' \"gdrive/My Drive/yolo_car_databe\""
      ],
      "metadata": {
        "id": "8Fx5M6zXmTAX",
        "outputId": "f58e6944-cfa4-4349-9cc3-7dbbe0f69864",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory â€˜/content/ChatGPT_academic_paperâ€™: File exists\n",
            "/content/ChatGPT_academic_paper\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!pwd\n",
        "%cd '/content/'\n",
        "from google.colab import drive\n",
        "import os\n",
        "import subprocess\n",
        "from docx import Document\n",
        "from django.utils.text import slugify\n",
        "\n",
        "# Mount Google Drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "def save_academic_paper_with_prompt_megazn(topic, prompt_my,contnet):\n",
        "  # Define the path to the folder in Google Drive\n",
        "  folder_path = r\"/content/ChatGPT_academic_paper/\"\n",
        "\n",
        "  Pdf_Dir= r\"/content/ChatGPT_academic_paper/\"\n",
        "  docx_path= f\"{folder_path}{topic}.docx\"\n",
        "  # Check if the folder exists\n",
        "  if not os.path.exists(folder_path):\n",
        "  # If the folder doesn't exist, create it\n",
        "    os.mkdir(folder_path)\n",
        "\n",
        "\n",
        "  # Replace spaces in the topic with underscores\n",
        "  #topic = topic[:12].replace(\" \", \"_\")\n",
        "  topic = slugify(topic)\n",
        "\n",
        "  # Define the path to the DOCX file in the folder\n",
        "\n",
        "\n",
        "  # Check if the DOCX file exists\n",
        "  if os.path.isfile(docx_path):\n",
        "    # If the DOCX file exists, open it\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"#+str(random.randint(0,9))+\".docx\"\n",
        "    doc = Document(docx_path)\n",
        "  else:\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"\n",
        "    #print(docx_path)\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "    doc = Document()\n",
        "\n",
        "  # Add the generated text to the document\n",
        "  p = doc.add_paragraph(prompt_my)\n",
        "  # Add the generated text to the document\n",
        "  # Add the generated text to the document\n",
        "  p.style = doc.styles['Heading 2']\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Revert the style of the paragraph back to 'Normal'\n",
        "  p = doc.add_paragraph(contnet)\n",
        "  p.style = doc.styles['Normal']\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Convert the DOCX file to a PDF\n",
        "  convert_docx_to_pdf(docx_path,Pdf_Dir)\n",
        "\n",
        "  os.chdir(folder_path)\n",
        "\n",
        "    # copy_tree('/content/yolo_car_database/'+command_title+'/', '/content/gdrive/My Drive/yolo_car_database/'+command_title+'/')\n",
        "\n",
        "  uplaod_mega_nz('/content/ChatGPT_Paper_wrting/')\n",
        "  uplaod_mega_nz('/content/ChatGPT_Paper_wrting/','google_drive')\n",
        "  return docx_path,Pdf_Dir"
      ],
      "metadata": {
        "id": "nv2vAOr8sskq",
        "outputId": "6e3ab39b-7215-4895-ca61-3f818e1bad82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/ChatGPT_academic_paper\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#save_academic_paper(\"Persian_\"+'topic','\\n**'+'choice_translated_prompt'+'**\\n'+\"choice_translated\")\n",
        "topic = TOPIC[:20].replace(\" \", \"_\")\n",
        "topic = slugify(TOPIC[:-5])\n",
        "docx_path = f\"{topic}.docx\"\n",
        "\n",
        "print(docx_path)"
      ],
      "metadata": {
        "id": "a76qNIRHs_gS",
        "outputId": "40a043ca-fe6c-44e6-e20b-5c15c132b4a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "benefit-of-brainstorming-techniques-for-leveraging-chatgpt-for-social-movement-analysis-a-free-and-open-source-app.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qQOCu3GyEFf1"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#I have tried to update the prompt by ChatGPT itself ðŸ‘‡ðŸ‘‡"
      ],
      "metadata": {
        "id": "wxqM4h1fw4fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_main_variables(prompts, variable):\n",
        "   main_variables= main_variables_0\n",
        "   for prompt in prompts:\n",
        "       variables = re.findall(r'\\{(\\w+)\\}', prompt)\n",
        "       for var in variables:\n",
        "           if var == 'TOPIC':\n",
        "               main_variables[var] = variable\n",
        "           else:\n",
        "               main_variables[var] = None\n",
        "\n",
        "   return main_variables"
      ],
      "metadata": {
        "id": "Jd711_MyBgje"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_main_variables(prompts, variable_para, var_content):\n",
        "    main_variables = main_variables_0\n",
        "\n",
        "    new_prompt = prompts[:]  # Create a deep copy of prompts\n",
        "\n",
        "    for i, prompt in enumerate(prompts):\n",
        "        for var in variable_para:\n",
        "            if var == variable_para :\n",
        "                main_variables[var] = var_content\n",
        "                new_prompt[i] = prompt.replace(var, var_content)\n",
        "        for var, value in main_variables.items():\n",
        "             if var == variable_para:\n",
        "                main_variables[var] = var_content\n",
        "                new_prompt[i] = new_prompt[i].replace('{'+var+'}', \"{\"+f\"{var}\"+'}'+f\" which is :{var_content}\")#f\"{{{variable}}}\")\n",
        "\n",
        "\n",
        "    return main_variables, new_prompt\n",
        "#TOPIC='my test topic'\n",
        "main_variables, prompt_new = extract_main_variables(prompts, 'TOPIC', TOPIC)\n",
        "print (\" topic is :\", TOPIC)\n",
        "print(\"main variable is :\", main_variables)\n",
        "print(\"new_prompt is :\", prompt_new)\n",
        "prompts= prompt_new\n",
        "print(\"prompt is :\", prompts)"
      ],
      "metadata": {
        "id": "VLFUpVSA2Pbr",
        "outputId": "c3961687-f66f-4de3-8cb1-aa26e8f2d491",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " topic is : Benefit of Brainstorming techniques for Leveraging ChatGPT for Social Movement Analysis: A Free and Open-Source Approach\n",
            "main variable is : {'TOPIC': 'Benefit of Brainstorming techniques for Leveraging ChatGPT for Social Movement Analysis: A Free and Open-Source Approach', 'PARAGRAPH': 'Doing ChatGPT can generate a comprehensive analysis based on the input prompts, utilizing its language model trained on a diverse range of internet text. for {TOPIC} to estimate effect of Personality of unknown person  on the social movment of :middle east femenism movment  ', 'role': 'brainstorming for social movements analyser'}\n",
            "new_prompt is : ['suggest one report Title wich is related to brainstorming for social movements analyser in less than 15 word, based of This Topic :(Benefit of Brainstorming techniques for Leveraging ChatGPT for Social Movement Analysis: A Free and Open-Source Approach) and the description:(Doing ChatGPT can generate a comprehensive analysis based on the input prompts, utilizing its language model trained on a diverse range of internet text. for {TOPIC} which is :Benefit of Brainstorming techniques for Leveraging ChatGPT for Social Movement Analysis: A Free and Open-Source Approach to estimate effect of Personality of unknown person  on the social movment of :middle east femenism movment  .', '1. Introduction: The role of brainstorming for social movements analyser is crucial in Benefit of Brainstorming techniques for Leveraging ChatGPT for Social Movement Analysis: A Free and Open-Source Approach. The personality traits of unknown person  as described by the Myers-Briggs Type Indicator (MBTI) framework can significantly affect the team dynamics and the success of the middle east femenism movment .', '2. Task: Analyze how the personality traits of unknown person  affected the team dynamics and the success of the middle east femenism movment  using the brainstorming method on Social Identity Model of Collective Action analyser.', '3. Conclusion: After analyzing the personality traits of unknown person , what are your conclusions about their impact on the team dynamics and the success of the middle east femenism movment ?', '4. Introduction: As a President Election Analyser, you need to understand the personality traits of unknown person  as described by the Myers-Briggs Type Indicator (MBTI) framework.', '5. Task: Analyze how the personality traits of unknown person  affected the team dynamics and the success of the middle east femenism movment  using the brainstorming method on Social Identity Model of Collective Action analyser.', '6. Conclusion: After analyzing the personality traits of unknown person , what are your conclusions about their impact on the team dynamics and the success of the middle east femenism movment ?', '7. Introduction: As a Terrorism and Game Theory Analyser, you need to understand the Big Five personality traits of unknown person .', '8. Task: Evaluate how the Big Five personality traits of unknown person  contributed to the effectiveness of the team in the middle east femenism movment  using the brainstorming method on Social Identity Model of Collective Action analyser.', '9. Conclusion: After evaluating the Big Five personality traits of unknown person , what are your conclusions about their contribution to the effectiveness of the team in the middle east femenism movment ?', '10. Introduction: As a President Election Analyser, you need to understand the personality traits of unknown person .', \"11. Task: Examine how the personality traits of unknown person  influenced the team's performance and the outcomes of the middle east femenism movment  using the brainstorming method on Social Identity Model of Collective Action analyser.\", \"12. Conclusion: After examining the personality traits of unknown person , what are your conclusions about their influence on the team's performance and the outcomes of the middle east femenism movment ?\", '13. Introduction: As a Terrorism and Game Theory Analyser, you need to understand the team-building structures developed by unknown person .', '14. Task: Assess how the team-building structures developed by unknown person  contributed to the success of the middle east femenism movment  using the brainstorming method on Social Identity Model of Collective Action analyser.', '15. Conclusion: After assessing the team-building structures developed by unknown person , what are your conclusions about their contribution to the success of the middle east femenism movment ?', '16. Introduction: As a President Election Analyser, you need to understand the personality traits and team-building structures of unknown person .', '17. Task: Discuss how the personality traits and team-building structures of unknown person  affected the social identity of the team and influenced the success of the middle east femenism movment  using the brainstorming method on Social Identity Model of Collective Action analyser.', '18. Conclusion: After discussing the personality traits and team-building structures of unknown person , what are your conclusions about their impact on the social identity of the team and their influence on the success of the middle east femenism movment ?', '19. Introduction: As a President Election Analyser, you need to find the best method of analysis for this task.', '20. Task: Find the best method of analysis for this task.', '21. Conclusion: After finding the best method of analysis for this task, what are your conclusions about its effectiveness in analyzing the personality traits and team-building structures of unknown person ?']\n",
            "prompt is : ['suggest one report Title wich is related to brainstorming for social movements analyser in less than 15 word, based of This Topic :(Benefit of Brainstorming techniques for Leveraging ChatGPT for Social Movement Analysis: A Free and Open-Source Approach) and the description:(Doing ChatGPT can generate a comprehensive analysis based on the input prompts, utilizing its language model trained on a diverse range of internet text. for {TOPIC} which is :Benefit of Brainstorming techniques for Leveraging ChatGPT for Social Movement Analysis: A Free and Open-Source Approach to estimate effect of Personality of unknown person  on the social movment of :middle east femenism movment  .', '1. Introduction: The role of brainstorming for social movements analyser is crucial in Benefit of Brainstorming techniques for Leveraging ChatGPT for Social Movement Analysis: A Free and Open-Source Approach. The personality traits of unknown person  as described by the Myers-Briggs Type Indicator (MBTI) framework can significantly affect the team dynamics and the success of the middle east femenism movment .', '2. Task: Analyze how the personality traits of unknown person  affected the team dynamics and the success of the middle east femenism movment  using the brainstorming method on Social Identity Model of Collective Action analyser.', '3. Conclusion: After analyzing the personality traits of unknown person , what are your conclusions about their impact on the team dynamics and the success of the middle east femenism movment ?', '4. Introduction: As a President Election Analyser, you need to understand the personality traits of unknown person  as described by the Myers-Briggs Type Indicator (MBTI) framework.', '5. Task: Analyze how the personality traits of unknown person  affected the team dynamics and the success of the middle east femenism movment  using the brainstorming method on Social Identity Model of Collective Action analyser.', '6. Conclusion: After analyzing the personality traits of unknown person , what are your conclusions about their impact on the team dynamics and the success of the middle east femenism movment ?', '7. Introduction: As a Terrorism and Game Theory Analyser, you need to understand the Big Five personality traits of unknown person .', '8. Task: Evaluate how the Big Five personality traits of unknown person  contributed to the effectiveness of the team in the middle east femenism movment  using the brainstorming method on Social Identity Model of Collective Action analyser.', '9. Conclusion: After evaluating the Big Five personality traits of unknown person , what are your conclusions about their contribution to the effectiveness of the team in the middle east femenism movment ?', '10. Introduction: As a President Election Analyser, you need to understand the personality traits of unknown person .', \"11. Task: Examine how the personality traits of unknown person  influenced the team's performance and the outcomes of the middle east femenism movment  using the brainstorming method on Social Identity Model of Collective Action analyser.\", \"12. Conclusion: After examining the personality traits of unknown person , what are your conclusions about their influence on the team's performance and the outcomes of the middle east femenism movment ?\", '13. Introduction: As a Terrorism and Game Theory Analyser, you need to understand the team-building structures developed by unknown person .', '14. Task: Assess how the team-building structures developed by unknown person  contributed to the success of the middle east femenism movment  using the brainstorming method on Social Identity Model of Collective Action analyser.', '15. Conclusion: After assessing the team-building structures developed by unknown person , what are your conclusions about their contribution to the success of the middle east femenism movment ?', '16. Introduction: As a President Election Analyser, you need to understand the personality traits and team-building structures of unknown person .', '17. Task: Discuss how the personality traits and team-building structures of unknown person  affected the social identity of the team and influenced the success of the middle east femenism movment  using the brainstorming method on Social Identity Model of Collective Action analyser.', '18. Conclusion: After discussing the personality traits and team-building structures of unknown person , what are your conclusions about their impact on the social identity of the team and their influence on the success of the middle east femenism movment ?', '19. Introduction: As a President Election Analyser, you need to find the best method of analysis for this task.', '20. Task: Find the best method of analysis for this task.', '21. Conclusion: After finding the best method of analysis for this task, what are your conclusions about its effectiveness in analyzing the personality traits and team-building structures of unknown person ?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "\n",
        "def generate_prompt_from_response(previous_response, main_variables):\n",
        "   # Customize this logic based on your needs\n",
        "   # For simplicity, let's use the last 50 characters of the response as the new prompt\n",
        "   new_prompt = previous_response[-50:]\n",
        "\n",
        "   # Replace the main variables in the new prompt\n",
        "   for var, value in main_variables.items():\n",
        "       if value is not None:\n",
        "           new_prompt = new_prompt.replace(value, f\"{{{var}}}\")\n",
        "\n",
        "   return new_prompt\n",
        "\n",
        "# Example usage\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\"\n",
        "\n",
        "prompts_1 = [\n",
        "f\"Find a research topic for a PhD in the area of '{TOPIC}'\",\n",
        "\n",
        "]\n",
        "#prompts_2 = [\n",
        "#   \"I need to find information on renewable energy for a research paper that will be 1,500 words and must include eight sources.\",\n",
        "#   \"The research paper should cover the latest advancements in renewable energy technology.\"\n",
        "#]\n",
        "\n",
        "#main_variables,prompt_new = extract_main_variables(prompts,'TOPIC',TOPIC)\n",
        "#print(main_variables)\n",
        "\n",
        "#previous_response = \"Previous GPT response\"\n",
        "#new_prompt = generate_prompt_from_response(previous_response, main_variables)\n",
        "#print(new_prompt)\n",
        "#print ( prompts)"
      ],
      "metadata": {
        "id": "NYegFb6aq_h8"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Updating the prompt by ChatGPT:ðŸ‘‡ðŸ‘‡"
      ],
      "metadata": {
        "id": "UgzzXkG9wjbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.get_encoding(encoding_name)\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "num_tokens_from_string(\"tiktoken is great!\", \"cl100k_base\")"
      ],
      "metadata": {
        "id": "oJ1QCUr62rtw",
        "outputId": "9f6ad439-b785-4aab-ae77-8344170cbb63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt_update_0(prompt, previous_content, main_variables):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   # Replace the TOPIC variable in the prompt\n",
        "   for var, value in main_variables.items():\n",
        "       if var == 'TOPIC' and value is not None:\n",
        "           prompt = prompt.replace(f\"{{{var}}}\", value)\n",
        "\n",
        "   # Construct the instruction for updating the prompt\n",
        "   instruction = f\"Given the previous content:\\n\\n{previous_content}\\n\\nUpdate the prompt: {prompt}\"\n",
        "\n",
        "   # Create the completion with the instruction\n",
        "   completion = client.completions.create(\n",
        "       model=model_engine,\n",
        "       prompt=instruction,\n",
        "       max_tokens=max_tokens,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "\n",
        "   # Extract and return the updated prompt from the response\n",
        "   updated_prompt = completion.choices[0].text.strip()\n",
        "   return updated_prompt"
      ],
      "metadata": {
        "id": "QbOCQqCDB8xb"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "def generate_prompt_update_a1(prompt_my):\n",
        "  model_engine = \"text-davinci-003\"\n",
        "  max_tokens = 2048\n",
        "\n",
        "  completion = client.completions.create(\n",
        "      model=\"gpt-3.5-turbo-instruct\",\n",
        "      #model=\"curie\"\n",
        "      prompt=prompt_my,\n",
        "      max_tokens=2048,\n",
        "      temperature=0.3,\n",
        "      n=1,\n",
        "      frequency_penalty=0,\n",
        "  )\n",
        "  return completion"
      ],
      "metadata": {
        "id": "WPRw6qJOuaS1"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import openai\n",
        "from openai import RateLimitError\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   api_key = openai_api# \"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\",\n",
        ")\n",
        "def retry_with_exponential_backoff(\n",
        "   func,\n",
        "   initial_delay: float = 1,\n",
        "   exponential_base: float = 2,\n",
        "   jitter: bool = True,\n",
        "   max_retries: int = 10,\n",
        "   errors: tuple = (RateLimitError,),\n",
        "):\n",
        "   \"\"\"Retry a function with exponential backoff.\"\"\"\n",
        "   def wrapper(*args, **kwargs):\n",
        "       # Initialize variables\n",
        "       num_retries = 0\n",
        "       delay = initial_delay\n",
        "       # Loop until a successful response or max_retries is hit or an exception is raised\n",
        "       while True:\n",
        "           try:\n",
        "               return func(*args, **kwargs)\n",
        "           # Retry on specified errors\n",
        "           except errors as e:\n",
        "               # Increment retries\n",
        "               num_retries += 1\n",
        "               # Check if max retries has been reached\n",
        "               if num_retries > max_retries:\n",
        "                  raise Exception(\n",
        "                      f\"Maximum number of retries ({max_retries}) exceeded.\"\n",
        "                  )\n",
        "               # Increment the delay\n",
        "               delay *= exponential_base * (1 + jitter * random.random())\n",
        "               # Sleep for the delay\n",
        "               time.sleep(delay)\n",
        "           # Raise exceptions for any errors not specified\n",
        "           except Exception as e:\n",
        "               raise e\n",
        "   return wrapper\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "\n",
        "@retry_with_exponential_backoff\n",
        "def generate_prompt_update(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "   print(f\"{num_tokens_from_string(prompt_my,model)} prompt tokens counted by num_tokens_from_messages().\")\n",
        "\n",
        "   completion = client.completions.create(\n",
        "     model=\"gpt-3.5-turbo-instruct\",\n",
        "     prompt=prompt_my,\n",
        "     max_tokens=500,\n",
        "     temperature=0.1,\n",
        "     n=1,\n",
        "     frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "\n",
        "@retry_with_exponential_backoff\n",
        "def generate_academic_paper(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "   print(f\"{num_tokens_from_string(prompt_my,model)} prompt tokens counted by num_tokens_from_messages().\")\n",
        "\n",
        "\n",
        "   completion = client.completion.create(\n",
        "     #model=\"gpt-3.5-turbo-instruct\",\n",
        "     model=\"gpt-3.5-turbo-1106\",\n",
        "     prompt=prompt_my,\n",
        "     max_tokens=2048,\n",
        "     temperature=0.3,\n",
        "     n=1,\n",
        "     frequency_penalty=0,\n",
        "   )\n",
        "   return completion"
      ],
      "metadata": {
        "id": "O2TNMQ8eFl8n"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def generate_content(prompts, variables, TOPIC, perviuse_content=\"\"):\n",
        "  # Generate content for each variable\n",
        "  variable_contents = {}\n",
        "\n",
        "\n",
        "  main_variables = main_variables_0\n",
        "  for prompt in prompts:\n",
        "      for var in variables:\n",
        "          if var in prompt:\n",
        "              print(f\"\\n---prompt is ----\\n{prompt}\")\n",
        "              #prompt_my = f\"Generate content for the variable '{var}' in the context of the topic '{TOPIC}'. Please consider the result must be in less than 10 words. The prompt is '{prompt}'. Also the more information for understanding better content is '{perviuse_content}'\"\n",
        "\n",
        "              prompt_my = f\"Generate content for the variable '{var}' in the context of the topic '{TOPIC}'. Please consider the result must be sumerized and as variable for chatgpt academic phd writer assistance. The prompt is '{prompt}'. Also the more information for understanding better content is '{perviuse_content}'\"\n",
        "              content = generate_prompt_update_a1(prompt_my)\n",
        "              for choice in content.choices:\n",
        "                print(\"\\n Result is :\"+choice.text)\n",
        "                variable_contents[var] = choice.text\n",
        "              print(f\"variable_contents[{var}] is: {variable_contents[var]}\")\n",
        "\n",
        "              time.sleep(random.randint(22, 40))\n",
        "\n",
        "  # Replace the variables in the prompts with the generated content\n",
        "  prompt_new = []\n",
        "  for prompt in prompts:\n",
        "      for var, content in variable_contents.items():\n",
        "          prompt = prompt.replace(f\"{{{var}}}\", variable_contents[var])\n",
        "      prompt_new.append(prompt)\n",
        "      print(\"\\n --- Updated prompt is :\\n\"+str(prompt_new))\n",
        "  return prompt_new\n",
        "\n",
        "# Define main variables\n",
        "#TOPIC = \"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"\n",
        "\n",
        "# List of variables\n",
        "variables = [\"RESEARCH_DOMAIN\", \"PARAGRAPH\", \"PARAGRAPHS\", \"TOPIC_SENTENCE\", \"LANGUAGE\", \"ABSTRACT_PARAGRAPH\", \"BIBLIOGRAPHY\", \"THEORY1\", \"THEORY2\", \"RESEARCH_QUESTIONS\", \"ACTION\", \"RESULT_PARAGRAPHS\", \"DATE\", \"NUMBER_OF_DAYS_MONTHS_YEARS\"]\n",
        "\n",
        "# List of prompts\n",
        "#prompts = [\"prompt1\", \"prompt2\", \"prompt3\"] # replace with your actual prompts\n",
        "#perviuse_content= \"test\"\n",
        "# Call the function and store the returned prompts\n",
        "#updated_prompts = generate_content(prompts, variables, TOPIC, perviuse_content)\n",
        "#print(\"Updated Prompts:\", updated_prompts)"
      ],
      "metadata": {
        "id": "uI21enmkhb0n"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def generate_content_2(prompts, variables, TOPIC, perviuse_content=\"\"):\n",
        "  # Generate content for each variable\n",
        "  variable_contents = {}\n",
        "  main_variables = main_variables_0\n",
        "  for prompt in prompts:\n",
        "      for var in variables:\n",
        "          if var in prompt:\n",
        "              print(f\"\\n---prompt is ----\\n{prompt}\")\n",
        "              prompt_my = f\"Generate content for the variable '{var}' in the context of the topic '{TOPIC}'. Please consider the result must be in less than 10 words. The prompt is '{prompt}'. Also the more information for understanding better content is '{perviuse_content}'\"\n",
        "              content = generate_prompt_update_a1(prompt_my)\n",
        "              for choice in content.choices:\n",
        "                print(\"\\n Result is :\"+choice.text)\n",
        "                variable_contents[var] = choice.text\n",
        "              print(f\"variable_contents[{var}] is: {variable_contents[var]}\")\n",
        "\n",
        "              time.sleep(random.randint(22, 40))\n",
        "\n",
        "  main_variables, prompt_new = extract_main_variables(prompts, var, variable_contents[var])\n",
        "\n",
        "  print(\"main variable is :\", main_variables)\n",
        "  print(\"new_prompt is :\", prompt_new)\n",
        "  prompts= prompt_new\n",
        "\n",
        "  # Replace the variables in the prompts with the generated content\n",
        "  prompt_new = []\n",
        "  for prompt in prompts:\n",
        "      for var, content in variable_contents.items():\n",
        "          prompt = prompt.replace(f\"{{{var}}}\", variable_contents[var])\n",
        "      prompt_new.append(prompt)\n",
        "      print(\"\\n --- Updated prompt is :\\n\"+str(prompt_new))\n",
        "  return prompt_new,main_variables\n",
        "\n",
        "# Define main variables\n",
        "#TOPIC = \"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"\n",
        "\n",
        "# List of variables\n",
        "variables = [\"RESEARCH_DOMAIN\", \"PARAGRAPH\", \"PARAGRAPHS\", \"TOPIC_SENTENCE\", \"LANGUAGE\", \"ABSTRACT_PARAGRAPH\", \"BIBLIOGRAPHY\", \"THEORY1\", \"THEORY2\", \"RESEARCH_QUESTIONS\", \"ACTION\", \"RESULT_PARAGRAPHS\", \"DATE\", \"NUMBER_OF_DAYS_MONTHS_YEARS\"]\n",
        "\n",
        "# List of prompts\n",
        "#prompts = [\"prompt1\", \"prompt2\", \"prompt3\"] # replace with your actual prompts\n",
        "#perviuse_content= \"test\"\n",
        "# Call the function and store the returned prompts\n",
        "#updated_prompts = generate_content(prompts, variables, TOPIC, perviuse_content)\n",
        "#print(\"Updated Prompts:\", updated_prompts)"
      ],
      "metadata": {
        "id": "-tAXnnAOkagH"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\" #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\"\n",
        "\n",
        "\n",
        "#topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "#client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   #api_key = \"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\",\n",
        "#)\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "# Create a Translator object\n",
        "translator = Translator()\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "def generate_academic_paper_a0(prompt_my):\n",
        "  model_engine = \"text-davinci-003\"\n",
        "  max_tokens = 2048\n",
        "\n",
        "  completion = client.completions.create(\n",
        "      model=\"gpt-3.5-turbo-instruct\",\n",
        "      prompt=prompt_my,\n",
        "      max_tokens=2048,\n",
        "      temperature=0.3,\n",
        "      n=1,\n",
        "      frequency_penalty=0,\n",
        "  )\n",
        "  return completion"
      ],
      "metadata": {
        "id": "44bkCJOHtmuJ"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time,random\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   api_key = openai_api#\"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\",\n",
        ")\n",
        "global k\n",
        "k=0\n",
        "def generate_papers(prompts, perviuse_content, perviuse_try_numner):\n",
        "  choice_text_all=[]\n",
        "  global prompt_Word_Topic,k\n",
        "  prompt_Word_Topic_1 = prompt_Word_Topic\n",
        "\n",
        "\n",
        "  for i in range(perviuse_try_numner, len(prompts), 20):\n",
        "     # Slice the prompts list to get the next 20 prompts\n",
        "     print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "\n",
        "     batch = prompts[i:i+20]\n",
        "     print(\"batch is \",batch)\n",
        "\n",
        "\n",
        "\n",
        "     for prompt in batch:\n",
        "\n",
        "         # Print the prompt\n",
        "         print(\"prompt is \",list({prompt}))\n",
        "\n",
        "         updated_prompts = generate_content(list({prompt}), variables, TOPIC, perviuse_content)\n",
        "         print(\"Updated Prompts:\", updated_prompts)\n",
        "\n",
        "\n",
        "\n",
        "         time.sleep(random.randint(22, 40))\n",
        "         response = generate_academic_paper_a0(updated_prompts)\n",
        "         print(\"\\nGenerated Academic Paper:\")\n",
        "         print(\"========================\\n\")\n",
        "         for choice in response.choices:\n",
        "           print(choice.text)\n",
        "           choice_in_loop = choice.text\n",
        "           choice_text_all.append(choice.text)\n",
        "\n",
        "\n",
        "         #save_academic_paper(topic,'\\n--------**\\n'+updated_prompts+'/n-------**\\n'+choice.text)\n",
        "\n",
        "         if k == 0 :\n",
        "            prompt_Word_Topic_1[0] = choice.text\n",
        "            prompt_Word_Topic_1[0] = prompt_Word_Topic_1[0].replace ( '\"','')\n",
        "            print ('Prompt for topic is',prompt_Word_Topic_1[0]  )\n",
        "\n",
        "            save_academic_paper_with_prompt(TOPIC[:20]+\"_Prompt\",''.join(prompt_Word_Topic_1[k]),\"\",perviuse_try_numner)\n",
        "            save_academic_paper_with_prompt_Tile(TOPIC[:20]+\"_T\",''.join(prompt_Word_Topic_1[k]),\"\",perviuse_try_numner)\n",
        "\n",
        "         else :\n",
        "            save_academic_paper_with_prompt(TOPIC[:20]+\"_Prompt\",'\\n**<<<  ChatGPT Prompt is:\\n'+''.join(updated_prompts)+'\\n>>>**\\n',choice.text,perviuse_try_numner)\n",
        "            save_academic_paper_with_prompt_Tile(TOPIC[:20]+'_T','\\n'+''.join(prompt_Word_Topic_1[k])+'\\n',choice.text,perviuse_try_numner)\n",
        "\n",
        "\n",
        "\n",
        "         save_academic_paper_with_prompt_megazn(TOPIC[:20],'\\n**<<<  ChatGPT Prompt is:\\n'+''.join(updated_prompts)+'\\n>>>**\\n',choice.text)\n",
        "         #save_academic_paper_with_prompt_megazn(TOPIC[:20],'\\n**<<<  ChatGPT Prompt is:\\n'+''.join(updated_prompts)+'\\n>>>**\\n',choice.text, 'google_drive')\n",
        "         if hasattr(choice, 'choices'):\n",
        "             extract_text(choice)\n",
        "\n",
        "         perviuse_content = choice_in_loop\n",
        "         print(\"\\n end of loop\")\n",
        "         print(\"========================\\n\")\n",
        "\n",
        "         time.sleep(random.randint(22, 40))\n",
        "         perviuse_try_numner = perviuse_try_numner+1\n",
        "         k=k+1\n",
        "  return choice_text_all,perviuse_try_numner\n",
        "\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\" #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\""
      ],
      "metadata": {
        "id": "Uf6RCPBz3aqJ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Final Results ðŸ‘‡ðŸŒ¹ðŸŒ±"
      ],
      "metadata": {
        "id": "xHPMNDjfToIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from django.utils.text import slugify\n",
        "\n",
        "\n",
        "\n",
        "def main_generate_papers(TOPIC, prompts, perviuse_content, perviuse_try_numner):\n",
        "    if not perviuse_try_numner:\n",
        "        perviuse_try_numner = 0\n",
        "        perviuse_content = ['fist step']\n",
        "\n",
        "    elif (perviuse_try_numner == len(prompts)):\n",
        "        perviuse_try_numner = 0\n",
        "        perviuse_content = ['fist step']\n",
        "\n",
        "    generate_papers(prompts, perviuse_content, perviuse_try_numner)\n",
        "\n",
        "    return perviuse_content, perviuse_try_numner\n",
        "\n",
        "topic = TOPIC_CLASS()\n",
        "\n",
        "if not topic.perviuse_try_numner:\n",
        "    topic.perviuse_try_numner = 0\n",
        "    topic.perviuse_content = ['fist step']\n",
        "\n",
        "elif (topic.perviuse_try_numner == len(prompts)):\n",
        "    topic.perviuse_try_numner = 0\n",
        "    topic.perviuse_content = ['fist step']\n",
        "\n",
        "topic.topic = TOPIC\n",
        "main_generate_papers(topic.topic, prompts, topic.perviuse_content, topic.perviuse_try_numner)"
      ],
      "metadata": {
        "id": "-YbWDEd4WzDq",
        "outputId": "facbad95-3260-4e87-867c-a0f6d9094d8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I is  0  Len of prompt Is: 22\n",
            "batch is  ['suggest one report Title wich is related to brainstorming for social movements analyser in less than 15 word, based of This Topic :(Benefit of Brainstorming techniques for Leveraging ChatGPT for Social Movement Analysis: A Free and Open-Source Approach) and the description:(Doing ChatGPT can generate a comprehensive analysis based on the input prompts, utilizing its language model trained on a diverse range of internet text. for {TOPIC} which is :Benefit of Brainstorming techniques for Leveraging ChatGPT for Social Movement Analysis: A Free and Open-Source Approach to estimate effect of Personality of unknown person  on the social movment of :middle east femenism movment  .', '1. Introduction: The role of brainstorming for social movements analyser is crucial in Benefit of Brainstorming techniques for Leveraging ChatGPT for Social Movement Analysis: A Free and Open-Source Approach. The personality traits of unknown person  as described by the Myers-Briggs Type Indicator (MBTI) framework can significantly affect the team dynamics and the success of the middle east femenism movment .', '2. Task: Analyze how the personality traits of unknown person  affected the team dynamics and the success of the middle east femenism movment  using the brainstorming method on Social Identity Model of Collective Action analyser.', '3. Conclusion: After analyzing the personality traits of unknown person , what are your conclusions about their impact on the team dynamics and the success of the middle east femenism movment ?', '4. Introduction: As a President Election Analyser, you need to understand the personality traits of unknown person  as described by the Myers-Briggs Type Indicator (MBTI) framework.', '5. Task: Analyze how the personality traits of unknown person  affected the team dynamics and the success of the middle east femenism movment  using the brainstorming method on Social Identity Model of Collective Action analyser.', '6. Conclusion: After analyzing the personality traits of unknown person , what are your conclusions about their impact on the team dynamics and the success of the middle east femenism movment ?', '7. Introduction: As a Terrorism and Game Theory Analyser, you need to understand the Big Five personality traits of unknown person .', '8. Task: Evaluate how the Big Five personality traits of unknown person  contributed to the effectiveness of the team in the middle east femenism movment  using the brainstorming method on Social Identity Model of Collective Action analyser.', '9. Conclusion: After evaluating the Big Five personality traits of unknown person , what are your conclusions about their contribution to the effectiveness of the team in the middle east femenism movment ?', '10. Introduction: As a President Election Analyser, you need to understand the personality traits of unknown person .', \"11. Task: Examine how the personality traits of unknown person  influenced the team's performance and the outcomes of the middle east femenism movment  using the brainstorming method on Social Identity Model of Collective Action analyser.\", \"12. Conclusion: After examining the personality traits of unknown person , what are your conclusions about their influence on the team's performance and the outcomes of the middle east femenism movment ?\", '13. Introduction: As a Terrorism and Game Theory Analyser, you need to understand the team-building structures developed by unknown person .', '14. Task: Assess how the team-building structures developed by unknown person  contributed to the success of the middle east femenism movment  using the brainstorming method on Social Identity Model of Collective Action analyser.', '15. Conclusion: After assessing the team-building structures developed by unknown person , what are your conclusions about their contribution to the success of the middle east femenism movment ?', '16. Introduction: As a President Election Analyser, you need to understand the personality traits and team-building structures of unknown person .', '17. Task: Discuss how the personality traits and team-building structures of unknown person  affected the social identity of the team and influenced the success of the middle east femenism movment  using the brainstorming method on Social Identity Model of Collective Action analyser.', '18. Conclusion: After discussing the personality traits and team-building structures of unknown person , what are your conclusions about their impact on the social identity of the team and their influence on the success of the middle east femenism movment ?', '19. Introduction: As a President Election Analyser, you need to find the best method of analysis for this task.']\n",
            "prompt is  ['suggest one report Title wich is related to brainstorming for social movements analyser in less than 15 word, based of This Topic :(Benefit of Brainstorming techniques for Leveraging ChatGPT for Social Movement Analysis: A Free and Open-Source Approach) and the description:(Doing ChatGPT can generate a comprehensive analysis based on the input prompts, utilizing its language model trained on a diverse range of internet text. for {TOPIC} which is :Benefit of Brainstorming techniques for Leveraging ChatGPT for Social Movement Analysis: A Free and Open-Source Approach to estimate effect of Personality of unknown person  on the social movment of :middle east femenism movment  .']\n",
            "\n",
            " --- Updated prompt is :\n",
            "['suggest one report Title wich is related to brainstorming for social movements analyser in less than 15 word, based of This Topic :(Benefit of Brainstorming techniques for Leveraging ChatGPT for Social Movement Analysis: A Free and Open-Source Approach) and the description:(Doing ChatGPT can generate a comprehensive analysis based on the input prompts, utilizing its language model trained on a diverse range of internet text. for {TOPIC} which is :Benefit of Brainstorming techniques for Leveraging ChatGPT for Social Movement Analysis: A Free and Open-Source Approach to estimate effect of Personality of unknown person  on the social movment of :middle east femenism movment  .']\n",
            "Updated Prompts: ['suggest one report Title wich is related to brainstorming for social movements analyser in less than 15 word, based of This Topic :(Benefit of Brainstorming techniques for Leveraging ChatGPT for Social Movement Analysis: A Free and Open-Source Approach) and the description:(Doing ChatGPT can generate a comprehensive analysis based on the input prompts, utilizing its language model trained on a diverse range of internet text. for {TOPIC} which is :Benefit of Brainstorming techniques for Leveraging ChatGPT for Social Movement Analysis: A Free and Open-Source Approach to estimate effect of Personality of unknown person  on the social movment of :middle east femenism movment  .']\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "\"Unleashing ChatGPT: Leveraging Brainstorming for Middle East Feminism Movement Analysis\"\n",
            "Prompt for topic is \n",
            "\n",
            "Unleashing ChatGPT: Leveraging Brainstorming for Middle East Feminism Movement Analysis\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  ['1. Introduction: The role of brainstorming for social movements analyser is crucial in Benefit of Brainstorming techniques for Leveraging ChatGPT for Social Movement Analysis: A Free and Open-Source Approach. The personality traits of unknown person  as described by the Myers-Briggs Type Indicator (MBTI) framework can significantly affect the team dynamics and the success of the middle east femenism movment .']\n",
            "\n",
            " --- Updated prompt is :\n",
            "['1. Introduction: The role of brainstorming for social movements analyser is crucial in Benefit of Brainstorming techniques for Leveraging ChatGPT for Social Movement Analysis: A Free and Open-Source Approach. The personality traits of unknown person  as described by the Myers-Briggs Type Indicator (MBTI) framework can significantly affect the team dynamics and the success of the middle east femenism movment .']\n",
            "Updated Prompts: ['1. Introduction: The role of brainstorming for social movements analyser is crucial in Benefit of Brainstorming techniques for Leveraging ChatGPT for Social Movement Analysis: A Free and Open-Source Approach. The personality traits of unknown person  as described by the Myers-Briggs Type Indicator (MBTI) framework can significantly affect the team dynamics and the success of the middle east femenism movment .']\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            " Therefore, it is important to have a systematic and effective approach to analyze and understand the personalities of individuals involved in social movements.\n",
            "\n",
            "Brainstorming is a technique that involves generating ideas and solutions through group discussion and collaboration. It can be a powerful tool for social movement analyzers as it allows for the exploration of different perspectives and ideas, leading to a more comprehensive understanding of the movement and its participants.\n",
            "\n",
            "2. Encourages Diverse Perspectives: One of the main benefits of brainstorming for social movement analysis is that it encourages the participation of individuals from diverse backgrounds and perspectives. This is crucial for understanding the complexity of social movements, as it allows for the consideration of different viewpoints and experiences. By incorporating a variety of perspectives, brainstorming can help to identify potential blind spots and biases in the analysis.\n",
            "\n",
            "3. Fosters Collaboration and Teamwork: Brainstorming also promotes collaboration and teamwork among individuals involved in the social movement analysis. By working together to generate ideas and solutions, team members can build trust and develop a deeper understanding of each other's strengths and weaknesses. This can lead to more effective communication and decision-making within the team.\n",
            "\n",
            "4. Generates Creative Solutions: Social movements are often complex and multifaceted, requiring innovative and creative solutions. Brainstorming provides a structured platform for individuals to freely express their ideas and think outside the box. This can lead to the generation of unique and creative solutions that may not have been considered otherwise.\n",
            "\n",
            "5. Allows for Open and Safe Communication: In order for social movement analysis to be effective, it is important for all team members to feel comfortable expressing their thoughts and opinions. Brainstorming provides a safe and open environment for individuals to share their ideas without fear of judgment or criticism. This can lead to more honest and open communication, allowing for a deeper understanding of the movement and its participants.\n",
            "\n",
            "6. Utilizes ChatGPT for Efficient Analysis: ChatGPT is a free and open-source tool that uses artificial intelligence to generate human-like text responses. By leveraging this technology, brainstorming sessions can be more efficient and effective in analyzing social movements. ChatGPT can help to generate a wide range of responses and perspectives, providing a more comprehensive analysis of the movement.\n",
            "\n",
            "In conclusion, brainstorming is a valuable technique for social movement analysis as it encourages diverse perspectives, fosters collaboration and teamwork, generates creative solutions, allows for open and safe communication, and can be enhanced by leveraging ChatGPT. By utilizing this approach, social movement analyzers can gain a deeper understanding of the personalities and dynamics within the movement, leading to more effective strategies and solutions. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  ['2. Task: Analyze how the personality traits of unknown person  affected the team dynamics and the success of the middle east femenism movment  using the brainstorming method on Social Identity Model of Collective Action analyser.']\n",
            "\n",
            " --- Updated prompt is :\n",
            "['2. Task: Analyze how the personality traits of unknown person  affected the team dynamics and the success of the middle east femenism movment  using the brainstorming method on Social Identity Model of Collective Action analyser.']\n",
            "Updated Prompts: ['2. Task: Analyze how the personality traits of unknown person  affected the team dynamics and the success of the middle east femenism movment  using the brainstorming method on Social Identity Model of Collective Action analyser.']\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "Personality traits play a crucial role in shaping team dynamics and the success of any movement. In the case of the Middle East feminism movement, the personality traits of an unknown person had a significant impact on the team dynamics and the success of the movement. To analyze this impact, we will use the brainstorming method on the Social Identity Model of Collective Action (SIMCA) analyzer.\n",
            "\n",
            "1. Brainstorming on the Social Identity Model of Collective Action (SIMCA) analyzer:\n",
            "\n",
            "- The Social Identity Model of Collective Action (SIMCA) is a theoretical framework that explains how individuals come together to form a collective identity and engage in collective action to achieve a common goal.\n",
            "- This model suggests that individuals' social identities, which are based on their group memberships, play a crucial role in motivating them to engage in collective action.\n",
            "- The SIMCA analyzer helps us understand how different factors, including personality traits, can influence the success of collective action.\n",
            "\n",
            "2. Personality traits of the unknown person:\n",
            "\n",
            "- The unknown person in question is assumed to be a leader or a key member of the Middle East feminism movement.\n",
            "- Based on the context, we can assume that this person possesses certain personality traits that have influenced the team dynamics and the success of the movement.\n",
            "- These traits could include charisma, determination, assertiveness, and passion for the cause.\n",
            "\n",
            "3. Impact on team dynamics:\n",
            "\n",
            "- The personality traits of the unknown person have a significant impact on team dynamics.\n",
            "- Charismatic leaders can inspire and motivate team members, leading to a more cohesive and united team.\n",
            "- Determined and assertive individuals can drive the team towards their goals and maintain focus, even in the face of challenges or setbacks.\n",
            "- Passionate individuals can create a sense of urgency and commitment within the team, leading to increased productivity and collaboration.\n",
            "\n",
            "4. Impact on the success of the movement:\n",
            "\n",
            "- The personality traits of the unknown person have also influenced the success of the Middle East feminism movement.\n",
            "- Charismatic leaders can attract more followers and garner support for the cause, leading to a larger and more influential movement.\n",
            "- Determined and assertive individuals can overcome obstacles and push for change, leading to tangible results.\n",
            "- Passionate individuals can create a sense of unity and solidarity within the movement, making it more effective in achieving its goals.\n",
            "\n",
            "5. Conclusion:\n",
            "\n",
            "- In conclusion, the personality traits of the unknown person have played a crucial role in shaping the team dynamics and the success of the Middle East feminism movement.\n",
            "- Their charisma, determination, assertiveness, and passion have motivated and inspired team members, leading to a more cohesive and productive team.\n",
            "- These traits have also influenced the success of the movement by attracting more followers, overcoming obstacles, and creating a sense of unity and solidarity. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  ['3. Conclusion: After analyzing the personality traits of unknown person , what are your conclusions about their impact on the team dynamics and the success of the middle east femenism movment ?']\n",
            "\n",
            " --- Updated prompt is :\n",
            "['3. Conclusion: After analyzing the personality traits of unknown person , what are your conclusions about their impact on the team dynamics and the success of the middle east femenism movment ?']\n",
            "Updated Prompts: ['3. Conclusion: After analyzing the personality traits of unknown person , what are your conclusions about their impact on the team dynamics and the success of the middle east femenism movment ?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating the sound by OpenAI: ðŸ‘‡ðŸ‘‡\n",
        "\n",
        "https://platform.openai.com/docs/guides/text-to-speech"
      ],
      "metadata": {
        "id": "2ctHZTF6wj0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"/content/ChatGPT_academic_paper\"\n",
        "from openai import OpenAI\n",
        "from django.utils.text import slugify\n",
        "\n",
        "\n",
        "client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   api_key = openai_api#\"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\",\n",
        ")\n",
        "\n",
        "response = client.audio.speech.create(\n",
        "    model=\"tts-1\",\n",
        "    voice=\"alloy\",\n",
        "    input=TOPIC#\"Hello world! This is a streaming test.\",\n",
        ")\n",
        "TOPIC_S = slugify(TOPIC)\n",
        "\n",
        "Sound_File=folder_path+f\"{TOPIC[:40]}\"+str(random.randint (0,1000))+\".mp3\"\n",
        "\n",
        "\n",
        "print (\"save folder is: \",Sound_File)#/content/drive/MyDrive/ChatGPT_Paper_wrting/\"+f\"{TOPIC_S}\"+str(random.randint (0,1000))+\".mp3\") #\"/\"+\"output.mp3\"\n",
        "#response.stream_to_file(\"/content/drive/My Drive/ChatGPT_Paper_wrting/\"+f\"{TOPIC_S}\"+str(random.randint (0,1000))+\".mp3\")#\"/\"+\"output.mp3\")\n",
        "\n",
        "response.stream_to_file(Sound_File)\n",
        "print ( 'topic is:',TOPIC)\n",
        "#print (\"save folder is: /content/drive/MyDrive/ChatGPT_Paper_wrting/\"+f\"{TOPIC[:40]}\"+str(random.randint (0,1000))+\".mp3\") #\"/\"+\"output.mp3\""
      ],
      "metadata": {
        "id": "d2YvDx5DwS7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from IPython.display import HTML\n",
        "\n",
        "def upload_files_to_transfer_sh(file_paths):\n",
        "  urls = []\n",
        "  html_content = \"<form>\"\n",
        "  for file_path in file_paths:\n",
        "      with open(file_path, 'rb') as file:\n",
        "          response = requests.post('https://transfer.sh/', files={'file': file})\n",
        "          response.raise_for_status()\n",
        "          urls.append(response.text)\n",
        "          html_content += f\"<p>File: {file_path} <br> And Upload URL is: <a href='{response.text}'>{response.text}</a></p>\"\n",
        "  html_content += \"</form>\"\n",
        "  return urls, html_content\n",
        "\n",
        "file_paths = [Sound_File, docx_path, docx_path.replace('docx','pdf')]\n",
        "urls, html_content = upload_files_to_transfer_sh(file_paths)\n",
        "for url in urls:\n",
        "  print(url)\n",
        "HTML(html_content)"
      ],
      "metadata": {
        "id": "JQVNA0T95rgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Emailing the content ðŸ‘‡ðŸ¢ðŸŒ¸"
      ],
      "metadata": {
        "id": "bIYfHcTCp9Qn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi-mail"
      ],
      "metadata": {
        "id": "Pku-t3QT_AsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "from fastapi_mail import FastMail, MessageSchema, ConnectionConfig\n",
        "import os\n",
        "import base64\n",
        "import zipfile\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "conf = ConnectionConfig(\n",
        "  MAIL_USERNAME = \"Your_Email\",\n",
        "  MAIL_PASSWORD = \"Your_Email_Password\",\n",
        "  MAIL_FROM = \"Your_Email\",\n",
        "  MAIL_PORT = 587,\n",
        "  MAIL_SERVER = \"smtp.gmail.com\",\n",
        "  MAIL_TLS = True,\n",
        "  MAIL_SSL = False,\n",
        "  USE_CREDENTIALS = True\n",
        ")\n",
        "\n",
        "@app.post(\"/send_email_summary/\")\n",
        "async def send_email_summary(news_content_summary: str, news_data_with_text_df_1_html: str, attachments: list):\n",
        "  # Create a zip file from the attachments\n",
        "  with zipfile.ZipFile('attachments.zip', 'w') as zipf:\n",
        "      for attachment in attachments:\n",
        "          zipf.write(attachment)\n",
        "\n",
        "  # Prepare attachments\n",
        "  with open('attachments.zip', 'rb') as f:\n",
        "      content = f.read()\n",
        "      encoded_content = base64.b64encode(content).decode()\n",
        "      attachments_data = [\n",
        "          {\n",
        "              'ContentType': 'application/zip',\n",
        "              'Filename': 'attachments.zip',\n",
        "              'Base64Content': encoded_content\n",
        "          }\n",
        "      ]\n",
        "\n",
        "  message = MessageSchema(\n",
        "      subject=\"GPT News Summary of Today\",\n",
        "      recipients=[\"Your_Email\"],\n",
        "      body=\"<h3>Here is the result of our code for today.</h3>{}<br><br> \\\n",
        "            <h3>GPT Gent Summary Sources</h3>{}<br><br> \\\n",
        "            <h4> The PDF,DICX and MP3 file has been added at attachment</h4>\".format(news_content_summary, news_data_with_text_df_1_html),\n",
        "      attachments=attachments_data\n",
        "  )\n",
        "\n",
        "  fm = FastMail(conf)\n",
        "  await fm.send_message(message)\n",
        "  return {\"message\": \"Email Sent\"}"
      ],
      "metadata": {
        "id": "n_r7b-Ud_FKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perviuse_content=''\n",
        "news_content_summary = 'Summary of the news'\n",
        "news_data_with_text_df_1_html = 'HTML table of news sources'\n",
        "attachments = [Sound_File, docx_path, docx_path.replace('docx','pdf')]\n",
        "\n",
        "send_email_summary(news_content_summary, news_data_with_text_df_1_html, attachments)"
      ],
      "metadata": {
        "id": "i4QMJkj8AF6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install mailjet_rest\n",
        "\n",
        "\n",
        "from mailjet_rest import Client\n",
        "import os\n",
        "import base64\n",
        "import zipfile\n",
        "\n",
        "def send_email_summary(api_key, api_secret, news_content_summary, news_data_with_text_df_1_html , attachments):\n",
        "  mailjet = Client(auth=(api_key, api_secret), version='v3.1')\n",
        "\n",
        "  # Create a zip file from the attachments\n",
        "  with zipfile.ZipFile('attachments.zip', 'w') as zipf:\n",
        "      for attachment in attachments:\n",
        "          zipf.write(attachment)\n",
        "\n",
        "  # Prepare attachments\n",
        "  attachments_data = []\n",
        "  with open('attachments.zip', 'rb') as f:\n",
        "      content = f.read()\n",
        "      encoded_content = base64.b64encode(content).decode()\n",
        "      attachments_data.append({\n",
        "          'ContentType': 'application/zip',\n",
        "          'Filename': 'attachments.zip',\n",
        "          'Base64Content': encoded_content\n",
        "      })\n",
        "\n",
        "  data = {\n",
        "    'Messages': [\n",
        "      {\n",
        "        \"From\": {\n",
        "          \"Email\": \"easonlai888@gmail.com\",\n",
        "          \"Name\": \"Eason\"\n",
        "        },\n",
        "        \"To\": [\n",
        "          {\n",
        "            \"Email\": \"Your_Email\",\n",
        "            \"Name\": \"Eason\"\n",
        "          }\n",
        "        ],\n",
        "        \"Subject\": \"GPT News Summary of Today\",\n",
        "        \"HTMLPart\": \"<h3>Here is the result of our code for today.</h3>{}<br><br> \\\n",
        "                  <h3>GPT Gent Summary Sources</h3>{}<br><br> \\\n",
        "                  <h4> The PDF,DICX and MP3 file has been added at attachment</h4>\",#.format(news_content_summary, news_data_with_text_df_1_html),\n",
        "        \"Attachments\": attachments_data\n",
        "      }\n",
        "    ]\n",
        "  }\n",
        "  result = mailjet.send.create(data=data)\n",
        "  print(result.status_code)\n",
        "  print(result.json())"
      ],
      "metadata": {
        "id": "lmNpBP9vrrSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = openai_api\n",
        "api_secret = 'PLEASE_ENTER_YOUR_OWNED_MAILJET_API_KEY_SECRET'\n",
        "perviuse_content=''\n",
        "news_content_summary = 'Summary of the news'\n",
        "news_data_with_text_df_1_html = 'HTML table of news sources'\n",
        "attachments = [Sound_File, docx_path, docx_path.replace('docx','pdf')]\n",
        "\n",
        "send_email_summary(api_key, api_secret, perviuse_content, news_data_with_text_df_1_html, attachments)"
      ],
      "metadata": {
        "id": "OZMmRxJyr1QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Only update the Prompt by the help of ChatGPT:ðŸ‘‡ðŸ‘‡"
      ],
      "metadata": {
        "id": "BAiQz23MlpUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define main variables\n",
        "#TOPIC = \"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"\n",
        "\n",
        "# List of variables\n",
        "variables = [\"RESEARCH_DOMAIN\", \"PARAGRAPH\", \"PARAGRAPHS\", \"TOPIC_SENTENCE\", \"LANGUAGE\", \"ABSTRACT_PARAGRAPH\", \"BIBLIOGRAPHY\", \"THEORY1\", \"THEORY2\", \"RESEARCH_QUESTIONS\", \"ACTION\", \"RESULT_PARAGRAPHS\", \"DATE\", \"NUMBER_OF_DAYS_MONTHS_YEARS\"]\n",
        "\n",
        "# Generate content for each variable\n",
        "variable_contents = {}\n",
        "for prompt in prompts:\n",
        "   for var in variables:\n",
        "       if var in prompt:\n",
        "           prompt = f\"Generate content for the variable '{var}' based on the topic '{TOPIC}'. For this prompt '{prompt}'\"\n",
        "           content= generate_academic_paper(prompt)\n",
        "           for choice in content.choices:\n",
        "               print(choice.text)\n",
        "               variable_contents[var] = choice.text\n",
        "           print(\"variable_contents[var] is: \",variable_contents[var])\n",
        "\n",
        "# Replace the variables in the prompts with the generated content\n",
        "for prompt in prompts:\n",
        "   for var, content in variable_contents.items():\n",
        "       prompt = prompt.replace(f\"{{{var}}}\", content)\n",
        "print(\"Updated Prompt:\", prompt)"
      ],
      "metadata": {
        "id": "kH3LygdiXsPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt_update_a3(prompt, previous_content):\n",
        "    model_engine = \"text-davinci-003\"\n",
        "    max_tokens = 2048\n",
        "\n",
        "    # Construct the instruction for updating the prompt\n",
        "    instruction = f\"Given the previous content:\\n\\n{previous_content}\\n\\nUpdate the prompt: {prompt}\"\n",
        "\n",
        "    # Create the completion with the instruction\n",
        "    completion = client.completions.create(\n",
        "        model=model_engine,\n",
        "        prompt=instruction,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=0.3,\n",
        "        n=1,\n",
        "        frequency_penalty=0,\n",
        "    )\n",
        "\n",
        "    # Extract and return the updated prompt from the response\n",
        "    updated_prompt = completion.choices[0].text.strip()\n",
        "    return updated_prompt\n",
        "# Inside your loop\n",
        "for prompt in prompts:\n",
        "    print(\"Original Prompt:\", prompt)\n",
        "    response = generate_academic_paper_a2(prompt)\n",
        "    previous_content = response.choices[0].text.strip()\n",
        "    updated_prompt = generate_prompt_update_2(prompt, previous_content)\n",
        "    print(\"Updated Prompt:\", updated_prompt)\n",
        "\n",
        "    # Continue with the rest of your processing\n",
        "    # ..."
      ],
      "metadata": {
        "id": "KviSdMwzwqAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# with no translation for become faster answer:ðŸ‘‡ðŸ‘‡ðŸ™"
      ],
      "metadata": {
        "id": "iuTPp4YYBg2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\"\n",
        "#topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key = openai_api#\"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\",\n",
        ")\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "# Create a Translator object\n",
        "translator = Translator()\n",
        "\n",
        "\n",
        "# Function to generate an academic paper\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "def generate_academic_paper_a2(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   completion = client.completions.create(\n",
        "       model=\"gpt-3.5-turbo-instruct\",\n",
        "       prompt=prompt_my,\n",
        "       max_tokens=2048,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "choice_text_all=[]\n",
        "\n",
        "import time\n",
        "# Function to generate academic papers for given prompts\n",
        "# Function to generate academic papers for given prompts\n",
        "def generate_papers(prompts):\n",
        "   for i in range(0, len(prompts), 20):\n",
        "       # Slice the prompts list to get the next 20 prompts\n",
        "       print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "\n",
        "       batch = prompts[i:i+20]\n",
        "       print(\"batch is \",batch)\n",
        "   #for j in range ( 0, Len(batch)):\n",
        "       # Generate papers for the next 20 prompts\n",
        "       for prompt in batch:\n",
        "      #   for prompt in prompt1:\n",
        "           # Print the prompt\n",
        "           print(\"prompt is \", prompt)\n",
        "           response = generate_academic_paper_a2(prompt)\n",
        "           print(\"\\nGenerated Academic Paper:\")\n",
        "           print(\"========================\\n\")\n",
        "           #print(response)\n",
        "           for choice in response.choices:\n",
        "             print(choice.text)\n",
        "             choice_text_all.append(choice.text)\n",
        "\n",
        "             # Translate the generated text to Persian\n",
        "         #  choice_translated = translate_to_persian(choice.text) #translator.translate(choice.text, dest='fa')\n",
        "         # choice_translated_prompt = translate_to_persian(prompt)#translator.translate(prompt, dest='fa')\n",
        "\n",
        "         #    print(\"\\n-----\\n Translated is \",choice_translated)\n",
        "         #    save_academic_paper(\"Persian_\"+topic,'\\n**'+choice_translated_prompt+'**\\n'+choice_translated)\n",
        "             save_academic_paper(topic,'\\n--------**\\n'+prompt+'/n-------**\\n'+choice.text)\n",
        "             # Recursively call the function for the nested Completion objects\n",
        "             if hasattr(choice, 'choices'):\n",
        "               extract_text(choice)\n",
        "\n",
        "           #generated_text = response.choices[0].text\n",
        "           # Print the generated text\n",
        "           #print(generated_text)\n",
        "           print(\"\\n end of loop\")\n",
        "           print(\"========================\\n\")\n",
        "\n",
        "           #print(\"loop\")\n",
        "       # Wait for a short period of time before sending the next batch of prompts\n",
        "           time.sleep(40)\n",
        "   return choice_text_all#,choice.translated\n",
        "\n",
        "# Generate academic papers for the given prompts\n",
        "generate_papers(prompts)"
      ],
      "metadata": {
        "id": "rl16DSYABo9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SETUP COLAB for run Streamlit\n",
        "!npm install localtunnel\n",
        "!curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "GRn7OkOUjcdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DL Translate\n",
        "A deep learning-based translation library built on Huggingface transformers and Facebook's mBART-Large\n",
        "\n",
        "https://colab.research.google.com/github/xhluca/dl-translate/blob/main/demos/colab_demo.ipynb#scrollTo=qdefSjR_YIiG"
      ],
      "metadata": {
        "id": "_I5yn6CCZdMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q dl-translate"
      ],
      "metadata": {
        "id": "c7-q341UWsr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dl_translate as dlt\n",
        "mt = dlt.TranslationModel('mbart50')"
      ],
      "metadata": {
        "id": "gtQcnXabalaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dl_translate as dlt\n",
        "\n",
        "def translate_to_persian(text):\n",
        "  # Initialize the translation model\n",
        "  #mt = dlt.TranslationModel('mbart50')\n",
        "\n",
        "  # Translate the text\n",
        "  translated = mt.translate(text, source=dlt.lang.ENGLISH, target=dlt.lang.PERSIAN)\n",
        "\n",
        "  return translated"
      ],
      "metadata": {
        "id": "iOX6FGFWaFqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key = openai_api#\"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\",\n",
        ")\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "# Create a Translator object\n",
        "translator = Translator()\n",
        "\n",
        "\n",
        "# Function to generate an academic paper\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=10, max_time=600)\n",
        "def generate_academic_paper_5(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   completion = client.completions.create(\n",
        "       model=\"gpt-3.5-turbo-instruct\",\n",
        "       prompt=prompt_my,\n",
        "       max_tokens=2048,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "choice_text_all=[]\n",
        "\n",
        "import time\n",
        "# Function to generate academic papers for given prompts\n",
        "# Function to generate academic papers for given prompts\n",
        "def generate_papers(prompts):\n",
        "   for i in range(0, len(prompts), 20):\n",
        "       # Slice the prompts list to get the next 20 prompts\n",
        "       print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "       batch = prompts[i:i+10]\n",
        "       print(\"batch is \",batch)\n",
        "       # Generate papers for the next 20 prompts\n",
        "       for prompt in batch:\n",
        "      #   for prompt in prompt1:\n",
        "           # Print the prompt\n",
        "           print(\"prompt is \", prompt)\n",
        "           response = generate_academic_paper(prompt)\n",
        "           print(\"\\nGenerated Academic Paper:\")\n",
        "           print(\"========================\\n\")\n",
        "           #print(response)\n",
        "           for choice in response.choices:\n",
        "             print(choice.text)\n",
        "             choice_text_all.append(choice.text)\n",
        "              # Translate the generated text to Persian\n",
        "             choice_translated = translate_to_persian(choice.text) #translator.translate(choice.text, dest='fa')\n",
        "             choice_translated_prompt = translate_to_persian(prompt)#translator.translate(prompt, dest='fa')\n",
        "\n",
        "             print(\"\\n-----\\n Translated is \",choice_translated)\n",
        "             save_academic_paper(\"Persian_\"+topic,'\\n**'+choice_translated_prompt+'**\\n'+choice_translated)\n",
        "             save_academic_paper(topic,'\\n**'+prompt+'**\\n'+choice.text)\n",
        "             # Recursively call the function for the nested Completion objects\n",
        "             if hasattr(choice, 'choices'):\n",
        "               extract_text(choice)\n",
        "\n",
        "           #generated_text = response.choices[0].text\n",
        "           # Print the generated text\n",
        "           #print(generated_text)\n",
        "           print(\"\\n end of loop\")\n",
        "           print(\"========================\\n\")\n",
        "\n",
        "           #print(\"loop\")\n",
        "       # Wait for a short period of time before sending the next batch of prompts\n",
        "           time.sleep(2)\n",
        "   return choice_text_all,choice.translated\n",
        "\n",
        "# Generate academic papers for the given prompts\n",
        "generate_papers(prompts3)"
      ],
      "metadata": {
        "id": "oVldhSpgEVZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#For solving queta prompt of Openai API;\n",
        "ðŸ‘‡ðŸ‘‡ðŸŒ±"
      ],
      "metadata": {
        "id": "GdTvLhAkKLEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "#import openai\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key = openai_api#\"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\",\n",
        ")\n",
        "\n",
        "def retry_with_exponential_backoff(\n",
        "   func,\n",
        "   initial_delay: float = 1,\n",
        "   exponential_base: float = 2,\n",
        "   jitter: bool = True,\n",
        "   max_retries: int = 10,\n",
        "   errors: tuple = (openai.error.RateLimitError,),\n",
        "):\n",
        "   \"\"\"Retry a function with exponential backoff.\"\"\"\n",
        "   def wrapper(*args, **kwargs):\n",
        "       # Initialize variables\n",
        "       num_retries = 0\n",
        "       delay = initial_delay\n",
        "       # Loop until a successful response or max_retries is hit or an exception is raised\n",
        "       while True:\n",
        "           try:\n",
        "               return func(*args, **kwargs)\n",
        "           # Retry on specified errors\n",
        "           except errors as e:\n",
        "               # Increment retries\n",
        "               num_retries += 1\n",
        "               # Check if max retries has been reached\n",
        "               if num_retries > max_retries:\n",
        "                  raise Exception(\n",
        "                      f\"Maximum number of retries ({max_retries}) exceeded.\"\n",
        "                  )\n",
        "               # Increment the delay\n",
        "               delay *= exponential_base * (1 + jitter * random.random())\n",
        "               # Sleep for the delay\n",
        "               time.sleep(delay)\n",
        "           # Raise exceptions for any errors not specified\n",
        "           except Exception as e:\n",
        "               raise e\n",
        "   return wrapper\n",
        "\n",
        "@retry_with_exponential_backoff\n",
        "def generate_academic_paper_0(prompt_my):\n",
        "  model_engine = \"text-davinci-003\"\n",
        "  max_tokens = 2048\n",
        "\n",
        "  completion = client.completions.create(\n",
        "      model=\"gpt-3.5-turbo-instruct\",\n",
        "      prompt=prompt_my,\n",
        "      max_tokens=2048,\n",
        "      temperature=0.3,\n",
        "      n=1,\n",
        "      frequency_penalty=0,\n",
        "  )\n",
        "  return completion"
      ],
      "metadata": {
        "id": "zLWA8i87KXks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vH0Z7EL5LnQc"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "openai.api_key = openai_api#\"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key= openai_api#\"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\",\n",
        ")\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Function to generate an academic paper\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=10, max_time=600)\n",
        "def generate_academic_paper_6(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   completion = client.completions.create(\n",
        "       model=\"gpt-3.5-turbo-instruct\",\n",
        "       prompt=prompt_my,\n",
        "       max_tokens=2048,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "choice_text_all=[]\n",
        "\n",
        "import time\n",
        "# Function to generate academic papers for given prompts\n",
        "# Function to generate academic papers for given prompts\n",
        "def generate_papers(prompts):\n",
        "   for i in range(0, len(prompts), 20):\n",
        "       # Slice the prompts list to get the next 20 prompts\n",
        "       print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "       batch = prompts[i:i+10]\n",
        "       print(\"batch is \",batch)\n",
        "       # Generate papers for the next 20 prompts\n",
        "       for prompt in batch:\n",
        "      #   for prompt in prompt1:\n",
        "           # Print the prompt\n",
        "           print(\"prompt is \", prompt)\n",
        "           response = generate_academic_paper(prompt)\n",
        "           print(\"\\nGenerated Academic Paper:\")\n",
        "           print(\"========================\\n\")\n",
        "           #print(response)\n",
        "           for choice in response.choices:\n",
        "             print(choice.text)\n",
        "             choice_text_all.append(choice.text)\n",
        "             save_academic_paper(TOPIC,'\\n**'+prompt+'**\\n'+choice.text)\n",
        "             # Recursively call the function for the nested Completion objects\n",
        "             if hasattr(choice, 'choices'):\n",
        "               extract_text(choice)\n",
        "\n",
        "           #generated_text = response.choices[0].text\n",
        "           # Print the generated text\n",
        "           #print(generated_text)\n",
        "           print(\"\\n end of loop\")\n",
        "           print(\"========================\\n\")\n",
        "\n",
        "           #print(\"loop\")\n",
        "       # Wait for a short period of time before sending the next batch of prompts\n",
        "           time.sleep(2)\n",
        "   return choice.text_all\n",
        "\n",
        "# Generate academic papers for the given prompts\n",
        "generate_papers(prompts3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJTgcojthnm7"
      },
      "outputs": [],
      "source": [
        "def render_index_page():\n",
        "   html_content = \"\"\"\n",
        "   <!DOCTYPE html>\n",
        "   <html>\n",
        "   <head>\n",
        "      <title>Generate Academic Papers</title>\n",
        "   </head>\n",
        "   <body>\n",
        "      <h1>Generate Academic Papers</h1>\n",
        "      <form method=\"POST\">\n",
        "          <label for=\"topic\">Topic:</label>\n",
        "          <input type=\"text\" id=\"topic\" name=\"topic\" required>\n",
        "          <input type=\"submit\" value=\"Generate\">\n",
        "      </form>\n",
        "   </body>\n",
        "   </html>\n",
        "   \"\"\"\n",
        "   return render_template_string(html_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKhSXALkhpL7"
      },
      "outputs": [],
      "source": [
        "def render_result_page(topic, docx_file, pdf_file, choice_text_all):\n",
        "   html_content = f\"\"\"\n",
        "   <!DOCTYPE html>\n",
        "   <html>\n",
        "   <head>\n",
        "       <title>Result</title>\n",
        "   </head>\n",
        "   <body>\n",
        "       <h1>Result</h1>\n",
        "       <p>Academic papers have been generated for the topic: {topic}</p>\n",
        "       <a href=\"/download/{docx_file}\">Download DOCX</a>\n",
        "       <a href=\"/download/{pdf_file}\">Download PDF</a>\n",
        "       <h2>Generated Text:</h2>\n",
        "       <p>{choice_text_all}</p>\n",
        "   </body>\n",
        "   </html>\n",
        "   \"\"\"\n",
        "   return render_template_string(html_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuTJlSSGgh4E"
      },
      "outputs": [],
      "source": [
        "# app.py\n",
        "\n",
        "from flask import Flask, request, render_template\n",
        "from academic_paper_generator import generate_papers\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def home():\n",
        "  if request.method == 'POST':\n",
        "      topic = request.form.get('topic')\n",
        "      prompts3 = [\n",
        "          f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "          f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "          f\"Identify gaps in the literature on '{topic}'\",\n",
        "          \"Generate 10 academic research questions about Perviuse action\",\n",
        "          f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "      ]\n",
        "      generate_papers(prompts3)\n",
        "      return render_template('result.html', topic=topic)\n",
        "  else:\n",
        "      return render_template('index.html')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  app.run(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}