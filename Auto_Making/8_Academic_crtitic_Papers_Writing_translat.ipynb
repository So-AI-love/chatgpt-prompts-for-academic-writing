{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/So-AI-love/chatgpt-prompts-for-academic-writing/blob/main/Auto_Making/8_Academic_crtitic_Papers_Writing_translat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AcaGPT MVP\n",
        "\n",
        "The gosl of this project is Creating something like AutoGPT but in the field of Academic Papers wrting.\n",
        "\n",
        "\n",
        "For example the MVP Lage has been made by this AI free website maker :\n",
        "\n",
        "https://acagpt.site.live/editv2/"
      ],
      "metadata": {
        "id": "qnaAEEnpFyLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Settings\n",
        "#@markdown Get your GPT-3 API key from https://openai.com\n",
        "\n",
        "openai_api = \"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\" # @param {type:\"string\"}\n",
        "#@markdown Enter a phrase each prompt should start with and the number of prompts to generate:\n",
        "\n",
        "Question = \"The Interplay of Religion and Conflict: A Study on the Quran and Its Verses on Peace and War\" #@param {type:\"string\"}\n",
        "#n = 20 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Try examples like these:\n",
        "#@markdown - Do paper\n",
        "\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown _For collaboration and updates, email to hulevin5376@gmail.com"
      ],
      "metadata": {
        "id": "DcaueH5bqr5_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The SWOT and ..., analysis of this startup is available at here:\n",
        "\n",
        "![enter image description here][1]\n",
        "\n",
        "Analysis and Feedback on a ChatGPT-based Academic Paper Writing Startup\n",
        "\n",
        "https://venturusai.com/report/3Qj8RT-if-possible-suggest-one-startup-in-the-field-of-chatgpt-for-\n",
        "\n",
        "\n",
        "  [1]: https://i.stack.imgur.com/DH3se.jpg"
      ],
      "metadata": {
        "id": "tvOJqqvAMHMD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHgZHeIxi31Q"
      },
      "source": [
        "## Aromatically wrrie apaper by the ChatGPT and this github prompt instruction:\n",
        "\n",
        "https://github.com/ahmetbersoz/chatgpt-prompts-for-academic-writing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os # Mount Google Drive\n",
        "if not os.path.isdir('/content/drive'):\n",
        "   # If not, mount the drive\n",
        "     drive.mount('/content/drive')\n",
        "else:\n",
        "     print(\"Drive is already mounted.\")"
      ],
      "metadata": {
        "id": "TuUq9juyIv4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "672fc29b-be05-4b63-a736-52a892dc7d21"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install openai ==1.2.*\n",
        "!pip uninstall openai -y\n",
        "!pip3 install openai"
      ],
      "metadata": {
        "id": "s_59fOGlm6m_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62c31850-fec4-49fb-f0df-79fedd356f3b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping openai as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting openai\n",
            "  Downloading openai-1.3.6-py3-none-any.whl (220 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.9/220.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vt7VN_fmGT3E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57648ef1-ab77-4e69-dc1f-3882f443ce22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting backoff\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: backoff\n",
            "Successfully installed backoff-2.2.1\n",
            "Collecting docx2pdf\n",
            "  Downloading docx2pdf-0.1.8-py3-none-any.whl (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from docx2pdf) (4.66.1)\n",
            "Installing collected packages: docx2pdf\n",
            "Successfully installed docx2pdf-0.1.8\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.5.0)\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.0\n",
            "Collecting django\n",
            "  Downloading Django-4.2.7-py3-none-any.whl (8.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asgiref<4,>=3.6.0 (from django)\n",
            "  Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from django) (0.4.4)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from asgiref<4,>=3.6.0->django) (4.5.0)\n",
            "Installing collected packages: asgiref, django\n",
            "Successfully installed asgiref-3.7.2 django-4.2.7\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (8.2.3)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.5.1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install backoff\n",
        "!pip install docx2pdf\n",
        "!pip install python-docx\n",
        "!pip install django\n",
        "\n",
        "\n",
        "!pip install tenacity\n",
        "!pip install tiktoken\n",
        "\n",
        "# SETUP COLAB for run Streamlit\n",
        "#!npm install localtunnel\n",
        "\n",
        "#!pip install -q dl-translate\n",
        "#!curl ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install libreoffice\n",
        "#!sudo apt-get install abiword\n",
        "!sudo apt install libreoffice-writer"
      ],
      "metadata": {
        "id": "AUeIF57v21gq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50bcbf80-5365-4d79-f543-f32456e07040"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.82)] [Connecting to security.ub\r0% [Connecting to archive.ubuntu.com (91.189.91.82)] [Connecting to security.ub\r                                                                               \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcont\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadconte\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\r0% [Waiting for headers] [3 InRelease 14.2 kB/110 kB 13%] [Connected to ppa.lau\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:7 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [47.6 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [632 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,027 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,265 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,494 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,520 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,292 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,535 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [32.6 kB]\n",
            "Fetched 9,186 kB in 3s (3,020 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  apparmor default-jre default-jre-headless dictionaries-common\n",
            "  firebird3.0-common firebird3.0-common-doc firebird3.0-server-core\n",
            "  firebird3.0-utils fonts-crosextra-caladea fonts-crosextra-carlito\n",
            "  fonts-dejavu fonts-dejavu-core fonts-dejavu-extra fonts-liberation2\n",
            "  fonts-linuxlibertine fonts-noto-core fonts-noto-extra fonts-noto-mono\n",
            "  fonts-noto-ui-core fonts-opensymbol fonts-sil-gentium\n",
            "  fonts-sil-gentium-basic gstreamer1.0-gl gstreamer1.0-gtk3 hunspell-en-us\n",
            "  libabsl20210324 libabw-0.1-1 libatk-wrapper-java libatk-wrapper-java-jni\n",
            "  libbsh-java libcdr-0.1-1 libclucene-contribs1v5 libclucene-core1v5\n",
            "  libcolamd2 libe-book-0.1-1 libel-api-java libeot0 libepubgen-0.1-1\n",
            "  libetonyek-0.1-1 libexttextcat-2.0-0 libexttextcat-data libfbclient2\n",
            "  libfontenc1 libfreehand-0.1-1 libgpgme11 libgpgmepp6 libgraphene-1.0-0\n",
            "  libgstreamer-gl1.0-0 libgudev-1.0-0 libharfbuzz-icu0 libhsqldb1.8.0-java\n",
            "  libhunspell-1.7-0 libhyphen0 libib-util libjsp-api-java liblangtag-common\n",
            "  liblangtag1 liblibreoffice-java libmhash2 libmspub-0.1-1 libmwaw-0.3-3\n",
            "  libmythes-1.2-0 libodfgen-0.1-1 liborcus-0.17-0 liborcus-parser-0.17-0\n",
            "  libpagemaker-0.0-0 libraptor2-0 librasqal3 librdf0 libreoffice-base\n",
            "  libreoffice-base-core libreoffice-base-drivers libreoffice-calc\n",
            "  libreoffice-common libreoffice-core libreoffice-draw libreoffice-gnome\n",
            "  libreoffice-gtk3 libreoffice-impress libreoffice-java-common\n",
            "  libreoffice-math libreoffice-nlpsolver libreoffice-report-builder\n",
            "  libreoffice-report-builder-bin libreoffice-script-provider-bsh\n",
            "  libreoffice-script-provider-js libreoffice-script-provider-python\n",
            "  libreoffice-sdbc-firebird libreoffice-sdbc-hsqldb libreoffice-sdbc-mysql\n",
            "  libreoffice-sdbc-postgresql libreoffice-style-colibre\n",
            "  libreoffice-style-elementary libreoffice-style-yaru\n",
            "  libreoffice-wiki-publisher libreoffice-writer librevenge-0.0-0\n",
            "  libservlet-api-java libservlet3.1-java libsuitesparseconfig5\n",
            "  libtext-iconv-perl libtommath1 libuno-cppu3 libuno-cppuhelpergcc3-3\n",
            "  libuno-purpenvhelpergcc3-3 libuno-sal3 libuno-salhelpergcc3-3\n",
            "  libunoloader-java libvisio-0.1-1 libwebsocket-api-java libwpd-0.10-10\n",
            "  libwpg-0.3-3 libwps-0.4-4 libxkbfile1 libxmlsec1 libxmlsec1-nss libxtst6\n",
            "  libxxf86dga1 libyajl2 lp-solve openjdk-11-jdk-headless openjdk-11-jre\n",
            "  openjdk-11-jre-headless poppler-data python3-uno uno-libs-private ure\n",
            "  ure-java x11-utils\n",
            "Suggested packages:\n",
            "  apparmor-profiles-extra apparmor-utils ispell | aspell | hunspell wordlist\n",
            "  firebird3.0-server firebird3.0-doc hunspell openoffice.org-hunspell\n",
            "  | openoffice.org-core java-virtual-machine libhsqldb1.8.0-java-gcj\n",
            "  raptor2-utils rasqal-utils librdf-storage-postgresql librdf-storage-mysql\n",
            "  librdf-storage-sqlite librdf-storage-virtuoso redland-utils cups-bsd firefox\n",
            "  | firefox-esr | thunderbird ghostscript gpa hyphen-hyphenation-patterns\n",
            "  imagemagick | graphicsmagick-imagemagick-compat libreoffice-grammarcheck\n",
            "  libreoffice-help libreoffice-l10n libreoffice-librelogo myspell-dictionary\n",
            "  mythes-thesaurus openclipart-libreoffice pstoedit unixodbc\n",
            "  gstreamer1.0-plugins-base gstreamer1.0-plugins-good\n",
            "  gstreamer1.0-plugins-ugly gstreamer1.0-plugins-bad gstreamer1.0-libav\n",
            "  libsane1 libofficebean-java libjtds-java libsqliteodbc | tdsodbc\n",
            "  | odbc-mdbtools libreoffice-evolution seahorse libreofficekit-data bluez\n",
            "  default-mysql-server | virtual-mysql-server postgresql mediawiki\n",
            "  openjdk-11-demo openjdk-11-source libnss-mdns fonts-ipafont-gothic\n",
            "  fonts-ipafont-mincho fonts-wqy-microhei | fonts-wqy-zenhei fonts-indic\n",
            "  poppler-utils fonts-japanese-mincho | fonts-ipafont-mincho\n",
            "  fonts-japanese-gothic | fonts-ipafont-gothic fonts-arphic-ukai\n",
            "  fonts-arphic-uming fonts-nanum mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  apparmor default-jre default-jre-headless dictionaries-common\n",
            "  firebird3.0-common firebird3.0-common-doc firebird3.0-server-core\n",
            "  firebird3.0-utils fonts-crosextra-caladea fonts-crosextra-carlito\n",
            "  fonts-dejavu fonts-dejavu-core fonts-dejavu-extra fonts-liberation2\n",
            "  fonts-linuxlibertine fonts-noto-core fonts-noto-extra fonts-noto-mono\n",
            "  fonts-noto-ui-core fonts-opensymbol fonts-sil-gentium\n",
            "  fonts-sil-gentium-basic gstreamer1.0-gl gstreamer1.0-gtk3 hunspell-en-us\n",
            "  libabsl20210324 libabw-0.1-1 libatk-wrapper-java libatk-wrapper-java-jni\n",
            "  libbsh-java libcdr-0.1-1 libclucene-contribs1v5 libclucene-core1v5\n",
            "  libcolamd2 libe-book-0.1-1 libel-api-java libeot0 libepubgen-0.1-1\n",
            "  libetonyek-0.1-1 libexttextcat-2.0-0 libexttextcat-data libfbclient2\n",
            "  libfontenc1 libfreehand-0.1-1 libgpgme11 libgpgmepp6 libgraphene-1.0-0\n",
            "  libgstreamer-gl1.0-0 libgudev-1.0-0 libharfbuzz-icu0 libhsqldb1.8.0-java\n",
            "  libhunspell-1.7-0 libhyphen0 libib-util libjsp-api-java liblangtag-common\n",
            "  liblangtag1 liblibreoffice-java libmhash2 libmspub-0.1-1 libmwaw-0.3-3\n",
            "  libmythes-1.2-0 libodfgen-0.1-1 liborcus-0.17-0 liborcus-parser-0.17-0\n",
            "  libpagemaker-0.0-0 libraptor2-0 librasqal3 librdf0 libreoffice\n",
            "  libreoffice-base libreoffice-base-core libreoffice-base-drivers\n",
            "  libreoffice-calc libreoffice-common libreoffice-core libreoffice-draw\n",
            "  libreoffice-gnome libreoffice-gtk3 libreoffice-impress\n",
            "  libreoffice-java-common libreoffice-math libreoffice-nlpsolver\n",
            "  libreoffice-report-builder libreoffice-report-builder-bin\n",
            "  libreoffice-script-provider-bsh libreoffice-script-provider-js\n",
            "  libreoffice-script-provider-python libreoffice-sdbc-firebird\n",
            "  libreoffice-sdbc-hsqldb libreoffice-sdbc-mysql libreoffice-sdbc-postgresql\n",
            "  libreoffice-style-colibre libreoffice-style-elementary\n",
            "  libreoffice-style-yaru libreoffice-wiki-publisher libreoffice-writer\n",
            "  librevenge-0.0-0 libservlet-api-java libservlet3.1-java\n",
            "  libsuitesparseconfig5 libtext-iconv-perl libtommath1 libuno-cppu3\n",
            "  libuno-cppuhelpergcc3-3 libuno-purpenvhelpergcc3-3 libuno-sal3\n",
            "  libuno-salhelpergcc3-3 libunoloader-java libvisio-0.1-1\n",
            "  libwebsocket-api-java libwpd-0.10-10 libwpg-0.3-3 libwps-0.4-4 libxkbfile1\n",
            "  libxmlsec1 libxmlsec1-nss libxtst6 libxxf86dga1 libyajl2 lp-solve\n",
            "  openjdk-11-jre poppler-data python3-uno uno-libs-private ure ure-java\n",
            "  x11-utils\n",
            "The following packages will be upgraded:\n",
            "  openjdk-11-jdk-headless openjdk-11-jre-headless\n",
            "2 upgraded, 128 newly installed, 0 to remove and 17 not upgraded.\n",
            "Need to get 343 MB of archives.\n",
            "After this operation, 855 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 fonts-opensymbol all 2:102.12+LibO7.3.7-0ubuntu0.22.04.3 [102 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libreoffice-style-colibre all 1:7.3.7-0ubuntu0.22.04.3 [1,293 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libuno-sal3 amd64 1:7.3.7-0ubuntu0.22.04.3 [196 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libuno-salhelpergcc3-3 amd64 1:7.3.7-0ubuntu0.22.04.3 [17.0 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libuno-cppu3 amd64 1:7.3.7-0ubuntu0.22.04.3 [87.8 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 uno-libs-private amd64 1:7.3.7-0ubuntu0.22.04.3 [232 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblangtag-common all 0.6.3-2ubuntu1 [193 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblangtag1 amd64 0.6.3-2ubuntu1 [53.8 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libuno-cppuhelpergcc3-3 amd64 1:7.3.7-0ubuntu0.22.04.3 [344 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libuno-purpenvhelpergcc3-3 amd64 1:7.3.7-0ubuntu0.22.04.3 [15.8 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ure amd64 1:7.3.7-0ubuntu0.22.04.3 [1,312 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libreoffice-common all 1:7.3.7-0ubuntu0.22.04.3 [23.4 MB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libabsl20210324 amd64 0~20210324.2-2 [387 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libclucene-core1v5 amd64 2.3.3.4+dfsg-1ubuntu5 [530 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libclucene-contribs1v5 amd64 2.3.3.4+dfsg-1ubuntu5 [96.7 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libeot0 amd64 0.01-5build2 [28.5 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libexttextcat-data all 3.4.5-1build2 [179 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libexttextcat-2.0-0 amd64 3.4.5-1build2 [13.7 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgpgme11 amd64 1.16.0-1.2ubuntu4.1 [136 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgpgmepp6 amd64 1.16.0-1.2ubuntu4.1 [109 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libharfbuzz-icu0 amd64 2.7.4-1ubuntu3.1 [5,886 B]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhunspell-1.7-0 amd64 1.7.0-4build1 [175 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhyphen0 amd64 2.8.8-7build2 [28.2 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmythes-1.2-0 amd64 2:1.2.4-4build1 [9,352 B]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 liborcus-parser-0.17-0 amd64 0.17.2-2 [107 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 liborcus-0.17-0 amd64 0.17.2-2 [393 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 libyajl2 amd64 2.1.0-3build2 [20.6 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libraptor2-0 amd64 2.0.15-0ubuntu4 [172 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmhash2 amd64 0.9.9.9-9build2 [95.9 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 librasqal3 amd64 0.9.33-0.2ubuntu1 [193 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 librdf0 amd64 1.0.17-1.1ubuntu3 [106 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy/main amd64 librevenge-0.0-0 amd64 0.0.4-6ubuntu7 [209 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxmlsec1 amd64 1.2.33-1build2 [139 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxmlsec1-nss amd64 1.2.33-1build2 [67.7 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libreoffice-core amd64 1:7.3.7-0ubuntu0.22.04.3 [40.4 MB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libreoffice-base-core amd64 1:7.3.7-0ubuntu0.22.04.3 [973 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libreoffice-base-drivers amd64 1:7.3.7-0ubuntu0.22.04.3 [602 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libreoffice-base amd64 1:7.3.7-0ubuntu0.22.04.3 [1,725 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu jammy/main amd64 poppler-data all 0.4.11-1 [2,171 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy/main amd64 libtext-iconv-perl amd64 1.7-7build3 [14.3 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.3 [595 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jdk-headless amd64 11.0.21+9-0ubuntu1~22.04 [73.5 MB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jre-headless amd64 11.0.21+9-0ubuntu1~22.04 [42.5 MB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jre-headless amd64 2:1.11-72build2 [3,042 B]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jre amd64 11.0.21+9-0ubuntu1~22.04 [214 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jre amd64 2:1.11-72build2 [896 B]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu jammy/main amd64 dictionaries-common all 1.28.14 [185 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu jammy/universe amd64 firebird3.0-common-doc all 3.0.8.33535.ds4-1ubuntu2 [26.8 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu jammy/universe amd64 firebird3.0-common all 3.0.8.33535.ds4-1ubuntu2 [15.5 kB]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtommath1 amd64 1.2.0-6ubuntu0.22.04.1 [56.5 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libfbclient2 amd64 3.0.8.33535.ds4-1ubuntu2 [512 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libib-util amd64 3.0.8.33535.ds4-1ubuntu2 [3,378 B]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu jammy/universe amd64 firebird3.0-server-core amd64 3.0.8.33535.ds4-1ubuntu2 [2,533 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu jammy/universe amd64 firebird3.0-utils amd64 3.0.8.33535.ds4-1ubuntu2 [872 kB]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-crosextra-caladea all 20130214-2.1 [82.4 kB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-crosextra-carlito all 20130920-1.1 [743 kB]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
            "Get:60 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-dejavu all 2.37-2build1 [3,192 B]\n",
            "Get:61 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-liberation2 all 2.1.5-1 [1,614 kB]\n",
            "Get:62 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-linuxlibertine all 5.3.0-6 [1,627 kB]\n",
            "Get:63 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-core all 20201225-1build1 [12.2 MB]\n",
            "Get:64 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-noto-extra all 20201225-1build1 [72.4 MB]\n",
            "Get:65 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-mono all 20201225-1build1 [397 kB]\n",
            "Get:66 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-ui-core all 20201225-1build1 [1,420 kB]\n",
            "Get:67 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-sil-gentium all 20081126:1.03-4 [245 kB]\n",
            "Get:68 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-sil-gentium-basic all 1.102-1.1 [384 kB]\n",
            "Get:69 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgraphene-1.0-0 amd64 1.10.8-1 [48.2 kB]\n",
            "Get:70 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgudev-1.0-0 amd64 1:237-2build1 [16.3 kB]\n",
            "Get:71 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgstreamer-gl1.0-0 amd64 1.20.1-1ubuntu0.1 [204 kB]\n",
            "Get:72 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gstreamer1.0-gl amd64 1.20.1-1ubuntu0.1 [125 kB]\n",
            "Get:73 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gstreamer1.0-gtk3 amd64 1.20.3-0ubuntu1.1 [33.2 kB]\n",
            "Get:74 http://archive.ubuntu.com/ubuntu jammy/main amd64 hunspell-en-us all 1:2020.12.07-2 [280 kB]\n",
            "Get:75 http://archive.ubuntu.com/ubuntu jammy/main amd64 libabw-0.1-1 amd64 0.1.3-1build3 [102 kB]\n",
            "Get:76 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:77 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:78 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:79 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:80 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
            "Get:81 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
            "Get:82 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libbsh-java all 2.0b4-20 [289 kB]\n",
            "Get:83 http://archive.ubuntu.com/ubuntu jammy/main amd64 libcdr-0.1-1 amd64 0.1.6-2build2 [392 kB]\n",
            "Get:84 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsuitesparseconfig5 amd64 1:5.10.1+dfsg-4build1 [10.4 kB]\n",
            "Get:85 http://archive.ubuntu.com/ubuntu jammy/main amd64 libcolamd2 amd64 1:5.10.1+dfsg-4build1 [18.0 kB]\n",
            "Get:86 http://archive.ubuntu.com/ubuntu jammy/main amd64 libe-book-0.1-1 amd64 0.1.3-2build2 [148 kB]\n",
            "Get:87 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libel-api-java all 3.0.0-3 [64.9 kB]\n",
            "Get:88 http://archive.ubuntu.com/ubuntu jammy/main amd64 libepubgen-0.1-1 amd64 0.1.1-1ubuntu5 [120 kB]\n",
            "Get:89 http://archive.ubuntu.com/ubuntu jammy/main amd64 libetonyek-0.1-1 amd64 0.1.10-3build1 [637 kB]\n",
            "Get:90 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfreehand-0.1-1 amd64 0.1.2-3build2 [272 kB]\n",
            "Get:91 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libservlet-api-java all 4.0.1-2 [81.0 kB]\n",
            "Get:92 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjsp-api-java all 2.3.4-3 [53.7 kB]\n",
            "Get:93 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libwebsocket-api-java all 1.1-2 [40.1 kB]\n",
            "Get:94 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libservlet3.1-java all 1:4.0.1-2 [9,276 B]\n",
            "Get:95 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libhsqldb1.8.0-java all 1.8.0.10+dfsg-11 [765 kB]\n",
            "Get:96 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libunoloader-java all 1:7.3.7-0ubuntu0.22.04.3 [12.6 kB]\n",
            "Get:97 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ure-java amd64 1:7.3.7-0ubuntu0.22.04.3 [83.4 kB]\n",
            "Get:98 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 liblibreoffice-java all 1:7.3.7-0ubuntu0.22.04.3 [1,604 kB]\n",
            "Get:99 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmspub-0.1-1 amd64 0.1.4-3build3 [144 kB]\n",
            "Get:100 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmwaw-0.3-3 amd64 0.3.21-1build1 [2,375 kB]\n",
            "Get:101 http://archive.ubuntu.com/ubuntu jammy/main amd64 libodfgen-0.1-1 amd64 0.1.8-2build2 [245 kB]\n",
            "Get:102 http://archive.ubuntu.com/ubuntu jammy/main amd64 libpagemaker-0.0-0 amd64 0.0.4-1build3 [55.9 kB]\n",
            "Get:103 http://archive.ubuntu.com/ubuntu jammy/main amd64 lp-solve amd64 5.5.2.5-2build2 [315 kB]\n",
            "Get:104 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwps-0.4-4 amd64 0.4.12-2build1 [812 kB]\n",
            "Get:105 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libreoffice-calc amd64 1:7.3.7-0ubuntu0.22.04.3 [8,426 kB]\n",
            "Get:106 http://archive.ubuntu.com/ubuntu jammy/main amd64 libvisio-0.1-1 amd64 0.1.7-1build5 [238 kB]\n",
            "Get:107 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwpd-0.10-10 amd64 0.10.3-2build1 [209 kB]\n",
            "Get:108 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwpg-0.3-3 amd64 0.3.3-1build3 [49.9 kB]\n",
            "Get:109 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libreoffice-draw amd64 1:7.3.7-0ubuntu0.22.04.3 [3,228 kB]\n",
            "Get:110 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libreoffice-impress amd64 1:7.3.7-0ubuntu0.22.04.3 [1,360 kB]\n",
            "Get:111 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libreoffice-math amd64 1:7.3.7-0ubuntu0.22.04.3 [596 kB]\n",
            "Get:112 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libreoffice-report-builder-bin amd64 1:7.3.7-0ubuntu0.22.04.3 [971 kB]\n",
            "Get:113 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libreoffice-writer amd64 1:7.3.7-0ubuntu0.22.04.3 [10.3 MB]\n",
            "Get:114 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-uno amd64 1:7.3.7-0ubuntu0.22.04.3 [148 kB]\n",
            "Get:115 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libreoffice amd64 1:7.3.7-0ubuntu0.22.04.3 [12.9 kB]\n",
            "Get:116 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libreoffice-gnome amd64 1:7.3.7-0ubuntu0.22.04.3 [72.9 kB]\n",
            "Get:117 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libreoffice-gtk3 amd64 1:7.3.7-0ubuntu0.22.04.3 [509 kB]\n",
            "Get:118 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libreoffice-java-common all 1:7.3.7-0ubuntu0.22.04.3 [621 kB]\n",
            "Get:119 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libreoffice-report-builder all 1:7.3.7-0ubuntu0.22.04.3 [2,112 kB]\n",
            "Get:120 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libreoffice-script-provider-bsh all 1:7.3.7-0ubuntu0.22.04.3 [42.3 kB]\n",
            "Get:121 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libreoffice-script-provider-js all 1:7.3.7-0ubuntu0.22.04.3 [645 kB]\n",
            "Get:122 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libreoffice-script-provider-python all 1:7.3.7-0ubuntu0.22.04.3 [16.5 kB]\n",
            "Get:123 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libreoffice-sdbc-firebird amd64 1:7.3.7-0ubuntu0.22.04.3 [176 kB]\n",
            "Get:124 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libreoffice-sdbc-hsqldb amd64 1:7.3.7-0ubuntu0.22.04.3 [135 kB]\n",
            "Get:125 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libreoffice-sdbc-mysql amd64 1:7.3.7-0ubuntu0.22.04.3 [123 kB]\n",
            "Get:126 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libreoffice-sdbc-postgresql amd64 1:7.3.7-0ubuntu0.22.04.3 [279 kB]\n",
            "Get:127 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libreoffice-style-elementary all 1:7.3.7-0ubuntu0.22.04.3 [8,020 kB]\n",
            "Get:128 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libreoffice-style-yaru all 1:7.3.7-0ubuntu0.22.04.3 [3,760 kB]\n",
            "Get:129 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libreoffice-wiki-publisher all 1.2.0+LibO7.3.7-0ubuntu0.22.04.3 [7,918 B]\n",
            "Get:130 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libreoffice-nlpsolver all 0.9+LibO7.3.7-0ubuntu0.22.04.3 [7,980 B]\n",
            "Fetched 343 MB in 11s (30.4 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 130.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-opensymbol.\n",
            "(Reading database ... 120882 files and directories currently installed.)\n",
            "Preparing to unpack .../000-fonts-opensymbol_2%3a102.12+LibO7.3.7-0ubuntu0.22.04.3_all.deb ...\n",
            "Unpacking fonts-opensymbol (2:102.12+LibO7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libreoffice-style-colibre.\n",
            "Preparing to unpack .../001-libreoffice-style-colibre_1%3a7.3.7-0ubuntu0.22.04.3_all.deb ...\n",
            "Unpacking libreoffice-style-colibre (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libuno-sal3.\n",
            "Preparing to unpack .../002-libuno-sal3_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libuno-sal3 (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libuno-salhelpergcc3-3.\n",
            "Preparing to unpack .../003-libuno-salhelpergcc3-3_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libuno-salhelpergcc3-3 (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libuno-cppu3.\n",
            "Preparing to unpack .../004-libuno-cppu3_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libuno-cppu3 (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package uno-libs-private.\n",
            "Preparing to unpack .../005-uno-libs-private_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking uno-libs-private (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package liblangtag-common.\n",
            "Preparing to unpack .../006-liblangtag-common_0.6.3-2ubuntu1_all.deb ...\n",
            "Unpacking liblangtag-common (0.6.3-2ubuntu1) ...\n",
            "Selecting previously unselected package liblangtag1:amd64.\n",
            "Preparing to unpack .../007-liblangtag1_0.6.3-2ubuntu1_amd64.deb ...\n",
            "Unpacking liblangtag1:amd64 (0.6.3-2ubuntu1) ...\n",
            "Selecting previously unselected package libuno-cppuhelpergcc3-3.\n",
            "Preparing to unpack .../008-libuno-cppuhelpergcc3-3_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libuno-cppuhelpergcc3-3 (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libuno-purpenvhelpergcc3-3.\n",
            "Preparing to unpack .../009-libuno-purpenvhelpergcc3-3_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libuno-purpenvhelpergcc3-3 (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package ure.\n",
            "Preparing to unpack .../010-ure_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking ure (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libreoffice-common.\n",
            "Preparing to unpack .../011-libreoffice-common_1%3a7.3.7-0ubuntu0.22.04.3_all.deb ...\n",
            "Unpacking libreoffice-common (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libabsl20210324:amd64.\n",
            "Preparing to unpack .../012-libabsl20210324_0~20210324.2-2_amd64.deb ...\n",
            "Unpacking libabsl20210324:amd64 (0~20210324.2-2) ...\n",
            "Selecting previously unselected package libclucene-core1v5:amd64.\n",
            "Preparing to unpack .../013-libclucene-core1v5_2.3.3.4+dfsg-1ubuntu5_amd64.deb ...\n",
            "Unpacking libclucene-core1v5:amd64 (2.3.3.4+dfsg-1ubuntu5) ...\n",
            "Selecting previously unselected package libclucene-contribs1v5:amd64.\n",
            "Preparing to unpack .../014-libclucene-contribs1v5_2.3.3.4+dfsg-1ubuntu5_amd64.deb ...\n",
            "Unpacking libclucene-contribs1v5:amd64 (2.3.3.4+dfsg-1ubuntu5) ...\n",
            "Selecting previously unselected package libeot0:amd64.\n",
            "Preparing to unpack .../015-libeot0_0.01-5build2_amd64.deb ...\n",
            "Unpacking libeot0:amd64 (0.01-5build2) ...\n",
            "Selecting previously unselected package libexttextcat-data.\n",
            "Preparing to unpack .../016-libexttextcat-data_3.4.5-1build2_all.deb ...\n",
            "Unpacking libexttextcat-data (3.4.5-1build2) ...\n",
            "Selecting previously unselected package libexttextcat-2.0-0:amd64.\n",
            "Preparing to unpack .../017-libexttextcat-2.0-0_3.4.5-1build2_amd64.deb ...\n",
            "Unpacking libexttextcat-2.0-0:amd64 (3.4.5-1build2) ...\n",
            "Selecting previously unselected package libgpgme11:amd64.\n",
            "Preparing to unpack .../018-libgpgme11_1.16.0-1.2ubuntu4.1_amd64.deb ...\n",
            "Unpacking libgpgme11:amd64 (1.16.0-1.2ubuntu4.1) ...\n",
            "Selecting previously unselected package libgpgmepp6:amd64.\n",
            "Preparing to unpack .../019-libgpgmepp6_1.16.0-1.2ubuntu4.1_amd64.deb ...\n",
            "Unpacking libgpgmepp6:amd64 (1.16.0-1.2ubuntu4.1) ...\n",
            "Selecting previously unselected package libharfbuzz-icu0:amd64.\n",
            "Preparing to unpack .../020-libharfbuzz-icu0_2.7.4-1ubuntu3.1_amd64.deb ...\n",
            "Unpacking libharfbuzz-icu0:amd64 (2.7.4-1ubuntu3.1) ...\n",
            "Selecting previously unselected package libhunspell-1.7-0:amd64.\n",
            "Preparing to unpack .../021-libhunspell-1.7-0_1.7.0-4build1_amd64.deb ...\n",
            "Unpacking libhunspell-1.7-0:amd64 (1.7.0-4build1) ...\n",
            "Selecting previously unselected package libhyphen0:amd64.\n",
            "Preparing to unpack .../022-libhyphen0_2.8.8-7build2_amd64.deb ...\n",
            "Unpacking libhyphen0:amd64 (2.8.8-7build2) ...\n",
            "Selecting previously unselected package libmythes-1.2-0:amd64.\n",
            "Preparing to unpack .../023-libmythes-1.2-0_2%3a1.2.4-4build1_amd64.deb ...\n",
            "Unpacking libmythes-1.2-0:amd64 (2:1.2.4-4build1) ...\n",
            "Selecting previously unselected package liborcus-parser-0.17-0:amd64.\n",
            "Preparing to unpack .../024-liborcus-parser-0.17-0_0.17.2-2_amd64.deb ...\n",
            "Unpacking liborcus-parser-0.17-0:amd64 (0.17.2-2) ...\n",
            "Selecting previously unselected package liborcus-0.17-0:amd64.\n",
            "Preparing to unpack .../025-liborcus-0.17-0_0.17.2-2_amd64.deb ...\n",
            "Unpacking liborcus-0.17-0:amd64 (0.17.2-2) ...\n",
            "Selecting previously unselected package libyajl2:amd64.\n",
            "Preparing to unpack .../026-libyajl2_2.1.0-3build2_amd64.deb ...\n",
            "Unpacking libyajl2:amd64 (2.1.0-3build2) ...\n",
            "Selecting previously unselected package libraptor2-0:amd64.\n",
            "Preparing to unpack .../027-libraptor2-0_2.0.15-0ubuntu4_amd64.deb ...\n",
            "Unpacking libraptor2-0:amd64 (2.0.15-0ubuntu4) ...\n",
            "Selecting previously unselected package libmhash2:amd64.\n",
            "Preparing to unpack .../028-libmhash2_0.9.9.9-9build2_amd64.deb ...\n",
            "Unpacking libmhash2:amd64 (0.9.9.9-9build2) ...\n",
            "Selecting previously unselected package librasqal3:amd64.\n",
            "Preparing to unpack .../029-librasqal3_0.9.33-0.2ubuntu1_amd64.deb ...\n",
            "Unpacking librasqal3:amd64 (0.9.33-0.2ubuntu1) ...\n",
            "Selecting previously unselected package librdf0:amd64.\n",
            "Preparing to unpack .../030-librdf0_1.0.17-1.1ubuntu3_amd64.deb ...\n",
            "Unpacking librdf0:amd64 (1.0.17-1.1ubuntu3) ...\n",
            "Selecting previously unselected package librevenge-0.0-0:amd64.\n",
            "Preparing to unpack .../031-librevenge-0.0-0_0.0.4-6ubuntu7_amd64.deb ...\n",
            "Unpacking librevenge-0.0-0:amd64 (0.0.4-6ubuntu7) ...\n",
            "Selecting previously unselected package libxmlsec1:amd64.\n",
            "Preparing to unpack .../032-libxmlsec1_1.2.33-1build2_amd64.deb ...\n",
            "Unpacking libxmlsec1:amd64 (1.2.33-1build2) ...\n",
            "Selecting previously unselected package libxmlsec1-nss:amd64.\n",
            "Preparing to unpack .../033-libxmlsec1-nss_1.2.33-1build2_amd64.deb ...\n",
            "Unpacking libxmlsec1-nss:amd64 (1.2.33-1build2) ...\n",
            "Selecting previously unselected package libreoffice-core.\n",
            "Preparing to unpack .../034-libreoffice-core_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libreoffice-core (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libreoffice-base-core.\n",
            "Preparing to unpack .../035-libreoffice-base-core_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libreoffice-base-core (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libreoffice-base-drivers.\n",
            "Preparing to unpack .../036-libreoffice-base-drivers_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libreoffice-base-drivers (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libreoffice-base.\n",
            "Preparing to unpack .../037-libreoffice-base_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "No diversion 'diversion of /usr/lib/libreoffice/share/basic/dialog.xlc to /usr/lib/libreoffice/share/basic/dialog.xlc.noaccess by libreoffice-base', none removed.\n",
            "No diversion 'diversion of /usr/lib/libreoffice/share/basic/script.xlc to /usr/lib/libreoffice/share/basic/script.xlc.noaccess by libreoffice-base', none removed.\n",
            "Unpacking libreoffice-base (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../038-poppler-data_0.4.11-1_all.deb ...\n",
            "Unpacking poppler-data (0.4.11-1) ...\n",
            "Selecting previously unselected package libtext-iconv-perl.\n",
            "Preparing to unpack .../039-libtext-iconv-perl_1.7-7build3_amd64.deb ...\n",
            "Unpacking libtext-iconv-perl (1.7-7build3) ...\n",
            "Selecting previously unselected package apparmor.\n",
            "Preparing to unpack .../040-apparmor_3.0.4-2ubuntu2.3_amd64.deb ...\n",
            "Unpacking apparmor (3.0.4-2ubuntu2.3) ...\n",
            "Preparing to unpack .../041-openjdk-11-jdk-headless_11.0.21+9-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-11-jdk-headless:amd64 (11.0.21+9-0ubuntu1~22.04) over (11.0.20.1+1-0ubuntu1~22.04) ...\n",
            "Preparing to unpack .../042-openjdk-11-jre-headless_11.0.21+9-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-11-jre-headless:amd64 (11.0.21+9-0ubuntu1~22.04) over (11.0.20.1+1-0ubuntu1~22.04) ...\n",
            "Selecting previously unselected package default-jre-headless.\n",
            "Preparing to unpack .../043-default-jre-headless_2%3a1.11-72build2_amd64.deb ...\n",
            "Unpacking default-jre-headless (2:1.11-72build2) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../044-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-11-jre:amd64.\n",
            "Preparing to unpack .../045-openjdk-11-jre_11.0.21+9-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-11-jre:amd64 (11.0.21+9-0ubuntu1~22.04) ...\n",
            "Selecting previously unselected package default-jre.\n",
            "Preparing to unpack .../046-default-jre_2%3a1.11-72build2_amd64.deb ...\n",
            "Unpacking default-jre (2:1.11-72build2) ...\n",
            "Selecting previously unselected package dictionaries-common.\n",
            "Preparing to unpack .../047-dictionaries-common_1.28.14_all.deb ...\n",
            "Adding 'diversion of /usr/share/dict/words to /usr/share/dict/words.pre-dictionaries-common by dictionaries-common'\n",
            "Unpacking dictionaries-common (1.28.14) ...\n",
            "Selecting previously unselected package firebird3.0-common-doc.\n",
            "Preparing to unpack .../048-firebird3.0-common-doc_3.0.8.33535.ds4-1ubuntu2_all.deb ...\n",
            "Unpacking firebird3.0-common-doc (3.0.8.33535.ds4-1ubuntu2) ...\n",
            "Selecting previously unselected package firebird3.0-common.\n",
            "Preparing to unpack .../049-firebird3.0-common_3.0.8.33535.ds4-1ubuntu2_all.deb ...\n",
            "Unpacking firebird3.0-common (3.0.8.33535.ds4-1ubuntu2) ...\n",
            "Selecting previously unselected package libtommath1:amd64.\n",
            "Preparing to unpack .../050-libtommath1_1.2.0-6ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libtommath1:amd64 (1.2.0-6ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libfbclient2:amd64.\n",
            "Preparing to unpack .../051-libfbclient2_3.0.8.33535.ds4-1ubuntu2_amd64.deb ...\n",
            "Unpacking libfbclient2:amd64 (3.0.8.33535.ds4-1ubuntu2) ...\n",
            "Selecting previously unselected package libib-util:amd64.\n",
            "Preparing to unpack .../052-libib-util_3.0.8.33535.ds4-1ubuntu2_amd64.deb ...\n",
            "Unpacking libib-util:amd64 (3.0.8.33535.ds4-1ubuntu2) ...\n",
            "Selecting previously unselected package firebird3.0-server-core:amd64.\n",
            "Preparing to unpack .../053-firebird3.0-server-core_3.0.8.33535.ds4-1ubuntu2_amd64.deb ...\n",
            "Unpacking firebird3.0-server-core:amd64 (3.0.8.33535.ds4-1ubuntu2) ...\n",
            "Selecting previously unselected package firebird3.0-utils.\n",
            "Preparing to unpack .../054-firebird3.0-utils_3.0.8.33535.ds4-1ubuntu2_amd64.deb ...\n",
            "Unpacking firebird3.0-utils (3.0.8.33535.ds4-1ubuntu2) ...\n",
            "Selecting previously unselected package fonts-crosextra-caladea.\n",
            "Preparing to unpack .../055-fonts-crosextra-caladea_20130214-2.1_all.deb ...\n",
            "Unpacking fonts-crosextra-caladea (20130214-2.1) ...\n",
            "Selecting previously unselected package fonts-crosextra-carlito.\n",
            "Preparing to unpack .../056-fonts-crosextra-carlito_20130920-1.1_all.deb ...\n",
            "Unpacking fonts-crosextra-carlito (20130920-1.1) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../057-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../058-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-dejavu.\n",
            "Preparing to unpack .../059-fonts-dejavu_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-liberation2.\n",
            "Preparing to unpack .../060-fonts-liberation2_2.1.5-1_all.deb ...\n",
            "Unpacking fonts-liberation2 (2.1.5-1) ...\n",
            "Selecting previously unselected package fonts-linuxlibertine.\n",
            "Preparing to unpack .../061-fonts-linuxlibertine_5.3.0-6_all.deb ...\n",
            "Unpacking fonts-linuxlibertine (5.3.0-6) ...\n",
            "Selecting previously unselected package fonts-noto-core.\n",
            "Preparing to unpack .../062-fonts-noto-core_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-core (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-noto-extra.\n",
            "Preparing to unpack .../063-fonts-noto-extra_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-extra (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../064-fonts-noto-mono_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-mono (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-noto-ui-core.\n",
            "Preparing to unpack .../065-fonts-noto-ui-core_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-ui-core (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-sil-gentium.\n",
            "Preparing to unpack .../066-fonts-sil-gentium_20081126%3a1.03-4_all.deb ...\n",
            "Unpacking fonts-sil-gentium (20081126:1.03-4) ...\n",
            "Selecting previously unselected package fonts-sil-gentium-basic.\n",
            "Preparing to unpack .../067-fonts-sil-gentium-basic_1.102-1.1_all.deb ...\n",
            "Unpacking fonts-sil-gentium-basic (1.102-1.1) ...\n",
            "Selecting previously unselected package libgraphene-1.0-0:amd64.\n",
            "Preparing to unpack .../068-libgraphene-1.0-0_1.10.8-1_amd64.deb ...\n",
            "Unpacking libgraphene-1.0-0:amd64 (1.10.8-1) ...\n",
            "Selecting previously unselected package libgudev-1.0-0:amd64.\n",
            "Preparing to unpack .../069-libgudev-1.0-0_1%3a237-2build1_amd64.deb ...\n",
            "Unpacking libgudev-1.0-0:amd64 (1:237-2build1) ...\n",
            "Selecting previously unselected package libgstreamer-gl1.0-0:amd64.\n",
            "Preparing to unpack .../070-libgstreamer-gl1.0-0_1.20.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libgstreamer-gl1.0-0:amd64 (1.20.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package gstreamer1.0-gl:amd64.\n",
            "Preparing to unpack .../071-gstreamer1.0-gl_1.20.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking gstreamer1.0-gl:amd64 (1.20.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package gstreamer1.0-gtk3:amd64.\n",
            "Preparing to unpack .../072-gstreamer1.0-gtk3_1.20.3-0ubuntu1.1_amd64.deb ...\n",
            "Unpacking gstreamer1.0-gtk3:amd64 (1.20.3-0ubuntu1.1) ...\n",
            "Selecting previously unselected package hunspell-en-us.\n",
            "Preparing to unpack .../073-hunspell-en-us_1%3a2020.12.07-2_all.deb ...\n",
            "Unpacking hunspell-en-us (1:2020.12.07-2) ...\n",
            "Selecting previously unselected package libabw-0.1-1:amd64.\n",
            "Preparing to unpack .../074-libabw-0.1-1_0.1.3-1build3_amd64.deb ...\n",
            "Unpacking libabw-0.1-1:amd64 (0.1.3-1build3) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../075-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../076-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../077-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../078-x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../079-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../080-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libbsh-java.\n",
            "Preparing to unpack .../081-libbsh-java_2.0b4-20_all.deb ...\n",
            "Unpacking libbsh-java (2.0b4-20) ...\n",
            "Selecting previously unselected package libcdr-0.1-1:amd64.\n",
            "Preparing to unpack .../082-libcdr-0.1-1_0.1.6-2build2_amd64.deb ...\n",
            "Unpacking libcdr-0.1-1:amd64 (0.1.6-2build2) ...\n",
            "Selecting previously unselected package libsuitesparseconfig5:amd64.\n",
            "Preparing to unpack .../083-libsuitesparseconfig5_1%3a5.10.1+dfsg-4build1_amd64.deb ...\n",
            "Unpacking libsuitesparseconfig5:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Selecting previously unselected package libcolamd2:amd64.\n",
            "Preparing to unpack .../084-libcolamd2_1%3a5.10.1+dfsg-4build1_amd64.deb ...\n",
            "Unpacking libcolamd2:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Selecting previously unselected package libe-book-0.1-1:amd64.\n",
            "Preparing to unpack .../085-libe-book-0.1-1_0.1.3-2build2_amd64.deb ...\n",
            "Unpacking libe-book-0.1-1:amd64 (0.1.3-2build2) ...\n",
            "Selecting previously unselected package libel-api-java.\n",
            "Preparing to unpack .../086-libel-api-java_3.0.0-3_all.deb ...\n",
            "Unpacking libel-api-java (3.0.0-3) ...\n",
            "Selecting previously unselected package libepubgen-0.1-1:amd64.\n",
            "Preparing to unpack .../087-libepubgen-0.1-1_0.1.1-1ubuntu5_amd64.deb ...\n",
            "Unpacking libepubgen-0.1-1:amd64 (0.1.1-1ubuntu5) ...\n",
            "Selecting previously unselected package libetonyek-0.1-1:amd64.\n",
            "Preparing to unpack .../088-libetonyek-0.1-1_0.1.10-3build1_amd64.deb ...\n",
            "Unpacking libetonyek-0.1-1:amd64 (0.1.10-3build1) ...\n",
            "Selecting previously unselected package libfreehand-0.1-1.\n",
            "Preparing to unpack .../089-libfreehand-0.1-1_0.1.2-3build2_amd64.deb ...\n",
            "Unpacking libfreehand-0.1-1 (0.1.2-3build2) ...\n",
            "Selecting previously unselected package libservlet-api-java.\n",
            "Preparing to unpack .../090-libservlet-api-java_4.0.1-2_all.deb ...\n",
            "Unpacking libservlet-api-java (4.0.1-2) ...\n",
            "Selecting previously unselected package libjsp-api-java.\n",
            "Preparing to unpack .../091-libjsp-api-java_2.3.4-3_all.deb ...\n",
            "Unpacking libjsp-api-java (2.3.4-3) ...\n",
            "Selecting previously unselected package libwebsocket-api-java.\n",
            "Preparing to unpack .../092-libwebsocket-api-java_1.1-2_all.deb ...\n",
            "Unpacking libwebsocket-api-java (1.1-2) ...\n",
            "Selecting previously unselected package libservlet3.1-java.\n",
            "Preparing to unpack .../093-libservlet3.1-java_1%3a4.0.1-2_all.deb ...\n",
            "Unpacking libservlet3.1-java (1:4.0.1-2) ...\n",
            "Selecting previously unselected package libhsqldb1.8.0-java.\n",
            "Preparing to unpack .../094-libhsqldb1.8.0-java_1.8.0.10+dfsg-11_all.deb ...\n",
            "Unpacking libhsqldb1.8.0-java (1.8.0.10+dfsg-11) ...\n",
            "Selecting previously unselected package libunoloader-java.\n",
            "Preparing to unpack .../095-libunoloader-java_1%3a7.3.7-0ubuntu0.22.04.3_all.deb ...\n",
            "Unpacking libunoloader-java (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package ure-java.\n",
            "Preparing to unpack .../096-ure-java_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking ure-java (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package liblibreoffice-java.\n",
            "Preparing to unpack .../097-liblibreoffice-java_1%3a7.3.7-0ubuntu0.22.04.3_all.deb ...\n",
            "Unpacking liblibreoffice-java (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libmspub-0.1-1:amd64.\n",
            "Preparing to unpack .../098-libmspub-0.1-1_0.1.4-3build3_amd64.deb ...\n",
            "Unpacking libmspub-0.1-1:amd64 (0.1.4-3build3) ...\n",
            "Selecting previously unselected package libmwaw-0.3-3:amd64.\n",
            "Preparing to unpack .../099-libmwaw-0.3-3_0.3.21-1build1_amd64.deb ...\n",
            "Unpacking libmwaw-0.3-3:amd64 (0.3.21-1build1) ...\n",
            "Selecting previously unselected package libodfgen-0.1-1:amd64.\n",
            "Preparing to unpack .../100-libodfgen-0.1-1_0.1.8-2build2_amd64.deb ...\n",
            "Unpacking libodfgen-0.1-1:amd64 (0.1.8-2build2) ...\n",
            "Selecting previously unselected package libpagemaker-0.0-0:amd64.\n",
            "Preparing to unpack .../101-libpagemaker-0.0-0_0.0.4-1build3_amd64.deb ...\n",
            "Unpacking libpagemaker-0.0-0:amd64 (0.0.4-1build3) ...\n",
            "Selecting previously unselected package lp-solve.\n",
            "Preparing to unpack .../102-lp-solve_5.5.2.5-2build2_amd64.deb ...\n",
            "Unpacking lp-solve (5.5.2.5-2build2) ...\n",
            "Selecting previously unselected package libwps-0.4-4:amd64.\n",
            "Preparing to unpack .../103-libwps-0.4-4_0.4.12-2build1_amd64.deb ...\n",
            "Unpacking libwps-0.4-4:amd64 (0.4.12-2build1) ...\n",
            "Selecting previously unselected package libreoffice-calc.\n",
            "Preparing to unpack .../104-libreoffice-calc_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libreoffice-calc (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libvisio-0.1-1:amd64.\n",
            "Preparing to unpack .../105-libvisio-0.1-1_0.1.7-1build5_amd64.deb ...\n",
            "Unpacking libvisio-0.1-1:amd64 (0.1.7-1build5) ...\n",
            "Selecting previously unselected package libwpd-0.10-10:amd64.\n",
            "Preparing to unpack .../106-libwpd-0.10-10_0.10.3-2build1_amd64.deb ...\n",
            "Unpacking libwpd-0.10-10:amd64 (0.10.3-2build1) ...\n",
            "Selecting previously unselected package libwpg-0.3-3:amd64.\n",
            "Preparing to unpack .../107-libwpg-0.3-3_0.3.3-1build3_amd64.deb ...\n",
            "Unpacking libwpg-0.3-3:amd64 (0.3.3-1build3) ...\n",
            "Selecting previously unselected package libreoffice-draw.\n",
            "Preparing to unpack .../108-libreoffice-draw_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libreoffice-draw (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libreoffice-impress.\n",
            "Preparing to unpack .../109-libreoffice-impress_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libreoffice-impress (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libreoffice-math.\n",
            "Preparing to unpack .../110-libreoffice-math_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libreoffice-math (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libreoffice-report-builder-bin.\n",
            "Preparing to unpack .../111-libreoffice-report-builder-bin_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libreoffice-report-builder-bin (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libreoffice-writer.\n",
            "Preparing to unpack .../112-libreoffice-writer_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libreoffice-writer (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package python3-uno.\n",
            "Preparing to unpack .../113-python3-uno_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking python3-uno (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libreoffice.\n",
            "Preparing to unpack .../114-libreoffice_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libreoffice (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libreoffice-gnome.\n",
            "Preparing to unpack .../115-libreoffice-gnome_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libreoffice-gnome (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libreoffice-gtk3.\n",
            "Preparing to unpack .../116-libreoffice-gtk3_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libreoffice-gtk3 (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libreoffice-java-common.\n",
            "Preparing to unpack .../117-libreoffice-java-common_1%3a7.3.7-0ubuntu0.22.04.3_all.deb ...\n",
            "Unpacking libreoffice-java-common (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libreoffice-report-builder.\n",
            "Preparing to unpack .../118-libreoffice-report-builder_1%3a7.3.7-0ubuntu0.22.04.3_all.deb ...\n",
            "Unpacking libreoffice-report-builder (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libreoffice-script-provider-bsh.\n",
            "Preparing to unpack .../119-libreoffice-script-provider-bsh_1%3a7.3.7-0ubuntu0.22.04.3_all.deb ...\n",
            "Unpacking libreoffice-script-provider-bsh (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libreoffice-script-provider-js.\n",
            "Preparing to unpack .../120-libreoffice-script-provider-js_1%3a7.3.7-0ubuntu0.22.04.3_all.deb ...\n",
            "Unpacking libreoffice-script-provider-js (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libreoffice-script-provider-python.\n",
            "Preparing to unpack .../121-libreoffice-script-provider-python_1%3a7.3.7-0ubuntu0.22.04.3_all.deb ...\n",
            "Unpacking libreoffice-script-provider-python (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libreoffice-sdbc-firebird.\n",
            "Preparing to unpack .../122-libreoffice-sdbc-firebird_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libreoffice-sdbc-firebird (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libreoffice-sdbc-hsqldb.\n",
            "Preparing to unpack .../123-libreoffice-sdbc-hsqldb_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libreoffice-sdbc-hsqldb (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libreoffice-sdbc-mysql.\n",
            "Preparing to unpack .../124-libreoffice-sdbc-mysql_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libreoffice-sdbc-mysql (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libreoffice-sdbc-postgresql.\n",
            "Preparing to unpack .../125-libreoffice-sdbc-postgresql_1%3a7.3.7-0ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libreoffice-sdbc-postgresql (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libreoffice-style-elementary.\n",
            "Preparing to unpack .../126-libreoffice-style-elementary_1%3a7.3.7-0ubuntu0.22.04.3_all.deb ...\n",
            "Unpacking libreoffice-style-elementary (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libreoffice-style-yaru.\n",
            "Preparing to unpack .../127-libreoffice-style-yaru_1%3a7.3.7-0ubuntu0.22.04.3_all.deb ...\n",
            "Unpacking libreoffice-style-yaru (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libreoffice-wiki-publisher.\n",
            "Preparing to unpack .../128-libreoffice-wiki-publisher_1.2.0+LibO7.3.7-0ubuntu0.22.04.3_all.deb ...\n",
            "Unpacking libreoffice-wiki-publisher (1.2.0+LibO7.3.7-0ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libreoffice-nlpsolver.\n",
            "Preparing to unpack .../129-libreoffice-nlpsolver_0.9+LibO7.3.7-0ubuntu0.22.04.3_all.deb ...\n",
            "Unpacking libreoffice-nlpsolver (0.9+LibO7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up libtext-iconv-perl (1.7-7build3) ...\n",
            "Setting up fonts-sil-gentium-basic (1.102-1.1) ...\n",
            "Setting up libharfbuzz-icu0:amd64 (2.7.4-1ubuntu3.1) ...\n",
            "Setting up fonts-noto-mono (20201225-1build1) ...\n",
            "Setting up libhyphen0:amd64 (2.8.8-7build2) ...\n",
            "Setting up dictionaries-common (1.28.14) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Setting up libtommath1:amd64 (1.2.0-6ubuntu0.22.04.1) ...\n",
            "Setting up fonts-noto-extra (20201225-1build1) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up openjdk-11-jre-headless:amd64 (11.0.21+9-0ubuntu1~22.04) ...\n",
            "Installing new version of config file /etc/java-11-openjdk/security/java.security ...\n",
            "Installing new version of config file /etc/java-11-openjdk/security/public_suffix_list.dat ...\n",
            "Setting up libyajl2:amd64 (2.1.0-3build2) ...\n",
            "Setting up libuno-sal3 (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up libel-api-java (3.0.0-3) ...\n",
            "Setting up openjdk-11-jre:amd64 (11.0.21+9-0ubuntu1~22.04) ...\n",
            "Setting up openjdk-11-jdk-headless:amd64 (11.0.21+9-0ubuntu1~22.04) ...\n",
            "Setting up libeot0:amd64 (0.01-5build2) ...\n",
            "Setting up libgpgme11:amd64 (1.16.0-1.2ubuntu4.1) ...\n",
            "Setting up firebird3.0-common-doc (3.0.8.33535.ds4-1ubuntu2) ...\n",
            "Setting up librevenge-0.0-0:amd64 (0.0.4-6ubuntu7) ...\n",
            "Setting up poppler-data (0.4.11-1) ...\n",
            "Setting up fonts-crosextra-carlito (20130920-1.1) ...\n",
            "Setting up firebird3.0-common (3.0.8.33535.ds4-1ubuntu2) ...\n",
            "Setting up apparmor (3.0.4-2ubuntu2.3) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service → /lib/systemd/system/apparmor.service.\n",
            "Setting up fonts-sil-gentium (20081126:1.03-4) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up libreoffice-style-colibre (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up liborcus-parser-0.17-0:amd64 (0.17.2-2) ...\n",
            "Setting up fonts-liberation2 (2.1.5-1) ...\n",
            "Setting up libwebsocket-api-java (1.1-2) ...\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up libfreehand-0.1-1 (0.1.2-3build2) ...\n",
            "Setting up libclucene-core1v5:amd64 (2.3.3.4+dfsg-1ubuntu5) ...\n",
            "Setting up libabsl20210324:amd64 (0~20210324.2-2) ...\n",
            "Setting up fonts-linuxlibertine (5.3.0-6) ...\n",
            "Setting up libbsh-java (2.0b4-20) ...\n",
            "Setting up libjsp-api-java (2.3.4-3) ...\n",
            "Setting up libmhash2:amd64 (0.9.9.9-9build2) ...\n",
            "Setting up libmythes-1.2-0:amd64 (2:1.2.4-4build1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
            "Setting up libexttextcat-data (3.4.5-1build2) ...\n",
            "Setting up libabw-0.1-1:amd64 (0.1.3-1build3) ...\n",
            "Setting up libservlet-api-java (4.0.1-2) ...\n",
            "Setting up libepubgen-0.1-1:amd64 (0.1.1-1ubuntu5) ...\n",
            "Setting up hunspell-en-us (1:2020.12.07-2) ...\n",
            "Setting up libuno-salhelpergcc3-3 (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up fonts-crosextra-caladea (20130214-2.1) ...\n",
            "Setting up libreoffice-style-yaru (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up liblangtag-common (0.6.3-2ubuntu1) ...\n",
            "Setting up libib-util:amd64 (3.0.8.33535.ds4-1ubuntu2) ...\n",
            "Setting up libhunspell-1.7-0:amd64 (1.7.0-4build1) ...\n",
            "Setting up libunoloader-java (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up fonts-noto-ui-core (20201225-1build1) ...\n",
            "Setting up libxmlsec1:amd64 (1.2.33-1build2) ...\n",
            "Setting up libwpd-0.10-10:amd64 (0.10.3-2build1) ...\n",
            "Setting up fonts-noto-core (20201225-1build1) ...\n",
            "Setting up libsuitesparseconfig5:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Setting up libgudev-1.0-0:amd64 (1:237-2build1) ...\n",
            "Setting up fonts-opensymbol (2:102.12+LibO7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up libgraphene-1.0-0:amd64 (1.10.8-1) ...\n",
            "Setting up libservlet3.1-java (1:4.0.1-2) ...\n",
            "Setting up libodfgen-0.1-1:amd64 (0.1.8-2build2) ...\n",
            "Setting up libvisio-0.1-1:amd64 (0.1.7-1build5) ...\n",
            "Setting up libreoffice-style-elementary (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up fonts-dejavu (2.37-2build1) ...\n",
            "Setting up libwps-0.4-4:amd64 (0.4.12-2build1) ...\n",
            "Setting up libcolamd2:amd64 (1:5.10.1+dfsg-4build1) ...\n",
            "Setting up default-jre-headless (2:1.11-72build2) ...\n",
            "Setting up libexttextcat-2.0-0:amd64 (3.4.5-1build2) ...\n",
            "Setting up libgpgmepp6:amd64 (1.16.0-1.2ubuntu4.1) ...\n",
            "Setting up libmspub-0.1-1:amd64 (0.1.4-3build3) ...\n",
            "Setting up libraptor2-0:amd64 (2.0.15-0ubuntu4) ...\n",
            "Setting up lp-solve (5.5.2.5-2build2) ...\n",
            "Setting up libpagemaker-0.0-0:amd64 (0.0.4-1build3) ...\n",
            "Setting up libmwaw-0.3-3:amd64 (0.3.21-1build1) ...\n",
            "Setting up default-jre (2:1.11-72build2) ...\n",
            "Setting up libcdr-0.1-1:amd64 (0.1.6-2build2) ...\n",
            "Setting up liblangtag1:amd64 (0.6.3-2ubuntu1) ...\n",
            "Setting up libfbclient2:amd64 (3.0.8.33535.ds4-1ubuntu2) ...\n",
            "Setting up liborcus-0.17-0:amd64 (0.17.2-2) ...\n",
            "Setting up libgstreamer-gl1.0-0:amd64 (1.20.1-1ubuntu0.1) ...\n",
            "Setting up firebird3.0-utils (3.0.8.33535.ds4-1ubuntu2) ...\n",
            "Setting up libuno-cppu3 (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up libhsqldb1.8.0-java (1.8.0.10+dfsg-11) ...\n",
            "Setting up libclucene-contribs1v5:amd64 (2.3.3.4+dfsg-1ubuntu5) ...\n",
            "Setting up libwpg-0.3-3:amd64 (0.3.3-1build3) ...\n",
            "Setting up libxmlsec1-nss:amd64 (1.2.33-1build2) ...\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Setting up libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Setting up gstreamer1.0-gl:amd64 (1.20.1-1ubuntu0.1) ...\n",
            "Setting up libuno-purpenvhelpergcc3-3 (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up uno-libs-private (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up firebird3.0-server-core:amd64 (3.0.8.33535.ds4-1ubuntu2) ...\n",
            "Setting up librasqal3:amd64 (0.9.33-0.2ubuntu1) ...\n",
            "Setting up libetonyek-0.1-1:amd64 (0.1.10-3build1) ...\n",
            "Setting up gstreamer1.0-gtk3:amd64 (1.20.3-0ubuntu1.1) ...\n",
            "Setting up libe-book-0.1-1:amd64 (0.1.3-2build2) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Setting up librdf0:amd64 (1.0.17-1.1ubuntu3) ...\n",
            "Setting up libuno-cppuhelpergcc3-3 (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up ure (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up libreoffice-common (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "\n",
            "Creating config file /etc/libreoffice/registry/main.xcd with new version\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "\n",
            "Creating config file /etc/libreoffice/registry/pdfimport.xcd with new version\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "\n",
            "Creating config file /etc/libreoffice/registry/xsltfilter.xcd with new version\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "\n",
            "Creating config file /etc/libreoffice/registry/lingucomponent.xcd with new version\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "\n",
            "Creating config file /etc/libreoffice/registry/Langpack-en-US.xcd with new version\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "\n",
            "Creating config file /etc/libreoffice/registry/res/fcfg_langpack_en-US.xcd with new version\n",
            "Setting up ure-java (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up libreoffice-core (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up libreoffice-math (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "\n",
            "Creating config file /etc/libreoffice/registry/math.xcd with new version\n",
            "Setting up libreoffice-gtk3 (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up libreoffice-sdbc-postgresql (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "\n",
            "Creating config file /etc/libreoffice/registry/postgresql.xcd with new version\n",
            "Setting up liblibreoffice-java (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up libreoffice-draw (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "\n",
            "Creating config file /etc/libreoffice/registry/draw.xcd with new version\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "\n",
            "Creating config file /etc/libreoffice/registry/graphicfilter.xcd with new version\n",
            "Setting up libreoffice-java-common (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up libreoffice-base-drivers (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up libreoffice-wiki-publisher (1.2.0+LibO7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up libreoffice-sdbc-firebird (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up libreoffice-sdbc-mysql (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up libreoffice-gnome (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "\n",
            "Creating config file /etc/libreoffice/registry/gnome.xcd with new version\n",
            "Setting up libreoffice-impress (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "\n",
            "Creating config file /etc/libreoffice/registry/impress.xcd with new version\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "\n",
            "Creating config file /etc/libreoffice/registry/ogltrans.xcd with new version\n",
            "Setting up libreoffice-base-core (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up python3-uno (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "\n",
            "Creating config file /etc/libreoffice/registry/pyuno.xcd with new version\n",
            "Setting up libreoffice-script-provider-bsh (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up libreoffice-script-provider-js (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up libreoffice-calc (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "\n",
            "Creating config file /etc/libreoffice/registry/calc.xcd with new version\n",
            "Setting up libreoffice-base (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "\n",
            "Creating config file /etc/libreoffice/registry/base.xcd with new version\n",
            "Setting up libreoffice-sdbc-hsqldb (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up libreoffice-writer (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "\n",
            "Creating config file /etc/libreoffice/registry/writer.xcd with new version\n",
            "Setting up libreoffice-script-provider-python (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up libreoffice-nlpsolver (0.9+LibO7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up libreoffice-report-builder-bin (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up libreoffice (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "Setting up libreoffice-report-builder (1:7.3.7-0ubuntu0.22.04.3) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "\n",
            "Creating config file /etc/libreoffice/registry/reportbuilder.xcd with new version\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for shared-mime-info (2.1-2) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for dictionaries-common (1.28.14) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libreoffice-writer is already the newest version (1:7.3.7-0ubuntu0.22.04.3).\n",
            "libreoffice-writer set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 17 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define main variables\n",
        "TOPIC = \"{TOPIC}\"\n",
        "RESEARCH_DOMAIN = \"{RESEARCH_DOMAIN}\"\n",
        "PARAGRAPH = \"{PARAGRAPH}\"\n",
        "PARAGRAPHS = \"{PARAGRAPHS}\"\n",
        "TOPIC_SENTENCE = \"{TOPIC_SENTENCE}\"\n",
        "LANGUAGE = \"{LANGUAGE}\"\n",
        "ABSTRACT_PARAGRAPH = \"{ABSTRACT_PARAGRAPH}\"\n",
        "BIBLIOGRAPHY = \"{BIBLIOGRAPHY}\"\n",
        "THEORY1 = \"{THEORY1}\"\n",
        "THEORY2 = \"{THEORY2}\"\n",
        "RESEARCH_QUESTIONS = \"{RESEARCH_QUESTIONS}\"\n",
        "ACTION = \"{ACTION}\"\n",
        "RESULT_PARAGRAPHS = \"{RESULT_PARAGRAPHS}\"\n",
        "DATE = \"{DATE}\"\n",
        "NUMBER_OF_DAYS_MONTHS_YEARS = \"{NUMBER_OF_DAYS_MONTHS_YEARS}\"\n",
        "\n",
        "main_variables_0 = {\n",
        "       'TOPIC': None,\n",
        "       'RESEARCH_DOMAIN': None,\n",
        "       'PARAGRAPH': None,\n",
        "       'PARAGRAPHS': None,\n",
        "       'TOPIC_SENTENCE': None,\n",
        "       'LANGUAGE': None,\n",
        "       'ABSTRACT_PARAGRAPH': None,\n",
        "       'BIBLIOGRAPHY': None,\n",
        "       'THEORY1': None,\n",
        "       'THEORY2': None,\n",
        "       'RESEARCH_QUESTIONS': None,\n",
        "       'ACTION': None,\n",
        "       'RESULT_PARAGRAPHS': None,\n",
        "       'DATE': None,\n",
        "       'NUMBER_OF_DAYS_MONTHS_YEARS': None\n",
        "   }\n",
        "\n",
        "# List of prompts for generating academic papers\n",
        "prompts = [\n",
        "\n",
        "  # Improving Language\n",
        "  f\"Write a counterargument to the following claim: '{PARAGRAPH}'\",\n",
        "  f\"Rewrite this in an academic voice: '{PARAGRAPH}'\",\n",
        "  f\"Expand these notes: '{PARAGRAPH}'\",\n",
        "  f\"Provide me a list of words and phrases which were repeatedly / more than 3 times used: '{PARAGRAPHS}'\",\n",
        "  f\"Provide me a list of synonyms for '{PARAGRAPH}' and evaluate them in the context of '{PARAGRAPH}'\",\n",
        "  f\"Act as a language expert, proofread my paper on '{TOPIC_SENTENCE}' while putting a focus on grammar and punctuation.\",\n",
        "  f\"In the context of '{RESEARCH_DOMAIN}' translate '{PARAGRAPH}' into the '{LANGUAGE}' language.\",\n",
        "\n",
        "   # Brainstorming\n",
        "   f\"Find a research topic for a PhD in the area of '{TOPIC}'\",\n",
        "   f\"Write a detailed proposal on the following research topic. Make sure it is free from plagiarism. '{PARAGRAPH}'\",\n",
        "   f\"Identify gaps in the literature on '{TOPIC_SENTENCE}'\",\n",
        "   f\"Generate 10 academic research questions about '{PARAGRAPHS}'\",\n",
        "   f\"Generate a list of research hypotheses related to '{TOPIC_SENTENCE}'\",\n",
        "   f\"Identify potential areas for future research in the context of this '{TOPIC_SENTENCE}'\",\n",
        "   f\"Suggest novel applications of '{TOPIC_SENTENCE}' within '{RESEARCH_DOMAIN}'\",\n",
        "\n",
        "   # Title/Topic Sentence\n",
        "   f\"Suggest 5 titles for the following abstract: '{ABSTRACT_PARAGRAPH}'\",\n",
        "   f\"Write a topic sentence for this paragraph: '{PARAGRAPH}'\",\n",
        "\n",
        "   # Keywords\n",
        "   f\"Provide 5 keywords for this: '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Abstract\n",
        "   f\"Generate an abstract for a scientific paper based on this information for: '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Outline\n",
        "   f\"Generate an outline for '{TOPIC_SENTENCE}'\",\n",
        "   f\"I want to write a journal article about '{TOPIC_SENTENCE}'. Give me an outline for the article that I can use as a starting point.\",\n",
        "\n",
        "   # Introduction\n",
        "   f\"Come up with an introduction for the following research topic: '{TOPIC_SENTENCE}'\",\n",
        "\n",
        "   # Literature Review\n",
        "   f\"Conduct a literature review on '{TOPIC_SENTENCE}' and provide review paper references\",\n",
        "   f\"Provide me with references and links to papers in '{PARAGRAPH}'\",\n",
        "   f\"Summarize the scholarly literature including in-text citations on '{PARAGRAPHS}'\",\n",
        "   f\"Write this in standard Harvard referencing '{PARAGRAPH}'\",\n",
        "   f\"Convert this '{BIBLIOGRAPHY}' from MLA to APA style.\",\n",
        "   f\"Compare and contrast '{THEORY1}' and '{THEORY2}' in the context of '{RESEARCH_DOMAIN}'\",\n",
        "\n",
        "   # Methodology\n",
        "   f\"Create objectives and methodology for '{TOPIC_SENTENCE}'\",\n",
        "   f\"Write a detailed methodology for the topic: '{TOPIC_SENTENCE}'\",\n",
        "   f\"Analyze the strengths and weaknesses of this methodology: '{PARAGRAPHS}'\",\n",
        "   f\"Write objectives for this study: '{TOPIC_SENTENCE}'\",\n",
        "   f\"What are the limitations of using '{TOPIC_SENTENCE}' in '{RESEARCH_DOMAIN}'?\",\n",
        "   f\"Create a recipe for the methods used in this '{PARAGRAPHS}'\",\n",
        "   f\"Suggest interdisciplinary approaches to '{TOPIC_SENTENCE}'\",\n",
        "   f\"Explain how qualitative/quantitative research methods can be used to address '{RESEARCH_QUESTIONS}'\",\n",
        "   f\"Recommend best practices for data collection and analysis in '{TOPIC_SENTENCE}'\",\n",
        "\n",
        "   # Experiments\n",
        "   f\"Design an experiment that '{ACTION}'\",\n",
        "\n",
        "   # Results\n",
        "   f\"Write a result section for the following paragraphs. Please write this in the third person. '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Discussion\n",
        "   f\"Discuss this results: '{RESULT_PARAGRAPHS}'\",\n",
        "\n",
        "   # Conclusion\n",
        "   f\"Generate a conclusion for this: '{PARAGRAPHS}'\",\n",
        "   f\"Give recommendations and conclusion for: '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Future Works\n",
        "   f\"Can you suggest 3 directions for future research on this topic: '{PARAGRAPH}'\",\n",
        "\n",
        "   # Plan/Presentation\n",
        "   f\"Develop a research plan for: '{TOPIC_SENTENCE}'\",\n",
        "   f\"Write a schedule for completion in '{TOPIC_SENTENCE}' in NUMBER OF DAYS MONTHS YEARS which is '{NUMBER_OF_DAYS_MONTHS_YEARS}'\",\n",
        "   f\"The deadline for the submission of the first draft is '{DATE}'. Give me a week-by-week breakdown so I can plan my writing better.\",\n",
        "   f\"Write a sensational press release for this research: '{PARAGRAPHS}'\",\n",
        "   f\"Make this more persuasive: '{PARAGRAPH}'\",\n",
        "   f\"Write 3 tweets about this research? '{PARAGRAPHS}'\",\n",
        "]"
      ],
      "metadata": {
        "id": "uPcmAM5Zq5M-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define main variables\n",
        "#TOPIC = \"Psychological symptoms detection for Iranian men in their 40s studying for a PHD degree\"\n",
        "#RESEARCH_DOMAIN = \"Psychology\"\n",
        "#PARAGRAPH = \"The symptoms include lack of energy for doing work and difficulty focusing the mind on something\"\n",
        "#PARAGRAPHS = \"Historical background showing narcissism, which doesn't accept the information of psychology science but suggests using new technologies for creating cooperation\"\n",
        "#TOPIC_SENTENCE = \"The aim of this study is to investigate the psychological symptoms of Iranian men in their 40s who are studying for a PHD degree\"\n",
        "#LANGUAGE = \"English\"\n",
        "#ABSTRACT_PARAGRAPH = \"This study aims to investigate the psychological symptoms of Iranian men in their 40s who are studying for a PHD degree\"\n",
        "#BIBLIOGRAPHY = \"Masoumeh Zandpour, Jafar Hasani, Carla Sharp\"\n",
        "#THEORY1 = \"Psychological symptoms detection\"\n",
        "#THEORY2 = \"Narcissism\"\n",
        "#RESEARCH_QUESTIONS = \"What are the psychological symptoms of Iranian men in their 40s who are studying for a PHD degree?\"\n",
        "#ACTION = \"Investigate the psychological symptoms of Iranian men in their 40s who are studying for a PHD degree\"\n",
        "#RESULT_PARAGRAPHS = \"The results of the study indicate...\"\n",
        "#DATE = \"11/26/2023\"\n",
        "#NUMBER_OF_DAYS_MONTHS_YEARS = \"2 months\""
      ],
      "metadata": {
        "id": "dMj_71pfRWfL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Goal adding 🙏👇🌸"
      ],
      "metadata": {
        "id": "19Ch-86-MDD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "global docx_path,Pdf_Dir\n",
        "\n",
        "\n",
        "TOPIC_0 = f\"Analyze the current situation in the Islamic Republic of Iran and the challenges faced by resistance forces. And Identify effective strategies used by resistance movements to navigate challenging political environments.\"\n",
        "TOPIC_0 = f\"Could you provide more insights into the challenges faced by the opposition groups in Iran and how they could overcome these challenges to effectively organize resistance against the Islamic Republic?\"\n",
        "\n",
        "#PASSWORD =  # @param {type:\"string\"}\n",
        "if not (Question == \"\"):\n",
        "\n",
        "    TOPIC  = Question\n",
        "\n",
        "else:\n",
        "    TOPIC  = TOPIC_0\n",
        "\n",
        "    print(\"Please Input your Mega IDs.\")\n",
        "\n",
        "print ('Your question is:',TOPIC)# has done successfully\")\n",
        "\n",
        "#Define main variables\n",
        "#TOPIC = \"{TOPIC}\"\n",
        "RESEARCH_DOMAIN = \"{RESEARCH_DOMAIN}\"\n",
        "PARAGRAPH = \"{PARAGRAPH}\"\n",
        "PARAGRAPHS = \"{PARAGRAPHS}\"\n",
        "TOPIC_SENTENCE = \"{TOPIC_SENTENCE}\"\n",
        "LANGUAGE = \"{LANGUAGE}\"\n",
        "ABSTRACT_PARAGRAPH = \"{ABSTRACT_PARAGRAPH}\"\n",
        "BIBLIOGRAPHY = \"{BIBLIOGRAPHY}\"\n",
        "THEORY1 = \"{THEORY1}\"\n",
        "THEORY2 = \"{THEORY2}\"\n",
        "RESEARCH_QUESTIONS = \"{RESEARCH_QUESTIONS}\"\n",
        "ACTION = \"{ACTION}\"\n",
        "RESULT_PARAGRAPHS = \"{RESULT_PARAGRAPHS}\"\n",
        "DATE = \"{DATE}\"\n",
        "NUMBER_OF_DAYS_MONTHS_YEARS = \"{NUMBER_OF_DAYS_MONTHS_YEARS}\"\n",
        "\n",
        "\n",
        "main_variables_0 = {\n",
        "      'TOPIC': TOPIC,\n",
        "      'RESEARCH_DOMAIN': RESEARCH_DOMAIN,\n",
        "      'PARAGRAPH': PARAGRAPH,\n",
        "      'PARAGRAPHS': PARAGRAPHS,\n",
        "      'TOPIC_SENTENCE': TOPIC_SENTENCE,\n",
        "      'LANGUAGE': LANGUAGE,\n",
        "      'ABSTRACT_PARAGRAPH': ABSTRACT_PARAGRAPH,\n",
        "      'BIBLIOGRAPHY': BIBLIOGRAPHY,\n",
        "      'THEORY1': THEORY1,\n",
        "      'THEORY2': THEORY2,\n",
        "      'RESEARCH_QUESTIONS': RESEARCH_QUESTIONS,\n",
        "      'ACTION': ACTION,\n",
        "      'RESULT_PARAGRAPHS': RESULT_PARAGRAPHS,\n",
        "      'DATE': DATE,\n",
        "      'NUMBER_OF_DAYS_MONTHS_YEARS': NUMBER_OF_DAYS_MONTHS_YEARS,\n",
        "      'Generative_ai_field': 'academic paper and PhD thesis writing assistance',\n",
        "      'OPTIONAL': 'Middle East',\n",
        "      'perviuse_content' : '{perviuse_content}''this is the first step and perviuse contnet not created',\n",
        "      'PROMPT_UPDATING': \"Generate content for the variable '{{{var}}}' in the context of the topic '{main_variables_0.get('TOPIC', 'Default Value')}'. Please consider the result must be summarized to save ChatGPT tokens as a step prompt for ChatGPT Generative AI for the main goad which was made by TOPIC which was :'{TOPIC}' as an expert in the field of '{main_variables_0.get('Generative_ai_field', 'Default Value')}'. The main prompt is '{prompt}'. Also the more information for understanding better content is '{main_variables_0.get('perviuse_content', 'Default Value')}'\"\n",
        "\n",
        "\n",
        "  }\n",
        "\n",
        "# List of prompts for generating academic papers\n",
        "prompts = [\n",
        "# Improving Language\n",
        "f\"Write a counterargument to the following claim: '{PARAGRAPH}'\",\n",
        "f\"Rewrite this in an academic voice: '{PARAGRAPH}'\",\n",
        "f\"Expand these notes: '{PARAGRAPH}'\",\n",
        "f\"Provide me a list of words and phrases which were repeatedly / more than 3 times used: '{PARAGRAPHS}'\",\n",
        "f\"Provide me a list of synonyms for '{PARAGRAPH}' and evaluate them in the context of '{PARAGRAPH}'\",\n",
        "f\"Act as a language expert, proofread my paper on '{TOPIC_SENTENCE}' while putting a focus on grammar and punctuation.\",\n",
        "f\"In the context of '{RESEARCH_DOMAIN}' translate '{PARAGRAPH}' into the '{LANGUAGE}' language.\",\n",
        "\n",
        "  # Brainstorming\n",
        "  f\"Find a research topic for a PhD in the area of '{TOPIC}'\",\n",
        "  f\"Write a detailed proposal on the following research topic. Make sure it is free from plagiarism. '{PARAGRAPH}'\",\n",
        "  f\"Identify gaps in the literature on '{TOPIC_SENTENCE}'\",\n",
        "  f\"Generate 10 academic research questions about '{PARAGRAPHS}'\",\n",
        "  f\"Generate a list of research hypotheses related to '{TOPIC_SENTENCE}'\",\n",
        "  f\"Identify potential areas for future research in the context of this '{TOPIC_SENTENCE}'\",\n",
        "  f\"Suggest novel applications of '{TOPIC_SENTENCE}' within '{RESEARCH_DOMAIN}'\",\n",
        "\n",
        "  # Title/Topic Sentence\n",
        "  f\"Suggest 5 titles for the following abstract: '{ABSTRACT_PARAGRAPH}'\",\n",
        "  f\"Write a topic sentence for this paragraph: '{PARAGRAPH}'\",\n",
        "\n",
        "  # Keywords\n",
        "  f\"Provide 5 keywords for this: '{PARAGRAPHS}'\",\n",
        "\n",
        "  # Abstract\n",
        "  f\"Generate an abstract for a scientific paper based on this information for: '{PARAGRAPHS}'\",\n",
        "\n",
        "  # Outline\n",
        "  f\"Generate an outline for '{TOPIC_SENTENCE}'\",\n",
        "  f\"I want to write a journal article about '{TOPIC_SENTENCE}'. Give me an outline for the article that I can use as a starting point.\",\n",
        "\n",
        "  # Introduction\n",
        "  f\"Come up with an introduction for the following research topic: '{TOPIC_SENTENCE}'\",\n",
        "\n",
        "  # Literature Review\n",
        "  f\"Conduct a literature review on '{TOPIC_SENTENCE}' and provide review paper references\",\n",
        "  f\"Provide me with references and links to papers in '{PARAGRAPH}'\",\n",
        "  f\"Summarize the scholarly literature including in-text citations on '{PARAGRAPHS}'\",\n",
        "  f\"Write this in standard Harvard referencing '{PARAGRAPH}'\",\n",
        "  f\"Convert this '{BIBLIOGRAPHY}' from MLA to APA style.\",\n",
        "  f\"Compare and contrast '{THEORY1}' and '{THEORY2}' in the context of '{RESEARCH_DOMAIN}'\",\n",
        "\n",
        "  # Methodology\n",
        "   f\"Create objectives and methodology for '{TOPIC_SENTENCE}'\",\n",
        "   f\"Write a detailed methodology for the topic: '{TOPIC_SENTENCE}'\",\n",
        "   f\"Analyze the strengths and weaknesses of this methodology: '{PARAGRAPHS}'\",\n",
        "   f\"Write objectives for this study: '{TOPIC_SENTENCE}'\",\n",
        "   f\"What are the limitations of using '{TOPIC_SENTENCE}' in '{RESEARCH_DOMAIN}'?\",\n",
        "   f\"Create a recipe for the methods used in this '{PARAGRAPHS}'\",\n",
        "   f\"Suggest interdisciplinary approaches to '{TOPIC_SENTENCE}'\",\n",
        "   f\"Explain how qualitative/quantitative research methods can be used to address '{RESEARCH_QUESTIONS}'\",\n",
        "   f\"Recommend best practices for data collection and analysis in '{TOPIC_SENTENCE}'\",\n",
        "\n",
        "   # Experiments\n",
        "   f\"Design an experiment that '{ACTION}'\",\n",
        "\n",
        "   # Results\n",
        "   f\"Write a result section for the following paragraphs. Please write this in the third person. '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Discussion\n",
        "   f\"Discuss this results: '{RESULT_PARAGRAPHS}'\",\n",
        "\n",
        "   # Conclusion\n",
        "   f\"Generate a conclusion for this: '{PARAGRAPHS}'\",\n",
        "   f\"Give recommendations and conclusion for: '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Future Works\n",
        "   f\"Can you suggest 3 directions for future research on this topic: '{PARAGRAPH}'\",\n",
        "\n",
        "   # Plan/Presentation\n",
        "   f\"Develop a research plan for: '{TOPIC_SENTENCE}'\",\n",
        "   f\"Write a schedule for completion in '{TOPIC_SENTENCE}' in NUMBER OF DAYS MONTHS YEARS which is '{NUMBER_OF_DAYS_MONTHS_YEARS}'\",\n",
        "   f\"The deadline for the submission of the first draft is '{DATE}'. Give me a week-by-week breakdown so I can plan my writing better.\",\n",
        "   f\"Write a sensational press release for this research: '{PARAGRAPHS}'\",\n",
        "   f\"Make this more persuasive: '{PARAGRAPH}'\",\n",
        "   f\"Write 3 tweets about this research? '{PARAGRAPHS}'\",\n",
        "]"
      ],
      "metadata": {
        "id": "ndWVOITXN7Xu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48d95c07-e1d9-4241-f876-b5f94988451f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your question is: The Interplay of Religion and Conflict: A Study on the Quran and Its Verses on Peace and War\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "global docx_path,Pdf_Dir\n",
        "\n",
        "\n",
        "TOPIC_0 = f\"Analyze the current situation in the Islamic Republic of Iran and the challenges faced by resistance forces. And Identify effective strategies used by resistance movements to navigate challenging political environments.\"\n",
        "TOPIC_0 = f\"Could you provide more insights into the challenges faced by the opposition groups in Iran and how they could overcome these challenges to effectively organize resistance against the Islamic Republic?\"\n",
        "\n",
        "#PASSWORD =  # @param {type:\"string\"}\n",
        "if not (Question == \"\"):\n",
        "\n",
        "    TOPIC  = Question\n",
        "\n",
        "else:\n",
        "    TOPIC  = TOPIC_0\n",
        "\n",
        "    print(\"Please Input your Mega IDs.\")\n",
        "\n",
        "print ('Your question is:',TOPIC)# has done successfully\")\n",
        "\n",
        "#Define main variables\n",
        "#TOPIC = \"{TOPIC}\"\n",
        "RESEARCH_DOMAIN = \"{RESEARCH_DOMAIN}\"\n",
        "PARAGRAPH = \"{PARAGRAPH}\"\n",
        "PARAGRAPHS = \"{PARAGRAPHS}\"\n",
        "TOPIC_SENTENCE = \"{TOPIC_SENTENCE}\"\n",
        "LANGUAGE = \"{LANGUAGE}\"\n",
        "ABSTRACT_PARAGRAPH = \"{ABSTRACT_PARAGRAPH}\"\n",
        "BIBLIOGRAPHY = \"{BIBLIOGRAPHY}\"\n",
        "THEORY1 = \"{THEORY1}\"\n",
        "THEORY2 = \"{THEORY2}\"\n",
        "RESEARCH_QUESTIONS = \"{RESEARCH_QUESTIONS}\"\n",
        "ACTION = \"{ACTION}\"\n",
        "RESULT_PARAGRAPHS = \"{RESULT_PARAGRAPHS}\"\n",
        "DATE = \"{DATE}\"\n",
        "NUMBER_OF_DAYS_MONTHS_YEARS = \"{NUMBER_OF_DAYS_MONTHS_YEARS}\"\n",
        "Previous_CONTENT = {Previous_CONTENT}\n",
        "\n",
        "main_variables_0 = {Previous_CONTENT}\n",
        "      'TOPIC': TOPIC,\n",
        "      'RESEARCH_DOMAIN': RESEARCH_DOMAIN,\n",
        "      'PARAGRAPH': PARAGRAPH,\n",
        "      'PARAGRAPHS': PARAGRAPHS,\n",
        "      'TOPIC_SENTENCE': TOPIC_SENTENCE,\n",
        "      'LANGUAGE': LANGUAGE,\n",
        "      'ABSTRACT_PARAGRAPH': ABSTRACT_PARAGRAPH,\n",
        "      'BIBLIOGRAPHY': BIBLIOGRAPHY,\n",
        "      'THEORY1': THEORY1,\n",
        "      'THEORY2': THEORY2,\n",
        "      'RESEARCH_QUESTIONS': RESEARCH_QUESTIONS,\n",
        "      'ACTION': ACTION,\n",
        "      'RESULT_PARAGRAPHS': RESULT_PARAGRAPHS,\n",
        "      'DATE': DATE,\n",
        "      'NUMBER_OF_DAYS_MONTHS_YEARS': NUMBER_OF_DAYS_MONTHS_YEARS,\n",
        "      'Generative_ai_field': 'academic paper and PhD thesis writing assistance',\n",
        "      'OPTIONAL': 'Middle East',\n",
        "      'perviuse_content' : '{perviuse_content}''this is the first step and perviuse contnet not created',\n",
        "      'PROMPT_UPDATING': \"Generate content for the variable '{{{var}}}' in the context of the topic '{main_variables_0.get('TOPIC', 'Default Value')}'. Please consider the result must be summarized to save ChatGPT tokens as a step prompt for ChatGPT Generative AI for the main goad which was made by TOPIC which was :'{TOPIC}' as an expert in the field of '{main_variables_0.get('Generative_ai_field', 'Default Value')}'. The main prompt is '{prompt}'. Also the more information for understanding better content is '{main_variables_0.get('perviuse_content', 'Default Value')}'\"\n",
        "\n",
        "\n",
        "  }\n",
        "\n",
        "# List of prompts for generating academic papers\n",
        "prompts = [\n",
        "  f\"Critically evaluate the following content related to the topic '{TOPIC}': '{Previous_CONTENT}'. Discuss any potential issues, limitations, or controversies in the ideas expressed.\",\n",
        "  f\"Identify the key points in the following content related to the topic '{TOPIC}': '{Previous_CONTENT}'.\",\n",
        "  f\"Explain the context of the following content related to the topic '{TOPIC}': '{Previous_CONTENT}'.\",\n",
        "  f\"Summarize the following content related to the topic '{TOPIC}': '{Previous_CONTENT}'.\",\n",
        "  f\"Identify the research methodology used in the following content related to the topic '{TOPIC}': '{Previous_CONTENT}'.\",\n",
        "  f\"Analyze the data collection and analysis methods used in the following content related to the topic '{TOPIC}': '{Previous_CONTENT}'.\",\n",
        "  f\"Identify the research questions in the following content related to the topic '{TOPIC}': '{Previous_CONTENT}'.\",\n",
        "  f\"Evaluate the conclusions drawn in the following content related to the topic '{TOPIC}': '{Previous_CONTENT}'.\",\n",
        "  f\"Identify the limitations of the research in the following content related to the topic '{TOPIC}': '{Previous_CONTENT}'.\",\n",
        "  f\"Identify any controversies or debates related to the research in the following content related to the topic '{TOPIC}': '{Previous_CONTENT}'.\"\n",
        "]"
      ],
      "metadata": {
        "id": "OXVebdzWsc8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#making the photo by this project:\n",
        "https://huggingface.co/docs/transformers/transformers_agents"
      ],
      "metadata": {
        "id": "7oLR_rQkEVfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup\n",
        "transformers_version = \"v4.29.0\" #@param [\"main\", \"v4.29.0\"] {allow-input: true}\n",
        "\n",
        "print(f\"Setting up everything with transformers version {transformers_version}\")\n",
        "\n",
        "!pip install huggingface_hub>=0.14.1 git+https://github.com/huggingface/transformers@$transformers_version -q diffusers accelerate datasets torch soundfile sentencepiece opencv-python openai #==0.28\n",
        "\n",
        "import IPython\n",
        "import soundfile as sf\n",
        "\n",
        "def play_audio(audio):\n",
        "    sf.write(\"speech_converted.wav\", audio.numpy(), samplerate=16000)\n",
        "    return IPython.display.Audio(\"speech_converted.wav\")\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "k_LNLIUPEhS5",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704,
          "referenced_widgets": [
            "7ef97061076f40149392f5990d01ef69",
            "b9bbc3c8fc0e48409e5da6404b269aa1",
            "8d41b1ed7a9641dfb4619a031e3e2597",
            "1b596278110847e88fac8e3d0c07e4f5",
            "21c584ecb2a64bada3e1bf21924fb847",
            "d99402c0d95d413fbe24d187d904d34c",
            "117c2fe613c24ce7aa944f882414a1b0",
            "a9c75f3ca51f4d85a17baa6d78c259aa",
            "814e24ce34864858a927688508f175fb",
            "734c44b4b9db4c078c8b49f35ee207c4",
            "688304ae329b478f90c2105376b3c74d",
            "008dcb79b800458cafbdaee0177c26b2",
            "07486940523841c4bc0945877e1e3da1",
            "d60abec06b424c1ea187ac637516cc8c",
            "8ccea0b86ecc408a948ee933dc8542a1",
            "80a4adb137604d2891e8bf9103ffa96f",
            "5703985a3cb34259bd6d17f1b7e63dbc"
          ]
        },
        "outputId": "2c439e1e-0274-4a98-e9b9-b64149514177"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up everything with transformers version v4.29.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ef97061076f40149392f5990d01ef69"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   api_key = openai_api# \"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\",\n",
        ")\n",
        "\n",
        "#@title Agent init\n",
        "agent_name = \"OpenAI (API Key)\" #@param [\"StarCoder (HF Token)\", \"OpenAssistant (HF Token)\", \"OpenAI (API Key)\"]\n",
        "#openai_api = \"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\" # @param {type:\"string\"}\n",
        "\n",
        "pswd = openai_api\n",
        "import getpass\n",
        "\n",
        "if agent_name == \"StarCoder (HF Token)\":\n",
        "    from transformers.tools import HfAgent\n",
        "    agent = HfAgent(\"https://api-inference.huggingface.co/models/bigcode/starcoder\")\n",
        "    print(\"StarCoder is initialized 💪\")\n",
        "elif agent_name == \"OpenAssistant (HF Token)\":\n",
        "    from transformers.tools import HfAgent\n",
        "    agent = HfAgent(url_endpoint=\"https://api-inference.huggingface.co/models/OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5\")\n",
        "    print(\"OpenAssistant is initialized 💪\")\n",
        "if agent_name == \"OpenAI (API Key)\":\n",
        "    from transformers.tools import OpenAiAgent\n",
        "    #pswd = getpass.getpass('OpenAI API key:')\n",
        "    #agent = OpenAiAgent(model=\"text-davinci-003\", api_key=pswd)\n",
        "    #print(\"OpenAI is initialized 💪\")"
      ],
      "metadata": {
        "id": "yG_JTtKbEmW3",
        "cellView": "form"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_making(my_prompt, image_path=('/content/image_folder/', 'topic_folder')):\n",
        "   # Generate the image\n",
        "   boat = agent.run(f\"Generate an image based on this prompt: '{my_prompt}'\")\n",
        "\n",
        "   # Define the path to the image\n",
        "   image_path = os.path.join(image_path[0], image_path[1])\n",
        "\n",
        "   # Check if the folder exists\n",
        "   if not os.path.exists(image_path):\n",
        "       # If the folder doesn't exist, create it\n",
        "       os.mkdir(image_path)\n",
        "\n",
        "   # Save the image\n",
        "   image_path=os.path.join(image_path, 'image.jpg')\n",
        "\n",
        "   boat.save(os.path.join(image_path))#, 'image.jpg'))\n",
        "\n",
        "   return image_path"
      ],
      "metadata": {
        "id": "UdGnsfCUI9ln"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title .\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of changes in the type of violence that continues in the aftermath of violence\"\n",
        "#TOPIC =f\"Dark Triad and Light Triad in the Middle East: A Critical Examination of their Influence and Impact on Iran\"+TOPIC\n",
        "folder_chatGPT = \"/content/ChatGPT_academic_paper\"\n",
        "#openai_api = \"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\"\n",
        "TOPIC = main_variables_0.get('TOPIC', 'Default Value')\n",
        "print ('TOPIC IS :', TOPIC)\n",
        "\n",
        "print ('PROMPT_UPDATING vale is :',main_variables_0.get('PROMPT_UPDATING', 'Default Value'))\n",
        "\n",
        "global TOPIC_CLASS\n",
        "class TOPIC_CLASS:\n",
        "    def __init__(self):\n",
        "        self.perviuse_try_numner = 0\n",
        "        self.perviuse_content = ['fist step']\n",
        "        self.topic= TOPIC\n",
        "TP= TOPIC_CLASS()\n",
        "#TOPIC = f\" \""
      ],
      "metadata": {
        "id": "I484Df8ONQVI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c02508e6-c2fa-4be1-ac59-56b9df814f17"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOPIC IS : The Interplay of Religion and Conflict: A Study on the Quran and Its Verses on Peace and War\n",
            "PROMPT_UPDATING vale is : Generate content for the variable '{{{var}}}' in the context of the topic '{main_variables_0.get('TOPIC', 'Default Value')}'. Please consider the result must be summarized to save ChatGPT tokens as a step prompt for ChatGPT Generative AI for the main goad which was made by TOPIC which was :'{TOPIC}' as an expert in the field of '{main_variables_0.get('Generative_ai_field', 'Default Value')}'. The main prompt is '{prompt}'. Also the more information for understanding better content is '{main_variables_0.get('perviuse_content', 'Default Value')}'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Funstions for saving as PDF and DOCX :\n",
        "👇🌱"
      ],
      "metadata": {
        "id": "lI5PG0BNPrPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install libreoffice\n",
        "#!sudo apt-get install abiword\n",
        "!sudo apt install libreoffice-writer"
      ],
      "metadata": {
        "id": "XDBHbtajP03B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "194692fb-f052-418b-8a11-1988c7b9ef02"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.36)] [\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.36)] [\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libreoffice is already the newest version (1:7.3.7-0ubuntu0.22.04.3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 17 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libreoffice-writer is already the newest version (1:7.3.7-0ubuntu0.22.04.3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 17 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "W2xiQx_camiB"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "def convert_docx_to_pdf0(docx_path, pdf_path):\n",
        "  subprocess.call(['abiword', '--to=pdf', docx_path, '--to-dir', pdf_path])\n",
        "\n",
        "def convert_docx_to_pdf(docx_path, pdf_path):\n",
        " command = ['libreoffice', '--headless', '--convert-to', 'pdf', '--outdir', pdf_path, docx_path]\n",
        " subprocess.call(command)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "from docx import Document\n",
        "\n",
        "\n",
        "\n",
        "def save_academic_paper(topic, prompt_my):\n",
        " # Define the path to the DOCX file\n",
        " docx_path = f\"/content/{topic}.docx\"\n",
        "\n",
        " # Check if the DOCX file exists\n",
        " if os.path.isfile(docx_path):\n",
        "     # If the DOCX file exists, open it\n",
        "     doc = Document(docx_path)\n",
        " else:\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "     doc = Document()\n",
        "\n",
        " # Add the generated text to the document\n",
        " #print (\"____&&&&&&&&&&\\n\",prompt_my)\n",
        " doc.add_paragraph(prompt_my)\n",
        "\n",
        " # Save the document\n",
        " doc.save(docx_path)\n",
        "\n",
        " # Convert the DOCX file to a PDF\n",
        " convert_docx_to_pdf(docx_path, \"/content/output/\")"
      ],
      "metadata": {
        "id": "uE2pz7Zp4QIZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import subprocess\n",
        "from docx import Document\n",
        "from django.utils.text import slugify\n",
        "\n",
        "\n",
        "def save_academic_paper(topic, prompt_my):\n",
        "  # Define the path to the folder in Google Drive\n",
        "  folder_path = r\"/content/drive/My Drive/ChatGPT_Paper_wrting/Academic_contnet/\"\n",
        "\n",
        "  # Mount Google Drive\n",
        "  #drive.mount('/content/drive')\n",
        "  # Check if the drive is already mounted\n",
        "  if not os.path.isdir('/content/drive'):\n",
        "   # If not, mount the drive\n",
        "     drive.mount('/content/drive')\n",
        "  else:\n",
        "     print(\"Drive is already mounted.\")\n",
        "\n",
        "  Pdf_Dir= r\"/content/drive/My Drive/ChatGPT_Paper_wrting/Academic_contnet/\"\n",
        "  docx_path= f\"{folder_path}{topic}.docx\"\n",
        "  # Check if the folder exists\n",
        "  if not os.path.exists(folder_path):\n",
        "  # If the folder doesn't exist, create it\n",
        "    os.mkdir(folder_path)\n",
        "\n",
        "\n",
        "  # Replace spaces in the topic with underscores\n",
        "  #topic = topic[:12].replace(\" \", \"_\")\n",
        "  topic = slugify(topic)\n",
        "\n",
        "  # Define the path to the DOCX file in the folder\n",
        "\n",
        "\n",
        "  # Check if the DOCX file exists\n",
        "  if os.path.isfile(docx_path):\n",
        "    # If the DOCX file exists, open it\n",
        "\n",
        "    #docx_path = f\"{folder_path}_Aca_Cont_{topic}.docx\"#+str(random.randint(0,9))+\".docx\"\n",
        "    doc = Document(docx_path)\n",
        "  else:\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"\n",
        "    #print(docx_path)\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "    doc = Document()\n",
        "\n",
        "  # Add the generated text to the document\n",
        "  doc.add_paragraph(prompt_my)\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Convert the DOCX file to a PDF\n",
        "  convert_docx_to_pdf(docx_path,Pdf_Dir)"
      ],
      "metadata": {
        "id": "gEC4g9KHOQwh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import subprocess\n",
        "from docx import Document\n",
        "from django.utils.text import slugify\n",
        "\n",
        "\n",
        "  # Mount Google Drive\n",
        "if not os.path.isdir('/content/drive'):\n",
        "   # If not, mount the drive\n",
        "     drive.mount('/content/drive')\n",
        "else:\n",
        "     print(\"Drive is already mounted.\")\n",
        "\n",
        "\n",
        "def save_academic_paper_with_prompt(topic, prompt_my,contnet):\n",
        "  # Define the path to the folder in Google Drive\n",
        "  folder_path = r\"/content/drive/My Drive/ChatGPT_Paper_wrting/Academic_contnet/\"\n",
        "\n",
        "\n",
        "  Pdf_Dir= r\"/content/drive/My Drive/ChatGPT_Paper_wrting/Academic_contnet/\"\n",
        "  docx_path= f\"{folder_path}{topic}.docx\"\n",
        "  # Check if the folder exists\n",
        "  if not os.path.exists(folder_path):\n",
        "  # If the folder doesn't exist, create it\n",
        "    os.mkdir(folder_path)\n",
        "\n",
        "\n",
        "  # Replace spaces in the topic with underscores\n",
        "  #topic = topic[:12].replace(\" \", \"_\")\n",
        "  topic = slugify(topic)\n",
        "\n",
        "  # Define the path to the DOCX file in the folder\n",
        "\n",
        "\n",
        "  # Check if the DOCX file exists\n",
        "  if os.path.isfile(docx_path):\n",
        "    # If the DOCX file exists, open it\n",
        "\n",
        "    #docx_path = f\"{folder_path}_Aca_Cont_{topic}.docx\"#+str(random.randint(0,9))+\".docx\"\n",
        "    doc = Document(docx_path)\n",
        "  else:\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"\n",
        "    #print(docx_path)\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "    doc = Document()\n",
        "\n",
        "  # Add the generated text to the document\n",
        "  p = doc.add_paragraph(prompt_my)\n",
        "  # Add the generated text to the document\n",
        "  # Add the generated text to the document\n",
        "  p.style = doc.styles['Heading 2']\n",
        "\n",
        "  #image_path=image_making(prompt_my,topic)\n",
        "  # Add the image to the document\n",
        "  #doc.add_picture(image_path, width=Inches(2), height=Inches(2))\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  doc2 = Document(docx_path)\n",
        "  # Revert the style of the paragraph back to 'Normal'\n",
        "  p2 = doc2.add_paragraph(contnet)\n",
        "  p2.style = doc2.styles['Normal']\n",
        "\n",
        "  # Save the document\n",
        "  doc2.save(docx_path)\n",
        "\n",
        "  # Convert the DOCX file to a PDF\n",
        "  convert_docx_to_pdf(docx_path,Pdf_Dir)"
      ],
      "metadata": {
        "id": "iYQv76ernY6l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce574c3e-610e-46c5-8b46-19e3b90aa4e9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive is already mounted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# @title\n",
        "# conect to [Mega.z](https://mega.nz/) cloud for storage files based ot this page:\n",
        "\n",
        "https://colab.research.google.com/github/sudo-ken/Mega-to-Google-Drive/blob/master/Transfer_files_from_Mega_to_Google_Drive.ipynb#scrollTo=Vgh1xlQYGZCO"
      ],
      "metadata": {
        "id": "x7XWsP_amNqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install youtube-dl\n",
        "#!apt install python3-distutils\n",
        "!pip install mega.py\n",
        "!apt install python3-distutils  -y\n",
        "\n",
        "# %cd '/content/'\n",
        "# !git clone https://github.com/jeroenmeulenaar/python3-mega.git\n",
        "# !(cd python3-mega; pip install urlobject pycrypto)\n",
        "\n",
        "# import os\n",
        "# os.chdir('python3-mega')\n",
        "# from mega import Mega\n",
        "# os.chdir('../')\n",
        "# m = Mega.from_ephemeral()\n",
        "\n",
        "# !git clone https://github.com/odwyersoftware/mega.py\n",
        "# %cd mega.py\n",
        "# !python setup.py install\n",
        "%cd '/content/'\n",
        "\n",
        "!rm -rf '/content/yoloOnGoogleColab'\n",
        "#!git clone https://github.com/CAR-Driving/yoloOnGoogleColab"
      ],
      "metadata": {
        "id": "L436PiVNmQog",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "469093a9-8042-4ebf-b056-f36ff8323496"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mega.py\n",
            "  Downloading mega.py-1.0.8-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests>=0.10 in /usr/local/lib/python3.10/dist-packages (from mega.py) (2.31.0)\n",
            "Collecting pycryptodome<4.0.0,>=3.9.6 (from mega.py)\n",
            "  Downloading pycryptodome-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pathlib==1.0.1 in /usr/local/lib/python3.10/dist-packages (from mega.py) (1.0.1)\n",
            "Collecting tenacity<6.0.0,>=5.1.5 (from mega.py)\n",
            "  Downloading tenacity-5.1.5-py2.py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=0.10->mega.py) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=0.10->mega.py) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=0.10->mega.py) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=0.10->mega.py) (2023.7.22)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from tenacity<6.0.0,>=5.1.5->mega.py) (1.16.0)\n",
            "Installing collected packages: tenacity, pycryptodome, mega.py\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 8.2.3\n",
            "    Uninstalling tenacity-8.2.3:\n",
            "      Successfully uninstalled tenacity-8.2.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "plotly 5.15.0 requires tenacity>=6.2.0, but you have tenacity 5.1.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mega.py-1.0.8 pycryptodome-3.19.0 tenacity-5.1.5\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-distutils is already the newest version (3.10.8-1~22.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 17 not upgraded.\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# @markdown <center><h3>Input Your Mega ID</h3></center><br>\n",
        "from functools import wraps\n",
        "import errno\n",
        "import os\n",
        "import signal\n",
        "import subprocess\n",
        "import shlex\n",
        "\n",
        "\n",
        "class TimeoutError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "def timeout(seconds=10, error_message=os.strerror(errno.ETIME)):\n",
        "    def decorator(func):\n",
        "        def _handle_timeout(signum, frame):\n",
        "            raise TimeoutError(error_message)\n",
        "\n",
        "        def wrapper(*args, **kwargs):\n",
        "            signal.signal(signal.SIGALRM, _handle_timeout)\n",
        "            signal.alarm(seconds)\n",
        "            try:\n",
        "                result = func(*args, **kwargs)\n",
        "            finally:\n",
        "                signal.alarm(0)\n",
        "            return result\n",
        "\n",
        "        return wraps(func)(wrapper)\n",
        "\n",
        "    return decorator\n",
        "\n",
        "\n",
        "if not os.path.exists(\"/root/.ipython/ocr.py\"):\n",
        "    from subprocess import run\n",
        "    from shlex import split\n",
        "\n",
        "    shellCmd = \"wget -qq https://raw.githubusercontent.com/biplobsd/OneClickRun/master/res/ocr.py \\\n",
        "                    -O /root/.ipython/ocr.py\"\n",
        "    run(split(shellCmd))\n",
        "from ocr import runSh\n",
        "\n",
        "@timeout(10)\n",
        "def runShT(args):\n",
        "    return runSh(args, output=True)\n",
        "\n",
        "\n",
        "# MEGAcmd installing\n",
        "if not os.path.exists(\"/usr/bin/mega-cmd\"):\n",
        "    print(\"Installing MEGA ...\")\n",
        "    runSh('sudo apt-get -y update')\n",
        "    runSh('sudo apt-get -y install libmms0 libc-ares2 libc6 libcrypto++6 libgcc1 libmediainfo0v5 libpcre3 libpcrecpp0v5 libssl1.1 libstdc++6 libzen0v5 zlib1g apt-transport-https')\n",
        "    runSh('sudo curl -sL -o /var/cache/apt/archives/MEGAcmd.deb https://mega.nz/linux/MEGAsync/Debian_9.0/amd64/megacmd-Debian_9.0_amd64.deb', output=True)\n",
        "    runSh('sudo dpkg -i /var/cache/apt/archives/MEGAcmd.deb', output=True)\n",
        "    print(\"MEGA is installed.\")\n",
        "else:\n",
        "    !pkill mega-cmd\n",
        "\n",
        "# INPUT YOUR MEGA ID\n",
        "\n",
        "USERNAME = 'kayeyoc231@llubed.com'  # @param {type:\"string\"}\n",
        "PASSWORD = \"ss123456\"  # @param {type:\"string\"}\n",
        "if not (USERNAME == \"\" or PASSWORD == \"\"):\n",
        "    try:\n",
        "        runShT(f\"mega-login {USERNAME} {PASSWORD}\")\n",
        "        print (\"megazn login has done successfully\")\n",
        "    except TimeoutError:\n",
        "        runSh('mega-whoami', output=True)\n",
        "else:\n",
        "    print(\"Please Input your Mega IDs.\")\n",
        "# @markdown *After signing in, use the above cell(Main Cell) to transfer files from Mega to GDrive using the transfer quota of your Mega Pro Account*"
      ],
      "metadata": {
        "id": "uqYuzvYFoMIM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a3071fb-9a36-48ba-a1aa-a32a822b9a50"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing MEGA ...\n",
            "Selecting previously unselected package megacmd.\n",
            "(Reading database ... 129191 files and directories currently installed.)\n",
            "Preparing to unpack .../cache/apt/archives/MEGAcmd.deb ...\n",
            "Unpacking megacmd (1.5.1-2.1) ...\n",
            "dpkg: dependency problems prevent configuration of megacmd:\n",
            "megacmd depends on libc-ares2 (>= 1.11.0~rc1); however:\n",
            "Package libc-ares2 is not installed.\n",
            "megacmd depends on libcrypto++6; however:\n",
            "Package libcrypto++6 is not installed.\n",
            "megacmd depends on libmediainfo0v5 (>= 0.7.56); however:\n",
            "Package libmediainfo0v5 is not installed.\n",
            "megacmd depends on libssl1.1 (>= 1.1.0); however:\n",
            "Package libssl1.1 is not installed.\n",
            "megacmd depends on libzen0v5 (>= 0.4.31-2~); however:\n",
            "Package libzen0v5 is not installed.\n",
            "\n",
            "dpkg: error processing package megacmd (--install):\n",
            "dependency problems - leaving unconfigured\n",
            "Errors were encountered while processing:\n",
            "megacmd\n",
            "MEGA is installed.\n",
            "[Initiating MEGAcmd server in background. Log: /root/.megaCmd/megacmdserver.log]\n",
            "Unable to connect to service: error=2\n",
            "Please ensure mega-cmd-server is running\n",
            "Failed to create socket for registering for state changes\n",
            "megazn login has done successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#!rm -rf '/content/ChatGPT_academic_paper'\n",
        "!mkdir '/content/ChatGPT_academic_paper'\n",
        "%cd '/content/ChatGPT_academic_paper'\n",
        "!echo 't' >> t.txt\n",
        "\n",
        "from subprocess import Popen, PIPE\n",
        "import shlex\n",
        "import errno, os\n",
        "\n",
        "from subprocess import Popen, PIPE\n",
        "import shlex\n",
        "from ocr import runSh\n",
        "import re\n",
        "from distutils.dir_util import copy_tree\n",
        "\n",
        "# copy subdirectory example\n",
        "fromDirectory = '/content/ChatGPT_academic_paper/'\n",
        "toDirectory = '/content/gdrive/My Drive/yolo_car_database/'\n",
        "\n",
        "runSh('mega-cd /' )\n",
        "runSh(' mega-mkdir ChatGPT_academic_paper ')\n",
        "runSh(' mega-ls ')\n",
        "runSh('mega-cd ChatGPT_academic_paper ')\n",
        "\n",
        "# copy_tree(fromDirectory, toDirectory)\n",
        "def uplaod_mega_nz(root,cloude='mega',title1=''):\n",
        "  if (cloude=='mega'):\n",
        "  #  from mega import Mega\n",
        "  #  mega = Mega()\n",
        "  #  email = 'woraqofa@ivyandmarj.com'\n",
        "  #  password = 'feripas800@wgraj.com'\n",
        "  #  m = mega.login(email, password)\n",
        "  #  # login using a temporary anonymous account\n",
        "  #  m = mega.login()\n",
        "  #  quota = m.get_quota()\n",
        "  #  # specify unit output kilo, mega, gig, else bytes will output\n",
        "  #  space = m.get_storage_space(kilo=True)\n",
        "  #  m.create_folder('yolo_car_database/'+title1+'/')\n",
        "  #  folder = m.find('yolo_car_database/'+title1+'/')\n",
        "   # m.upload('myfile.doc', folder[0])\n",
        "  #  run_command('mega-cd ~ && mega-mkdir Yolo_car_database && mega-cd Yolo_car_database && mega-put '+ root+'/* . ')\n",
        "\n",
        "   runSh('mega-cd ChatGPT_academic_paper' + title1 + '/')\n",
        "   runSh('mega-put '+ root+' . ')\n",
        "   runSh(' mega-ls')\n",
        "\n",
        "   for path, subdirs, files in os.walk( root):\n",
        "      for name in files:\n",
        "        print (files)\n",
        "          # m.upload(os.path.join(path, name), folder[0])\n",
        "   # public_exported_web_link = m.export('myfile.doc')\n",
        "   # public_exported_web_link = m.export('my_mega_folder/my_sub_folder_to_share')\n",
        "\n",
        "  if (cloude=='google_drive'):\n",
        "     run_command('mkdir '+root+'/')\n",
        "     for path, subdirs, files in os.walk( root):\n",
        "      for name in files:\n",
        "        # print ('cp -r \"'+os.path.join(path, name)+'\" '+'\"/content/gdrive/My Drive/ChatGPT_academic_paper/' + title1 + '/\"')\n",
        "        # print (os.path.join(path, change_name(name)))\n",
        "        # os.rename(os.path.join(path, name), os.path.join(path, change_name(name)))\n",
        "        run_command('cp -r  \"'+os.path.join(path, name)+'\" '+'\"/content/gdrive/My Drive/ChatGPT_academic_paper/' + title1 + '/\"')\n",
        "     try:\n",
        "        copy_tree(root,'/content/gdrive/My Drive/ChatGPT_academic_paper/' + title1 + '/')\n",
        "     except OSError as e: # this would be \"except OSError, e:\" before Python 2.6\n",
        "        if e.errno != errno.ENOENT: # errno.ENOENT = no such file or directory\n",
        "            # raise #\n",
        "            i=0\n",
        "def change_file_name(root):\n",
        "  for path, subdirs, files in os.walk( root):\n",
        "      for name in files:\n",
        "        print ('filename is: \"'+os.path.join(path, name))\n",
        "        print (os.path.join(path, change_name(name)))\n",
        "        os.rename(os.path.join(path, name), os.path.join(path, change_name(name)))\n",
        "\n",
        "def run_command(cmd):\n",
        "    with Popen(shlex.split(cmd), stdout=PIPE, bufsize=1, universal_newlines=False) as p:\n",
        "        while True:\n",
        "            line = p.stdout.readline()\n",
        "            if not line:\n",
        "                break\n",
        "            print(line)\n",
        "        exit_code = p.poll()\n",
        "    return exit_code\n",
        "def change_name(name):\n",
        "    name_file = ''.join(name)\n",
        "    name_file = name_file.replace(\" \", \"_\")\n",
        "    name_file = name_file.replace(\"'\", \"_\")\n",
        "    name_file = name_file.replace(\"\\n\", \"\")\n",
        "    name_file = name_file.replace(\"\\t\", \"\")\n",
        "    name_file = name_file.replace(\"!\", \"\")\n",
        "    name_file = name_file.replace(\"-\", \"\")\n",
        "    name_file = name_file.replace(\"$\", \"\")\n",
        "    name_file = re.sub(r'[\\\\/*?:\"<>|]',\"\",name_file)\n",
        "    return name_file\n",
        "def MegaZN_upload_file(command):\n",
        "    # command_title=re.split('([^a-zA-Z0-9])',command)\n",
        "    command_title_1 = re.split('([^a-zA-Z0-9])', command)\n",
        "    command_title = ''.join(command_title_1)\n",
        "    command_title=change_name(command_title)\n",
        "\n",
        "\n",
        "    # call_args = ' youtube-dl --match-title ' + ' \"'+command_title_1[0]+ '\" ' + '\"ytsearch10\":'+'\"'+command+ '\" '+\"--external-downloader-args   '-ss 00:00:03 -t 00:03:08' --write-info-json --write-annotation --write-thumbnail --write-sub -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4'\"\n",
        "    #call_args = ' youtube-dl --match-title ' + ' \"'+command_title_1[0]+ '\" ' + '\"ytsearch100\":'+'\"'+command+ '\" '+\"--playlist-end 3  --external-downloader-args   '-ss 00:00:03 -t 00:03:08' --write-info-json --write-annotation --write-thumbnail --write-sub -f 'best[ext=mp4,height<=1080]+best[filesize<100M]' \"\n",
        "\n",
        "    # call_args = call_args.split() # because call takes a list of strings\n",
        "    # print (call_args)\n",
        "    # call(call_args)\n",
        "    # os.chdir(\"/content/yolo_car_database\")\n",
        "    # run_command('cd \"/content/yolo_car_database\"')\n",
        "    # run_command(call_args)\n",
        "    # os.system(\"cp --recursive '/content/yolo_car_database' '/content/gdrive/My Drive/yolo_car_databe\")\n",
        "    # os.system('pwd && ls ')\n",
        "    # copy_tree(fromDirectory, toDirectory)\n",
        "    # p = Popen(shlex.split(call_args), bufsize=1, universal_newlines=True)\n",
        "    run_command('mkdir /content/ChatGPT_academic_paper/'+command_title)\n",
        "\n",
        "    os.chdir( '/content/ChatGPT_academic_paper/'+command_title+'/')\n",
        "    #run_command(call_args)\n",
        "    # copy_tree('/content/yolo_car_database/'+command_title+'/', '/content/gdrive/My Drive/yolo_car_database/'+command_title+'/')\n",
        "    change_file_name('/content/ChatGPT_academic_paper/'+command_title+'/')\n",
        "    uplaod_mega_nz('/content/ChatGPT_academic_paper/'+command_title+'/','mega',command_title)\n",
        "    try:\n",
        "        # call(call_args)\n",
        "        # run_command('mkdir /content/yolo_car_database/'+command_title)\n",
        "        # os.chdir( '/content/yolo_car_database/'+command_title+'/')\n",
        "        # run_command(call_args)\n",
        "        # copy_tree('/content/yolo_car_database/'+command_title+'/', toDirectory)\n",
        "\n",
        "        # print (call_args)\n",
        "        pp=0\n",
        "\n",
        "    except OSError as e: # this would be \"except OSError, e:\" before Python 2.6\n",
        "        if e.errno != errno.ENOENT: # errno.ENOENT = no such file or directory\n",
        "            raise # re-raise exception if a different error occurred\n",
        "\n",
        "    # return p.poll()\n",
        "\n",
        "# !wget https://github.com/spectrico/car-make-model-classifier-yolo3-python/blob/master/labels.txt\n",
        "\n",
        "i=0\n",
        "#for line in open('/content/yoloOnGoogleColab/car_type_label.txt','r').readlines():\n",
        "    #print (line)\n",
        "    #try:\n",
        "      #Youtube_download_video(line)\n",
        "\n",
        "    #except OSError as e: # this would be \"except OSError, e:\" before Python 2.6\n",
        "        #if e.errno != errno.ENOENT: # errno.ENOENT = no such file or directory\n",
        "            #i=1 # re-raise exception if a different error occurred\n",
        "    #i=i+1\n",
        "# !cp '/content/yolo_car_database' \"gdrive/My Drive/yolo_car_databe\""
      ],
      "metadata": {
        "id": "8Fx5M6zXmTAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "178312ee-d119-4e89-dff4-0055f8ad6d46"
      },
      "execution_count": 20,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/ChatGPT_academic_paper\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!pwd\n",
        "%cd '/content/'\n",
        "from google.colab import drive\n",
        "import os\n",
        "import subprocess\n",
        "from docx import Document\n",
        "from django.utils.text import slugify\n",
        "\n",
        "# Mount Google Drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "def save_academic_paper_with_prompt_megazn(topic, prompt_my,contnet):\n",
        "  # Define the path to the folder in Google Drive\n",
        "  folder_path = r\"/content/ChatGPT_academic_paper/\"\n",
        "\n",
        "  Pdf_Dir= r\"/content/ChatGPT_academic_paper/\"\n",
        "  docx_path= f\"{folder_path}{topic}.docx\"\n",
        "  # Check if the folder exists\n",
        "  if not os.path.exists(folder_path):\n",
        "  # If the folder doesn't exist, create it\n",
        "    os.mkdir(folder_path)\n",
        "\n",
        "\n",
        "  # Replace spaces in the topic with underscores\n",
        "  #topic = topic[:12].replace(\" \", \"_\")\n",
        "  topic = slugify(topic)\n",
        "\n",
        "  # Define the path to the DOCX file in the folder\n",
        "\n",
        "\n",
        "  # Check if the DOCX file exists\n",
        "  if os.path.isfile(docx_path):\n",
        "    # If the DOCX file exists, open it\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"#+str(random.randint(0,9))+\".docx\"\n",
        "    doc = Document(docx_path)\n",
        "  else:\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"\n",
        "    #print(docx_path)\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "    doc = Document()\n",
        "\n",
        "  # Add the generated text to the document\n",
        "  p = doc.add_paragraph(prompt_my)\n",
        "  # Add the generated text to the document\n",
        "  # Add the generated text to the document\n",
        "  p.style = doc.styles['Heading 2']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #image_path=image_making(prompt_my,topic)\n",
        "  # Add the image to the document\n",
        "  #doc.add_picture(image_path, width=Inches(2), height=Inches(2))\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "  doc2 = Document(docx_path)\n",
        "  # Revert the style of the paragraph back to 'Normal'\n",
        "  p2 = doc2.add_paragraph(contnet)\n",
        "  p2.style = doc2.styles['Normal']\n",
        "\n",
        "  # Save the document\n",
        "  doc2.save(docx_path)\n",
        "\n",
        "  # Convert the DOCX file to a PDF\n",
        "  convert_docx_to_pdf(docx_path,Pdf_Dir)\n",
        "\n",
        "  os.chdir(folder_path)\n",
        "\n",
        "    # copy_tree('/content/yolo_car_database/'+command_title+'/', '/content/gdrive/My Drive/yolo_car_database/'+command_title+'/')\n",
        "\n",
        "  uplaod_mega_nz('/content/ChatGPT_Paper_wrting/')\n",
        "  uplaod_mega_nz('/content/ChatGPT_Paper_wrting/','google_drive')"
      ],
      "metadata": {
        "id": "nv2vAOr8sskq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2290e825-1e1a-4aad-f6ee-6af1e63bbb85"
      },
      "execution_count": 21,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/ChatGPT_academic_paper\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#save_academic_paper(\"Persian_\"+'topic','\\n**'+'choice_translated_prompt'+'**\\n'+\"choice_translated\")\n",
        "topic = TOPIC[:20].replace(\" \", \"_\")\n",
        "topic = slugify(TOPIC[:-5])\n",
        "docx_path = f\"{topic}.docx\"\n",
        "\n",
        "print(docx_path)"
      ],
      "metadata": {
        "id": "a76qNIRHs_gS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "129f83fe-39db-4dca-edf0-34247ae6c075"
      },
      "execution_count": 22,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the-interplay-of-religion-and-conflict-a-study-on-the-quran-and-its-verses-on-peace-an.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install googletrans==4.0.0-rc1\n",
        "\n",
        "!pip install httpcore==0.15.0 httpx pymongo googletrans\n",
        "!pip install httpx==0.24.1"
      ],
      "metadata": {
        "id": "qQOCu3GyEFf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7a6683be-a465-43b7-a78d-a6aa8282e972"
      },
      "execution_count": 23,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting httpcore==0.15.0\n",
            "  Downloading httpcore-0.15.0-py3-none-any.whl (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.4/68.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Collecting pymongo\n",
            "  Downloading pymongo-4.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.1/677.1 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting googletrans\n",
            "  Downloading googletrans-3.0.0.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting h11<0.13,>=0.11 (from httpcore==0.15.0)\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio==1.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (1.3.0)\n",
            "Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (2023.7.22)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore==0.15.0) (3.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore==0.15.0) (1.1.3)\n",
            "INFO: pip is looking at multiple versions of httpx to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting httpx\n",
            "  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hstspreload (from httpx)\n",
            "  Downloading hstspreload-2023.1.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==3.* (from httpx)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna>=2.8 (from anyio==3.*->httpcore==0.15.0)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3 (from httpx)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting googletrans\n",
            "  Downloading googletrans-2.4.0.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from googletrans) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->googletrans) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->googletrans) (2.0.7)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-2.4.0-py3-none-any.whl size=15762 sha256=0f9a1b08f0fec4f34469ff5bb2b34f98e8e3574df57c686c5b8c2865ff7c90fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/5f/60/c4738a8b36085696062052befbbfb65fc94d2286fb17015856\n",
            "Successfully built googletrans\n",
            "Installing collected packages: h11, dnspython, pymongo, httpcore, googletrans, httpx\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.14.0\n",
            "    Uninstalling h11-0.14.0:\n",
            "      Successfully uninstalled h11-0.14.0\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.2\n",
            "    Uninstalling httpcore-1.0.2:\n",
            "      Successfully uninstalled httpcore-1.0.2\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.25.2\n",
            "    Uninstalling httpx-0.25.2:\n",
            "      Successfully uninstalled httpx-0.25.2\n",
            "Successfully installed dnspython-2.4.2 googletrans-2.4.0 h11-0.12.0 httpcore-0.15.0 httpx-0.25.1 pymongo-4.6.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "h11",
                  "httpcore"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting httpx==0.24.1\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (2023.7.22)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (0.15.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (1.3.0)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.1) (0.12.0)\n",
            "Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.1) (3.7.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore<0.18.0,>=0.15.0->httpx==0.24.1) (1.1.3)\n",
            "Installing collected packages: httpx\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.25.1\n",
            "    Uninstalling httpx-0.25.1:\n",
            "      Successfully uninstalled httpx-0.25.1\n",
            "Successfully installed httpx-0.24.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#I have tried to update the prompt by ChatGPT itself 👇👇"
      ],
      "metadata": {
        "id": "wxqM4h1fw4fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_main_variables(prompts, variable):\n",
        "   main_variables= main_variables_0\n",
        "   for prompt in prompts:\n",
        "       variables = re.findall(r'\\{(\\w+)\\}', prompt)\n",
        "       for var in variables:\n",
        "           if var == 'TOPIC':\n",
        "               main_variables[var] = variable\n",
        "           else:\n",
        "               main_variables[var] = None\n",
        "\n",
        "   return main_variables"
      ],
      "metadata": {
        "id": "Jd711_MyBgje"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_main_variables(prompts, variable_para, var_content):\n",
        "    main_variables = main_variables_0\n",
        "\n",
        "    new_prompt = prompts[:]  # Create a deep copy of prompts\n",
        "\n",
        "    for i, prompt in enumerate(prompts):\n",
        "        for var in variable_para:\n",
        "            if var == variable_para :\n",
        "                main_variables[var] = var_content\n",
        "                new_prompt[i] = prompt.replace(var, var_content)\n",
        "        for var, value in main_variables.items():\n",
        "             if var == variable_para:\n",
        "                main_variables[var] = var_content\n",
        "                new_prompt[i] = new_prompt[i].replace('{'+var+'}', \"{\"+f\"{var}\"+'}'+f\" which is :{var_content}\")#f\"{{{variable}}}\")\n",
        "\n",
        "\n",
        "    return main_variables, new_prompt\n",
        "#TOPIC='my test topic'\n",
        "main_variables, prompt_new = extract_main_variables(prompts, 'TOPIC', TOPIC)\n",
        "print (\" topic is :\", TOPIC)\n",
        "print(\"main variable is :\", main_variables)\n",
        "print(\"new_prompt is :\", prompt_new)\n",
        "prompts= prompt_new\n",
        "print(\"prompt is :\", prompts)"
      ],
      "metadata": {
        "id": "VLFUpVSA2Pbr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba435fd9-94ac-479d-f5f8-5f8f188587c7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " topic is : The Interplay of Religion and Conflict: A Study on the Quran and Its Verses on Peace and War\n",
            "main variable is : {'TOPIC': 'The Interplay of Religion and Conflict: A Study on the Quran and Its Verses on Peace and War', 'RESEARCH_DOMAIN': '{RESEARCH_DOMAIN}', 'PARAGRAPH': '{PARAGRAPH}', 'PARAGRAPHS': '{PARAGRAPHS}', 'TOPIC_SENTENCE': '{TOPIC_SENTENCE}', 'LANGUAGE': '{LANGUAGE}', 'ABSTRACT_PARAGRAPH': '{ABSTRACT_PARAGRAPH}', 'BIBLIOGRAPHY': '{BIBLIOGRAPHY}', 'THEORY1': '{THEORY1}', 'THEORY2': '{THEORY2}', 'RESEARCH_QUESTIONS': '{RESEARCH_QUESTIONS}', 'ACTION': '{ACTION}', 'RESULT_PARAGRAPHS': '{RESULT_PARAGRAPHS}', 'DATE': '{DATE}', 'NUMBER_OF_DAYS_MONTHS_YEARS': '{NUMBER_OF_DAYS_MONTHS_YEARS}', 'Generative_ai_field': 'academic paper and PhD thesis writing assistance', 'OPTIONAL': 'Middle East', 'perviuse_content': '{perviuse_content}this is the first step and perviuse contnet not created', 'PROMPT_UPDATING': \"Generate content for the variable '{{{var}}}' in the context of the topic '{main_variables_0.get('TOPIC', 'Default Value')}'. Please consider the result must be summarized to save ChatGPT tokens as a step prompt for ChatGPT Generative AI for the main goad which was made by TOPIC which was :'{TOPIC}' as an expert in the field of '{main_variables_0.get('Generative_ai_field', 'Default Value')}'. The main prompt is '{prompt}'. Also the more information for understanding better content is '{main_variables_0.get('perviuse_content', 'Default Value')}'\"}\n",
            "new_prompt is : [\"Write a counterargument to the following claim: '{PARAGRAPH}'\", \"Rewrite this in an academic voice: '{PARAGRAPH}'\", \"Expand these notes: '{PARAGRAPH}'\", \"Provide me a list of words and phrases which were repeatedly / more than 3 times used: '{PARAGRAPHS}'\", \"Provide me a list of synonyms for '{PARAGRAPH}' and evaluate them in the context of '{PARAGRAPH}'\", \"Act as a language expert, proofread my paper on '{TOPIC_SENTENCE}' while putting a focus on grammar and punctuation.\", \"In the context of '{RESEARCH_DOMAIN}' translate '{PARAGRAPH}' into the '{LANGUAGE}' language.\", \"Find a research topic for a PhD in the area of 'The Interplay of Religion and Conflict: A Study on the Quran and Its Verses on Peace and War'\", \"Write a detailed proposal on the following research topic. Make sure it is free from plagiarism. '{PARAGRAPH}'\", \"Identify gaps in the literature on '{TOPIC_SENTENCE}'\", \"Generate 10 academic research questions about '{PARAGRAPHS}'\", \"Generate a list of research hypotheses related to '{TOPIC_SENTENCE}'\", \"Identify potential areas for future research in the context of this '{TOPIC_SENTENCE}'\", \"Suggest novel applications of '{TOPIC_SENTENCE}' within '{RESEARCH_DOMAIN}'\", \"Suggest 5 titles for the following abstract: '{ABSTRACT_PARAGRAPH}'\", \"Write a topic sentence for this paragraph: '{PARAGRAPH}'\", \"Provide 5 keywords for this: '{PARAGRAPHS}'\", \"Generate an abstract for a scientific paper based on this information for: '{PARAGRAPHS}'\", \"Generate an outline for '{TOPIC_SENTENCE}'\", \"I want to write a journal article about '{TOPIC_SENTENCE}'. Give me an outline for the article that I can use as a starting point.\", \"Come up with an introduction for the following research topic: '{TOPIC_SENTENCE}'\", \"Conduct a literature review on '{TOPIC_SENTENCE}' and provide review paper references\", \"Provide me with references and links to papers in '{PARAGRAPH}'\", \"Summarize the scholarly literature including in-text citations on '{PARAGRAPHS}'\", \"Write this in standard Harvard referencing '{PARAGRAPH}'\", \"Convert this '{BIBLIOGRAPHY}' from MLA to APA style.\", \"Compare and contrast '{THEORY1}' and '{THEORY2}' in the context of '{RESEARCH_DOMAIN}'\", \"Create objectives and methodology for '{TOPIC_SENTENCE}'\", \"Write a detailed methodology for the topic: '{TOPIC_SENTENCE}'\", \"Analyze the strengths and weaknesses of this methodology: '{PARAGRAPHS}'\", \"Write objectives for this study: '{TOPIC_SENTENCE}'\", \"What are the limitations of using '{TOPIC_SENTENCE}' in '{RESEARCH_DOMAIN}'?\", \"Create a recipe for the methods used in this '{PARAGRAPHS}'\", \"Suggest interdisciplinary approaches to '{TOPIC_SENTENCE}'\", \"Explain how qualitative/quantitative research methods can be used to address '{RESEARCH_QUESTIONS}'\", \"Recommend best practices for data collection and analysis in '{TOPIC_SENTENCE}'\", \"Design an experiment that '{ACTION}'\", \"Write a result section for the following paragraphs. Please write this in the third person. '{PARAGRAPHS}'\", \"Discuss this results: '{RESULT_PARAGRAPHS}'\", \"Generate a conclusion for this: '{PARAGRAPHS}'\", \"Give recommendations and conclusion for: '{PARAGRAPHS}'\", \"Can you suggest 3 directions for future research on this topic: '{PARAGRAPH}'\", \"Develop a research plan for: '{TOPIC_SENTENCE}'\", \"Write a schedule for completion in '{TOPIC_SENTENCE}' in NUMBER OF DAYS MONTHS YEARS which is '{NUMBER_OF_DAYS_MONTHS_YEARS}'\", \"The deadline for the submission of the first draft is '{DATE}'. Give me a week-by-week breakdown so I can plan my writing better.\", \"Write a sensational press release for this research: '{PARAGRAPHS}'\", \"Make this more persuasive: '{PARAGRAPH}'\", \"Write 3 tweets about this research? '{PARAGRAPHS}'\"]\n",
            "prompt is : [\"Write a counterargument to the following claim: '{PARAGRAPH}'\", \"Rewrite this in an academic voice: '{PARAGRAPH}'\", \"Expand these notes: '{PARAGRAPH}'\", \"Provide me a list of words and phrases which were repeatedly / more than 3 times used: '{PARAGRAPHS}'\", \"Provide me a list of synonyms for '{PARAGRAPH}' and evaluate them in the context of '{PARAGRAPH}'\", \"Act as a language expert, proofread my paper on '{TOPIC_SENTENCE}' while putting a focus on grammar and punctuation.\", \"In the context of '{RESEARCH_DOMAIN}' translate '{PARAGRAPH}' into the '{LANGUAGE}' language.\", \"Find a research topic for a PhD in the area of 'The Interplay of Religion and Conflict: A Study on the Quran and Its Verses on Peace and War'\", \"Write a detailed proposal on the following research topic. Make sure it is free from plagiarism. '{PARAGRAPH}'\", \"Identify gaps in the literature on '{TOPIC_SENTENCE}'\", \"Generate 10 academic research questions about '{PARAGRAPHS}'\", \"Generate a list of research hypotheses related to '{TOPIC_SENTENCE}'\", \"Identify potential areas for future research in the context of this '{TOPIC_SENTENCE}'\", \"Suggest novel applications of '{TOPIC_SENTENCE}' within '{RESEARCH_DOMAIN}'\", \"Suggest 5 titles for the following abstract: '{ABSTRACT_PARAGRAPH}'\", \"Write a topic sentence for this paragraph: '{PARAGRAPH}'\", \"Provide 5 keywords for this: '{PARAGRAPHS}'\", \"Generate an abstract for a scientific paper based on this information for: '{PARAGRAPHS}'\", \"Generate an outline for '{TOPIC_SENTENCE}'\", \"I want to write a journal article about '{TOPIC_SENTENCE}'. Give me an outline for the article that I can use as a starting point.\", \"Come up with an introduction for the following research topic: '{TOPIC_SENTENCE}'\", \"Conduct a literature review on '{TOPIC_SENTENCE}' and provide review paper references\", \"Provide me with references and links to papers in '{PARAGRAPH}'\", \"Summarize the scholarly literature including in-text citations on '{PARAGRAPHS}'\", \"Write this in standard Harvard referencing '{PARAGRAPH}'\", \"Convert this '{BIBLIOGRAPHY}' from MLA to APA style.\", \"Compare and contrast '{THEORY1}' and '{THEORY2}' in the context of '{RESEARCH_DOMAIN}'\", \"Create objectives and methodology for '{TOPIC_SENTENCE}'\", \"Write a detailed methodology for the topic: '{TOPIC_SENTENCE}'\", \"Analyze the strengths and weaknesses of this methodology: '{PARAGRAPHS}'\", \"Write objectives for this study: '{TOPIC_SENTENCE}'\", \"What are the limitations of using '{TOPIC_SENTENCE}' in '{RESEARCH_DOMAIN}'?\", \"Create a recipe for the methods used in this '{PARAGRAPHS}'\", \"Suggest interdisciplinary approaches to '{TOPIC_SENTENCE}'\", \"Explain how qualitative/quantitative research methods can be used to address '{RESEARCH_QUESTIONS}'\", \"Recommend best practices for data collection and analysis in '{TOPIC_SENTENCE}'\", \"Design an experiment that '{ACTION}'\", \"Write a result section for the following paragraphs. Please write this in the third person. '{PARAGRAPHS}'\", \"Discuss this results: '{RESULT_PARAGRAPHS}'\", \"Generate a conclusion for this: '{PARAGRAPHS}'\", \"Give recommendations and conclusion for: '{PARAGRAPHS}'\", \"Can you suggest 3 directions for future research on this topic: '{PARAGRAPH}'\", \"Develop a research plan for: '{TOPIC_SENTENCE}'\", \"Write a schedule for completion in '{TOPIC_SENTENCE}' in NUMBER OF DAYS MONTHS YEARS which is '{NUMBER_OF_DAYS_MONTHS_YEARS}'\", \"The deadline for the submission of the first draft is '{DATE}'. Give me a week-by-week breakdown so I can plan my writing better.\", \"Write a sensational press release for this research: '{PARAGRAPHS}'\", \"Make this more persuasive: '{PARAGRAPH}'\", \"Write 3 tweets about this research? '{PARAGRAPHS}'\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "\n",
        "def generate_prompt_from_response(previous_response, main_variables):\n",
        "   # Customize this logic based on your needs\n",
        "   # For simplicity, let's use the last 50 characters of the response as the new prompt\n",
        "   new_prompt = previous_response[-50:]\n",
        "\n",
        "   # Replace the main variables in the new prompt\n",
        "   for var, value in main_variables.items():\n",
        "       if value is not None:\n",
        "           new_prompt = new_prompt.replace(value, f\"{{{var}}}\")\n",
        "\n",
        "   return new_prompt\n",
        "\n",
        "# Example usage\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\"\n",
        "\n",
        "prompts_1 = [\n",
        "f\"Find a research topic for a PhD in the area of '{TOPIC}'\",\n",
        "\n",
        "]\n",
        "#prompts_2 = [\n",
        "#   \"I need to find information on renewable energy for a research paper that will be 1,500 words and must include eight sources.\",\n",
        "#   \"The research paper should cover the latest advancements in renewable energy technology.\"\n",
        "#]\n",
        "\n",
        "#main_variables,prompt_new = extract_main_variables(prompts,'TOPIC',TOPIC)\n",
        "#print(main_variables)\n",
        "\n",
        "#previous_response = \"Previous GPT response\"\n",
        "#new_prompt = generate_prompt_from_response(previous_response, main_variables)\n",
        "#print(new_prompt)\n",
        "#print ( prompts)"
      ],
      "metadata": {
        "id": "NYegFb6aq_h8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Updating the prompt by ChatGPT:👇👇"
      ],
      "metadata": {
        "id": "UgzzXkG9wjbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.get_encoding(encoding_name)\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "num_tokens_from_string(\"tiktoken is great!\", \"cl100k_base\")"
      ],
      "metadata": {
        "id": "oJ1QCUr62rtw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d0b682f-bb75-48ca-86cf-7d21c8d6b643"
      },
      "execution_count": 27,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt_update_0(prompt, previous_content, main_variables):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   # Replace the TOPIC variable in the prompt\n",
        "   for var, value in main_variables.items():\n",
        "       if var == 'TOPIC' and value is not None:\n",
        "           prompt = prompt.replace(f\"{{{var}}}\", value)\n",
        "\n",
        "   # Construct the instruction for updating the prompt\n",
        "   instruction = f\"Given the previous content:\\n\\n{previous_content}\\n\\nUpdate the prompt: {prompt}\"\n",
        "\n",
        "   # Create the completion with the instruction\n",
        "   completion = client.completions.create(\n",
        "       model=model_engine,\n",
        "       prompt=instruction,\n",
        "       max_tokens=max_tokens,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "\n",
        "   # Extract and return the updated prompt from the response\n",
        "   updated_prompt = completion.choices[0].text.strip()\n",
        "   return updated_prompt"
      ],
      "metadata": {
        "id": "QbOCQqCDB8xb"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "def generate_prompt_update_a1(prompt_my):\n",
        "  model_engine = \"text-davinci-003\"\n",
        "  max_tokens = 2048\n",
        "\n",
        "  completion = client.completions.create(\n",
        "      model=\"gpt-3.5-turbo-instruct\",\n",
        "      #model=\"curie\"\n",
        "      prompt=prompt_my,\n",
        "      max_tokens=2048,\n",
        "      temperature=0.3,\n",
        "      n=1,\n",
        "      frequency_penalty=0,\n",
        "  )\n",
        "  return completion"
      ],
      "metadata": {
        "id": "WPRw6qJOuaS1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import openai\n",
        "from openai import RateLimitError\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   api_key = openai_api# \"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\",\n",
        ")\n",
        "def retry_with_exponential_backoff(\n",
        "   func,\n",
        "   initial_delay: float = 1,\n",
        "   exponential_base: float = 2,\n",
        "   jitter: bool = True,\n",
        "   max_retries: int = 10,\n",
        "   errors: tuple = (RateLimitError,),\n",
        "):\n",
        "   \"\"\"Retry a function with exponential backoff.\"\"\"\n",
        "   def wrapper(*args, **kwargs):\n",
        "       # Initialize variables\n",
        "       num_retries = 0\n",
        "       delay = initial_delay\n",
        "       # Loop until a successful response or max_retries is hit or an exception is raised\n",
        "       while True:\n",
        "           try:\n",
        "               return func(*args, **kwargs)\n",
        "           # Retry on specified errors\n",
        "           except errors as e:\n",
        "               # Increment retries\n",
        "               num_retries += 1\n",
        "               # Check if max retries has been reached\n",
        "               if num_retries > max_retries:\n",
        "                  raise Exception(\n",
        "                      f\"Maximum number of retries ({max_retries}) exceeded.\"\n",
        "                  )\n",
        "               # Increment the delay\n",
        "               delay *= exponential_base * (1 + jitter * random.random())\n",
        "               # Sleep for the delay\n",
        "               time.sleep(delay)\n",
        "           # Raise exceptions for any errors not specified\n",
        "           except Exception as e:\n",
        "               raise e\n",
        "   return wrapper\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "\n",
        "@retry_with_exponential_backoff\n",
        "def generate_prompt_update(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "   print(f\"{num_tokens_from_string(prompt_my,model)} prompt tokens counted by num_tokens_from_messages().\")\n",
        "\n",
        "   completion = client.completions.create(\n",
        "     model=\"gpt-3.5-turbo-instruct\",\n",
        "     prompt=prompt_my,\n",
        "     max_tokens=500,\n",
        "     temperature=0.1,\n",
        "     n=1,\n",
        "     frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "\n",
        "@retry_with_exponential_backoff\n",
        "def generate_academic_paper(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "   print(f\"{num_tokens_from_string(prompt_my,model)} prompt tokens counted by num_tokens_from_messages().\")\n",
        "\n",
        "\n",
        "   completion = client.completion.create(\n",
        "     #model=\"gpt-3.5-turbo-instruct\",\n",
        "     model=\"gpt-3.5-turbo-1106\",\n",
        "     prompt=prompt_my,\n",
        "     max_tokens=2048,\n",
        "     temperature=0.3,\n",
        "     n=1,\n",
        "     frequency_penalty=0,\n",
        "   )\n",
        "   return completion"
      ],
      "metadata": {
        "id": "O2TNMQ8eFl8n"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def generate_prompt(prompts, variables, TOPIC, perviuse_content=\"\"):\n",
        "  # Generate content for each variable\n",
        "  variable_contents = {}\n",
        "\n",
        "\n",
        "  main_variables = main_variables_0\n",
        "  prompt_my = f\"{main_variables_0.get('PROMPT_UPDATING', 'Default Value')}\"\n",
        "  for prompt in prompts:\n",
        "      for var in variables:\n",
        "          if var in prompt:\n",
        "              print(f\"\\n---prompt is ----\\n{prompt}\")\n",
        "              #prompt_my = f\"Generate content for the variable '{var}' in the context of the topic '{TOPIC}'. Please consider the result must be in less than 10 words. The prompt is '{prompt}'. Also the more information for understanding better content is '{perviuse_content}'\"\n",
        "              prompt_my =  f\"Generate ChatGPT  prompt in less than 45 word and one paragraph, as content for the variable '{var}' in the context of the topic '{TOPIC}'. Please consider the result must be sumerized and as variable for chatgpt academic phd writer assistance. The prompt is '{prompt}'. Also the more information for understanding better content is '{perviuse_content}'\"\n",
        "\n",
        "              #prompt_my = f\"{main_variables_0.get('PROMPT_UPDATING', 'Default Value')}\"\n",
        "\n",
        "              # Replace the variable in the code with the counterargument\n",
        "              #prompt_my = prompt_my.replace(\"{prompt}\", prompt)\n",
        "              #prompt_my = prompt_my.replace(\"{var}\", main_variables_0.get(var,'Default Value'))\n",
        "\n",
        "              print( \"Prompt is: \", prompt_my)\n",
        "              content = generate_prompt_update_a1(prompt_my)\n",
        "              for choice in content.choices:\n",
        "                print(\"\\n Result is :\"+choice.text)\n",
        "                variable_contents[var] = choice.text\n",
        "              print(f\"variable_contents[{var}] is: {variable_contents[var]}\")\n",
        "\n",
        "              time.sleep(random.randint(22, 40))\n",
        "\n",
        "  # Replace the variables in the prompts with the generated content\n",
        "  prompt_new = []\n",
        "  for prompt in prompts:\n",
        "      for var, content in variable_contents.items():\n",
        "          prompt = prompt.replace(f\"{{{var}}}\", variable_contents[var])\n",
        "      prompt_new.append(prompt)\n",
        "      print(\"\\n --- Updated prompt is :\\n\"+str(prompt_new))\n",
        "  return prompt_new\n",
        "\n",
        "# Define main variables\n",
        "#TOPIC = \"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"\n",
        "\n",
        "# List of variables\n",
        "variables = [\"RESEARCH_DOMAIN\", \"PARAGRAPH\", \"PARAGRAPHS\", \"TOPIC_SENTENCE\", \"LANGUAGE\", \"ABSTRACT_PARAGRAPH\", \"BIBLIOGRAPHY\", \"THEORY1\", \"THEORY2\", \"RESEARCH_QUESTIONS\", \"ACTION\", \"RESULT_PARAGRAPHS\", \"DATE\", \"NUMBER_OF_DAYS_MONTHS_YEARS\"]\n",
        "\n",
        "# List of prompts\n",
        "#prompts = [\"prompt1\", \"prompt2\", \"prompt3\"] # replace with your actual prompts\n",
        "#perviuse_content= \"test\"\n",
        "# Call the function and store the returned prompts\n",
        "#updated_prompts = generate_content(prompts, variables, TOPIC, perviuse_content)\n",
        "#print(\"Updated Prompts:\", updated_prompts)"
      ],
      "metadata": {
        "id": "uI21enmkhb0n"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def generate_prompt_2(prompts, variables, TOPIC, perviuse_content=\"\"):\n",
        "  # Generate content for each variable\n",
        "  variable_contents = {}\n",
        "  main_variables = main_variables_0\n",
        "  for prompt in prompts:\n",
        "      for var in variables:\n",
        "          if var in prompt:\n",
        "              print(f\"\\n---prompt is ----\\n{prompt}\")\n",
        "              prompt_my = f\"Generate content for the variable '{var}' in the context of the topic '{TOPIC}'. Please consider the result must be in less than 10 words. The prompt is '{prompt}'. Also the more information for understanding better content is '{perviuse_content}'\"\n",
        "              content = generate_prompt_update_a1(prompt_my)\n",
        "              for choice in content.choices:\n",
        "                print(\"\\n Result is :\"+choice.text)\n",
        "                variable_contents[var] = choice.text\n",
        "              print(f\"variable_contents[{var}] is: {variable_contents[var]}\")\n",
        "\n",
        "              time.sleep(random.randint(22, 40))\n",
        "\n",
        "  main_variables, prompt_new = extract_main_variables(prompts, var, variable_contents[var])\n",
        "\n",
        "  print(\"main variable is :\", main_variables)\n",
        "  print(\"new_prompt is :\", prompt_new)\n",
        "  prompts= prompt_new\n",
        "\n",
        "  # Replace the variables in the prompts with the generated content\n",
        "  prompt_new = []\n",
        "  for prompt in prompts:\n",
        "      for var, content in variable_contents.items():\n",
        "          prompt = prompt.replace(f\"{{{var}}}\", variable_contents[var])\n",
        "      prompt_new.append(prompt)\n",
        "      print(\"\\n --- Updated prompt is :\\n\"+str(prompt_new))\n",
        "  return prompt_new,main_variables\n",
        "\n",
        "# Define main variables\n",
        "#TOPIC = \"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"\n",
        "\n",
        "# List of variables\n",
        "variables = [\"RESEARCH_DOMAIN\", \"PARAGRAPH\", \"PARAGRAPHS\", \"TOPIC_SENTENCE\", \"LANGUAGE\", \"ABSTRACT_PARAGRAPH\", \"BIBLIOGRAPHY\", \"THEORY1\", \"THEORY2\", \"RESEARCH_QUESTIONS\", \"ACTION\", \"RESULT_PARAGRAPHS\", \"DATE\", \"NUMBER_OF_DAYS_MONTHS_YEARS\"]\n",
        "\n",
        "# List of prompts\n",
        "#prompts = [\"prompt1\", \"prompt2\", \"prompt3\"] # replace with your actual prompts\n",
        "#perviuse_content= \"test\"\n",
        "# Call the function and store the returned prompts\n",
        "#updated_prompts = generate_content(prompts, variables, TOPIC, perviuse_content)\n",
        "#print(\"Updated Prompts:\", updated_prompts)"
      ],
      "metadata": {
        "id": "-tAXnnAOkagH"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\" #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\"\n",
        "\n",
        "\n",
        "#topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "#client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   #api_key = \"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\",\n",
        "#)\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "# Create a Translator object\n",
        "translator = Translator()\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "def generate_academic_paper_a0(prompt_my):\n",
        "  model_engine = \"text-davinci-003\"\n",
        "  max_tokens = 2048\n",
        "\n",
        "  completion = client.completions.create(\n",
        "      model=\"gpt-3.5-turbo-instruct\",\n",
        "      prompt=prompt_my,\n",
        "      max_tokens=2048,\n",
        "      temperature=0.3,\n",
        "      n=1,\n",
        "      frequency_penalty=0,\n",
        "  )\n",
        "  return completion"
      ],
      "metadata": {
        "id": "44bkCJOHtmuJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time,random\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   api_key = openai_api#\"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\",\n",
        ")\n",
        "\n",
        "def generate_papers(prompts, perviuse_content, perviuse_try_numner):\n",
        "  choice_text_all=[]\n",
        "\n",
        "  for i in range(perviuse_try_numner, len(prompts), 20):\n",
        "     # Slice the prompts list to get the next 20 prompts\n",
        "     print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "\n",
        "     batch = prompts[i:i+20]\n",
        "     print(\"batch is \",batch)\n",
        "\n",
        "     for prompt in batch:\n",
        "\n",
        "         # Print the prompt\n",
        "         print(\"prompt is \",list({prompt}))\n",
        "\n",
        "         updated_prompts = generate_prompt(list({prompt}), variables, TOPIC, perviuse_content)\n",
        "         print(\"Updated Prompts:\", updated_prompts)\n",
        "\n",
        "         time.sleep(random.randint(22, 40))\n",
        "         response = generate_academic_paper_a0(updated_prompts)\n",
        "         print(\"\\nGenerated Academic Paper:\")\n",
        "         print(\"========================\\n\")\n",
        "         for choice in response.choices:\n",
        "           print(choice.text)\n",
        "           choice_in_loop = choice.text\n",
        "           choice_text_all.append(choice.text)\n",
        "\n",
        "\n",
        "         #save_academic_paper(topic,'\\n--------**\\n'+updated_prompts+'/n-------**\\n'+choice.text)\n",
        "         save_academic_paper_with_prompt(TOPIC[:20],'\\n**<<<  ChatGPT Prompt is:\\n'+''.join(updated_prompts)+'\\n>>>**\\n',choice.text)\n",
        "\n",
        "         save_academic_paper_with_prompt_megazn(TOPIC[:20],'\\n**<<<  ChatGPT Prompt is:\\n'+''.join(updated_prompts)+'\\n>>>**\\n',choice.text)\n",
        "         #save_academic_paper_with_prompt_megazn(TOPIC[:20],'\\n**<<<  ChatGPT Prompt is:\\n'+''.join(updated_prompts)+'\\n>>>**\\n',choice.text, 'google_drive')\n",
        "         if hasattr(choice, 'choices'):\n",
        "             extract_text(choice)\n",
        "\n",
        "         perviuse_content = choice_in_loop\n",
        "         print(\"\\n end of loop\")\n",
        "         print(\"========================\\n\")\n",
        "\n",
        "         time.sleep(random.randint(22, 40))\n",
        "         perviuse_try_numner = perviuse_try_numner+1\n",
        "  return choice_text_all,perviuse_try_numner\n",
        "\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\" #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\""
      ],
      "metadata": {
        "id": "JHIX17GHsecy"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Final answer: 👇🌹🌱"
      ],
      "metadata": {
        "id": "xHPMNDjfToIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from django.utils.text import slugify\n",
        "\n",
        "\n",
        "\n",
        "def main_generate_papers(TOPIC, prompts, perviuse_content, perviuse_try_numner):\n",
        "    if not perviuse_try_numner:\n",
        "        perviuse_try_numner = 0\n",
        "        perviuse_content = ['fist step']\n",
        "\n",
        "    elif (perviuse_try_numner == len(prompts)):\n",
        "        perviuse_try_numner = 0\n",
        "        perviuse_content = ['fist step']\n",
        "\n",
        "    generate_papers(prompts, perviuse_content, perviuse_try_numner)\n",
        "\n",
        "    return perviuse_content, perviuse_try_numner\n",
        "\n",
        "topic = TOPIC_CLASS()\n",
        "\n",
        "if not topic.perviuse_try_numner:\n",
        "    topic.perviuse_try_numner = 0\n",
        "    topic.perviuse_content = ['fist step']\n",
        "\n",
        "elif (topic.perviuse_try_numner == len(prompts)):\n",
        "    topic.perviuse_try_numner = 0\n",
        "    topic.perviuse_content = ['fist step']\n",
        "\n",
        "topic.topic = TOPIC\n",
        "main_generate_papers(topic.topic, prompts, topic.perviuse_content, topic.perviuse_try_numner)"
      ],
      "metadata": {
        "id": "-YbWDEd4WzDq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e9e500b-412f-45be-f69e-760f806f92fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I is  0  Len of prompt Is: 48\n",
            "batch is  [\"Write a counterargument to the following claim: '{PARAGRAPH}'\", \"Rewrite this in an academic voice: '{PARAGRAPH}'\", \"Expand these notes: '{PARAGRAPH}'\", \"Provide me a list of words and phrases which were repeatedly / more than 3 times used: '{PARAGRAPHS}'\", \"Provide me a list of synonyms for '{PARAGRAPH}' and evaluate them in the context of '{PARAGRAPH}'\", \"Act as a language expert, proofread my paper on '{TOPIC_SENTENCE}' while putting a focus on grammar and punctuation.\", \"In the context of '{RESEARCH_DOMAIN}' translate '{PARAGRAPH}' into the '{LANGUAGE}' language.\", \"Find a research topic for a PhD in the area of 'The Interplay of Religion and Conflict: A Study on the Quran and Its Verses on Peace and War'\", \"Write a detailed proposal on the following research topic. Make sure it is free from plagiarism. '{PARAGRAPH}'\", \"Identify gaps in the literature on '{TOPIC_SENTENCE}'\", \"Generate 10 academic research questions about '{PARAGRAPHS}'\", \"Generate a list of research hypotheses related to '{TOPIC_SENTENCE}'\", \"Identify potential areas for future research in the context of this '{TOPIC_SENTENCE}'\", \"Suggest novel applications of '{TOPIC_SENTENCE}' within '{RESEARCH_DOMAIN}'\", \"Suggest 5 titles for the following abstract: '{ABSTRACT_PARAGRAPH}'\", \"Write a topic sentence for this paragraph: '{PARAGRAPH}'\", \"Provide 5 keywords for this: '{PARAGRAPHS}'\", \"Generate an abstract for a scientific paper based on this information for: '{PARAGRAPHS}'\", \"Generate an outline for '{TOPIC_SENTENCE}'\", \"I want to write a journal article about '{TOPIC_SENTENCE}'. Give me an outline for the article that I can use as a starting point.\"]\n",
            "prompt is  [\"Write a counterargument to the following claim: '{PARAGRAPH}'\"]\n",
            "\n",
            "---prompt is ----\n",
            "Write a counterargument to the following claim: '{PARAGRAPH}'\n",
            "Prompt is:  Generate ChatGPT  prompt in less than 45 word and one paragraph, as content for the variable 'PARAGRAPH' in the context of the topic 'The Interplay of Religion and Conflict: A Study on the Quran and Its Verses on Peace and War'. Please consider the result must be sumerized and as variable for chatgpt academic phd writer assistance. The prompt is 'Write a counterargument to the following claim: '{PARAGRAPH}''. Also the more information for understanding better content is '['fist step']'\n",
            "\n",
            " Result is :\n",
            "\n",
            "PARAGRAPH = \"While some may argue that the Quran promotes violence and conflict through its verses on war, it is important to consider the context in which these verses were revealed. The Quran was revealed during a time of intense conflict and persecution against the early Muslim community. Therefore, these verses can be seen as a means of self-defense and protection rather than a call to aggression. Furthermore, the Quran also emphasizes the importance of peace and reconciliation, with verses such as 'And if they incline to peace, then incline to it also' (8:61). Thus, it is crucial to understand the interplay between religion and conflict in a nuanced manner, rather than making blanket statements based on isolated verses.\" \n",
            "\n",
            "Write a counterargument to the following claim: 'The Quran promotes violence and conflict through its verses on war'.\n",
            "variable_contents[PARAGRAPH] is: \n",
            "\n",
            "PARAGRAPH = \"While some may argue that the Quran promotes violence and conflict through its verses on war, it is important to consider the context in which these verses were revealed. The Quran was revealed during a time of intense conflict and persecution against the early Muslim community. Therefore, these verses can be seen as a means of self-defense and protection rather than a call to aggression. Furthermore, the Quran also emphasizes the importance of peace and reconciliation, with verses such as 'And if they incline to peace, then incline to it also' (8:61). Thus, it is crucial to understand the interplay between religion and conflict in a nuanced manner, rather than making blanket statements based on isolated verses.\" \n",
            "\n",
            "Write a counterargument to the following claim: 'The Quran promotes violence and conflict through its verses on war'.\n",
            "\n",
            " --- Updated prompt is :\n",
            "['Write a counterargument to the following claim: \\'\\n\\nPARAGRAPH = \"While some may argue that the Quran promotes violence and conflict through its verses on war, it is important to consider the context in which these verses were revealed. The Quran was revealed during a time of intense conflict and persecution against the early Muslim community. Therefore, these verses can be seen as a means of self-defense and protection rather than a call to aggression. Furthermore, the Quran also emphasizes the importance of peace and reconciliation, with verses such as \\'And if they incline to peace, then incline to it also\\' (8:61). Thus, it is crucial to understand the interplay between religion and conflict in a nuanced manner, rather than making blanket statements based on isolated verses.\" \\n\\nWrite a counterargument to the following claim: \\'The Quran promotes violence and conflict through its verses on war\\'.\\'']\n",
            "Updated Prompts: ['Write a counterargument to the following claim: \\'\\n\\nPARAGRAPH = \"While some may argue that the Quran promotes violence and conflict through its verses on war, it is important to consider the context in which these verses were revealed. The Quran was revealed during a time of intense conflict and persecution against the early Muslim community. Therefore, these verses can be seen as a means of self-defense and protection rather than a call to aggression. Furthermore, the Quran also emphasizes the importance of peace and reconciliation, with verses such as \\'And if they incline to peace, then incline to it also\\' (8:61). Thus, it is crucial to understand the interplay between religion and conflict in a nuanced manner, rather than making blanket statements based on isolated verses.\" \\n\\nWrite a counterargument to the following claim: \\'The Quran promotes violence and conflict through its verses on war\\'.\\'']\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "While it is true that some verses in the Quran mention war and conflict, it is important to note that these verses are not promoting violence, but rather providing guidance for Muslims during a time of war. The Quran also clearly states that violence and aggression are not permissible in Islam, with verses such as \"Fight in the way of Allah against those who fight against you, but do not transgress. Indeed, Allah does not like transgressors\" (2:190). This verse clearly outlines the principle of self-defense and prohibits any form of aggression. Additionally, the Quran also emphasizes the importance of justice and mercy, with verses such as \"And do not let the hatred of a people for having obstructed you from the Sacred Mosque lead you to transgress. And cooperate in righteousness and piety, but do not cooperate in sin and aggression\" (5:2). This verse highlights the importance of maintaining peace and avoiding aggression, even in times of conflict. Therefore, it is unfair to claim that the Quran promotes violence and conflict when it clearly condemns such actions and emphasizes the importance of peace and justice.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  [\"Rewrite this in an academic voice: '{PARAGRAPH}'\"]\n",
            "\n",
            "---prompt is ----\n",
            "Rewrite this in an academic voice: '{PARAGRAPH}'\n",
            "Prompt is:  Generate ChatGPT  prompt in less than 45 word and one paragraph, as content for the variable 'PARAGRAPH' in the context of the topic 'The Interplay of Religion and Conflict: A Study on the Quran and Its Verses on Peace and War'. Please consider the result must be sumerized and as variable for chatgpt academic phd writer assistance. The prompt is 'Rewrite this in an academic voice: '{PARAGRAPH}''. Also the more information for understanding better content is '\n",
            "\n",
            "While it is true that some verses in the Quran mention war and conflict, it is important to note that these verses are not promoting violence, but rather providing guidance for Muslims during a time of war. The Quran also clearly states that violence and aggression are not permissible in Islam, with verses such as \"Fight in the way of Allah against those who fight against you, but do not transgress. Indeed, Allah does not like transgressors\" (2:190). This verse clearly outlines the principle of self-defense and prohibits any form of aggression. Additionally, the Quran also emphasizes the importance of justice and mercy, with verses such as \"And do not let the hatred of a people for having obstructed you from the Sacred Mosque lead you to transgress. And cooperate in righteousness and piety, but do not cooperate in sin and aggression\" (5:2). This verse highlights the importance of maintaining peace and avoiding aggression, even in times of conflict. Therefore, it is unfair to claim that the Quran promotes violence and conflict when it clearly condemns such actions and emphasizes the importance of peace and justice.'\n",
            "\n",
            " Result is :\n",
            "\n",
            "'Rewrite this in an academic voice: '{PARAGRAPH}'\n",
            "\n",
            "The interplay between religion and conflict has been a topic of much debate and scrutiny, particularly in regards to the Quran and its verses on peace and war. While it is true that certain verses in the Quran mention war and conflict, it is crucial to note that these verses are not advocating for violence, but rather providing guidance for Muslims during times of war. In fact, the Quran explicitly prohibits any form of aggression and emphasizes the principle of self-defense. Furthermore, the Quran stresses the importance of justice and mercy, discouraging any actions that may lead to violence or aggression. Therefore, it is unjust to claim that the Quran promotes violence and conflict, as it clearly condemns such actions and prioritizes the pursuit of peace and justice.\n",
            "variable_contents[PARAGRAPH] is: \n",
            "\n",
            "'Rewrite this in an academic voice: '{PARAGRAPH}'\n",
            "\n",
            "The interplay between religion and conflict has been a topic of much debate and scrutiny, particularly in regards to the Quran and its verses on peace and war. While it is true that certain verses in the Quran mention war and conflict, it is crucial to note that these verses are not advocating for violence, but rather providing guidance for Muslims during times of war. In fact, the Quran explicitly prohibits any form of aggression and emphasizes the principle of self-defense. Furthermore, the Quran stresses the importance of justice and mercy, discouraging any actions that may lead to violence or aggression. Therefore, it is unjust to claim that the Quran promotes violence and conflict, as it clearly condemns such actions and prioritizes the pursuit of peace and justice.\n",
            "\n",
            " --- Updated prompt is :\n",
            "[\"Rewrite this in an academic voice: '\\n\\n'Rewrite this in an academic voice: '{PARAGRAPH}'\\n\\nThe interplay between religion and conflict has been a topic of much debate and scrutiny, particularly in regards to the Quran and its verses on peace and war. While it is true that certain verses in the Quran mention war and conflict, it is crucial to note that these verses are not advocating for violence, but rather providing guidance for Muslims during times of war. In fact, the Quran explicitly prohibits any form of aggression and emphasizes the principle of self-defense. Furthermore, the Quran stresses the importance of justice and mercy, discouraging any actions that may lead to violence or aggression. Therefore, it is unjust to claim that the Quran promotes violence and conflict, as it clearly condemns such actions and prioritizes the pursuit of peace and justice.'\"]\n",
            "Updated Prompts: [\"Rewrite this in an academic voice: '\\n\\n'Rewrite this in an academic voice: '{PARAGRAPH}'\\n\\nThe interplay between religion and conflict has been a topic of much debate and scrutiny, particularly in regards to the Quran and its verses on peace and war. While it is true that certain verses in the Quran mention war and conflict, it is crucial to note that these verses are not advocating for violence, but rather providing guidance for Muslims during times of war. In fact, the Quran explicitly prohibits any form of aggression and emphasizes the principle of self-defense. Furthermore, the Quran stresses the importance of justice and mercy, discouraging any actions that may lead to violence or aggression. Therefore, it is unjust to claim that the Quran promotes violence and conflict, as it clearly condemns such actions and prioritizes the pursuit of peace and justice.'\"]\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  [\"Expand these notes: '{PARAGRAPH}'\"]\n",
            "\n",
            "---prompt is ----\n",
            "Expand these notes: '{PARAGRAPH}'\n",
            "Prompt is:  Generate ChatGPT  prompt in less than 45 word and one paragraph, as content for the variable 'PARAGRAPH' in the context of the topic 'The Interplay of Religion and Conflict: A Study on the Quran and Its Verses on Peace and War'. Please consider the result must be sumerized and as variable for chatgpt academic phd writer assistance. The prompt is 'Expand these notes: '{PARAGRAPH}''. Also the more information for understanding better content is ''\n",
            "\n",
            " Result is :\n",
            "\n",
            "Expand these notes: The Interplay of Religion and Conflict: A Study on the Quran and Its Verses on Peace and War. The Quran, as the holy book of Islam, has been a source of guidance and inspiration for millions of believers. However, it has also been a subject of controversy and debate, particularly in regards to its verses on peace and war. Some argue that the Quran promotes violence and conflict, while others believe it preaches peace and harmony. As a PhD writer, I will delve into this complex interplay between religion and conflict, examining the various interpretations of the Quran's verses on peace and war and their impact on society. Through a thorough analysis, I will provide a comprehensive understanding of this topic and offer valuable insights for further research and discussion.\n",
            "variable_contents[PARAGRAPH] is: \n",
            "\n",
            "Expand these notes: The Interplay of Religion and Conflict: A Study on the Quran and Its Verses on Peace and War. The Quran, as the holy book of Islam, has been a source of guidance and inspiration for millions of believers. However, it has also been a subject of controversy and debate, particularly in regards to its verses on peace and war. Some argue that the Quran promotes violence and conflict, while others believe it preaches peace and harmony. As a PhD writer, I will delve into this complex interplay between religion and conflict, examining the various interpretations of the Quran's verses on peace and war and their impact on society. Through a thorough analysis, I will provide a comprehensive understanding of this topic and offer valuable insights for further research and discussion.\n",
            "\n",
            " --- Updated prompt is :\n",
            "[\"Expand these notes: '\\n\\nExpand these notes: The Interplay of Religion and Conflict: A Study on the Quran and Its Verses on Peace and War. The Quran, as the holy book of Islam, has been a source of guidance and inspiration for millions of believers. However, it has also been a subject of controversy and debate, particularly in regards to its verses on peace and war. Some argue that the Quran promotes violence and conflict, while others believe it preaches peace and harmony. As a PhD writer, I will delve into this complex interplay between religion and conflict, examining the various interpretations of the Quran's verses on peace and war and their impact on society. Through a thorough analysis, I will provide a comprehensive understanding of this topic and offer valuable insights for further research and discussion.'\"]\n",
            "Updated Prompts: [\"Expand these notes: '\\n\\nExpand these notes: The Interplay of Religion and Conflict: A Study on the Quran and Its Verses on Peace and War. The Quran, as the holy book of Islam, has been a source of guidance and inspiration for millions of believers. However, it has also been a subject of controversy and debate, particularly in regards to its verses on peace and war. Some argue that the Quran promotes violence and conflict, while others believe it preaches peace and harmony. As a PhD writer, I will delve into this complex interplay between religion and conflict, examining the various interpretations of the Quran's verses on peace and war and their impact on society. Through a thorough analysis, I will provide a comprehensive understanding of this topic and offer valuable insights for further research and discussion.'\"]\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "I will also explore the historical context in which these verses were revealed and how they have been interpreted and applied throughout history. This will include examining the role of religion in conflicts, both past and present, and how the Quran has been used to justify or condemn violence.\n",
            "\n",
            "Furthermore, I will analyze the different perspectives and interpretations of these verses within the Muslim community, including the views of scholars, religious leaders, and everyday believers. This will shed light on the diversity of opinions and beliefs within Islam and how they contribute to the understanding of the Quran's teachings on peace and war.\n",
            "\n",
            "In addition, I will examine the impact of these verses on interfaith relations and how they have been used to either promote or hinder peaceful coexistence between different religions. This will involve looking at examples of conflicts and collaborations between Muslims and non-Muslims and how the Quran's verses on peace and war have played a role in these interactions.\n",
            "\n",
            "Moreover, I will also consider the contemporary relevance of these verses and their implications for current global issues such as terrorism, extremism, and religious conflicts. This will involve analyzing the ways in which the Quran's teachings on peace and war are being interpreted and applied in today's world and the potential consequences of these interpretations.\n",
            "\n",
            "Overall, this study will provide a comprehensive and nuanced understanding of the interplay between religion and conflict, specifically focusing on the Quran's verses on peace and war. It will contribute to the ongoing discourse on the role of religion in promoting or preventing violence and offer valuable insights for promoting peace and harmony in diverse societies.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  [\"Provide me a list of words and phrases which were repeatedly / more than 3 times used: '{PARAGRAPHS}'\"]\n",
            "\n",
            "---prompt is ----\n",
            "Provide me a list of words and phrases which were repeatedly / more than 3 times used: '{PARAGRAPHS}'\n",
            "Prompt is:  Generate ChatGPT  prompt in less than 45 word and one paragraph, as content for the variable 'PARAGRAPH' in the context of the topic 'The Interplay of Religion and Conflict: A Study on the Quran and Its Verses on Peace and War'. Please consider the result must be sumerized and as variable for chatgpt academic phd writer assistance. The prompt is 'Provide me a list of words and phrases which were repeatedly / more than 3 times used: '{PARAGRAPHS}''. Also the more information for understanding better content is '\n",
            "\n",
            "I will also explore the historical context in which these verses were revealed and how they have been interpreted and applied throughout history. This will include examining the role of religion in conflicts, both past and present, and how the Quran has been used to justify or condemn violence.\n",
            "\n",
            "Furthermore, I will analyze the different perspectives and interpretations of these verses within the Muslim community, including the views of scholars, religious leaders, and everyday believers. This will shed light on the diversity of opinions and beliefs within Islam and how they contribute to the understanding of the Quran's teachings on peace and war.\n",
            "\n",
            "In addition, I will examine the impact of these verses on interfaith relations and how they have been used to either promote or hinder peaceful coexistence between different religions. This will involve looking at examples of conflicts and collaborations between Muslims and non-Muslims and how the Quran's verses on peace and war have played a role in these interactions.\n",
            "\n",
            "Moreover, I will also consider the contemporary relevance of these verses and their implications for current global issues such as terrorism, extremism, and religious conflicts. This will involve analyzing the ways in which the Quran's teachings on peace and war are being interpreted and applied in today's world and the potential consequences of these interpretations.\n",
            "\n",
            "Overall, this study will provide a comprehensive and nuanced understanding of the interplay between religion and conflict, specifically focusing on the Quran's verses on peace and war. It will contribute to the ongoing discourse on the role of religion in promoting or preventing violence and offer valuable insights for promoting peace and harmony in diverse societies.'\n",
            "\n",
            " Result is :Provide me a list of words and phrases which were repeatedly / more than 3 times used: 'historical context, interpretations, Muslim community, diversity of opinions, interfaith relations, contemporary relevance, global issues, terrorism, extremism, religious conflicts, discourse, promoting peace and harmony'.\n",
            "variable_contents[PARAGRAPH] is: Provide me a list of words and phrases which were repeatedly / more than 3 times used: 'historical context, interpretations, Muslim community, diversity of opinions, interfaith relations, contemporary relevance, global issues, terrorism, extremism, religious conflicts, discourse, promoting peace and harmony'.\n",
            "\n",
            "---prompt is ----\n",
            "Provide me a list of words and phrases which were repeatedly / more than 3 times used: '{PARAGRAPHS}'\n",
            "Prompt is:  Generate ChatGPT  prompt in less than 45 word and one paragraph, as content for the variable 'PARAGRAPHS' in the context of the topic 'The Interplay of Religion and Conflict: A Study on the Quran and Its Verses on Peace and War'. Please consider the result must be sumerized and as variable for chatgpt academic phd writer assistance. The prompt is 'Provide me a list of words and phrases which were repeatedly / more than 3 times used: '{PARAGRAPHS}''. Also the more information for understanding better content is '\n",
            "\n",
            "I will also explore the historical context in which these verses were revealed and how they have been interpreted and applied throughout history. This will include examining the role of religion in conflicts, both past and present, and how the Quran has been used to justify or condemn violence.\n",
            "\n",
            "Furthermore, I will analyze the different perspectives and interpretations of these verses within the Muslim community, including the views of scholars, religious leaders, and everyday believers. This will shed light on the diversity of opinions and beliefs within Islam and how they contribute to the understanding of the Quran's teachings on peace and war.\n",
            "\n",
            "In addition, I will examine the impact of these verses on interfaith relations and how they have been used to either promote or hinder peaceful coexistence between different religions. This will involve looking at examples of conflicts and collaborations between Muslims and non-Muslims and how the Quran's verses on peace and war have played a role in these interactions.\n",
            "\n",
            "Moreover, I will also consider the contemporary relevance of these verses and their implications for current global issues such as terrorism, extremism, and religious conflicts. This will involve analyzing the ways in which the Quran's teachings on peace and war are being interpreted and applied in today's world and the potential consequences of these interpretations.\n",
            "\n",
            "Overall, this study will provide a comprehensive and nuanced understanding of the interplay between religion and conflict, specifically focusing on the Quran's verses on peace and war. It will contribute to the ongoing discourse on the role of religion in promoting or preventing violence and offer valuable insights for promoting peace and harmony in diverse societies.'\n",
            "\n",
            " Result is :\n",
            "variable_contents[PARAGRAPHS] is: \n",
            "\n",
            " --- Updated prompt is :\n",
            "[\"Provide me a list of words and phrases which were repeatedly / more than 3 times used: ''\"]\n",
            "Updated Prompts: [\"Provide me a list of words and phrases which were repeatedly / more than 3 times used: ''\"]\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "1. \"I love you\"\n",
            "2. \"Thank you\"\n",
            "3. \"Please\"\n",
            "4. \"Sorry\"\n",
            "5. \"Excuse me\"\n",
            "6. \"Can you\"\n",
            "7. \"I'm sorry\"\n",
            "8. \"How are you\"\n",
            "9. \"What's up\"\n",
            "10. \"Good morning\"\n",
            "11. \"Goodbye\"\n",
            "12. \"See you later\"\n",
            "13. \"Have a nice day\"\n",
            "14. \"Nice to meet you\"\n",
            "15. \"No problem\"\n",
            "16. \"Yes\"\n",
            "17. \"No\"\n",
            "18. \"Maybe\"\n",
            "19. \"I don't know\"\n",
            "20. \"I understand\"\n",
            "21. \"I agree\"\n",
            "22. \"Absolutely\"\n",
            "23. \"Definitely\"\n",
            "24. \"Of course\"\n",
            "25. \"Absolutely not\"\n",
            "26. \"Definitely not\"\n",
            "27. \"Absolutely yes\"\n",
            "28. \"Definitely yes\"\n",
            "29. \"I'm sorry, I can't\"\n",
            "30. \"I'm sorry, I don't know\"\n",
            "31. \"I'm sorry, I don't understand\"\n",
            "32. \"I'm sorry, I can't help\"\n",
            "33. \"I'm sorry, I don't have\"\n",
            "34. \"I'm sorry, I'm busy\"\n",
            "35. \"I'm sorry, I'm not available\"\n",
            "36. \"I'm sorry, I have to go\"\n",
            "37. \"I'm sorry, I have to leave\"\n",
            "38. \"I'm sorry, I have to cancel\"\n",
            "39. \"I'm sorry, I have to reschedule\"\n",
            "40. \"I'm sorry, I have to decline\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  [\"Provide me a list of synonyms for '{PARAGRAPH}' and evaluate them in the context of '{PARAGRAPH}'\"]\n",
            "\n",
            "---prompt is ----\n",
            "Provide me a list of synonyms for '{PARAGRAPH}' and evaluate them in the context of '{PARAGRAPH}'\n",
            "Prompt is:  Generate ChatGPT  prompt in less than 45 word and one paragraph, as content for the variable 'PARAGRAPH' in the context of the topic 'The Interplay of Religion and Conflict: A Study on the Quran and Its Verses on Peace and War'. Please consider the result must be sumerized and as variable for chatgpt academic phd writer assistance. The prompt is 'Provide me a list of synonyms for '{PARAGRAPH}' and evaluate them in the context of '{PARAGRAPH}''. Also the more information for understanding better content is '\n",
            "\n",
            "1. \"I love you\"\n",
            "2. \"Thank you\"\n",
            "3. \"Please\"\n",
            "4. \"Sorry\"\n",
            "5. \"Excuse me\"\n",
            "6. \"Can you\"\n",
            "7. \"I'm sorry\"\n",
            "8. \"How are you\"\n",
            "9. \"What's up\"\n",
            "10. \"Good morning\"\n",
            "11. \"Goodbye\"\n",
            "12. \"See you later\"\n",
            "13. \"Have a nice day\"\n",
            "14. \"Nice to meet you\"\n",
            "15. \"No problem\"\n",
            "16. \"Yes\"\n",
            "17. \"No\"\n",
            "18. \"Maybe\"\n",
            "19. \"I don't know\"\n",
            "20. \"I understand\"\n",
            "21. \"I agree\"\n",
            "22. \"Absolutely\"\n",
            "23. \"Definitely\"\n",
            "24. \"Of course\"\n",
            "25. \"Absolutely not\"\n",
            "26. \"Definitely not\"\n",
            "27. \"Absolutely yes\"\n",
            "28. \"Definitely yes\"\n",
            "29. \"I'm sorry, I can't\"\n",
            "30. \"I'm sorry, I don't know\"\n",
            "31. \"I'm sorry, I don't understand\"\n",
            "32. \"I'm sorry, I can't help\"\n",
            "33. \"I'm sorry, I don't have\"\n",
            "34. \"I'm sorry, I'm busy\"\n",
            "35. \"I'm sorry, I'm not available\"\n",
            "36. \"I'm sorry, I have to go\"\n",
            "37. \"I'm sorry, I have to leave\"\n",
            "38. \"I'm sorry, I have to cancel\"\n",
            "39. \"I'm sorry, I have to reschedule\"\n",
            "40. \"I'm sorry, I have to decline\"'\n",
            "\n",
            " Result is :\n",
            "\n",
            "Provide me a list of synonyms for 'apologies' and evaluate them in the context of 'The Interplay of Religion and Conflict: A Study on the Quran and Its Verses on Peace and War'. Apologies are expressions of regret or sorrow for a wrongdoing or offense. In the context of religion and conflict, apologies can play a crucial role in promoting peace and resolving conflicts. They can also be seen as a form of seeking forgiveness and reconciliation. However, in some cases, apologies may not be enough to repair the damage caused by religious conflicts. Therefore, it is important to carefully evaluate the impact and effectiveness of apologies in the context of religion and conflict.\n",
            "variable_contents[PARAGRAPH] is: \n",
            "\n",
            "Provide me a list of synonyms for 'apologies' and evaluate them in the context of 'The Interplay of Religion and Conflict: A Study on the Quran and Its Verses on Peace and War'. Apologies are expressions of regret or sorrow for a wrongdoing or offense. In the context of religion and conflict, apologies can play a crucial role in promoting peace and resolving conflicts. They can also be seen as a form of seeking forgiveness and reconciliation. However, in some cases, apologies may not be enough to repair the damage caused by religious conflicts. Therefore, it is important to carefully evaluate the impact and effectiveness of apologies in the context of religion and conflict.\n",
            "\n",
            " --- Updated prompt is :\n",
            "[\"Provide me a list of synonyms for '\\n\\nProvide me a list of synonyms for 'apologies' and evaluate them in the context of 'The Interplay of Religion and Conflict: A Study on the Quran and Its Verses on Peace and War'. Apologies are expressions of regret or sorrow for a wrongdoing or offense. In the context of religion and conflict, apologies can play a crucial role in promoting peace and resolving conflicts. They can also be seen as a form of seeking forgiveness and reconciliation. However, in some cases, apologies may not be enough to repair the damage caused by religious conflicts. Therefore, it is important to carefully evaluate the impact and effectiveness of apologies in the context of religion and conflict.' and evaluate them in the context of '\\n\\nProvide me a list of synonyms for 'apologies' and evaluate them in the context of 'The Interplay of Religion and Conflict: A Study on the Quran and Its Verses on Peace and War'. Apologies are expressions of regret or sorrow for a wrongdoing or offense. In the context of religion and conflict, apologies can play a crucial role in promoting peace and resolving conflicts. They can also be seen as a form of seeking forgiveness and reconciliation. However, in some cases, apologies may not be enough to repair the damage caused by religious conflicts. Therefore, it is important to carefully evaluate the impact and effectiveness of apologies in the context of religion and conflict.'\"]\n",
            "Updated Prompts: [\"Provide me a list of synonyms for '\\n\\nProvide me a list of synonyms for 'apologies' and evaluate them in the context of 'The Interplay of Religion and Conflict: A Study on the Quran and Its Verses on Peace and War'. Apologies are expressions of regret or sorrow for a wrongdoing or offense. In the context of religion and conflict, apologies can play a crucial role in promoting peace and resolving conflicts. They can also be seen as a form of seeking forgiveness and reconciliation. However, in some cases, apologies may not be enough to repair the damage caused by religious conflicts. Therefore, it is important to carefully evaluate the impact and effectiveness of apologies in the context of religion and conflict.' and evaluate them in the context of '\\n\\nProvide me a list of synonyms for 'apologies' and evaluate them in the context of 'The Interplay of Religion and Conflict: A Study on the Quran and Its Verses on Peace and War'. Apologies are expressions of regret or sorrow for a wrongdoing or offense. In the context of religion and conflict, apologies can play a crucial role in promoting peace and resolving conflicts. They can also be seen as a form of seeking forgiveness and reconciliation. However, in some cases, apologies may not be enough to repair the damage caused by religious conflicts. Therefore, it is important to carefully evaluate the impact and effectiveness of apologies in the context of religion and conflict.'\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating the sound by OpenAI: 👇👇\n",
        "\n",
        "https://platform.openai.com/docs/guides/text-to-speech"
      ],
      "metadata": {
        "id": "2ctHZTF6wj0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"/content/ChatGPT_academic_paper\"\n",
        "from openai import OpenAI\n",
        "from django.utils.text import slugify\n",
        "\n",
        "\n",
        "client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   api_key = openai_api#\"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\",\n",
        ")\n",
        "\n",
        "response = client.audio.speech.create(\n",
        "    model=\"tts-1\",\n",
        "    voice=\"alloy\",\n",
        "    input=TOPIC#\"Hello world! This is a streaming test.\",\n",
        ")\n",
        "TOPIC_S = slugify(TOPIC)\n",
        "\n",
        "Sound_File= \"/content/drive/MyDrive/ChatGPT_Paper_wrting/\"+f\"{TOPIC[:40]}\"+str(random.randint (0,1000))+\".mp3\" #\"/\"+\"output.mp3\"\n",
        "\n",
        "print (\"save folder is: \",Sound_File)#/content/drive/MyDrive/ChatGPT_Paper_wrting/\"+f\"{TOPIC_S}\"+str(random.randint (0,1000))+\".mp3\") #\"/\"+\"output.mp3\"\n",
        "#response.stream_to_file(\"/content/drive/My Drive/ChatGPT_Paper_wrting/\"+f\"{TOPIC_S}\"+str(random.randint (0,1000))+\".mp3\")#\"/\"+\"output.mp3\")\n",
        "\n",
        "response.stream_to_file(Sound_File)\n",
        "print ( 'topic is:',TOPIC)\n",
        "#print (\"save folder is: /content/drive/MyDrive/ChatGPT_Paper_wrting/\"+f\"{TOPIC[:40]}\"+str(random.randint (0,1000))+\".mp3\") #\"/\"+\"output.mp3\""
      ],
      "metadata": {
        "id": "d2YvDx5DwS7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from IPython.display import HTML\n",
        "\n",
        "def upload_files_to_transfer_sh(file_paths):\n",
        "  urls = []\n",
        "  html_content = \"<form>\"\n",
        "  for file_path in file_paths:\n",
        "      with open(file_path, 'rb') as file:\n",
        "          response = requests.post('https://transfer.sh/', files={'file': file})\n",
        "          response.raise_for_status()\n",
        "          urls.append(response.text)\n",
        "          html_content += f\"<p>File: {file_path} <br> And Upload URL is: <a href='{response.text}'>{response.text}</a></p>\"\n",
        "  html_content += \"</form>\"\n",
        "  return urls, html_content\n",
        "\n",
        "file_paths = [Sound_File, docx_path, Pdf_Dir]\n",
        "urls, html_content = upload_files_to_transfer_sh(file_paths)\n",
        "for url in urls:\n",
        "  print(url)\n",
        "HTML(html_content)"
      ],
      "metadata": {
        "id": "4L7gC4uu_vPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Only update the Prompt by the help of ChatGPT:👇👇"
      ],
      "metadata": {
        "id": "BAiQz23MlpUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define main variables\n",
        "#TOPIC = \"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"\n",
        "\n",
        "# List of variables\n",
        "variables = [\"RESEARCH_DOMAIN\", \"PARAGRAPH\", \"PARAGRAPHS\", \"TOPIC_SENTENCE\", \"LANGUAGE\", \"ABSTRACT_PARAGRAPH\", \"BIBLIOGRAPHY\", \"THEORY1\", \"THEORY2\", \"RESEARCH_QUESTIONS\", \"ACTION\", \"RESULT_PARAGRAPHS\", \"DATE\", \"NUMBER_OF_DAYS_MONTHS_YEARS\"]\n",
        "\n",
        "# Generate content for each variable\n",
        "variable_contents = {}\n",
        "for prompt in prompts:\n",
        "   for var in variables:\n",
        "       if var in prompt:\n",
        "           prompt = f\"Generate content for the variable '{var}' based on the topic '{TOPIC}'. For this prompt '{prompt}'\"\n",
        "           content= generate_academic_paper(prompt)\n",
        "           for choice in content.choices:\n",
        "               print(choice.text)\n",
        "               variable_contents[var] = choice.text\n",
        "           print(\"variable_contents[var] is: \",variable_contents[var])\n",
        "\n",
        "# Replace the variables in the prompts with the generated content\n",
        "for prompt in prompts:\n",
        "   for var, content in variable_contents.items():\n",
        "       prompt = prompt.replace(f\"{{{var}}}\", content)\n",
        "print(\"Updated Prompt:\", prompt)"
      ],
      "metadata": {
        "id": "kH3LygdiXsPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt_update_a3(prompt, previous_content):\n",
        "    model_engine = \"text-davinci-003\"\n",
        "    max_tokens = 2048\n",
        "\n",
        "    # Construct the instruction for updating the prompt\n",
        "    instruction = f\"Given the previous content:\\n\\n{previous_content}\\n\\nUpdate the prompt: {prompt}\"\n",
        "\n",
        "    # Create the completion with the instruction\n",
        "    completion = client.completions.create(\n",
        "        model=model_engine,\n",
        "        prompt=instruction,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=0.3,\n",
        "        n=1,\n",
        "        frequency_penalty=0,\n",
        "    )\n",
        "\n",
        "    # Extract and return the updated prompt from the response\n",
        "    updated_prompt = completion.choices[0].text.strip()\n",
        "    return updated_prompt\n",
        "# Inside your loop\n",
        "for prompt in prompts:\n",
        "    print(\"Original Prompt:\", prompt)\n",
        "    response = generate_academic_paper_a2(prompt)\n",
        "    previous_content = response.choices[0].text.strip()\n",
        "    updated_prompt = generate_prompt_update_2(prompt, previous_content)\n",
        "    print(\"Updated Prompt:\", updated_prompt)\n",
        "\n",
        "    # Continue with the rest of your processing\n",
        "    # ..."
      ],
      "metadata": {
        "id": "KviSdMwzwqAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# with no translation for become faster answer:👇👇🙏"
      ],
      "metadata": {
        "id": "iuTPp4YYBg2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\"\n",
        "#topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key = openai_api#\"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\",\n",
        ")\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "# Create a Translator object\n",
        "translator = Translator()\n",
        "\n",
        "\n",
        "# Function to generate an academic paper\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "def generate_academic_paper_a2(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   completion = client.completions.create(\n",
        "       model=\"gpt-3.5-turbo-instruct\",\n",
        "       prompt=prompt_my,\n",
        "       max_tokens=2048,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "choice_text_all=[]\n",
        "\n",
        "import time\n",
        "# Function to generate academic papers for given prompts\n",
        "# Function to generate academic papers for given prompts\n",
        "def generate_papers(prompts):\n",
        "   for i in range(0, len(prompts), 20):\n",
        "       # Slice the prompts list to get the next 20 prompts\n",
        "       print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "\n",
        "       batch = prompts[i:i+20]\n",
        "       print(\"batch is \",batch)\n",
        "   #for j in range ( 0, Len(batch)):\n",
        "       # Generate papers for the next 20 prompts\n",
        "       for prompt in batch:\n",
        "      #   for prompt in prompt1:\n",
        "           # Print the prompt\n",
        "           print(\"prompt is \", prompt)\n",
        "           response = generate_academic_paper_a2(prompt)\n",
        "           print(\"\\nGenerated Academic Paper:\")\n",
        "           print(\"========================\\n\")\n",
        "           #print(response)\n",
        "           for choice in response.choices:\n",
        "             print(choice.text)\n",
        "             choice_text_all.append(choice.text)\n",
        "\n",
        "             # Translate the generated text to Persian\n",
        "         #  choice_translated = translate_to_persian(choice.text) #translator.translate(choice.text, dest='fa')\n",
        "         # choice_translated_prompt = translate_to_persian(prompt)#translator.translate(prompt, dest='fa')\n",
        "\n",
        "         #    print(\"\\n-----\\n Translated is \",choice_translated)\n",
        "         #    save_academic_paper(\"Persian_\"+topic,'\\n**'+choice_translated_prompt+'**\\n'+choice_translated)\n",
        "             save_academic_paper(topic,'\\n--------**\\n'+prompt+'/n-------**\\n'+choice.text)\n",
        "             # Recursively call the function for the nested Completion objects\n",
        "             if hasattr(choice, 'choices'):\n",
        "               extract_text(choice)\n",
        "\n",
        "           #generated_text = response.choices[0].text\n",
        "           # Print the generated text\n",
        "           #print(generated_text)\n",
        "           print(\"\\n end of loop\")\n",
        "           print(\"========================\\n\")\n",
        "\n",
        "           #print(\"loop\")\n",
        "       # Wait for a short period of time before sending the next batch of prompts\n",
        "           time.sleep(40)\n",
        "   return choice_text_all#,choice.translated\n",
        "\n",
        "# Generate academic papers for the given prompts\n",
        "generate_papers(prompts)"
      ],
      "metadata": {
        "id": "rl16DSYABo9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SETUP COLAB for run Streamlit\n",
        "!npm install localtunnel\n",
        "!curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "GRn7OkOUjcdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DL Translate\n",
        "A deep learning-based translation library built on Huggingface transformers and Facebook's mBART-Large\n",
        "\n",
        "https://colab.research.google.com/github/xhluca/dl-translate/blob/main/demos/colab_demo.ipynb#scrollTo=qdefSjR_YIiG"
      ],
      "metadata": {
        "id": "_I5yn6CCZdMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q dl-translate"
      ],
      "metadata": {
        "id": "c7-q341UWsr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dl_translate as dlt\n",
        "mt = dlt.TranslationModel('mbart50')"
      ],
      "metadata": {
        "id": "gtQcnXabalaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dl_translate as dlt\n",
        "\n",
        "def translate_to_persian(text):\n",
        "  # Initialize the translation model\n",
        "  #mt = dlt.TranslationModel('mbart50')\n",
        "\n",
        "  # Translate the text\n",
        "  translated = mt.translate(text, source=dlt.lang.ENGLISH, target=dlt.lang.PERSIAN)\n",
        "\n",
        "  return translated"
      ],
      "metadata": {
        "id": "iOX6FGFWaFqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key = openai_api#\"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\",\n",
        ")\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "# Create a Translator object\n",
        "translator = Translator()\n",
        "\n",
        "\n",
        "# Function to generate an academic paper\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=10, max_time=600)\n",
        "def generate_academic_paper_5(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   completion = client.completions.create(\n",
        "       model=\"gpt-3.5-turbo-instruct\",\n",
        "       prompt=prompt_my,\n",
        "       max_tokens=2048,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "choice_text_all=[]\n",
        "\n",
        "import time\n",
        "# Function to generate academic papers for given prompts\n",
        "# Function to generate academic papers for given prompts\n",
        "def generate_papers(prompts):\n",
        "   for i in range(0, len(prompts), 20):\n",
        "       # Slice the prompts list to get the next 20 prompts\n",
        "       print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "       batch = prompts[i:i+10]\n",
        "       print(\"batch is \",batch)\n",
        "       # Generate papers for the next 20 prompts\n",
        "       for prompt in batch:\n",
        "      #   for prompt in prompt1:\n",
        "           # Print the prompt\n",
        "           print(\"prompt is \", prompt)\n",
        "           response = generate_academic_paper(prompt)\n",
        "           print(\"\\nGenerated Academic Paper:\")\n",
        "           print(\"========================\\n\")\n",
        "           #print(response)\n",
        "           for choice in response.choices:\n",
        "             print(choice.text)\n",
        "             choice_text_all.append(choice.text)\n",
        "              # Translate the generated text to Persian\n",
        "             choice_translated = translate_to_persian(choice.text) #translator.translate(choice.text, dest='fa')\n",
        "             choice_translated_prompt = translate_to_persian(prompt)#translator.translate(prompt, dest='fa')\n",
        "\n",
        "             print(\"\\n-----\\n Translated is \",choice_translated)\n",
        "             save_academic_paper(\"Persian_\"+topic,'\\n**'+choice_translated_prompt+'**\\n'+choice_translated)\n",
        "             save_academic_paper(topic,'\\n**'+prompt+'**\\n'+choice.text)\n",
        "             # Recursively call the function for the nested Completion objects\n",
        "             if hasattr(choice, 'choices'):\n",
        "               extract_text(choice)\n",
        "\n",
        "           #generated_text = response.choices[0].text\n",
        "           # Print the generated text\n",
        "           #print(generated_text)\n",
        "           print(\"\\n end of loop\")\n",
        "           print(\"========================\\n\")\n",
        "\n",
        "           #print(\"loop\")\n",
        "       # Wait for a short period of time before sending the next batch of prompts\n",
        "           time.sleep(2)\n",
        "   return choice_text_all,choice.translated\n",
        "\n",
        "# Generate academic papers for the given prompts\n",
        "generate_papers(prompts3)"
      ],
      "metadata": {
        "id": "oVldhSpgEVZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#For solving queta prompt of Openai API;\n",
        "👇👇🌱"
      ],
      "metadata": {
        "id": "GdTvLhAkKLEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "#import openai\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key = openai_api#\"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\",\n",
        ")\n",
        "\n",
        "def retry_with_exponential_backoff(\n",
        "   func,\n",
        "   initial_delay: float = 1,\n",
        "   exponential_base: float = 2,\n",
        "   jitter: bool = True,\n",
        "   max_retries: int = 10,\n",
        "   errors: tuple = (openai.error.RateLimitError,),\n",
        "):\n",
        "   \"\"\"Retry a function with exponential backoff.\"\"\"\n",
        "   def wrapper(*args, **kwargs):\n",
        "       # Initialize variables\n",
        "       num_retries = 0\n",
        "       delay = initial_delay\n",
        "       # Loop until a successful response or max_retries is hit or an exception is raised\n",
        "       while True:\n",
        "           try:\n",
        "               return func(*args, **kwargs)\n",
        "           # Retry on specified errors\n",
        "           except errors as e:\n",
        "               # Increment retries\n",
        "               num_retries += 1\n",
        "               # Check if max retries has been reached\n",
        "               if num_retries > max_retries:\n",
        "                  raise Exception(\n",
        "                      f\"Maximum number of retries ({max_retries}) exceeded.\"\n",
        "                  )\n",
        "               # Increment the delay\n",
        "               delay *= exponential_base * (1 + jitter * random.random())\n",
        "               # Sleep for the delay\n",
        "               time.sleep(delay)\n",
        "           # Raise exceptions for any errors not specified\n",
        "           except Exception as e:\n",
        "               raise e\n",
        "   return wrapper\n",
        "\n",
        "@retry_with_exponential_backoff\n",
        "def generate_academic_paper_0(prompt_my):\n",
        "  model_engine = \"text-davinci-003\"\n",
        "  max_tokens = 2048\n",
        "\n",
        "  completion = client.completions.create(\n",
        "      model=\"gpt-3.5-turbo-instruct\",\n",
        "      prompt=prompt_my,\n",
        "      max_tokens=2048,\n",
        "      temperature=0.3,\n",
        "      n=1,\n",
        "      frequency_penalty=0,\n",
        "  )\n",
        "  return completion"
      ],
      "metadata": {
        "id": "zLWA8i87KXks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vH0Z7EL5LnQc"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "openai.api_key = openai_api#\"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key= openai_api#\"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\",\n",
        ")\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Function to generate an academic paper\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=10, max_time=600)\n",
        "def generate_academic_paper_6(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   completion = client.completions.create(\n",
        "       model=\"gpt-3.5-turbo-instruct\",\n",
        "       prompt=prompt_my,\n",
        "       max_tokens=2048,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "choice_text_all=[]\n",
        "\n",
        "import time\n",
        "# Function to generate academic papers for given prompts\n",
        "# Function to generate academic papers for given prompts\n",
        "def generate_papers(prompts):\n",
        "   for i in range(0, len(prompts), 20):\n",
        "       # Slice the prompts list to get the next 20 prompts\n",
        "       print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "       batch = prompts[i:i+10]\n",
        "       print(\"batch is \",batch)\n",
        "       # Generate papers for the next 20 prompts\n",
        "       for prompt in batch:\n",
        "      #   for prompt in prompt1:\n",
        "           # Print the prompt\n",
        "           print(\"prompt is \", prompt)\n",
        "           response = generate_academic_paper(prompt)\n",
        "           print(\"\\nGenerated Academic Paper:\")\n",
        "           print(\"========================\\n\")\n",
        "           #print(response)\n",
        "           for choice in response.choices:\n",
        "             print(choice.text)\n",
        "             choice_text_all.append(choice.text)\n",
        "             save_academic_paper(TOPIC,'\\n**'+prompt+'**\\n'+choice.text)\n",
        "             # Recursively call the function for the nested Completion objects\n",
        "             if hasattr(choice, 'choices'):\n",
        "               extract_text(choice)\n",
        "\n",
        "           #generated_text = response.choices[0].text\n",
        "           # Print the generated text\n",
        "           #print(generated_text)\n",
        "           print(\"\\n end of loop\")\n",
        "           print(\"========================\\n\")\n",
        "\n",
        "           #print(\"loop\")\n",
        "       # Wait for a short period of time before sending the next batch of prompts\n",
        "           time.sleep(2)\n",
        "   return choice.text_all\n",
        "\n",
        "# Generate academic papers for the given prompts\n",
        "generate_papers(prompts3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJTgcojthnm7"
      },
      "outputs": [],
      "source": [
        "def render_index_page():\n",
        "   html_content = \"\"\"\n",
        "   <!DOCTYPE html>\n",
        "   <html>\n",
        "   <head>\n",
        "      <title>Generate Academic Papers</title>\n",
        "   </head>\n",
        "   <body>\n",
        "      <h1>Generate Academic Papers</h1>\n",
        "      <form method=\"POST\">\n",
        "          <label for=\"topic\">Topic:</label>\n",
        "          <input type=\"text\" id=\"topic\" name=\"topic\" required>\n",
        "          <input type=\"submit\" value=\"Generate\">\n",
        "      </form>\n",
        "   </body>\n",
        "   </html>\n",
        "   \"\"\"\n",
        "   return render_template_string(html_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKhSXALkhpL7"
      },
      "outputs": [],
      "source": [
        "def render_result_page(topic, docx_file, pdf_file, choice_text_all):\n",
        "   html_content = f\"\"\"\n",
        "   <!DOCTYPE html>\n",
        "   <html>\n",
        "   <head>\n",
        "       <title>Result</title>\n",
        "   </head>\n",
        "   <body>\n",
        "       <h1>Result</h1>\n",
        "       <p>Academic papers have been generated for the topic: {topic}</p>\n",
        "       <a href=\"/download/{docx_file}\">Download DOCX</a>\n",
        "       <a href=\"/download/{pdf_file}\">Download PDF</a>\n",
        "       <h2>Generated Text:</h2>\n",
        "       <p>{choice_text_all}</p>\n",
        "   </body>\n",
        "   </html>\n",
        "   \"\"\"\n",
        "   return render_template_string(html_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuTJlSSGgh4E"
      },
      "outputs": [],
      "source": [
        "# app.py\n",
        "\n",
        "from flask import Flask, request, render_template\n",
        "from academic_paper_generator import generate_papers\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def home():\n",
        "  if request.method == 'POST':\n",
        "      topic = request.form.get('topic')\n",
        "      prompts3 = [\n",
        "          f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "          f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "          f\"Identify gaps in the literature on '{topic}'\",\n",
        "          \"Generate 10 academic research questions about Perviuse action\",\n",
        "          f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "      ]\n",
        "      generate_papers(prompts3)\n",
        "      return render_template('result.html', topic=topic)\n",
        "  else:\n",
        "      return render_template('index.html')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  app.run(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7ef97061076f40149392f5990d01ef69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9bbc3c8fc0e48409e5da6404b269aa1",
              "IPY_MODEL_8d41b1ed7a9641dfb4619a031e3e2597",
              "IPY_MODEL_1b596278110847e88fac8e3d0c07e4f5",
              "IPY_MODEL_21c584ecb2a64bada3e1bf21924fb847",
              "IPY_MODEL_d99402c0d95d413fbe24d187d904d34c"
            ],
            "layout": "IPY_MODEL_117c2fe613c24ce7aa944f882414a1b0"
          }
        },
        "b9bbc3c8fc0e48409e5da6404b269aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9c75f3ca51f4d85a17baa6d78c259aa",
            "placeholder": "​",
            "style": "IPY_MODEL_814e24ce34864858a927688508f175fb",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "8d41b1ed7a9641dfb4619a031e3e2597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_734c44b4b9db4c078c8b49f35ee207c4",
            "placeholder": "​",
            "style": "IPY_MODEL_688304ae329b478f90c2105376b3c74d",
            "value": ""
          }
        },
        "1b596278110847e88fac8e3d0c07e4f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_008dcb79b800458cafbdaee0177c26b2",
            "style": "IPY_MODEL_07486940523841c4bc0945877e1e3da1",
            "value": true
          }
        },
        "21c584ecb2a64bada3e1bf21924fb847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_d60abec06b424c1ea187ac637516cc8c",
            "style": "IPY_MODEL_8ccea0b86ecc408a948ee933dc8542a1",
            "tooltip": ""
          }
        },
        "d99402c0d95d413fbe24d187d904d34c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80a4adb137604d2891e8bf9103ffa96f",
            "placeholder": "​",
            "style": "IPY_MODEL_5703985a3cb34259bd6d17f1b7e63dbc",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "117c2fe613c24ce7aa944f882414a1b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "a9c75f3ca51f4d85a17baa6d78c259aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "814e24ce34864858a927688508f175fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "734c44b4b9db4c078c8b49f35ee207c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "688304ae329b478f90c2105376b3c74d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "008dcb79b800458cafbdaee0177c26b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07486940523841c4bc0945877e1e3da1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d60abec06b424c1ea187ac637516cc8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ccea0b86ecc408a948ee933dc8542a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "80a4adb137604d2891e8bf9103ffa96f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5703985a3cb34259bd6d17f1b7e63dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}