{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/So-AI-love/chatgpt-prompts-for-academic-writing/blob/main/Auto_Making/API_8_3_Financial_Model_Prompt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall openai -y"
      ],
      "metadata": {
        "id": "Khj3UP-O_6aQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00d38c50-587f-4b70-f71e-ce76fb526742"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping openai as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install retry backoff openai==0.28 pdfkit python-docx"
      ],
      "metadata": {
        "id": "eo0OhdMT_7SQ",
        "outputId": "fbe185b7-68bb-46d1-fd73-eec2f8558248",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting retry\n",
            "  Downloading retry-0.9.2-py2.py3-none-any.whl (8.0 kB)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: pdfkit in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n",
            "Requirement already satisfied: decorator>=3.4.2 in /usr/local/lib/python3.10/dist-packages (from retry) (4.4.2)\n",
            "Collecting py<2.0.0,>=1.4.26 (from retry)\n",
            "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: py, retry\n",
            "Successfully installed py-1.11.0 retry-0.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # @title (Please insert your request to be done by this code at below form:ðŸ‘‡ðŸ‘‡)\n",
        "TOPIC = \"PersonalityInteractions\" # @param {type:\"string\"}\n",
        "PARAGRAPH = \"Use game theory to understand how different personality types (Dark Triad, Dark Tetrad, Dark Empathy) might interact within a society \\u003CINFO> PowerPoint\" # @param {type:\"string\"}\n",
        "role = \"startup Entrepreneur\"# @param {type:\"string\"}\n",
        "\n",
        "\n",
        "Your_Email = \"hh@gmail.com\" # @param {type:\"string\"}\n",
        "\n",
        "openai_api = \"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\" # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "#!export OPENAI_API_KEY = openai_api\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = openai_api #'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'"
      ],
      "metadata": {
        "id": "vRIB557vAbP0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "id": "3BF-3djRAkVu",
        "outputId": "e659aad3-5920-4463-cf8f-82c70744f5a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This file contains the ChatGP class that generates a business plan using OpenAI's GPT model.\n",
        "'''\n",
        "import openai\n",
        "import pdfkit\n",
        "from docx import Document\n",
        "from dotenv import load_dotenv\n",
        "import os, random, time\n",
        "\n",
        "\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, openai.error.RateLimitError, max_tries=20, max_time=600)\n",
        "\n",
        "def retry_with_exponential_backoff(\n",
        "   func,\n",
        "   initial_delay: float = 1,\n",
        "   exponential_base: float = 2,\n",
        "   jitter: bool = True,\n",
        "   max_retries: int = 10,\n",
        "   errors: tuple = (openai.error.RateLimitError,),\n",
        "):\n",
        "   \"\"\"Retry a function with exponential backoff.\"\"\"\n",
        "   def wrapper(*args, **kwargs):\n",
        "       # Initialize variables\n",
        "       num_retries = 0\n",
        "       delay = initial_delay\n",
        "       # Loop until a successful response or max_retries is hit or an exception is raised\n",
        "       while True:\n",
        "           try:\n",
        "               return func(*args, **kwargs)\n",
        "           # Retry on specified errors\n",
        "           except errors as e:\n",
        "               # Increment retries\n",
        "               num_retries += 1\n",
        "               # Check if max retries has been reached\n",
        "               if num_retries > max_retries:\n",
        "                  raise Exception(\n",
        "                      f\"Maximum number of retries ({max_retries}) exceeded.\"\n",
        "                  )\n",
        "               # Increment the delay\n",
        "               delay *= exponential_base * (1 + jitter * random.random())\n",
        "               # Sleep for the delay\n",
        "               time.sleep(delay)\n",
        "           # Raise exceptions for any errors not specified\n",
        "           except Exception as e:\n",
        "               raise e\n",
        "   return wrapper\n",
        "\n",
        "class ChatGP:\n",
        "    def __init__(self):\n",
        "        load_dotenv()\n",
        "        self.api_key = os.getenv('OPENAI_API_KEY')\n",
        "    def generate_business_plan(self, topic, description):\n",
        "        prompts1 = [\n",
        "            \"1. Executive Summary:\",\n",
        "            \"2. Company Description:\",\n",
        "            \"3. Market Analysis:\",\n",
        "            \"4. Organization and Management:\",\n",
        "            \"5. Product or Service Line:\",\n",
        "            \"6. Marketing and Sales Strategy:\",\n",
        "            \"7. Funding Request:\",\n",
        "            \"8. Financial Projections:\",\n",
        "            \"9. Appendix:\",\n",
        "            \"10. Conclusion:\"\n",
        "        ]\n",
        "        prompts = [\n",
        "            \"1. Executive Summary:\",\n",
        "            \"2. Company Description:\",\n",
        "       ]\n",
        "\n",
        "        results = []\n",
        "        for i, prompt in enumerate(prompts):\n",
        "            response = self.generate_response(prompt, topic, description)\n",
        "            result = f\"{i+1}. {prompt}\\n{response}\"\n",
        "            results.append(result)\n",
        "\n",
        "            print('\\n Results is ---:\\n', result)\n",
        "        self.save_business_plan(results)\n",
        "        return results\n",
        "    @retry_with_exponential_backoff\n",
        "    def generate_response(self, prompt, topic, description):\n",
        "        openai.api_key = self.api_key\n",
        "        response = openai.Completion.create(\n",
        "            engine='text-davinci-003',\n",
        "            prompt=f\"{prompt} {topic} {description}\",\n",
        "\n",
        "            max_tokens=2048, #len(\"{prompt} {topic} {description}\"),\n",
        "            top_p=1.0,\n",
        "            frequency_penalty=0.0,\n",
        "            presence_penalty=0.0\n",
        "\n",
        "        )\n",
        "        return response.choices[0].text.strip()\n",
        "    def save_business_plan(self, results):\n",
        "        doc = Document()\n",
        "        for result in results:\n",
        "            title, content = result.split('\\n', 1)\n",
        "            subtitle, numbering = title.split('. ', 1)\n",
        "            doc.add_heading(subtitle, level=1)\n",
        "            doc.add_heading(numbering, level=2)\n",
        "            doc.add_paragraph(content)\n",
        "        dir = os.getcwd()\n",
        "        doc.save('{dir}\\business_plan.docx')\n",
        "        pdfkit.from_file('business_plan.docx', 'business_plan.pdf')"
      ],
      "metadata": {
        "id": "DlE3kHlfAL0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from docx import Document\n",
        "import pdfkit\n",
        "import openai\n",
        "from retry import retry\n",
        "\n",
        "class ChatGP:\n",
        "    def __init__(self):\n",
        "        load_dotenv()\n",
        "        self.api_key = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "    def update_prompt(self, prompt, main_variables):\n",
        "        # Replace variables in the prompt with corresponding values from main_variables\n",
        "        for variable, value in main_variables.items():\n",
        "            prompt = prompt.replace(f\"{{{variable}}}\", value)\n",
        "        return prompt\n",
        "\n",
        "    def generate_business_plan(self, topic, description, main_variables_0):\n",
        "        prompts = {\n",
        "            \"business_plan\": [\n",
        "                \"1. Executive Summary:\\nProvide a brief overview of the business.\",\n",
        "                \"2. Company Description:\\nDescribe the company, its history, and its mission.\",\n",
        "                \"3. Market Analysis:\\nAnalyze the target market and the competition.\",\n",
        "                \"4. Organization and Management:\\nDescribe the company's structure and key personnel.\",\n",
        "                \"5. Product or Service Line:\\nDetail the products or services offered by the company.\",\n",
        "                \"6. Marketing and Sales Strategy:\\nExplain the marketing and sales strategies of the company.\",\n",
        "                \"7. Funding Request:\\nProvide details about the funding request, including the amount and use of funds.\",\n",
        "                \"8. Financial Projections:\\nProvide financial projections for the company.\",\n",
        "                \"9. Appendix:\\nInclude any additional information or documents that support the business plan.\",\n",
        "                \"10. Conclusion:\\nSummarize the key points of the business plan.\"\n",
        "            ],\n",
        "            \"problem_solving\": [\n",
        "                f\"What are the key aspects of {main_variables_0['TOPIC']} that need to be addressed?\",\n",
        "                f\"Create a mind map of the main elements of {main_variables_0['TOPIC']} and how they are interconnected.\",\n",
        "                f\"Write down ideas on sticky notes about how to improve {main_variables_0['TOPIC']}. Then, group these ideas based on common themes.\",\n",
        "                f\"Take turns sharing ideas on how to improve {main_variables_0['TOPIC']}. Make sure everyone has a chance to contribute.\",\n",
        "                f\"Think of ways to create the problem in {main_variables_0['TOPIC']}. This will help you understand how to solve it.\",\n",
        "                f\"Apply the SCAMPER method to existing solutions or situations in {main_variables_0['TOPIC']}. This will spark new ideas.\",\n",
        "                f\"Assemble a diverse group of people from various backgrounds and disciplines to tackle {main_variables_0['TOPIC']}. This will ensure a more rounded and innovative solution.\",\n",
        "                f\"Envision a future state where {main_variables_0['TOPIC']} has been solved successfully. Starting from this endpoint, work backward to identify the series of events and decisions that led to that future.\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        results = {}\n",
        "        for category, category_prompts in prompts.items():\n",
        "            for prompt in category_prompts:\n",
        "                # Update the prompt with variables\n",
        "                updated_prompt = self.update_prompt(prompt, main_variables_0)\n",
        "\n",
        "                if category == \"business_plan\":\n",
        "                    response = self.generate_response(updated_prompt, topic, description)\n",
        "                elif category == \"problem_solving\":\n",
        "                    response = self.generate_response(updated_prompt, main_variables_0['TOPIC'], description)\n",
        "                results[updated_prompt] = response\n",
        "\n",
        "        self.save_business_plan(results)\n",
        "        return results\n",
        "\n",
        "    @retry\n",
        "    def generate_response(self, prompt, topic, description):\n",
        "        openai.api_key = self.api_key\n",
        "        response = openai.Completion.create(\n",
        "            engine='text-davinci-003',\n",
        "            prompt=f\"{prompt} {topic} {description}\",\n",
        "            max_tokens=2048,\n",
        "            top_p=1.0,\n",
        "            frequency_penalty=0.0,\n",
        "            presence_penalty=0.0\n",
        "        )\n",
        "        return response.choices[0].text.strip()\n",
        "\n",
        "    def save_business_plan(self, results):\n",
        "        dir = os.getcwd()\n",
        "\n",
        "        for prompt, content in results.items():\n",
        "            repo_name = prompt.split(\":\")[0].strip()\n",
        "            file_name = f\"{dir}/{repo_name.replace(' ', '_').lower()}_business_plan.docx\"\n",
        "\n",
        "            doc = Document()\n",
        "            doc.add_heading(prompt, level=1)\n",
        "            doc.add_paragraph(content)\n",
        "            doc.save(file_name)\n",
        "\n",
        "            pdf_file_name = file_name.replace('.docx', '.pdf')\n",
        "            pdfkit.from_file(file_name, pdf_file_name)\n",
        "\n",
        "# Example usage:\n",
        "TOPIC = \"{TOPIC}\"\n",
        "RESEARCH_DOMAIN = \"{RESEARCH_DOMAIN}\"\n",
        "# ... (other variables)\n",
        "\n",
        "main_variables_0 = {\n",
        "    'TOPIC': TOPIC,\n",
        "    'RESEARCH_DOMAIN': RESEARCH_DOMAIN,\n",
        "    # ... (other variables)\n",
        "}\n",
        "\n",
        "chat_gp = ChatGP()\n",
        "results = chat_gp.generate_business_plan(\"business_plan\", \"Topic\", \"Description\", main_variables_0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "MTpsF_eMHqHv",
        "outputId": "bedacb84-c1dc-4d8b-ae95-de7ac1aaeca9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a8b8c4bf4509>\u001b[0m in \u001b[0;36m<cell line: 88>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0mchat_gp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatGP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_gp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_business_plan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"business_plan\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Topic\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Description\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_variables_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: ChatGP.generate_business_plan() takes 4 positional arguments but 5 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic = TOPIC # request.form['topic']\n",
        "description = PARAGRAPH #  request.form['description']\n",
        "chatgp = ChatGP()\n",
        "results = chatgp.generate_business_plan(topic, description)"
      ],
      "metadata": {
        "id": "_bQqVCZnEDWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This file contains the main Flask application for the ChatGP business plan generator.\n",
        "'''\n",
        "from flask import Flask, render_template, request, redirect, url_for\n",
        "#from chatgp import ChatGP\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "@app.route('/generate', methods=['POST'])\n",
        "def generate():\n",
        "    topic = request.form['topic']\n",
        "    description = request.form['description']\n",
        "    chatgp = ChatGP()\n",
        "    results = chatgp.generate_business_plan(topic, description)\n",
        "    return render_template('results.html', results=results)\n",
        "@app.route('/send_email', methods=['POST'])\n",
        "def send_email():\n",
        "    email = request.form['email']\n",
        "    # Add code to send the generated business plan to the specified email address\n",
        "    return redirect(url_for('index'))\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ],
      "metadata": {
        "id": "t80qXWMOANAH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}