{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/So-AI-love/chatgpt-prompts-for-academic-writing/blob/main/Auto_Making/API_8_3_Financial_Model_Prompt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "  # Mount Google Drive\n",
        "if not os.path.isdir('/content/drive'):\n",
        "   # If not, mount the drive\n",
        "     drive.mount('/content/drive')\n",
        "else:\n",
        "     print(\"Drive is already mounted.\")\n",
        "\n",
        "dst = '/content/drive/MyDrive/ChatGPT_Paper_wrting/short/'\n",
        "if not os.path.exists(dst):\n",
        "   os.makedirs(dst)\n",
        "\n",
        "os.chdir(dst)\n",
        "print ( 'current directory is :', os. getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T0zX1TFyWLJ",
        "outputId": "6ff9e478-78b7-43f0-f088-e49595c2a0c8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "current directory is : /content/drive/MyDrive/ChatGPT_Paper_wrting/short\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall openai -y"
      ],
      "metadata": {
        "id": "Khj3UP-O_6aQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "037839d4-ae9d-49e6-8362-78b021747a2c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping openai as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tenacity retry backoff openai==0.28 pdfkit python-docx"
      ],
      "metadata": {
        "id": "eo0OhdMT_7SQ",
        "outputId": "f2bb30b6-74a7-4a1e-9466-3a6994b8bbe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (8.2.3)\n",
            "Collecting retry\n",
            "  Downloading retry-0.9.2-py2.py3-none-any.whl (8.0 kB)\n",
            "Collecting backoff\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfkit\n",
            "  Downloading pdfkit-1.0.0-py3-none-any.whl (12 kB)\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n",
            "Requirement already satisfied: decorator>=3.4.2 in /usr/local/lib/python3.10/dist-packages (from retry) (4.4.2)\n",
            "Collecting py<2.0.0,>=1.4.26 (from retry)\n",
            "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: pdfkit, python-docx, py, backoff, retry, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 openai-0.28.0 pdfkit-1.0.0 py-1.11.0 python-docx-1.1.0 retry-0.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # @title (Please insert your request to be done by this code at below form:👇👇)\n",
        "TOPIC = \"Debugging Toxic Masculinity: A Societal Transformation\" # @param {type:\"string\"}\n",
        "PARAGRAPH = \"If possible combine the syntax error debuging I. Program field by sustainable economy for Brian stomning this sistuin :( \" # @param {type:\"string\"}\n",
        "role = \"startup Entrepreneur\"# @param {type:\"string\"}\n",
        "\n",
        "\n",
        "Your_Email = \"hh@gmail.com\" # @param {type:\"string\"}\n",
        "\n",
        "openai_api = \"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\" # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "#!export OPENAI_API_KEY = openai_api\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = openai_api #'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'"
      ],
      "metadata": {
        "id": "vRIB557vAbP0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "id": "3BF-3djRAkVu",
        "outputId": "a12b2e27-271b-4588-a6d5-cb267eaddf2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This file contains the ChatGP class that generates a business plan using OpenAI's GPT model.\n",
        "'''\n",
        "import openai\n",
        "import pdfkit\n",
        "from docx import Document\n",
        "from dotenv import load_dotenv\n",
        "import os, random, time\n",
        "\n",
        "\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, openai.error.RateLimitError, max_tries=20, max_time=600)\n",
        "\n",
        "def retry_with_exponential_backoff(\n",
        "   func,\n",
        "   initial_delay: float = 1,\n",
        "   exponential_base: float = 2,\n",
        "   jitter: bool = True,\n",
        "   max_retries: int = 10,\n",
        "   errors: tuple = (openai.error.RateLimitError,),\n",
        "):\n",
        "   \"\"\"Retry a function with exponential backoff.\"\"\"\n",
        "   def wrapper(*args, **kwargs):\n",
        "       # Initialize variables\n",
        "       num_retries = 0\n",
        "       delay = initial_delay\n",
        "       # Loop until a successful response or max_retries is hit or an exception is raised\n",
        "       while True:\n",
        "           try:\n",
        "               return func(*args, **kwargs)\n",
        "           # Retry on specified errors\n",
        "           except errors as e:\n",
        "               # Increment retries\n",
        "               num_retries += 1\n",
        "               # Check if max retries has been reached\n",
        "               if num_retries > max_retries:\n",
        "                  raise Exception(\n",
        "                      f\"Maximum number of retries ({max_retries}) exceeded.\"\n",
        "                  )\n",
        "               # Increment the delay\n",
        "               delay *= exponential_base * (1 + jitter * random.random())\n",
        "               # Sleep for the delay\n",
        "               time.sleep(delay)\n",
        "           # Raise exceptions for any errors not specified\n",
        "           except Exception as e:\n",
        "               raise e\n",
        "   return wrapper\n",
        "\n",
        "class ChatGP:\n",
        "    def __init__(self):\n",
        "        load_dotenv()\n",
        "        self.api_key = os.getenv('OPENAI_API_KEY')\n",
        "    def generate_business_plan(self, topic, description):\n",
        "        prompts1 = [\n",
        "            \"1. Executive Summary:\",\n",
        "            \"2. Company Description:\",\n",
        "            \"3. Market Analysis:\",\n",
        "            \"4. Organization and Management:\",\n",
        "            \"5. Product or Service Line:\",\n",
        "            \"6. Marketing and Sales Strategy:\",\n",
        "            \"7. Funding Request:\",\n",
        "            \"8. Financial Projections:\",\n",
        "            \"9. Appendix:\",\n",
        "            \"10. Conclusion:\"\n",
        "        ]\n",
        "        prompts = [\n",
        "            \"1. Executive Summary:\",\n",
        "            \"2. Company Description:\",\n",
        "       ]\n",
        "\n",
        "        results = []\n",
        "        for i, prompt in enumerate(prompts):\n",
        "            response = self.generate_response(prompt, topic, description)\n",
        "            result = f\"{i+1}. {prompt}\\n{response}\"\n",
        "            results.append(result)\n",
        "\n",
        "            print('\\n Results is ---:\\n', result)\n",
        "        self.save_business_plan(results)\n",
        "        return results\n",
        "    @retry_with_exponential_backoff\n",
        "    def generate_response(self, prompt, topic, description):\n",
        "        openai.api_key = self.api_key\n",
        "        response = openai.Completion.create(\n",
        "            engine='text-davinci-003',\n",
        "            prompt=f\"{prompt} {topic} {description}\",\n",
        "\n",
        "            max_tokens=2048, #len(\"{prompt} {topic} {description}\"),\n",
        "            top_p=1.0,\n",
        "            frequency_penalty=0.0,\n",
        "            presence_penalty=0.0\n",
        "\n",
        "        )\n",
        "        return response.choices[0].text.strip()\n",
        "    def save_business_plan(self, results):\n",
        "        doc = Document()\n",
        "        for result in results:\n",
        "            title, content = result.split('\\n', 1)\n",
        "            subtitle, numbering = title.split('. ', 1)\n",
        "            doc.add_heading(subtitle, level=1)\n",
        "            doc.add_heading(numbering, level=2)\n",
        "            doc.add_paragraph(content)\n",
        "        dir = os.getcwd()\n",
        "        doc.save(f'{dir}/'+'business_plan.docx')\n",
        "        #pdfkit.from_file('business_plan.docx', 'business_plan.pdf')"
      ],
      "metadata": {
        "id": "DlE3kHlfAL0n"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from docx import Document\n",
        "import pdfkit\n",
        "import openai\n",
        "#from retry import retry\n",
        "from tenacity import retry\n",
        "\n",
        "class ChatGP:\n",
        "    def __init__(self):\n",
        "        load_dotenv()\n",
        "        self.api_key = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "    def update_prompt(self, prompt, main_variables):\n",
        "        # Replace variables in the prompt with corresponding values from main_variables\n",
        "        for variable, value in main_variables.items():\n",
        "            prompt = prompt.replace(f\"{{{variable}}}\", value)\n",
        "            print ( '\\n Prompt new us :', prompt)\n",
        "        return prompt\n",
        "\n",
        "    def generate_business_plan(self, topic, description, main_variables_0):\n",
        "        prompts = {\n",
        "            \"business_plan\": [\n",
        "                \"1. Executive Summary:Provide a brief overview of the business.\",\n",
        "                \"2. Company Description:\\nDescribe the company, its history, and its mission.\",\n",
        "                \"3. Market Analysis:\\nAnalyze the target market and the competition.\",\n",
        "                \"4. Organization and Management:\\nDescribe the company's structure and key personnel.\",\n",
        "                \"5. Product or Service Line:\\nDetail the products or services offered by the company.\",\n",
        "                \"6. Marketing and Sales Strategy:\\nExplain the marketing and sales strategies of the company.\",\n",
        "                \"7. Funding Request:\\nProvide details about the funding request, including the amount and use of funds.\",\n",
        "                \"8. Financial Projections:\\nProvide financial projections for the company.\",\n",
        "                \"9. Appendix:\\nInclude any additional information or documents that support the business plan.\",\n",
        "                \"10. Conclusion:\\nSummarize the key points of the business plan.\"\n",
        "            ],\n",
        "            \"problem_solving\": [\n",
        "                f\"What are the key aspects of {main_variables_0['TOPIC']} that need to be addressed?\",\n",
        "                f\"Create a mind map of the main elements of {main_variables_0['TOPIC']} and how they are interconnected.\",\n",
        "                f\"Write down ideas on sticky notes about how to improve {main_variables_0['TOPIC']}. Then, group these ideas based on common themes.\",\n",
        "                f\"Take turns sharing ideas on how to improve {main_variables_0['TOPIC']}. Make sure everyone has a chance to contribute.\",\n",
        "                f\"Think of ways to create the problem in {main_variables_0['TOPIC']}. This will help you understand how to solve it.\",\n",
        "                f\"Apply the SCAMPER method to existing solutions or situations in {main_variables_0['TOPIC']}. This will spark new ideas.\",\n",
        "                f\"Assemble a diverse group of people from various backgrounds and disciplines to tackle {main_variables_0['TOPIC']}. This will ensure a more rounded and innovative solution.\",\n",
        "                f\"Envision a future state where {main_variables_0['TOPIC']} has been solved successfully. Starting from this endpoint, work backward to identify the series of events and decisions that led to that future.\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        results = {}\n",
        "        for category, category_prompts in prompts.items():\n",
        "            for prompt in category_prompts:\n",
        "                # Update the prompt with variables\n",
        "                print ( '\\n category is :',category,'\\n hhhprompt is:',prompt)\n",
        "                updated_prompt = self.update_prompt(prompt, main_variables_0)\n",
        "\n",
        "                if category == \"business_plan\":\n",
        "                    response = self.generate_response(updated_prompt, topic, description)\n",
        "                elif category == \"problem_solving\":\n",
        "                    response = self.generate_response(updated_prompt, main_variables_0['TOPIC'], description)\n",
        "                results[updated_prompt] = response\n",
        "                print ('\\n results is :',response)\n",
        "        self.save_business_plan(results)\n",
        "        return results\n",
        "\n",
        "    @retry\n",
        "    def generate_response(self, prompt, topic, description):\n",
        "        openai.api_key = self.api_key\n",
        "        response = openai.Completion.create(\n",
        "            engine='text-davinci-003',\n",
        "            prompt=f\"{prompt} {topic} {description}\",\n",
        "            max_tokens=2048,\n",
        "            top_p=1.0,\n",
        "            frequency_penalty=0.0,\n",
        "            presence_penalty=0.0\n",
        "        )\n",
        "        return response.choices[0].text.strip()\n",
        "\n",
        "    def save_business_plan(self, results):\n",
        "        dir = os.getcwd()\n",
        "\n",
        "        for prompt, content in results.items():\n",
        "            repo_name = prompt.split(\":\")[0].strip()\n",
        "            print ( '\\n save repo_name filename is :',repo_name)\n",
        "            file_name = f\"{dir}/{repo_name.replace(' ', '_').lower()}_business_plan.docx\"\n",
        "            print ( '\\n location for file name is :', file_name)\n",
        "\n",
        "            doc = Document()\n",
        "            doc.add_heading(prompt, level=1)\n",
        "            doc.add_paragraph(content)\n",
        "            doc.save(file_name)\n",
        "\n",
        "            pdf_file_name = file_name.replace('.docx', '.pdf')\n",
        "            pdfkit.from_file(file_name, pdf_file_name)\n",
        "\n",
        "# Example usage:\n",
        "TOPIC = \"TOPIC\"\n",
        "RESEARCH_DOMAIN = \"RESEARCH_DOMAIN\"\n",
        "# ... (other variables)\n",
        "\n",
        "main_variables_0 = {\n",
        "    'TOPIC': TOPIC,\n",
        "    'RESEARCH_DOMAIN': RESEARCH_DOMAIN,\n",
        "    # ... (other variables)\n",
        "}\n",
        "\n",
        "chat_gp = ChatGP()\n",
        "results = chat_gp.generate_business_plan( \"Topic\", \"Description\", main_variables_0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTpsF_eMHqHv",
        "outputId": "cee95fdf-2d38-4028-d7f5-408ef6ec844c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " category is : business_plan \n",
            " hhhprompt is: 1. Executive Summary:Provide a brief overview of the business.\n",
            "\n",
            " Prompt new us : 1. Executive Summary:Provide a brief overview of the business.\n",
            "\n",
            " Prompt new us : 1. Executive Summary:Provide a brief overview of the business.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic = TOPIC # request.form['topic']\n",
        "description = PARAGRAPH #  request.form['description']\n",
        "chatgp = ChatGP()\n",
        "results = chatgp.generate_business_plan(topic, description)"
      ],
      "metadata": {
        "id": "_bQqVCZnEDWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This file contains the ChatGP class which generates a business plan using OpenAI GPT.\n",
        "'''\n",
        "import openai\n",
        "import pdfkit\n",
        "from docx import Document\n",
        "from docx.shared import Pt  # Add this import statement\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "class ChatGP:\n",
        "    def __init__(self):\n",
        "        # Load environment variables\n",
        "        load_dotenv()\n",
        "        self.api_key = os.getenv('OPENAI_API_KEY')\n",
        "        openai.api_key = self.api_key\n",
        "    def generate_business_plan(self, topic, description):\n",
        "        prompts = [\n",
        "            \"1. Executive Summary: Provide a brief overview of the business plan.\",\n",
        "            \"2. Company Description: Describe the company and its mission.\",\n",
        "            \"3. Market Analysis: Analyze the target market and competition.\",\n",
        "            \"4. Product or Service: Explain the product or service being offered.\",\n",
        "            \"5. Marketing and Sales Strategy: Outline the marketing and sales approach.\",\n",
        "            \"6. Organization and Management: Describe the organizational structure.\",\n",
        "            \"7. Financial Projections: Provide financial forecasts and projections.\",\n",
        "            \"8. Funding Request: Specify the funding requirements.\",\n",
        "            \"9. Appendix: Include any additional information or supporting documents.\",\n",
        "            \"10. Conclusion: Summarize the business plan and next steps.\"\n",
        "        ]\n",
        "        # Generate responses using OpenAI GPT\n",
        "        responses = openai.Completion.create(\n",
        "            engine='text-davinci-003',\n",
        "            prompt=topic + '\\n' + description + '\\n' + '\\n'.join(prompts),\n",
        "            max_tokens=1000,\n",
        "            n=10,\n",
        "            stop=None,\n",
        "            temperature=0.7\n",
        "        )\n",
        "        print (responses)\n",
        "        # Extract the text from each completion\n",
        "        results = [responses.choices[0].text for response in responses]\n",
        "\n",
        "        dir = os.getcwd()\n",
        "        repo_name = 'ss' # prompts.split(\":\")[0].strip()\n",
        "        file_name = f\"{dir}/{repo_name.replace(' ', '_').lower()}_business_plan.docx\"\n",
        "        # Format and save the business plan as PDF and DOC\n",
        "        doc = Document()\n",
        "        doc.add_heading('Business Plan', level=1)\n",
        "        doc.add_heading('Title: ' + topic, level=2)\n",
        "        doc.add_heading('Subtitle: ' + description, level=3)\n",
        "        for i, response in enumerate(responses.choices):\n",
        "            doc.add_heading(str(i+1) + '. ' + prompts[i], level=4)\n",
        "            p = doc.add_paragraph(response.text)\n",
        "            p.runs[0].font.size = Pt(12)  # Set the font size\n",
        "        doc.save(file_name)\n",
        "        #pdfkit.from_file('business_plan.docx', 'business_plan.pdf')\n",
        "        return results"
      ],
      "metadata": {
        "id": "JRM61gb3mCNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "topic = TOPIC # request.form['topic']\n",
        "description = PARAGRAPH #  request.form['description']\n",
        "chatgp = ChatGP()\n",
        "results = chatgp.generate_business_plan(topic, description)"
      ],
      "metadata": {
        "id": "3AB0mJ9Emru6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This file contains the main Flask application for the ChatGP business plan generator.\n",
        "'''\n",
        "from flask import Flask, render_template, request, redirect, url_for\n",
        "#from chatgp import ChatGP\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "@app.route('/generate', methods=['POST'])\n",
        "def generate():\n",
        "    topic = request.form['topic']\n",
        "    description = request.form['description']\n",
        "    chatgp = ChatGP()\n",
        "    results = chatgp.generate_business_plan(topic, description)\n",
        "    return render_template('results.html', results=results)\n",
        "@app.route('/send_email', methods=['POST'])\n",
        "def send_email():\n",
        "    email = request.form['email']\n",
        "    # Add code to send the generated business plan to the specified email address\n",
        "    return redirect(url_for('index'))\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ],
      "metadata": {
        "id": "t80qXWMOANAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This file contains the function to send an email with the generated business plan as an attachment.\n",
        "'''\n",
        "import smtplib\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.base import MIMEBase\n",
        "from email import encoders\n",
        "def send_email(email, file_path):\n",
        "    from_address = \"YOUR_EMAIL_ADDRESS\"\n",
        "    password = \"YOUR_EMAIL_PASSWORD\"\n",
        "    to_address = email\n",
        "    msg = MIMEMultipart()\n",
        "    msg['From'] = from_address\n",
        "    msg['To'] = to_address\n",
        "    msg['Subject'] = \"Business Plan\"\n",
        "    attachment = open(file_path, \"rb\")\n",
        "    part = MIMEBase('application', 'octet-stream')\n",
        "    part.set_payload((attachment).read())\n",
        "    encoders.encode_base64(part)\n",
        "    part.add_header('Content-Disposition', \"attachment; filename= %s\" % file_path)\n",
        "    msg.attach(part)\n",
        "    server = smtplib.SMTP('smtp.gmail.com', 587)\n",
        "    server.starttls()\n",
        "    server.login(from_address, password)\n",
        "    text = msg.as_string()\n",
        "    server.sendmail(from_address, to_address, text)\n",
        "    server.quit()"
      ],
      "metadata": {
        "id": "QfD1fBOpN7eE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}