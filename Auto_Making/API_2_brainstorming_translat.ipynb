{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/So-AI-love/chatgpt-prompts-for-academic-writing/blob/main/Auto_Making/API_2_brainstorming_translat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AcaGPT MVP\n",
        "\n",
        "The gosl of this project is Creating something like AutoGPT but in the field of Academic Papers wrting.\n",
        "\n",
        "\n",
        "For example the MVP Lage has been made by this AI free website maker :\n",
        "\n",
        "https://acagpt.site.live/editv2/"
      ],
      "metadata": {
        "id": "qnaAEEnpFyLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The SWOT and ..., analysis of this startup is available at here:\n",
        "\n",
        "![enter image description here][1]\n",
        "\n",
        "Analysis and Feedback on a ChatGPT-based Academic Paper Writing Startup\n",
        "\n",
        "https://venturusai.com/report/3Qj8RT-if-possible-suggest-one-startup-in-the-field-of-chatgpt-for-\n",
        "\n",
        "\n",
        "  [1]: https://i.stack.imgur.com/DH3se.jpg"
      ],
      "metadata": {
        "id": "tvOJqqvAMHMD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHgZHeIxi31Q"
      },
      "source": [
        "## Aromatically wrrie apaper by the ChatGPT and this github prompt instruction:\n",
        "\n",
        "https://github.com/ahmetbersoz/chatgpt-prompts-for-academic-writing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt7VN_fmGT3E",
        "outputId": "794f7faf-8fe6-44dc-fe87-39863b276321"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.3.5)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (0.15.0)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.12.0)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
            "Requirement already satisfied: docx2pdf in /usr/local/lib/python3.10/dist-packages (0.1.8)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from docx2pdf) (4.66.1)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.5.0)\n",
            "Requirement already satisfied: django in /usr/local/lib/python3.10/dist-packages (4.2.7)\n",
            "Requirement already satisfied: asgiref<4,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from django) (3.7.2)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from django) (0.4.4)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from asgiref<4,>=3.6.0->django) (4.5.0)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (5.1.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from tenacity) (1.16.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25h+ localtunnel@2.0.2\n",
            "updated 1 package and audited 36 packages in 0.478s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 2 \u001b[93mmoderate\u001b[0m severity vulnerabilities\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n",
            "\n",
            "\u001b[33m\u001b[39m\n",
            "\u001b[33m   â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[39m\n",
            "   \u001b[33mâ”‚\u001b[39m                                                                \u001b[33mâ”‚\u001b[39m\n",
            "   \u001b[33mâ”‚\u001b[39m      New \u001b[31mmajor\u001b[39m version of npm available! \u001b[31m6.14.8\u001b[39m â†’ \u001b[32m10.2.4\u001b[39m       \u001b[33mâ”‚\u001b[39m\n",
            "   \u001b[33mâ”‚\u001b[39m   \u001b[33mChangelog:\u001b[39m \u001b[36mhttps://github.com/npm/cli/releases/tag/v10.2.4\u001b[39m   \u001b[33mâ”‚\u001b[39m\n",
            "   \u001b[33mâ”‚\u001b[39m               Run \u001b[32mnpm install -g npm\u001b[39m to update!                \u001b[33mâ”‚\u001b[39m\n",
            "   \u001b[33mâ”‚\u001b[39m                                                                \u001b[33mâ”‚\u001b[39m\n",
            "\u001b[33m   â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[39m\n",
            "\u001b[33m\u001b[39m\n",
            "35.194.95.194\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install backoff\n",
        "!pip install docx2pdf\n",
        "!pip install python-docx\n",
        "!pip install django\n",
        "\n",
        "\n",
        "!pip install tenacity\n",
        "!pip install tiktoken\n",
        "\n",
        "# SETUP COLAB for run Streamlit\n",
        "!npm install localtunnel\n",
        "\n",
        "!pip install -q dl-translate\n",
        "!curl ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install libreoffice\n",
        "#!sudo apt-get install abiword\n",
        "!sudo apt install libreoffice-writer"
      ],
      "metadata": {
        "id": "AUeIF57v21gq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e8fc14d-e25b-44b7-e87e-f346482de445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (185.125.190.36)] [Connected to cloud.r-p\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "\r0% [2 InRelease 15.6 kB/119 kB 13%] [Connecting to security.ubuntu.com (185.125\r                                                                               \rHit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [2 InRelease 56.2 kB/119 kB 47%] [Connecting to security.ubuntu.com (185.125\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcont\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "\r0% [Waiting for headers] [Connecting to ppa.launchpadcontent.net (185.125.190.8\r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,248 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,467 kB]\n",
            "Fetched 2,944 kB in 2s (1,827 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libreoffice is already the newest version (1:7.3.7-0ubuntu0.22.04.3).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " megacmd : Depends: libc-ares2 (>= 1.11.0~rc1) but it is not going to be installed\n",
            "           Depends: libcrypto++6 but it is not installable\n",
            "           Depends: libmediainfo0v5 (>= 0.7.56) but it is not going to be installed\n",
            "           Depends: libssl1.1 (>= 1.1.0) but it is not installable\n",
            "           Depends: libzen0v5 (>= 0.4.31-2~) but it is not going to be installed\n",
            "E: Unmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libreoffice-writer is already the newest version (1:7.3.7-0ubuntu0.22.04.3).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " megacmd : Depends: libc-ares2 (>= 1.11.0~rc1) but it is not going to be installed\n",
            "           Depends: libcrypto++6 but it is not installable\n",
            "           Depends: libmediainfo0v5 (>= 0.7.56) but it is not going to be installed\n",
            "           Depends: libssl1.1 (>= 1.1.0) but it is not installable\n",
            "           Depends: libzen0v5 (>= 0.4.31-2~) but it is not going to be installed\n",
            "\u001b[1;31mE: \u001b[0mUnmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define main variables\n",
        "TOPIC = \"{TOPIC}\"\n",
        "RESEARCH_DOMAIN = \"{RESEARCH_DOMAIN}\"\n",
        "PARAGRAPH = \"{PARAGRAPH}\"\n",
        "PARAGRAPHS = \"{PARAGRAPHS}\"\n",
        "TOPIC_SENTENCE = \"{TOPIC_SENTENCE}\"\n",
        "LANGUAGE = \"{LANGUAGE}\"\n",
        "ABSTRACT_PARAGRAPH = \"{ABSTRACT_PARAGRAPH}\"\n",
        "BIBLIOGRAPHY = \"{BIBLIOGRAPHY}\"\n",
        "THEORY1 = \"{THEORY1}\"\n",
        "THEORY2 = \"{THEORY2}\"\n",
        "RESEARCH_QUESTIONS = \"{RESEARCH_QUESTIONS}\"\n",
        "ACTION = \"{ACTION}\"\n",
        "RESULT_PARAGRAPHS = \"{RESULT_PARAGRAPHS}\"\n",
        "DATE = \"{DATE}\"\n",
        "NUMBER_OF_DAYS_MONTHS_YEARS = \"{NUMBER_OF_DAYS_MONTHS_YEARS}\"\n",
        "\n",
        "main_variables_0 = {\n",
        "       'TOPIC': None,\n",
        "       'RESEARCH_DOMAIN': None,\n",
        "       'PARAGRAPH': None,\n",
        "       'PARAGRAPHS': None,\n",
        "       'TOPIC_SENTENCE': None,\n",
        "       'LANGUAGE': None,\n",
        "       'ABSTRACT_PARAGRAPH': None,\n",
        "       'BIBLIOGRAPHY': None,\n",
        "       'THEORY1': None,\n",
        "       'THEORY2': None,\n",
        "       'RESEARCH_QUESTIONS': None,\n",
        "       'ACTION': None,\n",
        "       'RESULT_PARAGRAPHS': None,\n",
        "       'DATE': None,\n",
        "       'NUMBER_OF_DAYS_MONTHS_YEARS': None\n",
        "   }\n",
        "\n",
        "# List of prompts for generating academic papers\n",
        "prompts = [\n",
        "\n",
        "  # Improving Language\n",
        "  f\"Write a counterargument to the following claim: '{PARAGRAPH}'\",\n",
        "  f\"Rewrite this in an academic voice: '{PARAGRAPH}'\",\n",
        "  f\"Expand these notes: '{PARAGRAPH}'\",\n",
        "  f\"Provide me a list of words and phrases which were repeatedly / more than 3 times used: '{PARAGRAPHS}'\",\n",
        "  f\"Provide me a list of synonyms for '{PARAGRAPH}' and evaluate them in the context of '{PARAGRAPH}'\",\n",
        "  f\"Act as a language expert, proofread my paper on '{TOPIC_SENTENCE}' while putting a focus on grammar and punctuation.\",\n",
        "  f\"In the context of '{RESEARCH_DOMAIN}' translate '{PARAGRAPH}' into the '{LANGUAGE}' language.\",\n",
        "\n",
        "   # Brainstorming\n",
        "   f\"Find a research topic for a PhD in the area of '{TOPIC}'\",\n",
        "   f\"Write a detailed proposal on the following research topic. Make sure it is free from plagiarism. '{PARAGRAPH}'\",\n",
        "   f\"Identify gaps in the literature on '{TOPIC_SENTENCE}'\",\n",
        "   f\"Generate 10 academic research questions about '{PARAGRAPHS}'\",\n",
        "   f\"Generate a list of research hypotheses related to '{TOPIC_SENTENCE}'\",\n",
        "   f\"Identify potential areas for future research in the context of this '{TOPIC_SENTENCE}'\",\n",
        "   f\"Suggest novel applications of '{TOPIC_SENTENCE}' within '{RESEARCH_DOMAIN}'\",\n",
        "\n",
        "   # Title/Topic Sentence\n",
        "   f\"Suggest 5 titles for the following abstract: '{ABSTRACT_PARAGRAPH}'\",\n",
        "   f\"Write a topic sentence for this paragraph: '{PARAGRAPH}'\",\n",
        "\n",
        "   # Keywords\n",
        "   f\"Provide 5 keywords for this: '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Abstract\n",
        "   f\"Generate an abstract for a scientific paper based on this information for: '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Outline\n",
        "   f\"Generate an outline for '{TOPIC_SENTENCE}'\",\n",
        "   f\"I want to write a journal article about '{TOPIC_SENTENCE}'. Give me an outline for the article that I can use as a starting point.\",\n",
        "\n",
        "   # Introduction\n",
        "   f\"Come up with an introduction for the following research topic: '{TOPIC_SENTENCE}'\",\n",
        "\n",
        "   # Literature Review\n",
        "   f\"Conduct a literature review on '{TOPIC_SENTENCE}' and provide review paper references\",\n",
        "   f\"Provide me with references and links to papers in '{PARAGRAPH}'\",\n",
        "   f\"Summarize the scholarly literature including in-text citations on '{PARAGRAPHS}'\",\n",
        "   f\"Write this in standard Harvard referencing '{PARAGRAPH}'\",\n",
        "   f\"Convert this '{BIBLIOGRAPHY}' from MLA to APA style.\",\n",
        "   f\"Compare and contrast '{THEORY1}' and '{THEORY2}' in the context of '{RESEARCH_DOMAIN}'\",\n",
        "\n",
        "   # Methodology\n",
        "   f\"Create objectives and methodology for '{TOPIC_SENTENCE}'\",\n",
        "   f\"Write a detailed methodology for the topic: '{TOPIC_SENTENCE}'\",\n",
        "   f\"Analyze the strengths and weaknesses of this methodology: '{PARAGRAPHS}'\",\n",
        "   f\"Write objectives for this study: '{TOPIC_SENTENCE}'\",\n",
        "   f\"What are the limitations of using '{TOPIC_SENTENCE}' in '{RESEARCH_DOMAIN}'?\",\n",
        "   f\"Create a recipe for the methods used in this '{PARAGRAPHS}'\",\n",
        "   f\"Suggest interdisciplinary approaches to '{TOPIC_SENTENCE}'\",\n",
        "   f\"Explain how qualitative/quantitative research methods can be used to address '{RESEARCH_QUESTIONS}'\",\n",
        "   f\"Recommend best practices for data collection and analysis in '{TOPIC_SENTENCE}'\",\n",
        "\n",
        "   # Experiments\n",
        "   f\"Design an experiment that '{ACTION}'\",\n",
        "\n",
        "   # Results\n",
        "   f\"Write a result section for the following paragraphs. Please write this in the third person. '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Discussion\n",
        "   f\"Discuss this results: '{RESULT_PARAGRAPHS}'\",\n",
        "\n",
        "   # Conclusion\n",
        "   f\"Generate a conclusion for this: '{PARAGRAPHS}'\",\n",
        "   f\"Give recommendations and conclusion for: '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Future Works\n",
        "   f\"Can you suggest 3 directions for future research on this topic: '{PARAGRAPH}'\",\n",
        "\n",
        "   # Plan/Presentation\n",
        "   f\"Develop a research plan for: '{TOPIC_SENTENCE}'\",\n",
        "   f\"Write a schedule for completion in '{TOPIC_SENTENCE}' in NUMBER OF DAYS MONTHS YEARS which is '{NUMBER_OF_DAYS_MONTHS_YEARS}'\",\n",
        "   f\"The deadline for the submission of the first draft is '{DATE}'. Give me a week-by-week breakdown so I can plan my writing better.\",\n",
        "   f\"Write a sensational press release for this research: '{PARAGRAPHS}'\",\n",
        "   f\"Make this more persuasive: '{PARAGRAPH}'\",\n",
        "   f\"Write 3 tweets about this research? '{PARAGRAPHS}'\",\n",
        "]"
      ],
      "metadata": {
        "id": "uPcmAM5Zq5M-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define main variables\n",
        "TOPIC = \"Psychological symptoms detection for Iranian men in their 40s studying for a PHD degree\"\n",
        "RESEARCH_DOMAIN = \"Psychology\"\n",
        "PARAGRAPH = \"The symptoms include lack of energy for doing work and difficulty focusing the mind on something\"\n",
        "PARAGRAPHS = \"Historical background showing narcissism, which doesn't accept the information of psychology science but suggests using new technologies for creating cooperation\"\n",
        "TOPIC_SENTENCE = \"The aim of this study is to investigate the psychological symptoms of Iranian men in their 40s who are studying for a PHD degree\"\n",
        "LANGUAGE = \"English\"\n",
        "ABSTRACT_PARAGRAPH = \"This study aims to investigate the psychological symptoms of Iranian men in their 40s who are studying for a PHD degree\"\n",
        "BIBLIOGRAPHY = \"Masoumeh Zandpour, Jafar Hasani, Carla Sharp\"\n",
        "THEORY1 = \"Psychological symptoms detection\"\n",
        "THEORY2 = \"Narcissism\"\n",
        "RESEARCH_QUESTIONS = \"What are the psychological symptoms of Iranian men in their 40s who are studying for a PHD degree?\"\n",
        "ACTION = \"Investigate the psychological symptoms of Iranian men in their 40s who are studying for a PHD degree\"\n",
        "RESULT_PARAGRAPHS = \"The results of the study indicate...\"\n",
        "DATE = \"11/26/2023\"\n",
        "NUMBER_OF_DAYS_MONTHS_YEARS = \"2 months\""
      ],
      "metadata": {
        "id": "dMj_71pfRWfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define main variables\n",
        "TOPIC = \"Psychological symptoms detection for Iranian men in their 40s studying for a PHD degree\"\n",
        "RESEARCH_DOMAIN = \"Psychology\"\n",
        "PARAGRAPH = \"The symptoms include lack of energy for doing work and difficulty focusing the mind on something\"\n",
        "PARAGRAPHS = \"Historical background showing narcissism, which doesn't accept the information of psychology science but suggests using new technologies for creating cooperation\"\n",
        "TOPIC_SENTENCE = \"The aim of this study is to investigate the psychological symptoms of Iranian men in their 40s who are studying for a PHD degree\"\n",
        "LANGUAGE = \"English\"\n",
        "ABSTRACT_PARAGRAPH = \"This study aims to investigate the psychological symptoms of Iranian men in their 40s who are studying for a PHD degree\"\n",
        "BIBLIOGRAPHY = \"Masoumeh Zandpour, Jafar Hasani, Carla Sharp\"\n",
        "THEORY1 = \"Psychological symptoms detection\"\n",
        "THEORY2 = \"Narcissism\"\n",
        "RESEARCH_QUESTIONS = \"What are the psychological symptoms of Iranian men in their 40s who are studying for a PHD degree?\"\n",
        "ACTION = \"Investigate the psychological symptoms of Iranian men in their 40s who are studying for a PHD degree\"\n",
        "RESULT_PARAGRAPHS = \"The results of the study indicate...\"\n",
        "DATE = \"11/26/2023\"\n",
        "NUMBER_OF_DAYS_MONTHS_YEARS = \"2 months\"\n",
        "\n",
        "main_variables_0 = {\n",
        "      'TOPIC': TOPIC,\n",
        "      'RESEARCH_DOMAIN': RESEARCH_DOMAIN,\n",
        "      'PARAGRAPH': PARAGRAPH,\n",
        "      'PARAGRAPHS': PARAGRAPHS,\n",
        "      'TOPIC_SENTENCE': TOPIC_SENTENCE,\n",
        "      'LANGUAGE': LANGUAGE,\n",
        "      'ABSTRACT_PARAGRAPH': ABSTRACT_PARAGRAPH,\n",
        "      'BIBLIOGRAPHY': BIBLIOGRAPHY,\n",
        "      'THEORY1': THEORY1,\n",
        "      'THEORY2': THEORY2,\n",
        "      'RESEARCH_QUESTIONS': RESEARCH_QUESTIONS,\n",
        "      'ACTION': ACTION,\n",
        "      'RESULT_PARAGRAPHS': RESULT_PARAGRAPHS,\n",
        "      'DATE': DATE,\n",
        "      'NUMBER_OF_DAYS_MONTHS_YEARS': NUMBER_OF_DAYS_MONTHS_YEARS\n",
        "  }\n",
        "\n",
        "# List of prompts for generating academic papers\n",
        "prompts = [\n",
        "# Improving Language\n",
        "f\"Write a counterargument to the following claim: '{PARAGRAPH}'\",\n",
        "f\"Rewrite this in an academic voice: '{PARAGRAPH}'\",\n",
        "f\"Expand these notes: '{PARAGRAPH}'\",\n",
        "f\"Provide me a list of words and phrases which were repeatedly / more than 3 times used: '{PARAGRAPHS}'\",\n",
        "f\"Provide me a list of synonyms for '{PARAGRAPH}' and evaluate them in the context of '{PARAGRAPH}'\",\n",
        "f\"Act as a language expert, proofread my paper on '{TOPIC_SENTENCE}' while putting a focus on grammar and punctuation.\",\n",
        "f\"In the context of '{RESEARCH_DOMAIN}' translate '{PARAGRAPH}' into the '{LANGUAGE}' language.\",\n",
        "\n",
        "  # Brainstorming\n",
        "  f\"Find a research topic for a PhD in the area of '{TOPIC}'\",\n",
        "  f\"Write a detailed proposal on the following research topic. Make sure it is free from plagiarism. '{PARAGRAPH}'\",\n",
        "  f\"Identify gaps in the literature on '{TOPIC_SENTENCE}'\",\n",
        "  f\"Generate 10 academic research questions about '{PARAGRAPHS}'\",\n",
        "  f\"Generate a list of research hypotheses related to '{TOPIC_SENTENCE}'\",\n",
        "  f\"Identify potential areas for future research in the context of this '{TOPIC_SENTENCE}'\",\n",
        "  f\"Suggest novel applications of '{TOPIC_SENTENCE}' within '{RESEARCH_DOMAIN}'\",\n",
        "\n",
        "  # Title/Topic Sentence\n",
        "  f\"Suggest 5 titles for the following abstract: '{ABSTRACT_PARAGRAPH}'\",\n",
        "  f\"Write a topic sentence for this paragraph: '{PARAGRAPH}'\",\n",
        "\n",
        "  # Keywords\n",
        "  f\"Provide 5 keywords for this: '{PARAGRAPHS}'\",\n",
        "\n",
        "  # Abstract\n",
        "  f\"Generate an abstract for a scientific paper based on this information for: '{PARAGRAPHS}'\",\n",
        "\n",
        "  # Outline\n",
        "  f\"Generate an outline for '{TOPIC_SENTENCE}'\",\n",
        "  f\"I want to write a journal article about '{TOPIC_SENTENCE}'. Give me an outline for the article that I can use as a starting point.\",\n",
        "\n",
        "  # Introduction\n",
        "  f\"Come up with an introduction for the following research topic: '{TOPIC_SENTENCE}'\",\n",
        "\n",
        "  # Literature Review\n",
        "  f\"Conduct a literature review on '{TOPIC_SENTENCE}' and provide review paper references\",\n",
        "  f\"Provide me with references and links to papers in '{PARAGRAPH}'\",\n",
        "  f\"Summarize the scholarly literature including in-text citations on '{PARAGRAPHS}'\",\n",
        "  f\"Write this in standard Harvard referencing '{PARAGRAPH}'\",\n",
        "  f\"Convert this '{BIBLIOGRAPHY}' from MLA to APA style.\",\n",
        "  f\"Compare and contrast '{THEORY1}' and '{THEORY2}' in the context of '{RESEARCH_DOMAIN}'\",\n",
        "\n",
        "  # Methodology\n",
        "   f\"Create objectives and methodology for '{TOPIC_SENTENCE}'\",\n",
        "   f\"Write a detailed methodology for the topic: '{TOPIC_SENTENCE}'\",\n",
        "   f\"Analyze the strengths and weaknesses of this methodology: '{PARAGRAPHS}'\",\n",
        "   f\"Write objectives for this study: '{TOPIC_SENTENCE}'\",\n",
        "   f\"What are the limitations of using '{TOPIC_SENTENCE}' in '{RESEARCH_DOMAIN}'?\",\n",
        "   f\"Create a recipe for the methods used in this '{PARAGRAPHS}'\",\n",
        "   f\"Suggest interdisciplinary approaches to '{TOPIC_SENTENCE}'\",\n",
        "   f\"Explain how qualitative/quantitative research methods can be used to address '{RESEARCH_QUESTIONS}'\",\n",
        "   f\"Recommend best practices for data collection and analysis in '{TOPIC_SENTENCE}'\",\n",
        "\n",
        "   # Experiments\n",
        "   f\"Design an experiment that '{ACTION}'\",\n",
        "\n",
        "   # Results\n",
        "   f\"Write a result section for the following paragraphs. Please write this in the third person. '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Discussion\n",
        "   f\"Discuss this results: '{RESULT_PARAGRAPHS}'\",\n",
        "\n",
        "   # Conclusion\n",
        "   f\"Generate a conclusion for this: '{PARAGRAPHS}'\",\n",
        "   f\"Give recommendations and conclusion for: '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Future Works\n",
        "   f\"Can you suggest 3 directions for future research on this topic: '{PARAGRAPH}'\",\n",
        "\n",
        "   # Plan/Presentation\n",
        "   f\"Develop a research plan for: '{TOPIC_SENTENCE}'\",\n",
        "   f\"Write a schedule for completion in '{TOPIC_SENTENCE}' in NUMBER OF DAYS MONTHS YEARS which is '{NUMBER_OF_DAYS_MONTHS_YEARS}'\",\n",
        "   f\"The deadline for the submission of the first draft is '{DATE}'. Give me a week-by-week breakdown so I can plan my writing better.\",\n",
        "   f\"Write a sensational press release for this research: '{PARAGRAPHS}'\",\n",
        "   f\"Make this more persuasive: '{PARAGRAPH}'\",\n",
        "   f\"Write 3 tweets about this research? '{PARAGRAPHS}'\",\n",
        "]"
      ],
      "metadata": {
        "id": "ndWVOITXN7Xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "main_variables_0 = {\n",
        "'TOPIC': 'stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups',\n",
        "'FIELD_STUDY': 'political science',\n",
        "'OPTIONAL': 'Middle East',\n",
        " 'perviuse_content' : 'this is the first step and perviuse contnet not created',\n",
        " 'PROMPT_UPDATING': f\"\"\"Generate content for the variable '{var}' in the context of the topic '{main_variables_0.get('TOPIC', 'Default Value')}'. Please consider the result must be summarized and as a variable for ChatGPT Generative AI for the {TOPIC}. The prompt is '{prompt}'. Also the more information for understanding better content is '{perviuse_content}'\"\"\"\n",
        "}\n",
        "\n",
        "prompts = [\n",
        " # Understanding the Issue\n",
        " f\"What are the key aspects of {main_variables_0['TOPIC']} that need to be addressed in the field of {main_variables_0['FIELD_STUDY']}?\",\n",
        "\n",
        " # Mind Mapping\n",
        " f\"Create a mind map of the main elements of {main_variables_0['TOPIC']} and how they are interconnected in the field of {main_variables_0['FIELD_STUDY']}.\",\n",
        "\n",
        " # Affinity Diagramming\n",
        " f\"Write down ideas on sticky notes about how to improve {main_variables_0['TOPIC']} in the field of {main_variables_0['FIELD_STUDY']}. Then, group these ideas based on common themes.\",\n",
        "\n",
        " # Round-Robin Brainstorming\n",
        " f\"Take turns sharing ideas on how to improve {main_variables_0['TOPIC']} in the field of {main_variables_0['FIELD_STUDY']}. Make sure everyone has a chance to contribute.\",\n",
        "\n",
        " # Reverse Brainstorming\n",
        " f\"Think of ways to create the problem in {main_variables_0['TOPIC']} in the field of {main_variables_0['FIELD_STUDY']}. This will help you understand how to solve it.\",\n",
        "\n",
        " # SCAMPER\n",
        " f\"Apply the SCAMPER method to existing solutions or situations in {main_variables_0['TOPIC']} in the field of {main_variables_0['FIELD_STUDY']}. This will spark new ideas.\",\n",
        "\n",
        " # Cross-Functional Brainstorming\n",
        " f\"Assemble a diverse group of people from various backgrounds and disciplines to tackle {main_variables_0['TOPIC']} in the field of {main_variables_0['FIELD_STUDY']}. This will ensure a more rounded and innovative solution.\",\n",
        "\n",
        " # Future Backwards\n",
        " f\"Envision a future state where {main_variables_0['TOPIC']} in the field of {main_variables_0['FIELD_STUDY']} has been solved successfully. Starting from this endpoint, work backward to identify the series of events and decisions that led to that future.\",\n",
        "\n",
        " # Four-Step Innovation Process\n",
        " f\"Let's go through a Four-Step Innovation Process to develop a new approach for {main_variables_0['TOPIC']} in the field of {main_variables_0['FIELD_STUDY']}. Start with identifying the correct problem.\",\n",
        "\n",
        " # Synectics\n",
        " f\"I'd like to use Synectics to generate innovative solutions for {main_variables_0['TOPIC']} in the field of {main_variables_0['FIELD_STUDY']}. Can you help me draw some analogies?\"\n",
        "]"
      ],
      "metadata": {
        "id": "O7LtXHHGhAM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of changes in the type of violence that continues in the aftermath of violence\"\n",
        "#TOPIC =f\"stop the WarDark Triad and Light Triad in the Middle East: A Critical Examination of their Influence and Impact on Iran\"+TOPIC\n",
        "\n",
        "#TOPIC = f\"{main_variables_0[TOPIC]}\" #f\"stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups\"\n",
        "TOPIC = main_variables_0.get('TOPIC', 'Default Value')\n",
        "#PROMPT_UPDATING = f\"\"\"Generate content for the variable '{var}' in the context of the topic '{TOPIC}'. Please consider the result must be summarized and as a variable for ChatGPT Generative AI for the {TOPIC}. The prompt is '{prompt}'. Also the more information for understanding better content is '{perviuse_content}'\"\"\"\n",
        "\n",
        "folder_chatGPT = \"/content/ChatGPT_academic_paper\"\n",
        "openai_api_0 = \"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\"\n",
        "openai_api = \"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\"\n",
        "global TOPIC_CLASS\n",
        "class TOPIC_CLASS:\n",
        "    def __init__(self):\n",
        "        self.perviuse_try_numner = 0\n",
        "        self.perviuse_content = ['fist step']\n",
        "        self.topic= TOPIC\n",
        "TP= TOPIC_CLASS()\n",
        "#TOPIC = f\" \""
      ],
      "metadata": {
        "id": "I484Df8ONQVI",
        "outputId": "ab91d122-9268-40f7-e65c-b78660ced41d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-121-91836792a648>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#TOPIC = f\"{main_variables_0[TOPIC]}\" #f\"stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mTOPIC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain_variables_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TOPIC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Default Value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mPROMPT_UPDATING\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\"\"Generate content for the variable '{var}' in the context of the topic '{TOPIC}'. Please consider the result must be summarized and as a variable for ChatGPT Generative AI for the {TOPIC}. The prompt is '{prompt}'. Also the more information for understanding better content is '{perviuse_content}'\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfolder_chatGPT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/ChatGPT_academic_paper\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'perviuse_content' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Funstions for saving as PDF and DOCX :\n",
        "ðŸ‘‡ðŸŒ±"
      ],
      "metadata": {
        "id": "lI5PG0BNPrPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install libreoffice\n",
        "#!sudo apt-get install abiword\n",
        "!sudo apt install libreoffice-writer"
      ],
      "metadata": {
        "id": "XDBHbtajP03B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b365439b-3e4d-4f22-c07d-23fec4f072cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [Conn\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.39)] [\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.39)] [\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libreoffice is already the newest version (1:7.3.7-0ubuntu0.22.04.3).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " megacmd : Depends: libc-ares2 (>= 1.11.0~rc1) but it is not going to be installed\n",
            "           Depends: libcrypto++6 but it is not installable\n",
            "           Depends: libmediainfo0v5 (>= 0.7.56) but it is not going to be installed\n",
            "           Depends: libssl1.1 (>= 1.1.0) but it is not installable\n",
            "           Depends: libzen0v5 (>= 0.4.31-2~) but it is not going to be installed\n",
            "E: Unmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libreoffice-writer is already the newest version (1:7.3.7-0ubuntu0.22.04.3).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " megacmd : Depends: libc-ares2 (>= 1.11.0~rc1) but it is not going to be installed\n",
            "           Depends: libcrypto++6 but it is not installable\n",
            "           Depends: libmediainfo0v5 (>= 0.7.56) but it is not going to be installed\n",
            "           Depends: libssl1.1 (>= 1.1.0) but it is not installable\n",
            "           Depends: libzen0v5 (>= 0.4.31-2~) but it is not going to be installed\n",
            "\u001b[1;31mE: \u001b[0mUnmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2xiQx_camiB"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "def convert_docx_to_pdf0(docx_path, pdf_path):\n",
        "  subprocess.call(['abiword', '--to=pdf', docx_path, '--to-dir', pdf_path])\n",
        "\n",
        "def convert_docx_to_pdf(docx_path, pdf_path):\n",
        " command = ['libreoffice', '--headless', '--convert-to', 'pdf', '--outdir', pdf_path, docx_path]\n",
        " subprocess.call(command)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "from docx import Document\n",
        "\n",
        "\n",
        "\n",
        "def save_academic_paper(topic, prompt_my):\n",
        " # Define the path to the DOCX file\n",
        " docx_path = f\"/content/{topic}.docx\"\n",
        "\n",
        " # Check if the DOCX file exists\n",
        " if os.path.isfile(docx_path):\n",
        "     # If the DOCX file exists, open it\n",
        "     doc = Document(docx_path)\n",
        " else:\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "     doc = Document()\n",
        "\n",
        " # Add the generated text to the document\n",
        " #print (\"____&&&&&&&&&&\\n\",prompt_my)\n",
        " doc.add_paragraph(prompt_my)\n",
        "\n",
        " # Save the document\n",
        " doc.save(docx_path)\n",
        "\n",
        " # Convert the DOCX file to a PDF\n",
        " convert_docx_to_pdf(docx_path, \"/content/output/\")"
      ],
      "metadata": {
        "id": "uE2pz7Zp4QIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import subprocess\n",
        "from docx import Document\n",
        "from django.utils.text import slugify\n",
        "\n",
        "\n",
        "def save_academic_paper(topic, prompt_my):\n",
        "  # Define the path to the folder in Google Drive\n",
        "  folder_path = r\"/content/drive/My Drive/ChatGPT_Paper_wrting/\"\n",
        "\n",
        "  # Mount Google Drive\n",
        "  if not os.path.isdir('/content/drive'):\n",
        "   # If not, mount the drive\n",
        "     drive.mount('/content/drive')\n",
        "   else:\n",
        "     print(\"Drive is already mounted.\")\n",
        "\n",
        "  Pdf_Dir= r\"/content/drive/My Drive/ChatGPT_Paper_wrting/\"\n",
        "  docx_path= f\"{folder_path}{topic}.docx\"\n",
        "  # Check if the folder exists\n",
        "  if not os.path.exists(folder_path):\n",
        "  # If the folder doesn't exist, create it\n",
        "    os.mkdir(folder_path)\n",
        "\n",
        "\n",
        "  # Replace spaces in the topic with underscores\n",
        "  #topic = topic[:12].replace(\" \", \"_\")\n",
        "  topic = slugify(topic)\n",
        "\n",
        "  # Define the path to the DOCX file in the folder\n",
        "\n",
        "\n",
        "  # Check if the DOCX file exists\n",
        "  if os.path.isfile(docx_path):\n",
        "    # If the DOCX file exists, open it\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"#+str(random.randint(0,9))+\".docx\"\n",
        "    doc = Document(docx_path)\n",
        "  else:\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"\n",
        "    #print(docx_path)\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "    doc = Document()\n",
        "\n",
        "  # Add the generated text to the document\n",
        "  doc.add_paragraph(prompt_my)\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Convert the DOCX file to a PDF\n",
        "  convert_docx_to_pdf(docx_path,Pdf_Dir)"
      ],
      "metadata": {
        "id": "gEC4g9KHOQwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import subprocess\n",
        "from docx import Document\n",
        "from django.utils.text import slugify\n",
        "\n",
        "\n",
        "  # Mount Google Drive\n",
        "if not os.path.isdir('/content/drive'):\n",
        "   # If not, mount the drive\n",
        "     drive.mount('/content/drive')\n",
        "   else:\n",
        "     print(\"Drive is already mounted.\")\n",
        "\n",
        "\n",
        "def save_academic_paper_with_prompt(topic, prompt_my,contnet):\n",
        "  # Define the path to the folder in Google Drive\n",
        "  folder_path = r\"/content/drive/My Drive/ChatGPT_Paper_wrting/\"\n",
        "\n",
        "\n",
        "  Pdf_Dir= r\"/content/drive/My Drive/ChatGPT_Paper_wrting/\"\n",
        "  docx_path= f\"{folder_path}{topic}.docx\"\n",
        "  # Check if the folder exists\n",
        "  if not os.path.exists(folder_path):\n",
        "  # If the folder doesn't exist, create it\n",
        "    os.mkdir(folder_path)\n",
        "\n",
        "\n",
        "  # Replace spaces in the topic with underscores\n",
        "  #topic = topic[:12].replace(\" \", \"_\")\n",
        "  topic = slugify(topic)\n",
        "\n",
        "  # Define the path to the DOCX file in the folder\n",
        "\n",
        "\n",
        "  # Check if the DOCX file exists\n",
        "  if os.path.isfile(docx_path):\n",
        "    # If the DOCX file exists, open it\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"#+str(random.randint(0,9))+\".docx\"\n",
        "    doc = Document(docx_path)\n",
        "  else:\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"\n",
        "    #print(docx_path)\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "    doc = Document()\n",
        "\n",
        "  # Add the generated text to the document\n",
        "  p = doc.add_paragraph(prompt_my)\n",
        "  # Add the generated text to the document\n",
        "  # Add the generated text to the document\n",
        "  p.style = doc.styles['Heading 3']\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Revert the style of the paragraph back to 'Normal'\n",
        "  p = doc.add_paragraph(contnet)\n",
        "  p.style = doc.styles['Normal']\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Convert the DOCX file to a PDF\n",
        "  convert_docx_to_pdf(docx_path,Pdf_Dir)"
      ],
      "metadata": {
        "id": "iYQv76ernY6l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "585f51aa-1ed1-48d5-9583-c18090abf58f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# @title\n",
        "# conect to [Mega.z](https://mega.nz/) cloud for storage files based ot this page:\n",
        "\n",
        "https://colab.research.google.com/github/sudo-ken/Mega-to-Google-Drive/blob/master/Transfer_files_from_Mega_to_Google_Drive.ipynb#scrollTo=Vgh1xlQYGZCO"
      ],
      "metadata": {
        "id": "x7XWsP_amNqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube-dl\n",
        "!apt install python3-distutils\n",
        "!pip install mega.py\n",
        "!apt install python3-distutils  -y\n",
        "\n",
        "# %cd '/content/'\n",
        "# !git clone https://github.com/jeroenmeulenaar/python3-mega.git\n",
        "# !(cd python3-mega; pip install urlobject pycrypto)\n",
        "\n",
        "# import os\n",
        "# os.chdir('python3-mega')\n",
        "# from mega import Mega\n",
        "# os.chdir('../')\n",
        "# m = Mega.from_ephemeral()\n",
        "\n",
        "# !git clone https://github.com/odwyersoftware/mega.py\n",
        "# %cd mega.py\n",
        "# !python setup.py install\n",
        "%cd '/content/'\n",
        "\n",
        "!rm -rf '/content/yoloOnGoogleColab'\n",
        "#!git clone https://github.com/CAR-Driving/yoloOnGoogleColab"
      ],
      "metadata": {
        "id": "L436PiVNmQog",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee36f70f-4655-4f22-a257-257fde1cab94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: youtube-dl in /usr/local/lib/python3.10/dist-packages (2021.12.17)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-distutils is already the newest version (3.10.8-1~22.04).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " megacmd : Depends: libc-ares2 (>= 1.11.0~rc1) but it is not going to be installed\n",
            "           Depends: libcrypto++6 but it is not installable\n",
            "           Depends: libmediainfo0v5 (>= 0.7.56) but it is not going to be installed\n",
            "           Depends: libssl1.1 (>= 1.1.0) but it is not installable\n",
            "           Depends: libzen0v5 (>= 0.4.31-2~) but it is not going to be installed\n",
            "\u001b[1;31mE: \u001b[0mUnmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\u001b[0m\n",
            "Requirement already satisfied: mega.py in /usr/local/lib/python3.10/dist-packages (1.0.8)\n",
            "Requirement already satisfied: requests>=0.10 in /usr/local/lib/python3.10/dist-packages (from mega.py) (2.31.0)\n",
            "Requirement already satisfied: pycryptodome<4.0.0,>=3.9.6 in /usr/local/lib/python3.10/dist-packages (from mega.py) (3.19.0)\n",
            "Requirement already satisfied: pathlib==1.0.1 in /usr/local/lib/python3.10/dist-packages (from mega.py) (1.0.1)\n",
            "Requirement already satisfied: tenacity<6.0.0,>=5.1.5 in /usr/local/lib/python3.10/dist-packages (from mega.py) (5.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=0.10->mega.py) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=0.10->mega.py) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=0.10->mega.py) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=0.10->mega.py) (2023.7.22)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from tenacity<6.0.0,>=5.1.5->mega.py) (1.16.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-distutils is already the newest version (3.10.8-1~22.04).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " megacmd : Depends: libc-ares2 (>= 1.11.0~rc1) but it is not going to be installed\n",
            "           Depends: libcrypto++6 but it is not installable\n",
            "           Depends: libmediainfo0v5 (>= 0.7.56) but it is not going to be installed\n",
            "           Depends: libssl1.1 (>= 1.1.0) but it is not installable\n",
            "           Depends: libzen0v5 (>= 0.4.31-2~) but it is not going to be installed\n",
            "\u001b[1;31mE: \u001b[0mUnmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\u001b[0m\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# @markdown <center><h3>Input Your Mega ID</h3></center><br>\n",
        "from functools import wraps\n",
        "import errno\n",
        "import os\n",
        "import signal\n",
        "import subprocess\n",
        "import shlex\n",
        "\n",
        "\n",
        "class TimeoutError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "def timeout(seconds=10, error_message=os.strerror(errno.ETIME)):\n",
        "    def decorator(func):\n",
        "        def _handle_timeout(signum, frame):\n",
        "            raise TimeoutError(error_message)\n",
        "\n",
        "        def wrapper(*args, **kwargs):\n",
        "            signal.signal(signal.SIGALRM, _handle_timeout)\n",
        "            signal.alarm(seconds)\n",
        "            try:\n",
        "                result = func(*args, **kwargs)\n",
        "            finally:\n",
        "                signal.alarm(0)\n",
        "            return result\n",
        "\n",
        "        return wraps(func)(wrapper)\n",
        "\n",
        "    return decorator\n",
        "\n",
        "\n",
        "if not os.path.exists(\"/root/.ipython/ocr.py\"):\n",
        "    from subprocess import run\n",
        "    from shlex import split\n",
        "\n",
        "    shellCmd = \"wget -qq https://raw.githubusercontent.com/biplobsd/OneClickRun/master/res/ocr.py \\\n",
        "                    -O /root/.ipython/ocr.py\"\n",
        "    run(split(shellCmd))\n",
        "from ocr import runSh\n",
        "\n",
        "@timeout(10)\n",
        "def runShT(args):\n",
        "    return runSh(args, output=True)\n",
        "\n",
        "\n",
        "# MEGAcmd installing\n",
        "if not os.path.exists(\"/usr/bin/mega-cmd\"):\n",
        "    print(\"Installing MEGA ...\")\n",
        "    runSh('sudo apt-get -y update')\n",
        "    runSh('sudo apt-get -y install libmms0 libc-ares2 libc6 libcrypto++6 libgcc1 libmediainfo0v5 libpcre3 libpcrecpp0v5 libssl1.1 libstdc++6 libzen0v5 zlib1g apt-transport-https')\n",
        "    runSh('sudo curl -sL -o /var/cache/apt/archives/MEGAcmd.deb https://mega.nz/linux/MEGAsync/Debian_9.0/amd64/megacmd-Debian_9.0_amd64.deb', output=True)\n",
        "    runSh('sudo dpkg -i /var/cache/apt/archives/MEGAcmd.deb', output=True)\n",
        "    print(\"MEGA is installed.\")\n",
        "else:\n",
        "    !pkill mega-cmd\n",
        "\n",
        "# INPUT YOUR MEGA ID\n",
        "\n",
        "USERNAME = 'kayeyoc231@llubed.com'  # @param {type:\"string\"}\n",
        "PASSWORD = \"ss123456\"  # @param {type:\"string\"}\n",
        "if not (USERNAME == \"\" or PASSWORD == \"\"):\n",
        "    try:\n",
        "        runShT(f\"mega-login {USERNAME} {PASSWORD}\")\n",
        "        print (\"megazn login has done successfully\")\n",
        "    except TimeoutError:\n",
        "        runSh('mega-whoami', output=True)\n",
        "else:\n",
        "    print(\"Please Input your Mega IDs.\")\n",
        "# @markdown *After signing in, use the above cell(Main Cell) to transfer files from Mega to GDrive using the transfer quota of your Mega Pro Account*"
      ],
      "metadata": {
        "id": "uqYuzvYFoMIM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9b0d01e-c1ab-455d-b863-d89d967c70bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Initiating MEGAcmd server in background. Log: /root/.megaCmd/megacmdserver.log]\n",
            "Unable to connect to service: error=2\n",
            "Please ensure mega-cmd-server is running\n",
            "Failed to create socket for registering for state changes\n",
            "megazn login has done successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#!rm -rf '/content/ChatGPT_academic_paper'\n",
        "!mkdir '/content/ChatGPT_academic_paper'\n",
        "%cd '/content/ChatGPT_academic_paper'\n",
        "!echo 't' >> t.txt\n",
        "\n",
        "from subprocess import Popen, PIPE\n",
        "import shlex\n",
        "import errno, os\n",
        "\n",
        "from subprocess import Popen, PIPE\n",
        "import shlex\n",
        "from ocr import runSh\n",
        "import re\n",
        "from distutils.dir_util import copy_tree\n",
        "\n",
        "# copy subdirectory example\n",
        "fromDirectory = '/content/ChatGPT_academic_paper/'\n",
        "toDirectory = '/content/gdrive/My Drive/yolo_car_database/'\n",
        "\n",
        "runSh('mega-cd /' )\n",
        "runSh(' mega-mkdir ChatGPT_academic_paper ')\n",
        "runSh(' mega-ls ')\n",
        "runSh('mega-cd ChatGPT_academic_paper ')\n",
        "\n",
        "# copy_tree(fromDirectory, toDirectory)\n",
        "def uplaod_mega_nz(root,cloude='mega',title1=''):\n",
        "  if (cloude=='mega'):\n",
        "  #  from mega import Mega\n",
        "  #  mega = Mega()\n",
        "  #  email = 'woraqofa@ivyandmarj.com'\n",
        "  #  password = 'feripas800@wgraj.com'\n",
        "  #  m = mega.login(email, password)\n",
        "  #  # login using a temporary anonymous account\n",
        "  #  m = mega.login()\n",
        "  #  quota = m.get_quota()\n",
        "  #  # specify unit output kilo, mega, gig, else bytes will output\n",
        "  #  space = m.get_storage_space(kilo=True)\n",
        "  #  m.create_folder('yolo_car_database/'+title1+'/')\n",
        "  #  folder = m.find('yolo_car_database/'+title1+'/')\n",
        "   # m.upload('myfile.doc', folder[0])\n",
        "  #  run_command('mega-cd ~ && mega-mkdir Yolo_car_database && mega-cd Yolo_car_database && mega-put '+ root+'/* . ')\n",
        "\n",
        "   runSh('mega-cd ChatGPT_academic_paper' + title1 + '/')\n",
        "   runSh('mega-put '+ root+' . ')\n",
        "   runSh(' mega-ls')\n",
        "\n",
        "   for path, subdirs, files in os.walk( root):\n",
        "      for name in files:\n",
        "        print (files)\n",
        "          # m.upload(os.path.join(path, name), folder[0])\n",
        "   # public_exported_web_link = m.export('myfile.doc')\n",
        "   # public_exported_web_link = m.export('my_mega_folder/my_sub_folder_to_share')\n",
        "\n",
        "  if (cloude=='google_drive'):\n",
        "     run_command('mkdir '+root+'/')\n",
        "     for path, subdirs, files in os.walk( root):\n",
        "      for name in files:\n",
        "        # print ('cp -r \"'+os.path.join(path, name)+'\" '+'\"/content/gdrive/My Drive/ChatGPT_academic_paper/' + title1 + '/\"')\n",
        "        # print (os.path.join(path, change_name(name)))\n",
        "        # os.rename(os.path.join(path, name), os.path.join(path, change_name(name)))\n",
        "        run_command('cp -r  \"'+os.path.join(path, name)+'\" '+'\"/content/gdrive/My Drive/ChatGPT_academic_paper/' + title1 + '/\"')\n",
        "     try:\n",
        "        copy_tree(root,'/content/gdrive/My Drive/ChatGPT_academic_paper/' + title1 + '/')\n",
        "     except OSError as e: # this would be \"except OSError, e:\" before Python 2.6\n",
        "        if e.errno != errno.ENOENT: # errno.ENOENT = no such file or directory\n",
        "            # raise #\n",
        "            i=0\n",
        "def change_file_name(root):\n",
        "  for path, subdirs, files in os.walk( root):\n",
        "      for name in files:\n",
        "        print ('filename is: \"'+os.path.join(path, name))\n",
        "        print (os.path.join(path, change_name(name)))\n",
        "        os.rename(os.path.join(path, name), os.path.join(path, change_name(name)))\n",
        "\n",
        "def run_command(cmd):\n",
        "    with Popen(shlex.split(cmd), stdout=PIPE, bufsize=1, universal_newlines=False) as p:\n",
        "        while True:\n",
        "            line = p.stdout.readline()\n",
        "            if not line:\n",
        "                break\n",
        "            print(line)\n",
        "        exit_code = p.poll()\n",
        "    return exit_code\n",
        "def change_name(name):\n",
        "    name_file = ''.join(name)\n",
        "    name_file = name_file.replace(\" \", \"_\")\n",
        "    name_file = name_file.replace(\"'\", \"_\")\n",
        "    name_file = name_file.replace(\"\\n\", \"\")\n",
        "    name_file = name_file.replace(\"\\t\", \"\")\n",
        "    name_file = name_file.replace(\"!\", \"\")\n",
        "    name_file = name_file.replace(\"-\", \"\")\n",
        "    name_file = name_file.replace(\"$\", \"\")\n",
        "    name_file = re.sub(r'[\\\\/*?:\"<>|]',\"\",name_file)\n",
        "    return name_file\n",
        "def MegaZN_upload_file(command):\n",
        "    # command_title=re.split('([^a-zA-Z0-9])',command)\n",
        "    command_title_1 = re.split('([^a-zA-Z0-9])', command)\n",
        "    command_title = ''.join(command_title_1)\n",
        "    command_title=change_name(command_title)\n",
        "\n",
        "\n",
        "    # call_args = ' youtube-dl --match-title ' + ' \"'+command_title_1[0]+ '\" ' + '\"ytsearch10\":'+'\"'+command+ '\" '+\"--external-downloader-args   '-ss 00:00:03 -t 00:03:08' --write-info-json --write-annotation --write-thumbnail --write-sub -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4'\"\n",
        "    #call_args = ' youtube-dl --match-title ' + ' \"'+command_title_1[0]+ '\" ' + '\"ytsearch100\":'+'\"'+command+ '\" '+\"--playlist-end 3  --external-downloader-args   '-ss 00:00:03 -t 00:03:08' --write-info-json --write-annotation --write-thumbnail --write-sub -f 'best[ext=mp4,height<=1080]+best[filesize<100M]' \"\n",
        "\n",
        "    # call_args = call_args.split() # because call takes a list of strings\n",
        "    # print (call_args)\n",
        "    # call(call_args)\n",
        "    # os.chdir(\"/content/yolo_car_database\")\n",
        "    # run_command('cd \"/content/yolo_car_database\"')\n",
        "    # run_command(call_args)\n",
        "    # os.system(\"cp --recursive '/content/yolo_car_database' '/content/gdrive/My Drive/yolo_car_databe\")\n",
        "    # os.system('pwd && ls ')\n",
        "    # copy_tree(fromDirectory, toDirectory)\n",
        "    # p = Popen(shlex.split(call_args), bufsize=1, universal_newlines=True)\n",
        "    run_command('mkdir /content/ChatGPT_academic_paper/'+command_title)\n",
        "\n",
        "    os.chdir( '/content/ChatGPT_academic_paper/'+command_title+'/')\n",
        "    #run_command(call_args)\n",
        "    # copy_tree('/content/yolo_car_database/'+command_title+'/', '/content/gdrive/My Drive/yolo_car_database/'+command_title+'/')\n",
        "    change_file_name('/content/ChatGPT_academic_paper/'+command_title+'/')\n",
        "    uplaod_mega_nz('/content/ChatGPT_academic_paper/'+command_title+'/','mega',command_title)\n",
        "    try:\n",
        "        # call(call_args)\n",
        "        # run_command('mkdir /content/yolo_car_database/'+command_title)\n",
        "        # os.chdir( '/content/yolo_car_database/'+command_title+'/')\n",
        "        # run_command(call_args)\n",
        "        # copy_tree('/content/yolo_car_database/'+command_title+'/', toDirectory)\n",
        "\n",
        "        # print (call_args)\n",
        "        pp=0\n",
        "\n",
        "    except OSError as e: # this would be \"except OSError, e:\" before Python 2.6\n",
        "        if e.errno != errno.ENOENT: # errno.ENOENT = no such file or directory\n",
        "            raise # re-raise exception if a different error occurred\n",
        "\n",
        "    # return p.poll()\n",
        "\n",
        "# !wget https://github.com/spectrico/car-make-model-classifier-yolo3-python/blob/master/labels.txt\n",
        "\n",
        "i=0\n",
        "#for line in open('/content/yoloOnGoogleColab/car_type_label.txt','r').readlines():\n",
        "    #print (line)\n",
        "    #try:\n",
        "      #Youtube_download_video(line)\n",
        "\n",
        "    #except OSError as e: # this would be \"except OSError, e:\" before Python 2.6\n",
        "        #if e.errno != errno.ENOENT: # errno.ENOENT = no such file or directory\n",
        "            #i=1 # re-raise exception if a different error occurred\n",
        "    #i=i+1\n",
        "# !cp '/content/yolo_car_database' \"gdrive/My Drive/yolo_car_databe\""
      ],
      "metadata": {
        "id": "8Fx5M6zXmTAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7435bce-9aa0-4fb3-dfc2-f4688a656b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory â€˜/content/ChatGPT_academic_paperâ€™: File exists\n",
            "/content/ChatGPT_academic_paper\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!pwd\n",
        "%cd '/content/'\n",
        "from google.colab import drive\n",
        "import os\n",
        "import subprocess\n",
        "from docx import Document\n",
        "from django.utils.text import slugify\n",
        "\n",
        "# Mount Google Drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "def save_academic_paper_with_prompt_megazn(topic, prompt_my,contnet):\n",
        "  # Define the path to the folder in Google Drive\n",
        "  folder_path = r\"/content/ChatGPT_academic_paper/\"\n",
        "\n",
        "  Pdf_Dir= r\"/content/ChatGPT_academic_paper/\"\n",
        "  docx_path= f\"{folder_path}{topic}.docx\"\n",
        "  # Check if the folder exists\n",
        "  if not os.path.exists(folder_path):\n",
        "  # If the folder doesn't exist, create it\n",
        "    os.mkdir(folder_path)\n",
        "\n",
        "\n",
        "  # Replace spaces in the topic with underscores\n",
        "  #topic = topic[:12].replace(\" \", \"_\")\n",
        "  topic = slugify(topic)\n",
        "\n",
        "  # Define the path to the DOCX file in the folder\n",
        "\n",
        "\n",
        "  # Check if the DOCX file exists\n",
        "  if os.path.isfile(docx_path):\n",
        "    # If the DOCX file exists, open it\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"#+str(random.randint(0,9))+\".docx\"\n",
        "    doc = Document(docx_path)\n",
        "  else:\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"\n",
        "    #print(docx_path)\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "    doc = Document()\n",
        "\n",
        "  # Add the generated text to the document\n",
        "  p = doc.add_paragraph(prompt_my)\n",
        "  # Add the generated text to the document\n",
        "  # Add the generated text to the document\n",
        "  p.style = doc.styles['Heading 2']\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Revert the style of the paragraph back to 'Normal'\n",
        "  p = doc.add_paragraph(contnet)\n",
        "  p.style = doc.styles['Normal']\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Convert the DOCX file to a PDF\n",
        "  convert_docx_to_pdf(docx_path,Pdf_Dir)\n",
        "\n",
        "  os.chdir(folder_path)\n",
        "\n",
        "    # copy_tree('/content/yolo_car_database/'+command_title+'/', '/content/gdrive/My Drive/yolo_car_database/'+command_title+'/')\n",
        "\n",
        "  uplaod_mega_nz('/content/ChatGPT_Paper_wrting/')\n",
        "  uplaod_mega_nz('/content/ChatGPT_Paper_wrting/','google_drive')"
      ],
      "metadata": {
        "id": "nv2vAOr8sskq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f025c3d-8300-4734-f419-3e40cf4bdb62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ChatGPT_academic_paper\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#save_academic_paper(\"Persian_\"+'topic','\\n**'+'choice_translated_prompt'+'**\\n'+\"choice_translated\")\n",
        "topic = TOPIC[:20].replace(\" \", \"_\")\n",
        "topic = slugify(TOPIC[:-5])\n",
        "docx_path = f\"{topic}.docx\"\n",
        "\n",
        "print(docx_path)"
      ],
      "metadata": {
        "id": "a76qNIRHs_gS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4800bcc-82d8-4c88-af46-7d6c9e097539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stopping-the-war-in-the-middle-east-activating-unactivated-iranian-people-and-protecting-light-triad-personality-g.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install googletrans==4.0.0-rc1\n",
        "\n",
        "!pip install httpcore==0.15.0 httpx pymongo googletrans\n",
        "!pip install httpx==0.24.1"
      ],
      "metadata": {
        "id": "qQOCu3GyEFf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77cd28c0-e26f-4334-a81f-df12462f517d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: httpcore==0.15.0 in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (0.24.1)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.6.0)\n",
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (0.12.0)\n",
            "Requirement already satisfied: sniffio==1.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (1.3.0)\n",
            "Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (2023.7.22)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore==0.15.0) (3.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore==0.15.0) (1.1.3)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from googletrans) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->googletrans) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->googletrans) (2.0.7)\n",
            "Requirement already satisfied: httpx==0.24.1 in /usr/local/lib/python3.10/dist-packages (0.24.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (2023.7.22)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (0.15.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (1.3.0)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.1) (0.12.0)\n",
            "Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.1) (3.7.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore<0.18.0,>=0.15.0->httpx==0.24.1) (1.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#I have tried to update the prompt by ChatGPT itself ðŸ‘‡ðŸ‘‡"
      ],
      "metadata": {
        "id": "wxqM4h1fw4fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_main_variables(prompts, variable):\n",
        "   main_variables= main_variables_0\n",
        "   for prompt in prompts:\n",
        "       variables = re.findall(r'\\{(\\w+)\\}', prompt)\n",
        "       for var in variables:\n",
        "           if var == 'TOPIC':\n",
        "               main_variables[var] = variable\n",
        "           else:\n",
        "               main_variables[var] = None\n",
        "\n",
        "   return main_variables"
      ],
      "metadata": {
        "id": "Jd711_MyBgje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_main_variables(prompts, variable_para, var_content):\n",
        "    main_variables = main_variables_0\n",
        "\n",
        "    new_prompt = prompts[:]  # Create a deep copy of prompts\n",
        "\n",
        "    for i, prompt in enumerate(prompts):\n",
        "        for var in variable_para:\n",
        "            if var == variable_para :\n",
        "                main_variables[var] = var_content\n",
        "                new_prompt[i] = prompt.replace(var, var_content)\n",
        "        for var, value in main_variables.items():\n",
        "             if var == variable_para:\n",
        "                main_variables[var] = var_content\n",
        "                new_prompt[i] = new_prompt[i].replace('{'+var+'}', \"{\"+f\"{var}\"+'}'+f\" which is :{var_content}\")#f\"{{{variable}}}\")\n",
        "\n",
        "\n",
        "    return main_variables, new_prompt\n",
        "#TOPIC='my test topic'\n",
        "main_variables, prompt_new = extract_main_variables(prompts, 'TOPIC', TOPIC)\n",
        "print (\" topic is :\", TOPIC)\n",
        "print(\"main variable is :\", main_variables)\n",
        "print(\"new_prompt is :\", prompt_new)\n",
        "prompts= prompt_new\n",
        "print(\"prompt is :\", prompts)"
      ],
      "metadata": {
        "id": "VLFUpVSA2Pbr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcb5c26a-cc04-45a5-a671-11a64da63afb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " topic is : stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups\n",
            "main variable is : {'TOPIC': 'stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups'}\n",
            "new_prompt is : ['What are the key aspects of Psychological symptoms detection for Iranian men in their 40s studying for a PHD degree that need to be addressed?', 'Create a mind map of the main elements of Psychological symptoms detection for Iranian men in their 40s studying for a PHD degree and how they are interconnected.', 'Write down ideas on sticky notes about how to improve Psychological symptoms detection for Iranian men in their 40s studying for a PHD degree. Then, group these ideas based on common themes.', 'Take turns sharing ideas on how to improve Psychological symptoms detection for Iranian men in their 40s studying for a PHD degree. Make sure everyone has a chance to contribute.', 'Think of ways to create the problem in Psychological symptoms detection for Iranian men in their 40s studying for a PHD degree. This will help you understand how to solve it.', 'Apply the SCAMPER method to existing solutions or situations in Psychological symptoms detection for Iranian men in their 40s studying for a PHD degree. This will spark new ideas.', 'Assemble a diverse group of people from various backgrounds and disciplines to tackle Psychological symptoms detection for Iranian men in their 40s studying for a PHD degree. This will ensure a more rounded and innovative solution.', 'Envision a future state where Psychological symptoms detection for Iranian men in their 40s studying for a PHD degree has been solved successfully. Starting from this endpoint, work backward to identify the series of events and decisions that led to that future.']\n",
            "prompt is : ['What are the key aspects of Psychological symptoms detection for Iranian men in their 40s studying for a PHD degree that need to be addressed?', 'Create a mind map of the main elements of Psychological symptoms detection for Iranian men in their 40s studying for a PHD degree and how they are interconnected.', 'Write down ideas on sticky notes about how to improve Psychological symptoms detection for Iranian men in their 40s studying for a PHD degree. Then, group these ideas based on common themes.', 'Take turns sharing ideas on how to improve Psychological symptoms detection for Iranian men in their 40s studying for a PHD degree. Make sure everyone has a chance to contribute.', 'Think of ways to create the problem in Psychological symptoms detection for Iranian men in their 40s studying for a PHD degree. This will help you understand how to solve it.', 'Apply the SCAMPER method to existing solutions or situations in Psychological symptoms detection for Iranian men in their 40s studying for a PHD degree. This will spark new ideas.', 'Assemble a diverse group of people from various backgrounds and disciplines to tackle Psychological symptoms detection for Iranian men in their 40s studying for a PHD degree. This will ensure a more rounded and innovative solution.', 'Envision a future state where Psychological symptoms detection for Iranian men in their 40s studying for a PHD degree has been solved successfully. Starting from this endpoint, work backward to identify the series of events and decisions that led to that future.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "\n",
        "def generate_prompt_from_response(previous_response, main_variables):\n",
        "   # Customize this logic based on your needs\n",
        "   # For simplicity, let's use the last 50 characters of the response as the new prompt\n",
        "   new_prompt = previous_response[-50:]\n",
        "\n",
        "   # Replace the main variables in the new prompt\n",
        "   for var, value in main_variables.items():\n",
        "       if value is not None:\n",
        "           new_prompt = new_prompt.replace(value, f\"{{{var}}}\")\n",
        "\n",
        "   return new_prompt\n",
        "\n",
        "# Example usage\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\"\n",
        "\n",
        "prompts_1 = [\n",
        "f\"Find a research topic for a PhD in the area of '{TOPIC}'\",\n",
        "\n",
        "]\n",
        "#prompts_2 = [\n",
        "#   \"I need to find information on renewable energy for a research paper that will be 1,500 words and must include eight sources.\",\n",
        "#   \"The research paper should cover the latest advancements in renewable energy technology.\"\n",
        "#]\n",
        "\n",
        "#main_variables,prompt_new = extract_main_variables(prompts,'TOPIC',TOPIC)\n",
        "#print(main_variables)\n",
        "\n",
        "#previous_response = \"Previous GPT response\"\n",
        "#new_prompt = generate_prompt_from_response(previous_response, main_variables)\n",
        "#print(new_prompt)\n",
        "#print ( prompts)"
      ],
      "metadata": {
        "id": "NYegFb6aq_h8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Updating the prompt by ChatGPT:ðŸ‘‡ðŸ‘‡"
      ],
      "metadata": {
        "id": "UgzzXkG9wjbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.get_encoding(encoding_name)\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "num_tokens_from_string(\"tiktoken is great!\", \"cl100k_base\")"
      ],
      "metadata": {
        "id": "oJ1QCUr62rtw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73824f37-d724-4827-9789-bc42ac5daa9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt_update_0(prompt, previous_content, main_variables):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   # Replace the TOPIC variable in the prompt\n",
        "   for var, value in main_variables.items():\n",
        "       if var == 'TOPIC' and value is not None:\n",
        "           prompt = prompt.replace(f\"{{{var}}}\", value)\n",
        "\n",
        "   # Construct the instruction for updating the prompt\n",
        "   instruction = f\"Given the previous content:\\n\\n{previous_content}\\n\\nUpdate the prompt: {prompt}\"\n",
        "\n",
        "   # Create the completion with the instruction\n",
        "   completion = client.completions.create(\n",
        "       model=model_engine,\n",
        "       prompt=instruction,\n",
        "       max_tokens=max_tokens,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "\n",
        "   # Extract and return the updated prompt from the response\n",
        "   updated_prompt = completion.choices[0].text.strip()\n",
        "   return updated_prompt"
      ],
      "metadata": {
        "id": "QbOCQqCDB8xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "def generate_prompt_update_a1(prompt_my):\n",
        "  model_engine = \"text-davinci-003\"\n",
        "  max_tokens = 2048\n",
        "\n",
        "  completion = client.completions.create(\n",
        "      model=\"gpt-3.5-turbo-instruct\",\n",
        "      #model=\"curie\"\n",
        "      prompt=prompt_my,\n",
        "      max_tokens=2048,\n",
        "      temperature=0.3,\n",
        "      n=1,\n",
        "      frequency_penalty=0,\n",
        "  )\n",
        "  return completion"
      ],
      "metadata": {
        "id": "WPRw6qJOuaS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import openai\n",
        "from openai import RateLimitError\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   api_key = openai_api# \"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\",\n",
        ")\n",
        "def retry_with_exponential_backoff(\n",
        "   func,\n",
        "   initial_delay: float = 1,\n",
        "   exponential_base: float = 2,\n",
        "   jitter: bool = True,\n",
        "   max_retries: int = 10,\n",
        "   errors: tuple = (RateLimitError,),\n",
        "):\n",
        "   \"\"\"Retry a function with exponential backoff.\"\"\"\n",
        "   def wrapper(*args, **kwargs):\n",
        "       # Initialize variables\n",
        "       num_retries = 0\n",
        "       delay = initial_delay\n",
        "       # Loop until a successful response or max_retries is hit or an exception is raised\n",
        "       while True:\n",
        "           try:\n",
        "               return func(*args, **kwargs)\n",
        "           # Retry on specified errors\n",
        "           except errors as e:\n",
        "               # Increment retries\n",
        "               num_retries += 1\n",
        "               # Check if max retries has been reached\n",
        "               if num_retries > max_retries:\n",
        "                  raise Exception(\n",
        "                      f\"Maximum number of retries ({max_retries}) exceeded.\"\n",
        "                  )\n",
        "               # Increment the delay\n",
        "               delay *= exponential_base * (1 + jitter * random.random())\n",
        "               # Sleep for the delay\n",
        "               time.sleep(delay)\n",
        "           # Raise exceptions for any errors not specified\n",
        "           except Exception as e:\n",
        "               raise e\n",
        "   return wrapper\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "\n",
        "@retry_with_exponential_backoff\n",
        "def generate_prompt_update(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "   print(f\"{num_tokens_from_string(prompt_my,model)} prompt tokens counted by num_tokens_from_messages().\")\n",
        "\n",
        "   completion = client.completions.create(\n",
        "     model=\"gpt-3.5-turbo-instruct\",\n",
        "     prompt=prompt_my,\n",
        "     max_tokens=500,\n",
        "     temperature=0.1,\n",
        "     n=1,\n",
        "     frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "\n",
        "@retry_with_exponential_backoff\n",
        "def generate_academic_paper(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "   print(f\"{num_tokens_from_string(prompt_my,model)} prompt tokens counted by num_tokens_from_messages().\")\n",
        "\n",
        "\n",
        "   completion = client.completion.create(\n",
        "     #model=\"gpt-3.5-turbo-instruct\",\n",
        "     model=\"gpt-3.5-turbo-1106\",\n",
        "     prompt=prompt_my,\n",
        "     max_tokens=2048,\n",
        "     temperature=0.3,\n",
        "     n=1,\n",
        "     frequency_penalty=0,\n",
        "   )\n",
        "   return completion"
      ],
      "metadata": {
        "id": "O2TNMQ8eFl8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def generate_content(prompts, variables, TOPIC, perviuse_content=\"\"):\n",
        "  # Generate content for each variable\n",
        "  variable_contents = {}\n",
        "\n",
        "\n",
        "  main_variables = main_variables_0\n",
        "  for prompt in prompts:\n",
        "      for var in variables:\n",
        "          if var in prompt:\n",
        "              print(f\"\\n---prompt is ----\\n{prompt}\")\n",
        "              #prompt_my = f\"Generate content for the variable '{var}' in the context of the topic '{TOPIC}'. Please consider the result must be in less than 10 words. The prompt is '{prompt}'. Also the more information for understanding better content is '{perviuse_content}'\"\n",
        "\n",
        "              prompt_my = f\"Generate content for the variable '{var}' in the context of the topic '{TOPIC}'. Please consider the result must be sumerized and as variable for chatgpt academic phd writer assistance. The prompt is '{prompt}'. Also the more information for understanding better content is '{perviuse_content}'\"\n",
        "              content = generate_prompt_update_a1(prompt_my)\n",
        "              for choice in content.choices:\n",
        "                print(\"\\n Result is :\"+choice.text)\n",
        "                variable_contents[var] = choice.text\n",
        "              print(f\"variable_contents[{var}] is: {variable_contents[var]}\")\n",
        "\n",
        "              time.sleep(random.randint(22, 40))\n",
        "\n",
        "  # Replace the variables in the prompts with the generated content\n",
        "  prompt_new = []\n",
        "  for prompt in prompts:\n",
        "      for var, content in variable_contents.items():\n",
        "          prompt = prompt.replace(f\"{{{var}}}\", variable_contents[var])\n",
        "      prompt_new.append(prompt)\n",
        "      print(\"\\n --- Updated prompt is :\\n\"+str(prompt_new))\n",
        "  return prompt_new\n",
        "\n",
        "# Define main variables\n",
        "#TOPIC = \"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"\n",
        "\n",
        "# List of variables\n",
        "variables = [\"RESEARCH_DOMAIN\", \"PARAGRAPH\", \"PARAGRAPHS\", \"TOPIC_SENTENCE\", \"LANGUAGE\", \"ABSTRACT_PARAGRAPH\", \"BIBLIOGRAPHY\", \"THEORY1\", \"THEORY2\", \"RESEARCH_QUESTIONS\", \"ACTION\", \"RESULT_PARAGRAPHS\", \"DATE\", \"NUMBER_OF_DAYS_MONTHS_YEARS\"]\n",
        "\n",
        "# List of prompts\n",
        "#prompts = [\"prompt1\", \"prompt2\", \"prompt3\"] # replace with your actual prompts\n",
        "#perviuse_content= \"test\"\n",
        "# Call the function and store the returned prompts\n",
        "#updated_prompts = generate_content(prompts, variables, TOPIC, perviuse_content)\n",
        "#print(\"Updated Prompts:\", updated_prompts)"
      ],
      "metadata": {
        "id": "uI21enmkhb0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def generate_content_2(prompts, variables, TOPIC, perviuse_content=\"\"):\n",
        "  # Generate content for each variable\n",
        "  variable_contents = {}\n",
        "  main_variables = main_variables_0\n",
        "  for prompt in prompts:\n",
        "      for var in variables:\n",
        "          if var in prompt:\n",
        "              print(f\"\\n---prompt is ----\\n{prompt}\")\n",
        "              prompt_my = f\"Generate content for the variable '{var}' in the context of the topic '{TOPIC}'. Please consider the result must be in less than 10 words. The prompt is '{prompt}'. Also the more information for understanding better content is '{perviuse_content}'\"\n",
        "              content = generate_prompt_update_a1(prompt_my)\n",
        "              for choice in content.choices:\n",
        "                print(\"\\n Result is :\"+choice.text)\n",
        "                variable_contents[var] = choice.text\n",
        "              print(f\"variable_contents[{var}] is: {variable_contents[var]}\")\n",
        "\n",
        "              time.sleep(random.randint(22, 40))\n",
        "\n",
        "  main_variables, prompt_new = extract_main_variables(prompts, var, variable_contents[var])\n",
        "\n",
        "  print(\"main variable is :\", main_variables)\n",
        "  print(\"new_prompt is :\", prompt_new)\n",
        "  prompts= prompt_new\n",
        "\n",
        "  # Replace the variables in the prompts with the generated content\n",
        "  prompt_new = []\n",
        "  for prompt in prompts:\n",
        "      for var, content in variable_contents.items():\n",
        "          prompt = prompt.replace(f\"{{{var}}}\", variable_contents[var])\n",
        "      prompt_new.append(prompt)\n",
        "      print(\"\\n --- Updated prompt is :\\n\"+str(prompt_new))\n",
        "  return prompt_new,main_variables\n",
        "\n",
        "# Define main variables\n",
        "#TOPIC = \"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"\n",
        "\n",
        "# List of variables\n",
        "variables = [\"RESEARCH_DOMAIN\", \"PARAGRAPH\", \"PARAGRAPHS\", \"TOPIC_SENTENCE\", \"LANGUAGE\", \"ABSTRACT_PARAGRAPH\", \"BIBLIOGRAPHY\", \"THEORY1\", \"THEORY2\", \"RESEARCH_QUESTIONS\", \"ACTION\", \"RESULT_PARAGRAPHS\", \"DATE\", \"NUMBER_OF_DAYS_MONTHS_YEARS\"]\n",
        "\n",
        "# List of prompts\n",
        "#prompts = [\"prompt1\", \"prompt2\", \"prompt3\"] # replace with your actual prompts\n",
        "#perviuse_content= \"test\"\n",
        "# Call the function and store the returned prompts\n",
        "#updated_prompts = generate_content(prompts, variables, TOPIC, perviuse_content)\n",
        "#print(\"Updated Prompts:\", updated_prompts)"
      ],
      "metadata": {
        "id": "-tAXnnAOkagH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\" #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\"\n",
        "\n",
        "\n",
        "#topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "#client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   #api_key = \"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\",\n",
        "#)\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "# Create a Translator object\n",
        "translator = Translator()\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "def generate_academic_paper_a0(prompt_my):\n",
        "  model_engine = \"text-davinci-003\"\n",
        "  max_tokens = 2048\n",
        "\n",
        "  completion = client.completions.create(\n",
        "      model=\"gpt-3.5-turbo-instruct\",\n",
        "      prompt=prompt_my,\n",
        "      max_tokens=2048,\n",
        "      temperature=0.3,\n",
        "      n=1,\n",
        "      frequency_penalty=0,\n",
        "  )\n",
        "  return completion"
      ],
      "metadata": {
        "id": "44bkCJOHtmuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time,random\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   api_key = openai_api#\"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\",\n",
        ")\n",
        "\n",
        "def generate_papers(prompts, perviuse_content, perviuse_try_numner):\n",
        "  choice_text_all=[]\n",
        "\n",
        "  for i in range(perviuse_try_numner, len(prompts), 20):\n",
        "     # Slice the prompts list to get the next 20 prompts\n",
        "     print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "\n",
        "     batch = prompts[i:i+20]\n",
        "     print(\"batch is \",batch)\n",
        "\n",
        "     for prompt in batch:\n",
        "\n",
        "         # Print the prompt\n",
        "         print(\"prompt is \",list({prompt}))\n",
        "\n",
        "         updated_prompts = generate_content(list({prompt}), variables, TOPIC, perviuse_content)\n",
        "         print(\"Updated Prompts:\", updated_prompts)\n",
        "\n",
        "         time.sleep(random.randint(22, 40))\n",
        "         response = generate_academic_paper_a0(updated_prompts)\n",
        "         print(\"\\nGenerated Academic Paper:\")\n",
        "         print(\"========================\\n\")\n",
        "         for choice in response.choices:\n",
        "           print(choice.text)\n",
        "           choice_in_loop = choice.text\n",
        "           choice_text_all.append(choice.text)\n",
        "\n",
        "\n",
        "         #save_academic_paper(topic,'\\n--------**\\n'+updated_prompts+'/n-------**\\n'+choice.text)\n",
        "         save_academic_paper_with_prompt(TOPIC[:20],'\\n**<<<  ChatGPT Prompt is:\\n'+''.join(updated_prompts)+'\\n>>>**\\n',choice.text)\n",
        "\n",
        "         save_academic_paper_with_prompt_megazn(TOPIC[:20],'\\n**<<<  ChatGPT Prompt is:\\n'+''.join(updated_prompts)+'\\n>>>**\\n',choice.text)\n",
        "         #save_academic_paper_with_prompt_megazn(TOPIC[:20],'\\n**<<<  ChatGPT Prompt is:\\n'+''.join(updated_prompts)+'\\n>>>**\\n',choice.text, 'google_drive')\n",
        "         if hasattr(choice, 'choices'):\n",
        "             extract_text(choice)\n",
        "\n",
        "         perviuse_content = choice_in_loop\n",
        "         print(\"\\n end of loop\")\n",
        "         print(\"========================\\n\")\n",
        "\n",
        "         time.sleep(random.randint(22, 40))\n",
        "         perviuse_try_numner = perviuse_try_numner+1\n",
        "  return choice_text_all,perviuse_try_numner\n",
        "\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\" #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\""
      ],
      "metadata": {
        "id": "JHIX17GHsecy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the sound by OpenAI: ðŸ‘‡ðŸ‘‡\n",
        "\n",
        "https://platform.openai.com/docs/guides/text-to-speech"
      ],
      "metadata": {
        "id": "2ctHZTF6wj0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!mkdir \"/content/ChatGPT_academic_paper\"\n",
        "from openai import OpenAI\n",
        "from django.utils.text import slugify\n",
        "\n",
        "client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   api_key = openai_api#\"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\",\n",
        ")\n",
        "\n",
        "response = client.audio.speech.create(\n",
        "    model=\"tts-1\",\n",
        "    voice=\"alloy\",\n",
        "    input=TOPIC#\"Hello world! This is a streaming test.\",\n",
        ")\n",
        "topic = slugify(TOPIC)\n",
        "\n",
        "response.stream_to_file(\"/content/ChatGPT_academic_paper/\"+topic+\".mp3\")#\"/content/drive/MyDrive/ChatGPT_Paper_wrting/\"+\"output.mp3\")"
      ],
      "metadata": {
        "id": "d2YvDx5DwS7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c619b640-6b83-44a9-9245-94859c6b5a88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory â€˜/content/ChatGPT_academic_paperâ€™: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xHPMNDjfToIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from django.utils.text import slugify\n",
        "\n",
        "\n",
        "\n",
        "def main_generate_papers(TOPIC, prompts, perviuse_content, perviuse_try_numner):\n",
        "    if not perviuse_try_numner:\n",
        "        perviuse_try_numner = 0\n",
        "        perviuse_content = ['fist step']\n",
        "\n",
        "    elif (perviuse_try_numner == len(prompts)):\n",
        "        perviuse_try_numner = 0\n",
        "        perviuse_content = ['fist step']\n",
        "\n",
        "    generate_papers(prompts, perviuse_content, perviuse_try_numner)\n",
        "\n",
        "    return perviuse_content, perviuse_try_numner\n",
        "\n",
        "topic = TOPIC_CLASS()\n",
        "\n",
        "if not topic.perviuse_try_numner:\n",
        "    topic.perviuse_try_numner = 0\n",
        "    topic.perviuse_content = ['fist step']\n",
        "\n",
        "elif (topic.perviuse_try_numner == len(prompts)):\n",
        "    topic.perviuse_try_numner = 0\n",
        "    topic.perviuse_content = ['fist step']\n",
        "\n",
        "topic.topic = main_variables_0.get('TOPIC','Default Value')\n",
        "print (\"Topic is: \", TOPIC)\n",
        "main_generate_papers(topic.topic, prompts, topic.perviuse_content, topic.perviuse_try_numner)"
      ],
      "metadata": {
        "id": "-YbWDEd4WzDq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "520beff3-9f6b-4c37-b27e-eb7c6ad1217d"
      },
      "execution_count": 117,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topic is:  stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups\n",
            "I is  0  Len of prompt Is: 10\n",
            "batch is  ['What are the key aspects of stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups that need to be addressed in the field of political science?', 'Create a mind map of the main elements of stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups and how they are interconnected in the field of political science.', 'Write down ideas on sticky notes about how to improve stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. Then, group these ideas based on common themes.', 'Take turns sharing ideas on how to improve stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. Make sure everyone has a chance to contribute.', 'Think of ways to create the problem in stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. This will help you understand how to solve it.', 'Apply the SCAMPER method to existing solutions or situations in stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. This will spark new ideas.', 'Assemble a diverse group of people from various backgrounds and disciplines to tackle stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. This will ensure a more rounded and innovative solution.', 'Envision a future state where stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science has been solved successfully. Starting from this endpoint, work backward to identify the series of events and decisions that led to that future.', \"Let's go through a Four-Step Innovation Process to develop a new approach for stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. Start with identifying the correct problem.\", \"I'd like to use Synectics to generate innovative solutions for stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. Can you help me draw some analogies?\"]\n",
            "prompt is  ['What are the key aspects of stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups that need to be addressed in the field of political science?']\n",
            "\n",
            " --- Updated prompt is :\n",
            "['What are the key aspects of stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups that need to be addressed in the field of political science?']\n",
            "Updated Prompts: ['What are the key aspects of stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups that need to be addressed in the field of political science?']\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "1. Diplomatic Efforts: One of the key aspects of stopping the war in the Middle East is to engage in diplomatic efforts. This involves negotiations and dialogue between the conflicting parties to find a peaceful resolution to the conflict. Political scientists can study the historical and cultural factors that have led to the conflict and use this knowledge to facilitate effective diplomatic efforts.\n",
            "\n",
            "2. International Cooperation: The involvement of other countries and international organizations is crucial in stopping the war in the Middle East. Political scientists can analyze the role of different actors, such as the United Nations, regional powers, and global superpowers, in the conflict and suggest ways to enhance cooperation among them.\n",
            "\n",
            "3. Addressing Root Causes: To achieve lasting peace in the Middle East, it is essential to address the root causes of the conflict. This includes issues such as territorial disputes, religious differences, and economic disparities. Political scientists can conduct research and provide insights on how to address these underlying issues effectively.\n",
            "\n",
            "4. Public Opinion: The support of the general public is crucial in stopping the war in the Middle East. Political scientists can study the attitudes and beliefs of the people in the region and suggest ways to mobilize public support for peace efforts. This can include promoting interfaith dialogue, promoting cultural understanding, and countering extremist ideologies.\n",
            "\n",
            "5. Activating Unactivated Iranian People: In order to bring about change in Iran, it is important to engage and activate the unactivated Iranian people. Political scientists can study the political and social dynamics in Iran and suggest strategies to empower and mobilize the Iranian people to demand change and participate in the peace process.\n",
            "\n",
            "6. Protecting Light-Triad Personality Groups: Light-triad personality groups, which include individuals who possess traits of empathy, compassion, and altruism, are often targeted and persecuted in times of conflict. Political scientists can research ways to protect these groups and promote their involvement in peacebuilding efforts.\n",
            "\n",
            "7. Conflict Resolution Strategies: Political scientists can also study and develop conflict resolution strategies that are specific to the Middle East region. This can include analyzing successful peace processes in other parts of the world and adapting them to the unique dynamics of the Middle East.\n",
            "\n",
            "8. Humanitarian Aid: The ongoing war in the Middle East has resulted in a humanitarian crisis, with millions of people displaced and in need of aid. Political scientists can study the impact of the conflict on the civilian population and suggest ways to provide humanitarian aid and support to those affected.\n",
            "\n",
            "9. Reconciliation and Healing: In addition to stopping the war, it is important to promote reconciliation and healing among the conflicting parties. Political scientists can research and recommend ways to promote forgiveness, reconciliation, and healing in the aftermath of the conflict.\n",
            "\n",
            "10. Sustainable Peacebuilding: Finally, political scientists can play a crucial role in promoting sustainable peacebuilding in the Middle East. This involves developing long-term strategies to prevent the reoccurrence of conflict and promote stability and prosperity in the region. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  ['Create a mind map of the main elements of stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups and how they are interconnected in the field of political science.']\n",
            "\n",
            " --- Updated prompt is :\n",
            "['Create a mind map of the main elements of stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups and how they are interconnected in the field of political science.']\n",
            "Updated Prompts: ['Create a mind map of the main elements of stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups and how they are interconnected in the field of political science.']\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "Main Elements:\n",
            "1. Stopping the War in the Middle East\n",
            "2. Activating Unactivated Iranian People\n",
            "3. Protecting Light-Triad Personality Groups\n",
            "\n",
            "Interconnections:\n",
            "1. Diplomacy and Negotiations:\n",
            "- Diplomatic efforts to end the war in the Middle East can involve engaging with all parties involved, including Iran and other regional powers.\n",
            "- Negotiations can also be used to address the grievances of unactivated Iranian people and to protect the rights of light-triad personality groups.\n",
            "\n",
            "2. International Organizations:\n",
            "- The United Nations and other international organizations can play a role in facilitating peace talks and promoting human rights in the region.\n",
            "- These organizations can also provide aid and support to unactivated Iranian people and light-triad personality groups affected by the war.\n",
            "\n",
            "3. Political Leadership:\n",
            "- Effective political leadership is crucial in resolving conflicts and promoting peace in the Middle East.\n",
            "- Leaders can also work towards empowering and activating unactivated Iranian people and protecting the rights of light-triad personality groups.\n",
            "\n",
            "4. Public Opinion:\n",
            "- Public opinion can influence political decisions and actions towards ending the war in the Middle East.\n",
            "- It can also play a role in raising awareness and support for the rights of unactivated Iranian people and light-triad personality groups.\n",
            "\n",
            "5. Human Rights:\n",
            "- Protecting human rights is essential in promoting peace and stability in the Middle East.\n",
            "- This includes ensuring the rights of unactivated Iranian people and light-triad personality groups are respected and upheld.\n",
            "\n",
            "6. Cultural Understanding:\n",
            "- Building cultural understanding and promoting intercultural dialogue can help bridge divides and promote peace in the region.\n",
            "- This can also aid in activating unactivated Iranian people and protecting the rights of light-triad personality groups who may face discrimination based on their cultural or religious beliefs.\n",
            "\n",
            "7. Economic Factors:\n",
            "- Economic stability and development can contribute to a more peaceful and stable Middle East.\n",
            "- This can also help in activating unactivated Iranian people and providing opportunities for light-triad personality groups to thrive.\n",
            "\n",
            "8. Security:\n",
            "- Ensuring security and stability in the region is crucial for ending the war and protecting vulnerable groups.\n",
            "- This can involve addressing security concerns of all parties involved and promoting a sense of safety for unactivated Iranian people and light-triad personality groups.\n",
            "\n",
            "9. Education:\n",
            "- Education can play a role in promoting peace and understanding in the Middle East.\n",
            "- This can also help in activating unactivated Iranian people and promoting the rights and values of light-triad personality groups.\n",
            "\n",
            "10. Media:\n",
            "- The media can influence public opinion and shape perceptions of the war in the Middle East.\n",
            "- Responsible and unbiased reporting can help in promoting peace and understanding, as well as raising awareness about the rights of unactivated Iranian people and light-triad personality groups.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  ['Write down ideas on sticky notes about how to improve stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. Then, group these ideas based on common themes.']\n",
            "\n",
            " --- Updated prompt is :\n",
            "['Write down ideas on sticky notes about how to improve stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. Then, group these ideas based on common themes.']\n",
            "Updated Prompts: ['Write down ideas on sticky notes about how to improve stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. Then, group these ideas based on common themes.']\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "1. Increase diplomatic efforts and negotiations between conflicting parties\n",
            "2. Implement economic sanctions on countries supporting the war\n",
            "3. Increase humanitarian aid and support for refugees\n",
            "4. Encourage and support grassroots peace movements\n",
            "5. Utilize international organizations such as the United Nations for mediation\n",
            "6. Promote cultural exchange and understanding between different groups\n",
            "7. Address underlying issues such as poverty, inequality, and political instability\n",
            "8. Increase media coverage and awareness of the situation\n",
            "9. Involve neutral third-party countries in peace talks\n",
            "10. Implement stricter arms control and disarmament measures\n",
            "11. Support and empower moderate voices in the region\n",
            "12. Increase education and access to information for unactivated Iranian people\n",
            "13. Utilize social media and technology to connect and mobilize unactivated Iranians\n",
            "14. Provide resources and platforms for unactivated Iranians to voice their opinions and concerns\n",
            "15. Protect and support light-triad personality groups through legislation and policies\n",
            "16. Increase representation of light-triad personalities in political decision-making processes\n",
            "17. Implement diversity and inclusion training for political leaders and officials\n",
            "18. Create safe spaces for light-triad personalities to express their views without fear of persecution\n",
            "19. Increase awareness and education about the importance of diversity and inclusion in politics\n",
            "20. Encourage and support the formation of alliances and coalitions among light-triad personality groups.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  ['Take turns sharing ideas on how to improve stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. Make sure everyone has a chance to contribute.']\n",
            "\n",
            " --- Updated prompt is :\n",
            "['Take turns sharing ideas on how to improve stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. Make sure everyone has a chance to contribute.']\n",
            "Updated Prompts: ['Take turns sharing ideas on how to improve stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. Make sure everyone has a chance to contribute.']\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "1. Increase diplomatic efforts: One way to improve stopping the war in the Middle East is to increase diplomatic efforts between the countries involved. This could involve setting up peace talks, mediation, and negotiations to find a peaceful resolution.\n",
            "\n",
            "2. Promote cultural understanding: Another idea is to promote cultural understanding between different groups in the Middle East. This could involve educational programs, cultural exchanges, and initiatives that bring people from different backgrounds together.\n",
            "\n",
            "3. Address underlying issues: It's important to address the underlying issues that are fueling the conflict in the Middle East. This could include addressing economic disparities, political grievances, and religious tensions.\n",
            "\n",
            "4. Utilize social media: Social media can be a powerful tool in activating unactivated Iranian people. By sharing information, news, and personal stories, we can help raise awareness and mobilize people to take action for peace.\n",
            "\n",
            "5. Support grassroots organizations: There are many grassroots organizations in the Middle East that are working towards peace and promoting human rights. Supporting these organizations can help amplify their voices and efforts.\n",
            "\n",
            "6. Engage in dialogue: It's important to engage in open and respectful dialogue with people from different backgrounds and perspectives. This can help bridge divides and promote understanding.\n",
            "\n",
            "7. Advocate for non-violent solutions: As political scientists, we can use our knowledge and expertise to advocate for non-violent solutions to conflicts. This could involve promoting peacebuilding strategies and highlighting the negative impacts of war.\n",
            "\n",
            "8. Provide humanitarian aid: In times of conflict, it's crucial to provide humanitarian aid to those affected by the violence. This can help alleviate suffering and build goodwill between different groups.\n",
            "\n",
            "9. Encourage government involvement: Governments have a crucial role to play in stopping the war in the Middle East. As citizens, we can use our voices to urge our governments to take action for peace.\n",
            "\n",
            "10. Educate ourselves and others: Finally, it's important to educate ourselves and others about the complexities of the conflict in the Middle East. By understanding the root causes and dynamics of the conflict, we can better work towards finding solutions.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  ['Think of ways to create the problem in stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. This will help you understand how to solve it.']\n",
            "\n",
            " --- Updated prompt is :\n",
            "['Think of ways to create the problem in stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. This will help you understand how to solve it.']\n",
            "Updated Prompts: ['Think of ways to create the problem in stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. This will help you understand how to solve it.']\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "1. Lack of International Cooperation: One of the main challenges in stopping the war in the Middle East is the lack of cooperation among key international players. Countries like the United States, Russia, and Iran have conflicting interests and agendas, making it difficult to reach a consensus on how to end the war. This creates a problem as any solution proposed by one party may not be accepted by the others, leading to a stalemate.\n",
            "\n",
            "Solution: To address this problem, it is important to engage in diplomatic efforts and negotiations to bring all parties to the table. This could involve the use of international organizations such as the United Nations to facilitate dialogue and find common ground among the conflicting parties.\n",
            "\n",
            "2. Political Instability in Iran: The Iranian government has been known to suppress dissent and limit the political participation of its citizens. This has led to a large portion of the population feeling disenfranchised and unactivated, making it difficult to mobilize them for any cause, including stopping the war.\n",
            "\n",
            "Solution: To activate unactivated Iranian people, it is crucial to promote democracy and human rights in Iran. This could involve supporting civil society organizations and promoting freedom of speech and assembly. Additionally, engaging with moderate political leaders and empowering them to advocate for peace and stability in the region could also help in activating the Iranian population.\n",
            "\n",
            "3. Extremist Groups: The Middle East is home to various extremist groups, such as ISIS and Al-Qaeda, who thrive in the chaos and instability of the region. These groups not only perpetuate the war but also pose a threat to the safety and security of light-triad personality groups, such as women and religious minorities.\n",
            "\n",
            "Solution: To protect these vulnerable groups, it is essential to address the root causes of extremism, such as poverty, lack of education, and political grievances. This could involve providing economic opportunities and promoting education in conflict-affected areas. Additionally, targeted efforts to counter extremist propaganda and ideologies could also help in protecting light-triad personality groups.\n",
            "\n",
            "4. Lack of Political Will: Despite the devastating impact of the war in the Middle East, there is a lack of political will among key players to take decisive action to end it. This could be due to various factors, such as vested interests, domestic political considerations, and fear of backlash.\n",
            "\n",
            "Solution: To overcome this challenge, it is crucial to build a strong public and international pressure for peace. This could involve media campaigns, public demonstrations, and advocacy efforts to raise awareness about the humanitarian crisis in the region and the urgent need for a peaceful resolution. Additionally, holding political leaders accountable for their actions and promoting a culture of peace and dialogue could also help in creating the necessary political will to end the war.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  ['Apply the SCAMPER method to existing solutions or situations in stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. This will spark new ideas.']\n",
            "\n",
            " --- Updated prompt is :\n",
            "['Apply the SCAMPER method to existing solutions or situations in stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. This will spark new ideas.']\n",
            "Updated Prompts: ['Apply the SCAMPER method to existing solutions or situations in stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. This will spark new ideas.']\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "S - Substitute:\n",
            "- Instead of relying on military intervention, substitute with diplomatic negotiations and peace talks to stop the war in the Middle East.\n",
            "- Instead of using force, substitute with education and awareness campaigns to activate unactivated Iranian people.\n",
            "- Instead of solely focusing on protecting light-triad personality groups, substitute with promoting tolerance and understanding among all political groups.\n",
            "\n",
            "C - Combine:\n",
            "- Combine efforts from multiple countries and organizations to create a unified approach in stopping the war in the Middle East.\n",
            "- Combine traditional and modern methods of communication to reach and activate unactivated Iranian people.\n",
            "- Combine protection measures with empowerment programs for light-triad personality groups to create a stronger and more resilient community.\n",
            "\n",
            "A - Adapt:\n",
            "- Adapt strategies and tactics based on cultural and historical context in the Middle East to effectively stop the war.\n",
            "- Adapt messaging and communication styles to resonate with the values and beliefs of unactivated Iranian people.\n",
            "- Adapt protection measures to fit the specific needs and challenges faced by light-triad personality groups in the political arena.\n",
            "\n",
            "M - Modify:\n",
            "- Modify foreign policies and approaches towards the Middle East to address underlying issues and root causes of the war.\n",
            "- Modify traditional methods of activism to engage and activate unactivated Iranian people, such as using social media and technology.\n",
            "- Modify protection measures to be more proactive and preventative, rather than reactive.\n",
            "\n",
            "P - Put to another use:\n",
            "- Put resources and funds towards rebuilding and developing war-torn areas in the Middle East, rather than solely focusing on military efforts.\n",
            "- Put the energy and passion of unactivated Iranian people towards positive and constructive actions, such as community building and advocacy.\n",
            "- Put the skills and abilities of light-triad personality groups towards promoting peace and conflict resolution in the political sphere.\n",
            "\n",
            "E - Eliminate:\n",
            "- Eliminate biased and one-sided narratives in media coverage of the war in the Middle East, and instead promote balanced and objective reporting.\n",
            "- Eliminate barriers and restrictions that prevent unactivated Iranian people from participating in political processes and decision-making.\n",
            "- Eliminate discrimination and prejudice against light-triad personality groups, and instead promote inclusivity and diversity in the political arena.\n",
            "\n",
            "R - Rearrange:\n",
            "- Rearrange priorities and focus on long-term solutions rather than short-term fixes in stopping the war in the Middle East.\n",
            "- Rearrange traditional power structures and involve unactivated Iranian people in decision-making processes.\n",
            "- Rearrange protection measures to be more comprehensive and address all forms of discrimination and violence against light-triad personality groups.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  ['Assemble a diverse group of people from various backgrounds and disciplines to tackle stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. This will ensure a more rounded and innovative solution.']\n",
            "\n",
            " --- Updated prompt is :\n",
            "['Assemble a diverse group of people from various backgrounds and disciplines to tackle stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. This will ensure a more rounded and innovative solution.']\n",
            "Updated Prompts: ['Assemble a diverse group of people from various backgrounds and disciplines to tackle stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. This will ensure a more rounded and innovative solution.']\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            " The group could include:\n",
            "\n",
            "1. Political scientists and experts in Middle Eastern politics: These individuals can provide a deep understanding of the political dynamics and history of the region, and offer insights on potential solutions for stopping the war.\n",
            "\n",
            "2. Diplomats and foreign policy experts: Their experience in international relations and negotiations can be valuable in finding diplomatic solutions to the conflict.\n",
            "\n",
            "3. Military strategists and experts: Their knowledge of military tactics and operations can help in devising a plan to end the war and protect light-triad personality groups.\n",
            "\n",
            "4. Human rights activists: Their perspectives on human rights violations in the region and their advocacy for peace and justice can bring a moral compass to the group's discussions.\n",
            "\n",
            "5. Religious leaders: As the conflict in the Middle East has deep religious roots, the input of religious leaders from different faiths can help in finding common ground and promoting peace.\n",
            "\n",
            "6. Psychologists and sociologists: These professionals can provide insights into the psychological and social factors driving the conflict and offer strategies for promoting peace and reconciliation.\n",
            "\n",
            "7. Economists: The economic impact of the war in the Middle East is significant, and economists can offer solutions for rebuilding and stabilizing the region.\n",
            "\n",
            "8. Journalists and media experts: Their understanding of media and communication can help in crafting effective messaging and strategies for reaching unactivated Iranian people.\n",
            "\n",
            "9. Refugees and individuals from conflict-affected communities: Their firsthand experiences can provide valuable insights and perspectives on the impact of the war and potential solutions.\n",
            "\n",
            "10. Politicians and government officials: Their knowledge of policy-making and decision-making processes can help in implementing any proposed solutions and advocating for change at the political level.\n",
            "\n",
            "By bringing together this diverse group of individuals, we can tap into a wide range of expertise, perspectives, and experiences to develop a comprehensive and effective plan for stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups. It is important to ensure that the group is inclusive and representative of different backgrounds and viewpoints to foster open and productive discussions.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  ['Envision a future state where stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science has been solved successfully. Starting from this endpoint, work backward to identify the series of events and decisions that led to that future.']\n",
            "\n",
            " --- Updated prompt is :\n",
            "['Envision a future state where stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science has been solved successfully. Starting from this endpoint, work backward to identify the series of events and decisions that led to that future.']\n",
            "Updated Prompts: ['Envision a future state where stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science has been solved successfully. Starting from this endpoint, work backward to identify the series of events and decisions that led to that future.']\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "1. Successful Negotiations: The first step towards stopping the war in the Middle East was successful negotiations between all parties involved. This was achieved through the use of skilled diplomats and mediators who were able to facilitate productive discussions and find common ground.\n",
            "\n",
            "2. International Support: The negotiations were supported by key international players, including the United Nations, who provided resources and assistance to ensure a peaceful resolution.\n",
            "\n",
            "3. Implementation of Agreements: Once agreements were reached, they were implemented and enforced by all parties involved. This included the withdrawal of troops, disarmament of militant groups, and the establishment of demilitarized zones.\n",
            "\n",
            "4. Rebuilding Efforts: With the war officially ended, efforts were made to rebuild the affected areas and provide aid to those who were displaced or affected by the conflict. This helped to stabilize the region and improve living conditions for the local population.\n",
            "\n",
            "5. Political Reforms: In order to prevent future conflicts, political reforms were implemented in the countries involved in the war. This included promoting democracy, protecting minority rights, and addressing underlying issues such as corruption and inequality.\n",
            "\n",
            "6. Activating Unactivated Iranian People: With the war over and political reforms in place, the Iranian people were able to fully participate in the political process and have their voices heard. This led to a more inclusive and representative government.\n",
            "\n",
            "7. Education and Empowerment: Efforts were made to educate and empower the Iranian people, particularly women and marginalized groups, in order to promote a more progressive and tolerant society.\n",
            "\n",
            "8. Protection of Light-Triad Personality Groups: As political reforms and education efforts took place, the protection of light-triad personality groups, such as human rights activists and journalists, became a priority. This was achieved through the implementation of laws and policies that safeguarded their rights and freedoms.\n",
            "\n",
            "9. International Cooperation: The success of these efforts was also aided by strong international cooperation and support. This included sharing resources, expertise, and technology to promote peace and stability in the region.\n",
            "\n",
            "10. Continued Efforts: The journey towards this future state was not easy and required ongoing efforts and commitment from all parties involved. This included continued dialogue, monitoring and addressing any potential issues, and promoting a culture of peace and understanding.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  [\"Let's go through a Four-Step Innovation Process to develop a new approach for stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. Start with identifying the correct problem.\"]\n",
            "\n",
            " --- Updated prompt is :\n",
            "[\"Let's go through a Four-Step Innovation Process to develop a new approach for stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. Start with identifying the correct problem.\"]\n",
            "Updated Prompts: [\"Let's go through a Four-Step Innovation Process to develop a new approach for stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. Start with identifying the correct problem.\"]\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "Step 1: Identify the Problem\n",
            "The first step in the innovation process is to clearly identify the problem that needs to be solved. In this case, the problem is three-fold: stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science.\n",
            "\n",
            "Step 2: Research and Gather Information\n",
            "The next step is to research and gather information about the problem. This could involve studying the history and current state of the war in the Middle East, understanding the cultural and political dynamics in Iran, and examining the challenges faced by light-triad personality groups in the field of political science.\n",
            "\n",
            "Step 3: Generate Ideas\n",
            "Once enough information has been gathered, the next step is to generate ideas for potential solutions. This could involve brainstorming, conducting surveys or interviews, and seeking input from experts in the field. Some potential ideas could include diplomatic negotiations, grassroots activism, and education and training programs for light-triad personality groups.\n",
            "\n",
            "Step 4: Develop and Implement a Solution\n",
            "The final step is to develop and implement a solution based on the ideas generated in the previous step. This could involve creating a comprehensive peace plan for the Middle East, organizing campaigns to engage and empower Iranian citizens, and implementing policies and programs to protect and support light-triad personality groups in the field of political science.\n",
            "\n",
            "It is important to continuously evaluate and adapt the solution as needed to ensure its effectiveness and address any challenges that may arise. Additionally, collaboration and cooperation with relevant stakeholders, such as governments, organizations, and individuals, can also be crucial in successfully implementing the solution.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  [\"I'd like to use Synectics to generate innovative solutions for stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. Can you help me draw some analogies?\"]\n",
            "\n",
            " --- Updated prompt is :\n",
            "[\"I'd like to use Synectics to generate innovative solutions for stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. Can you help me draw some analogies?\"]\n",
            "Updated Prompts: [\"I'd like to use Synectics to generate innovative solutions for stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science. Can you help me draw some analogies?\"]\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "Sure, let's start by defining Synectics. Synectics is a creative problem-solving technique that involves making connections between seemingly unrelated ideas or concepts. It encourages individuals to think outside the box and come up with innovative solutions by drawing analogies between different fields or domains.\n",
            "\n",
            "Now, let's apply Synectics to the three issues you mentioned: stopping the war in the Middle East, activating unactivated Iranian people, and protecting light-triad personality groups in the field of political science.\n",
            "\n",
            "1. Stopping the war in the Middle East:\n",
            "\n",
            "Analogies:\n",
            "- A doctor treating a patient: Just as a doctor diagnoses the root cause of a patient's illness and prescribes the appropriate treatment, political scientists can analyze the underlying issues causing the war in the Middle East and propose effective solutions.\n",
            "- A mediator in a conflict resolution: Similar to how a mediator facilitates communication and negotiation between conflicting parties, political scientists can act as mediators between warring factions in the Middle East to find common ground and reach a peaceful resolution.\n",
            "- A firefighter putting out a fire: Just as a firefighter uses various strategies and techniques to extinguish a fire, political scientists can employ different approaches, such as diplomacy, economic incentives, and international pressure, to end the war in the Middle East.\n",
            "\n",
            "2. Activating unactivated Iranian people:\n",
            "\n",
            "Analogies:\n",
            "- A coach motivating their team: Like a coach who inspires and motivates their team to perform at their best, political scientists can use persuasive communication and targeted messaging to activate the Iranian people and encourage them to take action.\n",
            "- A gardener nurturing plants: Similar to how a gardener tends to their plants, providing them with the right conditions and resources to grow, political scientists can create an enabling environment for the Iranian people to become more engaged and involved in their country's political processes.\n",
            "- A teacher educating their students: Just as a teacher uses different teaching methods to engage and stimulate their students' minds, political scientists can use creative and interactive methods to educate and empower the Iranian people to participate in their country's political system.\n",
            "\n",
            "3. Protecting light-triad personality groups in the field of political science:\n",
            "\n",
            "Analogies:\n",
            "- A shield protecting a castle: Like a shield that protects a castle from external threats, political scientists can develop policies and measures to safeguard the rights and interests of light-triad personality groups in the political arena.\n",
            "- A doctor preventing the spread of disease: Similar to how a doctor takes preventive measures to stop the spread of disease, political scientists can proactively address potential discrimination or marginalization of light-triad personality groups in the political sphere.\n",
            "- A bridge connecting two sides: Just as a bridge connects two sides, political scientists can act as a bridge between light-triad personality groups and the rest of society, promoting understanding and inclusivity in the political landscape.\n",
            "\n",
            "By using Synectics and drawing these analogies, we can generate new and innovative ideas for addressing these complex issues in the field of political science. Remember to keep an open mind and explore different perspectives to come up with creative solutions.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(['fist step'], 0)"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Only update the Prompt by the help of ChatGPT:ðŸ‘‡ðŸ‘‡"
      ],
      "metadata": {
        "id": "BAiQz23MlpUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define main variables\n",
        "#TOPIC = \"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"\n",
        "\n",
        "# List of variables\n",
        "variables = [\"RESEARCH_DOMAIN\", \"PARAGRAPH\", \"PARAGRAPHS\", \"TOPIC_SENTENCE\", \"LANGUAGE\", \"ABSTRACT_PARAGRAPH\", \"BIBLIOGRAPHY\", \"THEORY1\", \"THEORY2\", \"RESEARCH_QUESTIONS\", \"ACTION\", \"RESULT_PARAGRAPHS\", \"DATE\", \"NUMBER_OF_DAYS_MONTHS_YEARS\"]\n",
        "\n",
        "# Generate content for each variable\n",
        "variable_contents = {}\n",
        "for prompt in prompts:\n",
        "   for var in variables:\n",
        "       if var in prompt:\n",
        "           prompt = f\"Generate content for the variable '{var}' based on the topic '{TOPIC}'. For this prompt '{prompt}'\"\n",
        "           content= generate_academic_paper(prompt)\n",
        "           for choice in content.choices:\n",
        "               print(choice.text)\n",
        "               variable_contents[var] = choice.text\n",
        "           print(\"variable_contents[var] is: \",variable_contents[var])\n",
        "\n",
        "# Replace the variables in the prompts with the generated content\n",
        "for prompt in prompts:\n",
        "   for var, content in variable_contents.items():\n",
        "       prompt = prompt.replace(f\"{{{var}}}\", content)\n",
        "print(\"Updated Prompt:\", prompt)"
      ],
      "metadata": {
        "id": "kH3LygdiXsPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt_update_a3(prompt, previous_content):\n",
        "    model_engine = \"text-davinci-003\"\n",
        "    max_tokens = 2048\n",
        "\n",
        "    # Construct the instruction for updating the prompt\n",
        "    instruction = f\"Given the previous content:\\n\\n{previous_content}\\n\\nUpdate the prompt: {prompt}\"\n",
        "\n",
        "    # Create the completion with the instruction\n",
        "    completion = client.completions.create(\n",
        "        model=model_engine,\n",
        "        prompt=instruction,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=0.3,\n",
        "        n=1,\n",
        "        frequency_penalty=0,\n",
        "    )\n",
        "\n",
        "    # Extract and return the updated prompt from the response\n",
        "    updated_prompt = completion.choices[0].text.strip()\n",
        "    return updated_prompt\n",
        "# Inside your loop\n",
        "for prompt in prompts:\n",
        "    print(\"Original Prompt:\", prompt)\n",
        "    response = generate_academic_paper_a2(prompt)\n",
        "    previous_content = response.choices[0].text.strip()\n",
        "    updated_prompt = generate_prompt_update_2(prompt, previous_content)\n",
        "    print(\"Updated Prompt:\", updated_prompt)\n",
        "\n",
        "    # Continue with the rest of your processing\n",
        "    # ..."
      ],
      "metadata": {
        "id": "KviSdMwzwqAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# with no translation for become faster answer:ðŸ‘‡ðŸ‘‡ðŸ™"
      ],
      "metadata": {
        "id": "iuTPp4YYBg2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\"\n",
        "#topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key = openai_api#\"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\",\n",
        ")\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "# Create a Translator object\n",
        "translator = Translator()\n",
        "\n",
        "\n",
        "# Function to generate an academic paper\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "def generate_academic_paper_a2(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   completion = client.completions.create(\n",
        "       model=\"gpt-3.5-turbo-instruct\",\n",
        "       prompt=prompt_my,\n",
        "       max_tokens=2048,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "choice_text_all=[]\n",
        "\n",
        "import time\n",
        "# Function to generate academic papers for given prompts\n",
        "# Function to generate academic papers for given prompts\n",
        "def generate_papers(prompts):\n",
        "   for i in range(0, len(prompts), 20):\n",
        "       # Slice the prompts list to get the next 20 prompts\n",
        "       print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "\n",
        "       batch = prompts[i:i+20]\n",
        "       print(\"batch is \",batch)\n",
        "   #for j in range ( 0, Len(batch)):\n",
        "       # Generate papers for the next 20 prompts\n",
        "       for prompt in batch:\n",
        "      #   for prompt in prompt1:\n",
        "           # Print the prompt\n",
        "           print(\"prompt is \", prompt)\n",
        "           response = generate_academic_paper_a2(prompt)\n",
        "           print(\"\\nGenerated Academic Paper:\")\n",
        "           print(\"========================\\n\")\n",
        "           #print(response)\n",
        "           for choice in response.choices:\n",
        "             print(choice.text)\n",
        "             choice_text_all.append(choice.text)\n",
        "\n",
        "             # Translate the generated text to Persian\n",
        "         #  choice_translated = translate_to_persian(choice.text) #translator.translate(choice.text, dest='fa')\n",
        "         # choice_translated_prompt = translate_to_persian(prompt)#translator.translate(prompt, dest='fa')\n",
        "\n",
        "         #    print(\"\\n-----\\n Translated is \",choice_translated)\n",
        "         #    save_academic_paper(\"Persian_\"+topic,'\\n**'+choice_translated_prompt+'**\\n'+choice_translated)\n",
        "             save_academic_paper(topic,'\\n--------**\\n'+prompt+'/n-------**\\n'+choice.text)\n",
        "             # Recursively call the function for the nested Completion objects\n",
        "             if hasattr(choice, 'choices'):\n",
        "               extract_text(choice)\n",
        "\n",
        "           #generated_text = response.choices[0].text\n",
        "           # Print the generated text\n",
        "           #print(generated_text)\n",
        "           print(\"\\n end of loop\")\n",
        "           print(\"========================\\n\")\n",
        "\n",
        "           #print(\"loop\")\n",
        "       # Wait for a short period of time before sending the next batch of prompts\n",
        "           time.sleep(40)\n",
        "   return choice_text_all#,choice.translated\n",
        "\n",
        "# Generate academic papers for the given prompts\n",
        "generate_papers(prompts)"
      ],
      "metadata": {
        "id": "rl16DSYABo9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SETUP COLAB for run Streamlit\n",
        "!npm install localtunnel\n",
        "!curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "GRn7OkOUjcdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DL Translate\n",
        "A deep learning-based translation library built on Huggingface transformers and Facebook's mBART-Large\n",
        "\n",
        "https://colab.research.google.com/github/xhluca/dl-translate/blob/main/demos/colab_demo.ipynb#scrollTo=qdefSjR_YIiG"
      ],
      "metadata": {
        "id": "_I5yn6CCZdMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q dl-translate"
      ],
      "metadata": {
        "id": "c7-q341UWsr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dl_translate as dlt\n",
        "mt = dlt.TranslationModel('mbart50')"
      ],
      "metadata": {
        "id": "gtQcnXabalaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dl_translate as dlt\n",
        "\n",
        "def translate_to_persian(text):\n",
        "  # Initialize the translation model\n",
        "  #mt = dlt.TranslationModel('mbart50')\n",
        "\n",
        "  # Translate the text\n",
        "  translated = mt.translate(text, source=dlt.lang.ENGLISH, target=dlt.lang.PERSIAN)\n",
        "\n",
        "  return translated"
      ],
      "metadata": {
        "id": "iOX6FGFWaFqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key = openai_api#\"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\",\n",
        ")\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "# Create a Translator object\n",
        "translator = Translator()\n",
        "\n",
        "\n",
        "# Function to generate an academic paper\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=10, max_time=600)\n",
        "def generate_academic_paper_5(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   completion = client.completions.create(\n",
        "       model=\"gpt-3.5-turbo-instruct\",\n",
        "       prompt=prompt_my,\n",
        "       max_tokens=2048,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "choice_text_all=[]\n",
        "\n",
        "import time\n",
        "# Function to generate academic papers for given prompts\n",
        "# Function to generate academic papers for given prompts\n",
        "def generate_papers(prompts):\n",
        "   for i in range(0, len(prompts), 20):\n",
        "       # Slice the prompts list to get the next 20 prompts\n",
        "       print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "       batch = prompts[i:i+10]\n",
        "       print(\"batch is \",batch)\n",
        "       # Generate papers for the next 20 prompts\n",
        "       for prompt in batch:\n",
        "      #   for prompt in prompt1:\n",
        "           # Print the prompt\n",
        "           print(\"prompt is \", prompt)\n",
        "           response = generate_academic_paper(prompt)\n",
        "           print(\"\\nGenerated Academic Paper:\")\n",
        "           print(\"========================\\n\")\n",
        "           #print(response)\n",
        "           for choice in response.choices:\n",
        "             print(choice.text)\n",
        "             choice_text_all.append(choice.text)\n",
        "              # Translate the generated text to Persian\n",
        "             choice_translated = translate_to_persian(choice.text) #translator.translate(choice.text, dest='fa')\n",
        "             choice_translated_prompt = translate_to_persian(prompt)#translator.translate(prompt, dest='fa')\n",
        "\n",
        "             print(\"\\n-----\\n Translated is \",choice_translated)\n",
        "             save_academic_paper(\"Persian_\"+topic,'\\n**'+choice_translated_prompt+'**\\n'+choice_translated)\n",
        "             save_academic_paper(topic,'\\n**'+prompt+'**\\n'+choice.text)\n",
        "             # Recursively call the function for the nested Completion objects\n",
        "             if hasattr(choice, 'choices'):\n",
        "               extract_text(choice)\n",
        "\n",
        "           #generated_text = response.choices[0].text\n",
        "           # Print the generated text\n",
        "           #print(generated_text)\n",
        "           print(\"\\n end of loop\")\n",
        "           print(\"========================\\n\")\n",
        "\n",
        "           #print(\"loop\")\n",
        "       # Wait for a short period of time before sending the next batch of prompts\n",
        "           time.sleep(2)\n",
        "   return choice_text_all,choice.translated\n",
        "\n",
        "# Generate academic papers for the given prompts\n",
        "generate_papers(prompts3)"
      ],
      "metadata": {
        "id": "oVldhSpgEVZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#For solving queta prompt of Openai API;\n",
        "ðŸ‘‡ðŸ‘‡ðŸŒ±"
      ],
      "metadata": {
        "id": "GdTvLhAkKLEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "#import openai\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key = openai_api#\"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\",\n",
        ")\n",
        "\n",
        "def retry_with_exponential_backoff(\n",
        "   func,\n",
        "   initial_delay: float = 1,\n",
        "   exponential_base: float = 2,\n",
        "   jitter: bool = True,\n",
        "   max_retries: int = 10,\n",
        "   errors: tuple = (openai.error.RateLimitError,),\n",
        "):\n",
        "   \"\"\"Retry a function with exponential backoff.\"\"\"\n",
        "   def wrapper(*args, **kwargs):\n",
        "       # Initialize variables\n",
        "       num_retries = 0\n",
        "       delay = initial_delay\n",
        "       # Loop until a successful response or max_retries is hit or an exception is raised\n",
        "       while True:\n",
        "           try:\n",
        "               return func(*args, **kwargs)\n",
        "           # Retry on specified errors\n",
        "           except errors as e:\n",
        "               # Increment retries\n",
        "               num_retries += 1\n",
        "               # Check if max retries has been reached\n",
        "               if num_retries > max_retries:\n",
        "                  raise Exception(\n",
        "                      f\"Maximum number of retries ({max_retries}) exceeded.\"\n",
        "                  )\n",
        "               # Increment the delay\n",
        "               delay *= exponential_base * (1 + jitter * random.random())\n",
        "               # Sleep for the delay\n",
        "               time.sleep(delay)\n",
        "           # Raise exceptions for any errors not specified\n",
        "           except Exception as e:\n",
        "               raise e\n",
        "   return wrapper\n",
        "\n",
        "@retry_with_exponential_backoff\n",
        "def generate_academic_paper_0(prompt_my):\n",
        "  model_engine = \"text-davinci-003\"\n",
        "  max_tokens = 2048\n",
        "\n",
        "  completion = client.completions.create(\n",
        "      model=\"gpt-3.5-turbo-instruct\",\n",
        "      prompt=prompt_my,\n",
        "      max_tokens=2048,\n",
        "      temperature=0.3,\n",
        "      n=1,\n",
        "      frequency_penalty=0,\n",
        "  )\n",
        "  return completion"
      ],
      "metadata": {
        "id": "zLWA8i87KXks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vH0Z7EL5LnQc"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "openai.api_key = openai_api#\"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key= openai_api#\"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\",\n",
        ")\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Function to generate an academic paper\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=10, max_time=600)\n",
        "def generate_academic_paper_6(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   completion = client.completions.create(\n",
        "       model=\"gpt-3.5-turbo-instruct\",\n",
        "       prompt=prompt_my,\n",
        "       max_tokens=2048,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "choice_text_all=[]\n",
        "\n",
        "import time\n",
        "# Function to generate academic papers for given prompts\n",
        "# Function to generate academic papers for given prompts\n",
        "def generate_papers(prompts):\n",
        "   for i in range(0, len(prompts), 20):\n",
        "       # Slice the prompts list to get the next 20 prompts\n",
        "       print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "       batch = prompts[i:i+10]\n",
        "       print(\"batch is \",batch)\n",
        "       # Generate papers for the next 20 prompts\n",
        "       for prompt in batch:\n",
        "      #   for prompt in prompt1:\n",
        "           # Print the prompt\n",
        "           print(\"prompt is \", prompt)\n",
        "           response = generate_academic_paper(prompt)\n",
        "           print(\"\\nGenerated Academic Paper:\")\n",
        "           print(\"========================\\n\")\n",
        "           #print(response)\n",
        "           for choice in response.choices:\n",
        "             print(choice.text)\n",
        "             choice_text_all.append(choice.text)\n",
        "             save_academic_paper(TOPIC,'\\n**'+prompt+'**\\n'+choice.text)\n",
        "             # Recursively call the function for the nested Completion objects\n",
        "             if hasattr(choice, 'choices'):\n",
        "               extract_text(choice)\n",
        "\n",
        "           #generated_text = response.choices[0].text\n",
        "           # Print the generated text\n",
        "           #print(generated_text)\n",
        "           print(\"\\n end of loop\")\n",
        "           print(\"========================\\n\")\n",
        "\n",
        "           #print(\"loop\")\n",
        "       # Wait for a short period of time before sending the next batch of prompts\n",
        "           time.sleep(2)\n",
        "   return choice.text_all\n",
        "\n",
        "# Generate academic papers for the given prompts\n",
        "generate_papers(prompts3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJTgcojthnm7"
      },
      "outputs": [],
      "source": [
        "def render_index_page():\n",
        "   html_content = \"\"\"\n",
        "   <!DOCTYPE html>\n",
        "   <html>\n",
        "   <head>\n",
        "      <title>Generate Academic Papers</title>\n",
        "   </head>\n",
        "   <body>\n",
        "      <h1>Generate Academic Papers</h1>\n",
        "      <form method=\"POST\">\n",
        "          <label for=\"topic\">Topic:</label>\n",
        "          <input type=\"text\" id=\"topic\" name=\"topic\" required>\n",
        "          <input type=\"submit\" value=\"Generate\">\n",
        "      </form>\n",
        "   </body>\n",
        "   </html>\n",
        "   \"\"\"\n",
        "   return render_template_string(html_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKhSXALkhpL7"
      },
      "outputs": [],
      "source": [
        "def render_result_page(topic, docx_file, pdf_file, choice_text_all):\n",
        "   html_content = f\"\"\"\n",
        "   <!DOCTYPE html>\n",
        "   <html>\n",
        "   <head>\n",
        "       <title>Result</title>\n",
        "   </head>\n",
        "   <body>\n",
        "       <h1>Result</h1>\n",
        "       <p>Academic papers have been generated for the topic: {topic}</p>\n",
        "       <a href=\"/download/{docx_file}\">Download DOCX</a>\n",
        "       <a href=\"/download/{pdf_file}\">Download PDF</a>\n",
        "       <h2>Generated Text:</h2>\n",
        "       <p>{choice_text_all}</p>\n",
        "   </body>\n",
        "   </html>\n",
        "   \"\"\"\n",
        "   return render_template_string(html_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuTJlSSGgh4E"
      },
      "outputs": [],
      "source": [
        "# app.py\n",
        "\n",
        "from flask import Flask, request, render_template\n",
        "from academic_paper_generator import generate_papers\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def home():\n",
        "  if request.method == 'POST':\n",
        "      topic = request.form.get('topic')\n",
        "      prompts3 = [\n",
        "          f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "          f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "          f\"Identify gaps in the literature on '{topic}'\",\n",
        "          \"Generate 10 academic research questions about Perviuse action\",\n",
        "          f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "      ]\n",
        "      generate_papers(prompts3)\n",
        "      return render_template('result.html', topic=topic)\n",
        "  else:\n",
        "      return render_template('index.html')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  app.run(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}