{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/So-AI-love/chatgpt-prompts-for-academic-writing/blob/main/Auto_Making/API_8_1_Financial_Model_Prompt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AcaGPT MVP\n",
        "\n",
        "The gosl of this project is Creating something like AutoGPT but in the field of Academic Papers wrting.\n",
        "\n",
        "\n",
        "For example the MVP Lage has been made by this AI free website maker :\n",
        "\n",
        "https://acagpt.site.live/editv2/"
      ],
      "metadata": {
        "id": "qnaAEEnpFyLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The SWOT and ..., analysis of this startup is available at here:\n",
        "\n",
        "![enter image description here][1]\n",
        "\n",
        "Analysis and Feedback on a ChatGPT-based Academic Paper Writing Startup\n",
        "\n",
        "https://venturusai.com/report/3Qj8RT-if-possible-suggest-one-startup-in-the-field-of-chatgpt-for-\n",
        "\n",
        "\n",
        "  [1]: https://i.stack.imgur.com/DH3se.jpg"
      ],
      "metadata": {
        "id": "tvOJqqvAMHMD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHgZHeIxi31Q"
      },
      "source": [
        "## Aromatically wrrie apaper by the ChatGPT and this github prompt instruction:\n",
        "\n",
        "https://github.com/ahmetbersoz/chatgpt-prompts-for-academic-writing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "  # Mount Google Drive\n",
        "if not os.path.isdir('/content/drive'):\n",
        "   # If not, mount the drive\n",
        "     drive.mount('/content/drive')\n",
        "else:\n",
        "     print(\"Drive is already mounted.\")"
      ],
      "metadata": {
        "id": "6GjtEabAJCXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vt7VN_fmGT3E",
        "outputId": "21834e56-8a4d-40cd-ffe1-33a2cbd95bfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.3.9)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (0.15.0)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.12.0)\n",
            "Collecting backoff\n",
            "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: backoff\n",
            "Successfully installed backoff-2.2.1\n",
            "Requirement already satisfied: docx2pdf in /usr/local/lib/python3.10/dist-packages (0.1.8)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from docx2pdf) (4.66.1)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.5.0)\n",
            "Requirement already satisfied: django in /usr/local/lib/python3.10/dist-packages (5.0)\n",
            "Requirement already satisfied: asgiref>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from django) (3.7.2)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from django) (0.4.4)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from asgiref>=3.7.0->django) (4.5.0)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (5.1.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from tenacity) (1.16.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n",
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "updated 1 package and audited 36 packages in 0.539s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 2 \u001b[93mmoderate\u001b[0m severity vulnerabilities\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n",
            "\u001b[K\u001b[?25h\n",
            "\u001b[33m\u001b[39m\n",
            "\u001b[33m   ╭────────────────────────────────────────────────────────────────╮\u001b[39m\n",
            "   \u001b[33m│\u001b[39m                                                                \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m      New \u001b[31mmajor\u001b[39m version of npm available! \u001b[31m6.14.8\u001b[39m → \u001b[32m10.2.5\u001b[39m       \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m   \u001b[33mChangelog:\u001b[39m \u001b[36mhttps://github.com/npm/cli/releases/tag/v10.2.5\u001b[39m   \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m               Run \u001b[32mnpm install -g npm\u001b[39m to update!                \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m                                                                \u001b[33m│\u001b[39m\n",
            "\u001b[33m   ╰────────────────────────────────────────────────────────────────╯\u001b[39m\n",
            "\u001b[33m\u001b[39m\n",
            "34.135.134.51\n",
            "Requirement already satisfied: mega.py in /usr/local/lib/python3.10/dist-packages (1.0.8)\n",
            "Requirement already satisfied: requests>=0.10 in /usr/local/lib/python3.10/dist-packages (from mega.py) (2.31.0)\n",
            "Requirement already satisfied: pycryptodome<4.0.0,>=3.9.6 in /usr/local/lib/python3.10/dist-packages (from mega.py) (3.19.0)\n",
            "Requirement already satisfied: pathlib==1.0.1 in /usr/local/lib/python3.10/dist-packages (from mega.py) (1.0.1)\n",
            "Requirement already satisfied: tenacity<6.0.0,>=5.1.5 in /usr/local/lib/python3.10/dist-packages (from mega.py) (5.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=0.10->mega.py) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=0.10->mega.py) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=0.10->mega.py) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=0.10->mega.py) (2023.11.17)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from tenacity<6.0.0,>=5.1.5->mega.py) (1.16.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-distutils is already the newest version (3.10.8-1~22.04).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " megacmd : Depends: libc-ares2 (>= 1.11.0~rc1) but it is not going to be installed\n",
            "           Depends: libcrypto++6 but it is not installable\n",
            "           Depends: libmediainfo0v5 (>= 0.7.56) but it is not going to be installed\n",
            "           Depends: libssl1.1 (>= 1.1.0) but it is not installable\n",
            "           Depends: libzen0v5 (>= 0.4.31-2~) but it is not going to be installed\n",
            "\u001b[1;31mE: \u001b[0mUnmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\u001b[0m\n",
            "Requirement already satisfied: httpcore==0.15.0 in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (0.24.1)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.6.1)\n",
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (0.12.0)\n",
            "Requirement already satisfied: sniffio==1.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (1.3.0)\n",
            "Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (2023.11.17)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore==0.15.0) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore==0.15.0) (1.2.0)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from googletrans) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->googletrans) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->googletrans) (2.0.7)\n",
            "Requirement already satisfied: httpx==0.24.1 in /usr/local/lib/python3.10/dist-packages (0.24.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (2023.11.17)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (0.15.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (1.3.0)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.1) (0.12.0)\n",
            "Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.1) (3.7.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore<0.18.0,>=0.15.0->httpx==0.24.1) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install backoff\n",
        "!pip install docx2pdf\n",
        "!pip install python-docx\n",
        "!pip install django\n",
        "\n",
        "\n",
        "!pip install tenacity\n",
        "!pip install tiktoken\n",
        "\n",
        "# SETUP COLAB for run Streamlit\n",
        "!npm install localtunnel\n",
        "\n",
        "!pip install -q dl-translate\n",
        "!curl ipv4.icanhazip.com\n",
        "\n",
        "#!pip install youtube-dl\n",
        "#!apt install python3-distutils\n",
        "!pip install mega.py\n",
        "!apt install python3-distutils  -y\n",
        "\n",
        "#!pip install googletrans==4.0.0-rc1\n",
        "\n",
        "!pip install httpcore==0.15.0 httpx pymongo googletrans\n",
        "!pip install httpx==0.24.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install libreoffice\n",
        "#!sudo apt-get install abiword\n",
        "!sudo apt install libreoffice-writer"
      ],
      "metadata": {
        "id": "AUeIF57v21gq",
        "outputId": "4a266e97-b6b0-4f87-8789-bae65cfe9615",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.83)] [Connecting to security.ub\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.83)] [Connecting to security.ub\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libreoffice is already the newest version (1:7.3.7-0ubuntu0.22.04.4).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " megacmd : Depends: libc-ares2 (>= 1.11.0~rc1) but it is not going to be installed\n",
            "           Depends: libcrypto++6 but it is not installable\n",
            "           Depends: libmediainfo0v5 (>= 0.7.56) but it is not going to be installed\n",
            "           Depends: libssl1.1 (>= 1.1.0) but it is not installable\n",
            "           Depends: libzen0v5 (>= 0.4.31-2~) but it is not going to be installed\n",
            "E: Unmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libreoffice-writer is already the newest version (1:7.3.7-0ubuntu0.22.04.4).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " megacmd : Depends: libc-ares2 (>= 1.11.0~rc1) but it is not going to be installed\n",
            "           Depends: libcrypto++6 but it is not installable\n",
            "           Depends: libmediainfo0v5 (>= 0.7.56) but it is not going to be installed\n",
            "           Depends: libssl1.1 (>= 1.1.0) but it is not installable\n",
            "           Depends: libzen0v5 (>= 0.4.31-2~) but it is not going to be installed\n",
            "\u001b[1;31mE: \u001b[0mUnmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define main variables\n",
        "TOPIC = \"{TOPIC}\"\n",
        "RESEARCH_DOMAIN = \"{RESEARCH_DOMAIN}\"\n",
        "PARAGRAPH = \"{PARAGRAPH}\"\n",
        "PARAGRAPHS = \"{PARAGRAPHS}\"\n",
        "TOPIC_SENTENCE = \"{TOPIC_SENTENCE}\"\n",
        "LANGUAGE = \"{LANGUAGE}\"\n",
        "ABSTRACT_PARAGRAPH = \"{ABSTRACT_PARAGRAPH}\"\n",
        "BIBLIOGRAPHY = \"{BIBLIOGRAPHY}\"\n",
        "THEORY1 = \"{THEORY1}\"\n",
        "THEORY2 = \"{THEORY2}\"\n",
        "RESEARCH_QUESTIONS = \"{RESEARCH_QUESTIONS}\"\n",
        "ACTION = \"{ACTION}\"\n",
        "RESULT_PARAGRAPHS = \"{RESULT_PARAGRAPHS}\"\n",
        "DATE = \"{DATE}\"\n",
        "NUMBER_OF_DAYS_MONTHS_YEARS = \"{NUMBER_OF_DAYS_MONTHS_YEARS}\"\n",
        "\n",
        "main_variables_0 = {\n",
        "       'TOPIC': None,\n",
        "       'RESEARCH_DOMAIN': None,\n",
        "       'PARAGRAPH': None,\n",
        "       'PARAGRAPHS': None,\n",
        "       'TOPIC_SENTENCE': None,\n",
        "       'LANGUAGE': None,\n",
        "       'ABSTRACT_PARAGRAPH': None,\n",
        "       'BIBLIOGRAPHY': None,\n",
        "       'THEORY1': None,\n",
        "       'THEORY2': None,\n",
        "       'RESEARCH_QUESTIONS': None,\n",
        "       'ACTION': None,\n",
        "       'RESULT_PARAGRAPHS': None,\n",
        "       'DATE': None,\n",
        "       'NUMBER_OF_DAYS_MONTHS_YEARS': None\n",
        "   }\n",
        "\n",
        "# List of prompts for generating academic papers\n",
        "prompts = [\n",
        "\n",
        "  # Improving Language\n",
        "  f\"Write a counterargument to the following claim: '{PARAGRAPH}'\",\n",
        "  f\"Rewrite this in an academic voice: '{PARAGRAPH}'\",\n",
        "  f\"Expand these notes: '{PARAGRAPH}'\",\n",
        "  f\"Provide me a list of words and phrases which were repeatedly / more than 3 times used: '{PARAGRAPHS}'\",\n",
        "  f\"Provide me a list of synonyms for '{PARAGRAPH}' and evaluate them in the context of '{PARAGRAPH}'\",\n",
        "  f\"Act as a language expert, proofread my paper on '{TOPIC_SENTENCE}' while putting a focus on grammar and punctuation.\",\n",
        "  f\"In the context of '{RESEARCH_DOMAIN}' translate '{PARAGRAPH}' into the '{LANGUAGE}' language.\",\n",
        "\n",
        "   # Brainstorming\n",
        "   f\"Find a research topic for a PhD in the area of '{TOPIC}'\",\n",
        "   f\"Write a detailed proposal on the following research topic. Make sure it is free from plagiarism. '{PARAGRAPH}'\",\n",
        "   f\"Identify gaps in the literature on '{TOPIC_SENTENCE}'\",\n",
        "   f\"Generate 10 academic research questions about '{PARAGRAPHS}'\",\n",
        "   f\"Generate a list of research hypotheses related to '{TOPIC_SENTENCE}'\",\n",
        "   f\"Identify potential areas for future research in the context of this '{TOPIC_SENTENCE}'\",\n",
        "   f\"Suggest novel applications of '{TOPIC_SENTENCE}' within '{RESEARCH_DOMAIN}'\",\n",
        "\n",
        "   # Title/Topic Sentence\n",
        "   f\"Suggest 5 titles for the following abstract: '{ABSTRACT_PARAGRAPH}'\",\n",
        "   f\"Write a topic sentence for this paragraph: '{PARAGRAPH}'\",\n",
        "\n",
        "   # Keywords\n",
        "   f\"Provide 5 keywords for this: '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Abstract\n",
        "   f\"Generate an abstract for a scientific paper based on this information for: '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Outline\n",
        "   f\"Generate an outline for '{TOPIC_SENTENCE}'\",\n",
        "   f\"I want to write a journal article about '{TOPIC_SENTENCE}'. Give me an outline for the article that I can use as a starting point.\",\n",
        "\n",
        "   # Introduction\n",
        "   f\"Come up with an introduction for the following research topic: '{TOPIC_SENTENCE}'\",\n",
        "\n",
        "   # Literature Review\n",
        "   f\"Conduct a literature review on '{TOPIC_SENTENCE}' and provide review paper references\",\n",
        "   f\"Provide me with references and links to papers in '{PARAGRAPH}'\",\n",
        "   f\"Summarize the scholarly literature including in-text citations on '{PARAGRAPHS}'\",\n",
        "   f\"Write this in standard Harvard referencing '{PARAGRAPH}'\",\n",
        "   f\"Convert this '{BIBLIOGRAPHY}' from MLA to APA style.\",\n",
        "   f\"Compare and contrast '{THEORY1}' and '{THEORY2}' in the context of '{RESEARCH_DOMAIN}'\",\n",
        "\n",
        "   # Methodology\n",
        "   f\"Create objectives and methodology for '{TOPIC_SENTENCE}'\",\n",
        "   f\"Write a detailed methodology for the topic: '{TOPIC_SENTENCE}'\",\n",
        "   f\"Analyze the strengths and weaknesses of this methodology: '{PARAGRAPHS}'\",\n",
        "   f\"Write objectives for this study: '{TOPIC_SENTENCE}'\",\n",
        "   f\"What are the limitations of using '{TOPIC_SENTENCE}' in '{RESEARCH_DOMAIN}'?\",\n",
        "   f\"Create a recipe for the methods used in this '{PARAGRAPHS}'\",\n",
        "   f\"Suggest interdisciplinary approaches to '{TOPIC_SENTENCE}'\",\n",
        "   f\"Explain how qualitative/quantitative research methods can be used to address '{RESEARCH_QUESTIONS}'\",\n",
        "   f\"Recommend best practices for data collection and analysis in '{TOPIC_SENTENCE}'\",\n",
        "\n",
        "   # Experiments\n",
        "   f\"Design an experiment that '{ACTION}'\",\n",
        "\n",
        "   # Results\n",
        "   f\"Write a result section for the following paragraphs. Please write this in the third person. '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Discussion\n",
        "   f\"Discuss this results: '{RESULT_PARAGRAPHS}'\",\n",
        "\n",
        "   # Conclusion\n",
        "   f\"Generate a conclusion for this: '{PARAGRAPHS}'\",\n",
        "   f\"Give recommendations and conclusion for: '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Future Works\n",
        "   f\"Can you suggest 3 directions for future research on this topic: '{PARAGRAPH}'\",\n",
        "\n",
        "   # Plan/Presentation\n",
        "   f\"Develop a research plan for: '{TOPIC_SENTENCE}'\",\n",
        "   f\"Write a schedule for completion in '{TOPIC_SENTENCE}' in NUMBER OF DAYS MONTHS YEARS which is '{NUMBER_OF_DAYS_MONTHS_YEARS}'\",\n",
        "   f\"The deadline for the submission of the first draft is '{DATE}'. Give me a week-by-week breakdown so I can plan my writing better.\",\n",
        "   f\"Write a sensational press release for this research: '{PARAGRAPHS}'\",\n",
        "   f\"Make this more persuasive: '{PARAGRAPH}'\",\n",
        "   f\"Write 3 tweets about this research? '{PARAGRAPHS}'\",\n",
        "]"
      ],
      "metadata": {
        "id": "uPcmAM5Zq5M-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define main variables\n",
        "#TOPIC = \"Psychological symptoms detection for Iranian men in their 40s studying for a PHD degree\"\n",
        "#RESEARCH_DOMAIN = \"Psychology\"\n",
        "#PARAGRAPH = \"The symptoms include lack of energy for doing work and difficulty focusing the mind on something\"\n",
        "#PARAGRAPHS = \"Historical background showing narcissism, which doesn't accept the information of psychology science but suggests using new technologies for creating cooperation\"\n",
        "#TOPIC_SENTENCE = \"The aim of this study is to investigate the psychological symptoms of Iranian men in their 40s who are studying for a PHD degree\"\n",
        "#LANGUAGE = \"English\"\n",
        "#ABSTRACT_PARAGRAPH = \"This study aims to investigate the psychological symptoms of Iranian men in their 40s who are studying for a PHD degree\"\n",
        "#BIBLIOGRAPHY = \"Masoumeh Zandpour, Jafar Hasani, Carla Sharp\"\n",
        "#THEORY1 = \"Psychological symptoms detection\"\n",
        "#THEORY2 = \"Narcissism\"\n",
        "#RESEARCH_QUESTIONS = \"What are the psychological symptoms of Iranian men in their 40s who are studying for a PHD degree?\"\n",
        "#ACTION = \"Investigate the psychological symptoms of Iranian men in their 40s who are studying for a PHD degree\"\n",
        "#RESULT_PARAGRAPHS = \"The results of the study indicate...\"\n",
        "#DATE = \"11/26/2023\"\n",
        "#NUMBER_OF_DAYS_MONTHS_YEARS = \"2 months\""
      ],
      "metadata": {
        "id": "dMj_71pfRWfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define main variables\n",
        "TOPIC = \"{TOPIC}\"\n",
        "RESEARCH_DOMAIN = \"{RESEARCH_DOMAIN}\"\n",
        "PARAGRAPH = \"{PARAGRAPH}\"\n",
        "PARAGRAPHS = \"{PARAGRAPHS}\"\n",
        "TOPIC_SENTENCE = \"{TOPIC_SENTENCE}\"\n",
        "LANGUAGE = \"{LANGUAGE}\"\n",
        "ABSTRACT_PARAGRAPH = \"{ABSTRACT_PARAGRAPH}\"\n",
        "BIBLIOGRAPHY = \"{BIBLIOGRAPHY}\"\n",
        "THEORY1 = \"{THEORY1}\"\n",
        "THEORY2 = \"{THEORY2}\"\n",
        "RESEARCH_QUESTIONS = \"{RESEARCH_QUESTIONS}\"\n",
        "ACTION = \"{ACTION}\"\n",
        "RESULT_PARAGRAPHS = \"{RESULT_PARAGRAPHS}\"\n",
        "DATE = \"{DATE}\"\n",
        "NUMBER_OF_DAYS_MONTHS_YEARS = \"{NUMBER_OF_DAYS_MONTHS_YEARS}\"\n",
        "\n",
        "main_variables_0 = {\n",
        "      'TOPIC': TOPIC,\n",
        "      'RESEARCH_DOMAIN': RESEARCH_DOMAIN,\n",
        "      'PARAGRAPH': PARAGRAPH,\n",
        "      'PARAGRAPHS': PARAGRAPHS,\n",
        "      'TOPIC_SENTENCE': TOPIC_SENTENCE,\n",
        "      'LANGUAGE': LANGUAGE,\n",
        "      'ABSTRACT_PARAGRAPH': ABSTRACT_PARAGRAPH,\n",
        "      'BIBLIOGRAPHY': BIBLIOGRAPHY,\n",
        "      'THEORY1': THEORY1,\n",
        "      'THEORY2': THEORY2,\n",
        "      'RESEARCH_QUESTIONS': RESEARCH_QUESTIONS,\n",
        "      'ACTION': ACTION,\n",
        "      'RESULT_PARAGRAPHS': RESULT_PARAGRAPHS,\n",
        "      'DATE': DATE,\n",
        "      'NUMBER_OF_DAYS_MONTHS_YEARS': NUMBER_OF_DAYS_MONTHS_YEARS\n",
        "  }\n",
        "\n",
        "# List of prompts for generating academic papers\n",
        "prompts = [\n",
        "# Improving Language\n",
        "f\"Write a counterargument to the following claim: '{PARAGRAPH}'\",\n",
        "f\"Rewrite this in an academic voice: '{PARAGRAPH}'\",\n",
        "f\"Expand these notes: '{PARAGRAPH}'\",\n",
        "f\"Provide me a list of words and phrases which were repeatedly / more than 3 times used: '{PARAGRAPHS}'\",\n",
        "f\"Provide me a list of synonyms for '{PARAGRAPH}' and evaluate them in the context of '{PARAGRAPH}'\",\n",
        "f\"Act as a language expert, proofread my paper on '{TOPIC_SENTENCE}' while putting a focus on grammar and punctuation.\",\n",
        "f\"In the context of '{RESEARCH_DOMAIN}' translate '{PARAGRAPH}' into the '{LANGUAGE}' language.\",\n",
        "\n",
        "  # Brainstorming\n",
        "  f\"Find a research topic for a PhD in the area of '{TOPIC}'\",\n",
        "  f\"Write a detailed proposal on the following research topic. Make sure it is free from plagiarism. '{PARAGRAPH}'\",\n",
        "  f\"Identify gaps in the literature on '{TOPIC_SENTENCE}'\",\n",
        "  f\"Generate 10 academic research questions about '{PARAGRAPHS}'\",\n",
        "  f\"Generate a list of research hypotheses related to '{TOPIC_SENTENCE}'\",\n",
        "  f\"Identify potential areas for future research in the context of this '{TOPIC_SENTENCE}'\",\n",
        "  f\"Suggest novel applications of '{TOPIC_SENTENCE}' within '{RESEARCH_DOMAIN}'\",\n",
        "\n",
        "  # Title/Topic Sentence\n",
        "  f\"Suggest 5 titles for the following abstract: '{ABSTRACT_PARAGRAPH}'\",\n",
        "  f\"Write a topic sentence for this paragraph: '{PARAGRAPH}'\",\n",
        "\n",
        "  # Keywords\n",
        "  f\"Provide 5 keywords for this: '{PARAGRAPHS}'\",\n",
        "\n",
        "  # Abstract\n",
        "  f\"Generate an abstract for a scientific paper based on this information for: '{PARAGRAPHS}'\",\n",
        "\n",
        "  # Outline\n",
        "  f\"Generate an outline for '{TOPIC_SENTENCE}'\",\n",
        "  f\"I want to write a journal article about '{TOPIC_SENTENCE}'. Give me an outline for the article that I can use as a starting point.\",\n",
        "\n",
        "  # Introduction\n",
        "  f\"Come up with an introduction for the following research topic: '{TOPIC_SENTENCE}'\",\n",
        "\n",
        "  # Literature Review\n",
        "  f\"Conduct a literature review on '{TOPIC_SENTENCE}' and provide review paper references\",\n",
        "  f\"Provide me with references and links to papers in '{PARAGRAPH}'\",\n",
        "  f\"Summarize the scholarly literature including in-text citations on '{PARAGRAPHS}'\",\n",
        "  f\"Write this in standard Harvard referencing '{PARAGRAPH}'\",\n",
        "  f\"Convert this '{BIBLIOGRAPHY}' from MLA to APA style.\",\n",
        "  f\"Compare and contrast '{THEORY1}' and '{THEORY2}' in the context of '{RESEARCH_DOMAIN}'\",\n",
        "\n",
        "  # Methodology\n",
        "   f\"Create objectives and methodology for '{TOPIC_SENTENCE}'\",\n",
        "   f\"Write a detailed methodology for the topic: '{TOPIC_SENTENCE}'\",\n",
        "   f\"Analyze the strengths and weaknesses of this methodology: '{PARAGRAPHS}'\",\n",
        "   f\"Write objectives for this study: '{TOPIC_SENTENCE}'\",\n",
        "   f\"What are the limitations of using '{TOPIC_SENTENCE}' in '{RESEARCH_DOMAIN}'?\",\n",
        "   f\"Create a recipe for the methods used in this '{PARAGRAPHS}'\",\n",
        "   f\"Suggest interdisciplinary approaches to '{TOPIC_SENTENCE}'\",\n",
        "   f\"Explain how qualitative/quantitative research methods can be used to address '{RESEARCH_QUESTIONS}'\",\n",
        "   f\"Recommend best practices for data collection and analysis in '{TOPIC_SENTENCE}'\",\n",
        "\n",
        "   # Experiments\n",
        "   f\"Design an experiment that '{ACTION}'\",\n",
        "\n",
        "   # Results\n",
        "   f\"Write a result section for the following paragraphs. Please write this in the third person. '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Discussion\n",
        "   f\"Discuss this results: '{RESULT_PARAGRAPHS}'\",\n",
        "\n",
        "   # Conclusion\n",
        "   f\"Generate a conclusion for this: '{PARAGRAPHS}'\",\n",
        "   f\"Give recommendations and conclusion for: '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Future Works\n",
        "   f\"Can you suggest 3 directions for future research on this topic: '{PARAGRAPH}'\",\n",
        "\n",
        "   # Plan/Presentation\n",
        "   f\"Develop a research plan for: '{TOPIC_SENTENCE}'\",\n",
        "   f\"Write a schedule for completion in '{TOPIC_SENTENCE}' in NUMBER OF DAYS MONTHS YEARS which is '{NUMBER_OF_DAYS_MONTHS_YEARS}'\",\n",
        "   f\"The deadline for the submission of the first draft is '{DATE}'. Give me a week-by-week breakdown so I can plan my writing better.\",\n",
        "   f\"Write a sensational press release for this research: '{PARAGRAPHS}'\",\n",
        "   f\"Make this more persuasive: '{PARAGRAPH}'\",\n",
        "   f\"Write 3 tweets about this research? '{PARAGRAPHS}'\",\n",
        "]"
      ],
      "metadata": {
        "id": "ndWVOITXN7Xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Goal adding 🙏👇🌸"
      ],
      "metadata": {
        "id": "Jl9PPovDuhlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# @title (Please insert your request to be done by this code at below form:👇👇)\n",
        "Topic = \"From Paper to Pixels: Smart Cities' Paperless Shift\" # @param {type:\"string\"}\n",
        "PARAGRAPH = \"please make in perisan market and toman money calculation based maikingfinancial model for From Paper to Pixels: Smart Cities' Paperless Shift As cities around the world continue to grapple with the challenges of sustainability and environmental conservation, one area that has seen significant progress is the reduction of paper usage. This shift towards a more sustainable and environmentally friendly approach to waste management is not only beneficial for the environment but also for the cities themselves.  The Shift Towards Digital Solutions In recent years, cities have started to understand that environmental sustainability and smart city concepts go hand in hand, aiming to increase efficiency and build resilience. The most common example of this is the shift from paper to digital displays, which not only reduces the use of paper and paper waste but also saves a significant amount of energy. For instance, an LED display consumes 40 to 100 kilowatt-hours of electricity annually, whereas bistable digital signage only consumes 4 to 10 KWh 2.  The Impact on Citizens and the City This shift towards digital solutions also has a significant impact on citizens and the city as a whole. By reducing paper usage, cities can save on resources and create jobs in the digital economy. Citizens, on the other hand, can benefit from a more efficient and sustainable city, where resources are used and reused as much as possible, reducing waste and conserving resources.  The Role of Citizens in Waste Management Systems Citizens play a crucial role in waste management systems. By participating in recycling programs, citizens can help reduce the amount of waste that ends up in landfills. This not only benefits the environment but also the city, as it reduces the cost of waste management.  The Potential for Revenue Generation The shift towards digital solutions also opens up new opportunities for revenue generation. For instance, cities could charge a fee for the use of digital displays, or they could generate revenue from the sale of recycled paper products. This revenue could then be used to fund other city services or programs.  The Future of Smart Cities The future of smart cities is energy-efficient and sustainable. As cities continue to implement digital solutions and engage citizens in waste management systems, they are not only reducing their environmental impact but also creating a more sustainable and livable city for their residents.  In conclusion, the shift from paper to digital solutions in smart cities is a significant step towards sustainability and environmental conservation. By reducing paper usage, cities can save resources, create jobs, and generate revenue, all while benefiting their residents. The future of smart cities lies in this direction, and as more cities embrace this shift, we can expect to see even more sustainable and livable cities in the future\" # @param {type:\"string\"}\n",
        "role = \"startup Entrepreneur\"# @param {type:\"string\"}\n",
        "\n",
        "\n",
        "Your_Email = \"hh@gmail.com\" # @param {type:\"string\"}\n",
        "\n",
        "openai_api = \"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\" # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "TOPIC_0 = f\"Analyze the current situation in the Islamic Republic of Iran and the challenges faced by resistance forces. And Identify effective strategies used by resistance movements to navigate challenging political environments.\"\n",
        "TOPIC_0 = f\"Could you provide more insights into the challenges faced by the opposition groups in Iran and how they could overcome these challenges to effectively organize resistance against the Islamic Republic?\"\n",
        "\n",
        "Question=Topic\n",
        "#PASSWORD =  # @param {type:\"string\"}\n",
        "if not (Question == \"\"):\n",
        "\n",
        "    TOPIC  = Question\n",
        "\n",
        "else:\n",
        "    TOPIC  = TOPIC_0\n",
        "\n",
        "    print(\"Please Input your Mega IDs.\")\n",
        "# @markdown *After signing\n",
        "print ('Your question is:',TOPIC)# has done successfully\")\n",
        "main_variables_0 = {\n",
        "   'TOPIC': TOPIC,\n",
        "   'PARAGRAPH':PARAGRAPH,\n",
        "    'role':role\n",
        "}\n",
        "\n",
        "prompts = [\n",
        "# Understanding the Issue\n",
        "f\"What are the key aspects of {main_variables_0['TOPIC']} that need to be addressed?\",\n",
        "\n",
        "# Mind Mapping\n",
        "f\"Create a mind map of the main elements of {main_variables_0['TOPIC']} and how they are interconnected.\",\n",
        "\n",
        "# Affinity Diagramming\n",
        "f\"Write down ideas on sticky notes about how to improve {main_variables_0['TOPIC']}. Then, group these ideas based on common themes.\",\n",
        "\n",
        "# Round-Robin Brainstorming\n",
        "f\"Take turns sharing ideas on how to improve {main_variables_0['TOPIC']}. Make sure everyone has a chance to contribute.\",\n",
        "\n",
        "# Reverse Brainstorming\n",
        "f\"Think of ways to create the problem in {main_variables_0['TOPIC']}. This will help you understand how to solve it.\",\n",
        "\n",
        "# SCAMPER\n",
        "f\"Apply the SCAMPER method to existing solutions or situations in {main_variables_0['TOPIC']}. This will spark new ideas.\",\n",
        "\n",
        "# Cross-Functional Brainstorming\n",
        "f\"Assemble a diverse group of people from various backgrounds and disciplines to tackle {main_variables_0['TOPIC']}. This will ensure a more rounded and innovative solution.\",\n",
        "\n",
        "# Future Backwards\n",
        "f\"Envision a future state where {main_variables_0['TOPIC']} has been solved successfully. Starting from this endpoint, work backward to identify the series of events and decisions that led to that future.\"\n",
        "]"
      ],
      "metadata": {
        "id": "rmbkC20f6RWu",
        "outputId": "f90456f9-d2bd-416d-8e7b-53fe51ab2d67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your question is: EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TOPIC_0 = \"task to investigate various gaming groups in Iran, following the Mahsa Movement in the second year. The gaming groups being investigated include the dark solidarity group, the dark trilogy, the dark quadrilogy, the regular people, the bright solidarity group, and the bright trilogy. The aim is to gather information about each group, analyze their characteristics, objectives, and any associated psychological syndromes. This information will then be presented in a table for easier understanding and comparison.\" # Replace this with your topic\n",
        "RESEARCH_DOMAIN = \"Environmental startup field\" # Replace this with your research domain\n",
        "\n",
        "global docx_path,Pdf_Dir,prompt_Word_Topic\n",
        "\n",
        "if not (Question == \"\"):\n",
        "\n",
        "    TOPIC  = Question\n",
        "\n",
        "else:\n",
        "    TOPIC  = TOPIC_0\n",
        "\n",
        "main_variables_0 = {\n",
        "   'TOPIC': TOPIC,\n",
        "   'RESEARCH_DOMAIN' : RESEARCH_DOMAIN,\n",
        "   'PARAGRAPH':PARAGRAPH\n",
        "}\n",
        "\n",
        "TOPIC = f\"{main_variables_0['TOPIC']}\"\n",
        "RESEARCH_DOMAIN = \"{RESEARCH_DOMAIN}\"\n",
        "\n",
        "prompts_old = [\n",
        "  f\"For the {TOPIC} of Business Overview, provide a detailed description of your business, including its location, legal structure, owners, vision, mission, and history.\",\n",
        "  f\"For the {TOPIC} of Market Analysis, provide information about your target market, market size, growth potential, competitors, market trends, and regulatory environment.\",\n",
        "  f\"For the {TOPIC} of Products and Services, describe your products and services in detail.\",\n",
        "  f\"For the {TOPIC} of Marketing and Sales Strategies, outline your marketing, sales, pricing, and customer retention strategies.\",\n",
        "  f\"For the {TOPIC} of Operations Plan, describe daily business activities, individuals responsible, tools and equipment required, inventory, cost, and any other special requirements.\",\n",
        "  f\"For the {TOPIC} of Management Team, describe the founders, key executives, senior management, their educational and professional background, compensation plan, business hierarchy, and business advisors/consultants.\",\n",
        "  f\"For the {TOPIC} of Financial Plan, provide a thorough understanding of operational costs, net profit, and financing to estimate revenue projections.\",\n",
        "  f\"For the {TOPIC} of Executive Summary, provide an overview of the entire business plan. This is usually written after the entire plan is ready.\",\n",
        "  f\"For the {TOPIC} of Appendix, provide additional information supporting your business plan’s main content.\"\n",
        "]\n",
        "\n",
        "prompts_old_2 = [\n",
        "f\"suggest one Business Plans repost Title based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\"\n",
        " f\"Provide a detailed description of your business, including its location, legal structure, owners, vision, mission, and history. This is for the {TOPIC} of Business Overview. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        " f\"Provide information about your target market, market size, growth potential, competitors, market trends, and regulatory environment. This is for the {TOPIC} of Market Analysis.More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        " f\"Describe your products and services in detail. This is for the {TOPIC} of Products and Services.More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        " f\"Outline your marketing, sales, pricing, and customer retention strategies. This is for the {TOPIC} of Marketing and Sales Strategies.More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        " f\"Describe daily business activities, individuals responsible, tools and equipment required, inventory, cost, and any other special requirements. This is for the {TOPIC} of Operations Plan.More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        " f\"Describe the founders, key executives, senior management, their educational and professional background, compensation plan, business hierarchy, and business advisors/consultants. This is for the {TOPIC} of Management Team.More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        " f\"Provide a thorough understanding of operational costs, net profit, and financing to estimate revenue projections. This is for the {TOPIC} of Financial Plan.More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        " f\"Provide an overview of the entire business plan. This is usually written after the entire plan is ready. This is for the {TOPIC} of Executive Summary.More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        " f\"Provide additional information supporting your business plan’s main content. This is for the {TOPIC} of Appendix.More Description about the Topic is show at here: {PARAGRAPH}\"\n",
        "f\"Provide additional information about SWOT for supporting your business plan’s main content. This is for the {TOPIC} of Appendix.More Description about the Topic is show at here: {PARAGRAPH}\"\n",
        "\n",
        "]\n",
        "\n",
        "prompt_Word_Topic_old_2 = [\n",
        "   f\"suggest one Business Plans repost Title in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\"\n",
        "   \"Provide business overview details\",\n",
        "   \"Describe target market information\",\n",
        "   \"Detail products and services\",\n",
        "   \"Outline marketing, sales strategies\",\n",
        "   \"Describe daily business activities\",\n",
        "   \"Detail management team\",\n",
        "   \"Understand operational costs, profit\",\n",
        "   \"Provide business plan overview\",\n",
        "   \"Support business plan with additional info\"\n",
        "   \" SWOT Analysis \"\n",
        "]"
      ],
      "metadata": {
        "id": "kWdIhuI-yhPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://www.phind.com/search? cache=dmmj0id2em6rm8lo88sqhm6o\n",
        "prompts_old_3 = [\n",
        "  f\"suggest one Business Plans repost Title in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "\n",
        "  f\"1. **Executive Summary**: Provide a concise summary of the business, its goals, and the market it operates in. This is for the {TOPIC} of Executive Summary. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"2. **Company Description**: Provide a detailed description of the company, its mission, vision, and the problem it aims to solve. This is for the {TOPIC} of Company Description. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"3. **Market Analysis**: Provide a comprehensive PESTEL analysis for the company, including Political, Economic, Sociocultural, Technological, Environmental, and Legal factors. This is for the {TOPIC} of Market Analysis. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"4. **Organization and Management**: Describe the company's organizational structure, its team, and their roles and responsibilities. This is for the {TOPIC} of Organization and Management. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"5. **Service or Product Line**: Describe the services or products offered by the company. This is for the {TOPIC} of Service or Product Line. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"6. **Marketing and Sales Strategy**: Outline the strategies for marketing and sales, including the target audience, user stories, suitable business strategies, and marketing platforms. This is for the {TOPIC} of Marketing and Sales Strategy. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"7. **Funding Request**: Detail the amount of funding needed, how it will be used, and the expected return on investment. This is for the {TOPIC} of Funding Request. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"8. **Financial Projections**: Provide financial forecasts for the next few years, including revenue, costs, and profitability. This is for the {TOPIC} of Financial Projections. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"9. **Appendix**: Include any additional information that supports the business plan, such as legal documents, contracts, or market research data. This is for the {TOPIC} of Appendix. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"10. **Industry Insight**: Provide a detailed industry insight for the business plan. This is for the {TOPIC} of Industry Insight. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"11. **SWOT Analysis**: Conduct a SWOT analysis for the business plan. This is for the {TOPIC} of SWOT Analysis. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"12. **Target Audience and User Stories**: Identify the target audience and user stories for the business plan. This is for the {TOPIC} of Target Audience and User Stories. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"13. **Suitable Business Strategies**: Provide suitable business strategies for the business plan. This is for the {TOPIC} of Suitable Business Strategies. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"14. **Business Frameworks**: Provide business frameworks for the business plan. This is for the {TOPIC} of Business Frameworks. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"15. **Requirements Analysis**: Conduct a requirements analysis for the business plan. This is for the {TOPIC} of Requirements Analysis. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"16. **Additional Revenue Streams**: Identify additional revenue streams for the business plan. This is for the {TOPIC} of Additional Revenue Streams. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"17. **Marketing Strategy and Brand Awareness**: Provide a marketing strategy and brand awareness for the business plan. This is for the {TOPIC} of Marketing Strategy and Brand Awareness. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"18. **Branding Suggestions**: Provide branding suggestions for the business plan. This is for the {TOPIC} of Branding Suggestions. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"19. **Recommended Marketing Platforms**: Recommend marketing platforms for the business plan. This is for the {TOPIC} of Recommended Marketing Platforms. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"20. **Game-Changing Idea**: Provide a game-changing idea for the business plan. This is for the {TOPIC} of Game-Changing Idea. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"21. **Porter's Five Forces Analysis**: Conduct a Porter's Five Forces analysis for the business plan. This is for the {TOPIC} of Porter's Five Forces Analysis. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"22. **CATWOE Analysis**: Provide a CATWOE analysis for the business plan. This is for the {TOPIC} of CATWOE Analysis. More Description about the Topic is show at here: {PARAGRAPH}\"\n",
        "]\n",
        "\n",
        "prompts = [\n",
        "    f\"suggest one Business Plans repost Title in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "    f\"1. **Executive Summary** (As a {role}): In this section, provide a concise summary of the business highlighting its unique value proposition, target market, and projected growth. Describe the company's goals, mission, and the market landscape it operates in. This is for the {TOPIC} of Executive Summary. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"2. **Company Description** (As a {role}): Detail the company's history, its founding principles, values, and the problem it addresses. Explain the company's vision, its core competencies, and how it stands out in the market. This is for the {TOPIC} of Company Description. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"3. **Market Analysis** (As a {role}): Conduct an in-depth PESTEL analysis covering Political, Economic, Sociocultural, Technological, Environmental, and Legal factors. Provide insights into market trends, potential risks, and opportunities. This is for the {TOPIC} of Market Analysis. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"4. **Organization and Management** (As a {role}): Outline the company's organizational structure, key personnel, their roles, and responsibilities. Explain how the team contributes to the company's success. This is for the {TOPIC} of Organization and Management. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"5. **Service or Product Line** (As a {role}): Elaborate on the services or products offered by the company. Highlight their unique features, benefits, and how they fulfill market needs. This is for the {TOPIC} of Service or Product Line. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"6. **Marketing and Sales Strategy** (As a {role}): Explain the strategies for marketing and sales, target audience identification, user stories, and chosen marketing platforms. This is for the {TOPIC} of Marketing and Sales Strategy. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"7. **Funding Request** (As a {role}): Specify the funding amount required, the allocation plan, and the anticipated return on investment. Justify the funding request based on growth projections. This is for the {TOPIC} of Funding Request. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"8. **Financial Projections** (As a {role}): Present detailed financial forecasts covering revenue, costs, and profitability for the upcoming years. Base projections on market analysis and business strategies. This is for the {TOPIC} of Financial Projections. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"9. **Appendix** (As a {role}): Include supporting documents like legal papers, contracts, and additional market research data that strengthen the business plan. This is for the {TOPIC} of Appendix. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"10. **Industry Insight** (As a {role}): Provide a comprehensive analysis of the industry, including current trends, competitive landscape, and future predictions. This is for the {TOPIC} of Industry Insight. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"11. **SWOT Analysis** (As a {role}): Perform a SWOT analysis, highlighting the company's strengths, weaknesses, opportunities, and threats. This is for the {TOPIC} of SWOT Analysis. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"12. **Target Audience and User Stories** (As a {role}): Identify the target audience demographics and behaviors. Create user stories illustrating their needs and experiences. This is for the {TOPIC} of Target Audience and User Stories. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"13. **Suitable Business Strategies** (As a {role}): Present specific business strategies tailored to the company's objectives, market conditions, and competitive positioning. This is for the {TOPIC} of Suitable Business Strategies. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"14. **Business Frameworks** (As a {role}): Propose relevant business frameworks or methodologies to guide the company's operations and decision-making. This is for the {TOPIC} of Business Frameworks. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    # 14-1. **SWOT Analysis**:\n",
        "    f\"Identify strengths, weaknesses, opportunities, and threats affecting the {TOPIC} business plan. This is for the {TOPIC} of SWOT Analysis. More Description about the Topic is shown here: {PARAGRAPH} The role of ChatGPT is to assist in generating insights and strategies.\",\n",
        "    # 14-2. **Porter's Five Forces**:\n",
        "    f\"Analyze industry competitiveness to understand market dynamics and potential competitors in the context of {TOPIC}. This is for the {TOPIC} of Porter's Five Forces Analysis. More Description about the Topic is shown here: {PARAGRAPH} ChatGPT's role is to provide a comprehensive analysis of market forces.\",\n",
        "    # 14-3. **Value Chain Analysis**:\n",
        "    f\"Break down activities to enhance value creation and operational efficiency for the {TOPIC} business plan. This is for the {TOPIC} of Value Chain Analysis. More Description about the Topic is shown here: {PARAGRAPH} ChatGPT will help in identifying areas of value creation and optimization.\",\n",
        "    # 14-4. **Business Model Canvas**:\n",
        "    f\"Visualize and communicate the business model clearly for the {TOPIC} stakeholders. This is for the {TOPIC} of Business Model Canvas. More Description about the Topic is shown here: {PARAGRAPH} ChatGPT's role is to aid in presenting a comprehensive business model.\",\n",
        "    # 14-5. **Ansoff Matrix**:\n",
        "    f\"Determine growth strategies for market penetration, development, and diversification tailored to {TOPIC}. This is for the {TOPIC} of Ansoff Matrix. More Description about the Topic is shown here: {PARAGRAPH} ChatGPT will assist in identifying growth strategies for the business.\",\n",
        "    # 14-6. **PESTEL Analysis**:\n",
        "    f\"Assess political, economic, social, technological, environmental, and legal factors impacting the {TOPIC} business plan. This is for the {TOPIC} of PESTEL Analysis. More Description about the Topic is shown here: {PARAGRAPH} ChatGPT's role is to analyze external factors affecting the business environment.\",\n",
        "    # 14-7. **Balanced Scorecard**:\n",
        "    f\"Monitor performance against strategic objectives and adjust the {TOPIC} business plan accordingly. This is for the {TOPIC} of Balanced Scorecard. More Description about the Topic is shown here: {PARAGRAPH} ChatGPT's role is to assist in monitoring and aligning strategies with objectives.\",\n",
        "    f\"15. **Requirements Analysis** (As a {role}): Detail the requirements necessary for successful implementation of the business plan, including resources, technology, and workforce. This is for the {TOPIC} of Requirements Analysis. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"16. **Additional Revenue Streams** (As a {role}): Identify and explore potential additional revenue streams or business diversification opportunities. This is for the {TOPIC} of Additional Revenue Streams. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"17. **Marketing Strategy and Brand Awareness** (As a {role}): Develop a comprehensive marketing strategy focusing on brand awareness, positioning, and customer acquisition. This is for the {TOPIC} of Marketing Strategy and Brand Awareness. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"18. **Branding Suggestions** (As a {role}): Provide recommendations for branding strategies, including visual elements, messaging, and brand personality. This is for the {TOPIC} of Branding Suggestions. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"19. **Recommended Marketing Platforms** (As a {role}): Recommend specific marketing platforms or channels suitable for the target audience and business objectives. This is for the {TOPIC} of Recommended Marketing Platforms. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"20. **Game-Changing Idea** (As a {role}): Present an innovative idea or strategy that could revolutionize the industry or significantly impact the company's growth. This is for the {TOPIC} of Game-Changing Idea. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"21. **Porter's Five Forces Analysis** (As a {role}): Conduct a thorough Porter's Five Forces analysis to evaluate the competitive forces within the industry. Assess factors affecting profitability and market attractiveness. This is for the {TOPIC} of Porter's Five Forces Analysis. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"22. **CATWOE Analysis** (As a {role}): Perform a comprehensive CATWOE analysis considering Customers, Actors, Transformation, Worldview, Owners, and Environmental Constraints. Analyze the impacts on the business strategy and operations. This is for the {TOPIC} of CATWOE Analysis. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "]\n",
        "\n",
        "\n",
        "prompt_Word_Topic = [\n",
        "f\"suggest one Business Plans repost Title in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "\"1. Executive Summary: Business overview\",\n",
        "\"2. Company Description: Company identity\",\n",
        "\"3. Market Analysis: External factors\",\n",
        "\"4. Organization: Organizational structure\",\n",
        "\"5. Products/Services: Services/Products\",\n",
        "\"6. Marketing Strategy: Marketing strategies\",\n",
        "\"7. Funding: Funding details\",\n",
        "\"8. Financial Projections: Financial forecasts\",\n",
        "\"9. Appendix: Additional information\",\n",
        "\"10. Industry: Industry overview\",\n",
        "\"11. SWOT: Strengths, Weaknesses, Opportunities, Threats\",\n",
        "\"12. Target Audience: Target audience and user stories\",\n",
        "\"13. Business Strategies: Business strategies\",\n",
        "\"14. Frameworks: Business frameworks\",\n",
        "\"14-1. **SWOT Analysis**: Identify strengths, weaknesses, opportunities, and threats. Business insights provided.\",\n",
        "\"14-2. **Porter's Five Forces**: Analyze industry competitiveness, understand potential competitors.\",\n",
        "\"14-3. **Value Chain Analysis**: Enhance value creation, improve operational efficiency.\",\n",
        "\"14-4. **Business Model Canvas**: Visualize and communicate business model clearly.\",\n",
        "\"14-5. **Ansoff Matrix**: Determine growth strategies for market penetration.\",\n",
        "\"14-6. **PESTEL Analysis**: Assess political, economic, social factors impacting.\",\n",
        "\"14-7. **Balanced Scorecard**: Monitor performance, align strategies with objectives.\",\n",
        "\"15. Requirements: Requirements analysis\",\n",
        "\"16. Revenue: Additional revenue\",\n",
        "\"17. Marketing: Marketing and branding\",\n",
        "\"18. Branding: Branding suggestions\",\n",
        "\"19. Marketing Platforms: Recommended marketing platforms\",\n",
        "\"20. Idea: Game-changing idea\",\n",
        "\"21. Porter's Five Forces: Porter's Five Forces analysis\",\n",
        "\"22. CATWOE: CATWOE analysis\"\n",
        "]"
      ],
      "metadata": {
        "id": "OW6pwn7OPpVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#https://www.phind.com/search?cache=mn7fgo273k158vv941hewfxg\n",
        "TOPIC_0 = \"task to investigate various gaming groups in Iran, following the Mahsa Movement in the second year. The gaming groups being investigated include the dark solidarity group, the dark trilogy, the dark quadrilogy, the regular people, the bright solidarity group, and the bright trilogy. The aim is to gather information about each group, analyze their characteristics, objectives, and any associated psychological syndromes. This information will then be presented in a table for easier understanding and comparison.\" # Replace this with your topic\n",
        "RESEARCH_DOMAIN = \"Environmental startup field\" # Replace this with your research domain\n",
        "\n",
        "global docx_path,Pdf_Dir\n",
        "\n",
        "if not (Question == \"\"):\n",
        "\n",
        "    TOPIC  = Question\n",
        "\n",
        "else:\n",
        "    TOPIC  = TOPIC_0\n",
        "\n",
        "main_variables_0 = {\n",
        "   'TOPIC': TOPIC,\n",
        "   'RESEARCH_DOMAIN' : RESEARCH_DOMAIN,\n",
        "   'PARAGRAPH':PARAGRAPH,\n",
        "}\n",
        "\n",
        "TOPIC = f\"{main_variables_0['TOPIC']}\"\n",
        "RESEARCH_DOMAIN = \"{RESEARCH_DOMAIN}\"\n",
        "\n",
        "\n",
        "prompts = [\n",
        "f\"suggest one Business Plans repost Title in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "\n",
        "f\"1. Do what for the '{TOPIC}' with this description: '{PARAGRAPH}'?, also use word system format as bolding and ...\",\n",
        "f\"1. Critique the business model for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\",\n",
        "\n",
        "f\"2. Calculate the startup costs for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\",\n",
        "f\"2. Critique the startup costs for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\",\n",
        "\n",
        "f\"3. Track the revenue for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\",\n",
        "f\"3. Critique the revenue tracking for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\",\n",
        "\n",
        "f\"4. Review the projections for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\",\n",
        "f\"4. Critique the projections for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\",\n",
        "\n",
        "f\"5. Generate a detailed financial model for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system formats as bolding and ...\",\n",
        "f\"5. Critique the detailed financial model for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\",\n",
        "\n",
        "f\"6. Analyze the financial model for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\",\n",
        "f\"6. Critique the financial model analysis for the '{TOPIC}' with this description: '{PARAGRAPH}'.also use word system format as bolding and ...\",\n",
        "\n",
        "f\"7. Adjust the financial model for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\",\n",
        "f\"7. Critique the adjustments made to the financial model for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\",\n",
        "\n",
        "f\"8. Finalize the financial model for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\",\n",
        "f\"8. Critique the finalized financial model for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\"\n",
        "]\n",
        "#https://www.phind.com/search?cache=fbhlj5n08cwpl4y42l99w8sq\n",
        "prompt_Word_Topic = [\n",
        "  f\"suggest one Business Plans repost Title in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "  \"1. Determine tasks for topic.\",\n",
        "  \"2. Critique business model.\",\n",
        "  \"3. Calculate startup costs.\",\n",
        "  \"4. Critique startup costs.\",\n",
        "  \"5. Track revenue.\",\n",
        "  \"6. Critique revenue tracking.\",\n",
        "  \"7. Review projections.\",\n",
        "  \"8. Critique projections.\",\n",
        "  \"9. Generate detailed financial model.\",\n",
        "  \"10. Critique financial model.\",\n",
        "  \"11. Analyze financial model.\",\n",
        "  \"12. Critique analysis.\",\n",
        "  \"13. Adjust financial model.\",\n",
        "  \"14. Critique adjustments.\",\n",
        "  \"15. Finalize financial model.\",\n",
        "  \"16. Critique finalized model.\",\n",
        "]"
      ],
      "metadata": {
        "id": "bRdDZr2zPkv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "TOPIC_0 = \"task to investigate various gaming groups in Iran, following the Mahsa Movement in the second year. The gaming groups being investigated include the dark solidarity group, the dark trilogy, the dark quadrilogy, the regular people, the bright solidarity group, and the bright trilogy. The aim is to gather information about each group, analyze their characteristics, objectives, and any associated psychological syndromes. This information will then be presented in a table for easier understanding and comparison.\" # Replace this with your topic\n",
        "RESEARCH_DOMAIN = \"Making Pitch deck file for the TOPIC \"\n",
        "\n",
        "if not (Question == \"\"):\n",
        "   TOPIC = Question\n",
        "else:\n",
        "   TOPIC = TOPIC_0\n",
        "\n",
        "main_variables_0 = {\n",
        "  'TOPIC': TOPIC,\n",
        "  'RESEARCH_DOMAIN' : RESEARCH_DOMAIN,\n",
        "  'PARAGRAPH':PARAGRAPH,\n",
        "}\n",
        "\n",
        "prompts_pitch = [\n",
        "f\"suggest one pitch deck  report Title in less than 15 word, based of This Topic :({main_variables_0['TOPIC']}) and the description:({main_variables_0['PARAGRAPH']}).\",\n",
        "\n",
        "f\"1.What are the key aspects of {main_variables_0['TOPIC']} that need to be addressed in the context of {main_variables_0['PARAGRAPH']}?\",\n",
        "f\"2.Create a mind map of the main elements of {main_variables_0['TOPIC']} and how they are interconnected in the context of {main_variables_0['PARAGRAPH']}.\",\n",
        "f\"3.Write down ideas on sticky notes about how to improve {main_variables_0['TOPIC']} in the context of {main_variables_0['PARAGRAPH']}. Then, group these ideas based on common themes.\",\n",
        "f\"4.Take turns sharing ideas on how to improve {main_variables_0['TOPIC']} in the context of {main_variables_0['PARAGRAPH']}. Make sure everyone has a chance to contribute.\",\n",
        "f\"5.Think of ways to create the problem in {main_variables_0['TOPIC']} in the context of {main_variables_0['PARAGRAPH']}. This will help you understand how to solve it.\",\n",
        "f\"6.Apply the SCAMPER method to existing solutions or situations in {main_variables_0['TOPIC']} in the context of {main_variables_0['PARAGRAPH']}. This will spark new ideas.\",\n",
        "f\"7.Assemble a diverse group of people from various backgrounds and disciplines to tackle {main_variables_0['TOPIC']} in the context of {main_variables_0['PARAGRAPH']}. This will ensure a more rounded and innovative solution.\",\n",
        "f\"8.Envision a future state where {main_variables_0['TOPIC']} has been solved successfully in the context of {main_variables_0['PARAGRAPH']}. Starting from this endpoint, work backward to identify the series of events and decisions that led to that future.\"\n",
        "]\n",
        "\n",
        "prompt_Word_Topic_pitch = [\n",
        "  f\"suggest one pitch deck report Title in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "\n",
        "\n",
        "  f\"1. Identify key aspects of startup pitch deck.\",\n",
        "  f\"2. Create a mind map of startup elements.\",\n",
        "  f\"3. Brainstorm ideas for startup improvement.\",\n",
        "  f\"4. Share ideas for startup improvement.\",\n",
        "  f\"5. Identify startup problems for solutions.\",\n",
        "  f\"6. Apply SCAMPER method to startup.\",\n",
        "  f\"7. Assemble diverse team for startup.\",\n",
        "  f\"8. Envision successful startup future.\"\n",
        "]"
      ],
      "metadata": {
        "id": "M1anh0IcnFnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title .\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of changes in the type of violence that continues in the aftermath of violence\"\n",
        "#TOPIC =f\"stop the WarDark Triad and Light Triad in the Middle East: A Critical Examination of their Influence and Impact on Iran\"+TOPIC\n",
        "\n",
        "#TOPIC = f\"If possible read this post ( https://www.geeky-gadgets.com/chatgpt-brainstorming-prompts/ ) and suggest  one python block code 10 prompt in the for on ( prompt=[The suggested prompt based of [var1] ). The prompt must have 10 line and at least three necessary value like TOPIC , FIELD_SUDY,and the third vale is your optional . Also you can have more variable or prompt for doing this post main goal which is brainstorming for one topic based of ChatGPT promptimg. This would be ChatGPT cheat sheet prompting.\"\n",
        "TOPIC = main_variables_0.get('TOPIC', 'Default Value')\n",
        "print ('TOPIC IS :', TOPIC)\n",
        "\n",
        "folder_chatGPT = \"/content/ChatGPT_academic_paper\"\n",
        "#openai_api_0 = \"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\"\n",
        "#openai_api = \"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\"\n",
        "global TOPIC_CLASS\n",
        "class TOPIC_CLASS:\n",
        "    def __init__(self):\n",
        "        self.perviuse_try_numner = 0\n",
        "        self.perviuse_content = ['fist step']\n",
        "        self.topic= TOPIC\n",
        "TP= TOPIC_CLASS()\n",
        "#TOPIC = f\" \""
      ],
      "metadata": {
        "id": "I484Df8ONQVI",
        "outputId": "d46bff1e-dce6-4f62-c07b-e78ae039b3df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOPIC IS : EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Funstions for saving as PDF and DOCX :\n",
        "👇🌱"
      ],
      "metadata": {
        "id": "lI5PG0BNPrPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install libreoffice\n",
        "#!sudo apt-get install abiword\n",
        "!sudo apt install libreoffice-writer"
      ],
      "metadata": {
        "id": "XDBHbtajP03B",
        "outputId": "d2059ff3-173f-4ef8-ebdc-42a0417f72fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.36)] [\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.36)] [\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.36)] [\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libreoffice is already the newest version (1:7.3.7-0ubuntu0.22.04.4).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " megacmd : Depends: libc-ares2 (>= 1.11.0~rc1) but it is not going to be installed\n",
            "           Depends: libcrypto++6 but it is not installable\n",
            "           Depends: libmediainfo0v5 (>= 0.7.56) but it is not going to be installed\n",
            "           Depends: libssl1.1 (>= 1.1.0) but it is not installable\n",
            "           Depends: libzen0v5 (>= 0.4.31-2~) but it is not going to be installed\n",
            "E: Unmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libreoffice-writer is already the newest version (1:7.3.7-0ubuntu0.22.04.4).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " megacmd : Depends: libc-ares2 (>= 1.11.0~rc1) but it is not going to be installed\n",
            "           Depends: libcrypto++6 but it is not installable\n",
            "           Depends: libmediainfo0v5 (>= 0.7.56) but it is not going to be installed\n",
            "           Depends: libssl1.1 (>= 1.1.0) but it is not installable\n",
            "           Depends: libzen0v5 (>= 0.4.31-2~) but it is not going to be installed\n",
            "\u001b[1;31mE: \u001b[0mUnmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2xiQx_camiB"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "def convert_docx_to_pdf0(docx_path, pdf_path):\n",
        "  subprocess.call(['abiword', '--to=pdf', docx_path, '--to-dir', pdf_path])\n",
        "\n",
        "def convert_docx_to_pdf(docx_path, pdf_path):\n",
        " command = ['libreoffice', '--headless', '--convert-to', 'pdf', '--outdir', pdf_path, docx_path]\n",
        " subprocess.call(command)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "\n",
        "def add_text_with_bold(paragraph, text,p):\n",
        "   parts = text.split('**')\n",
        "   #doc.style('normal')\n",
        "   #p.style = doc.styles['Normal']\n",
        "\n",
        "   for i in range(len(parts)):\n",
        "       if i % 2 == 0:\n",
        "           p.add_run(parts[i])\n",
        "       else:\n",
        "           run = p.add_run(parts[i])\n",
        "           run.bold = True\n",
        "\n",
        "   return paragraph\n",
        "\n",
        "#add_text_with_bold(doc, 'This is some **bold** text',p)"
      ],
      "metadata": {
        "id": "xWvptzlbCPxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import subprocess\n",
        "from docx import Document\n",
        "from django.utils.text import slugify\n",
        "\n",
        "\n",
        "def save_academic_paper(topic, prompt_my):\n",
        "  global docx_path,Pdf_Dir\n",
        "\n",
        "  # Define the path to the folder in Google Drive\n",
        "  folder_path = r\"/content/drive/My Drive/ChatGPT_Paper_wrting/Bussiness_Plane/\"\n",
        "\n",
        "  # Mount Google Drive\n",
        "  if not os.path.isdir('/content/drive'):\n",
        "   # If not, mount the drive\n",
        "     drive.mount('/content/drive')\n",
        "  else:\n",
        "     print(\"Drive is already mounted.\")\n",
        "\n",
        "  Pdf_Dir= r\"/content/drive/My Drive/ChatGPT_Paper_wrting/Bussiness_Plane/\"\n",
        "  docx_path= f\"{folder_path}\"+\"FM\"+f\"{topic}.docx\"\n",
        "  # Check if the folder exists\n",
        "  if not os.path.exists(folder_path):\n",
        "  # If the folder doesn't exist, create it\n",
        "    os.mkdir(folder_path)\n",
        "\n",
        "\n",
        "  # Replace spaces in the topic with underscores\n",
        "  #topic = topic[:12].replace(\" \", \"_\")\n",
        "  topic = slugify(topic)\n",
        "\n",
        "  # Define the path to the DOCX file in the folder\n",
        "\n",
        "\n",
        "  # Check if the DOCX file exists\n",
        "  if os.path.isfile(docx_path):\n",
        "    # If the DOCX file exists, open it\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"#+str(random.randint(0,9))+\".docx\"\n",
        "    doc = Document(docx_path)\n",
        "  else:\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"\n",
        "    #print(docx_path)\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "    doc = Document()\n",
        "\n",
        "  # Add the generated text to the document\n",
        "  #doc.add_paragraph(prompt_my)\n",
        "  doc = add_text_with_bold(doc,0,prompt_my)\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Convert the DOCX file to a PDF\n",
        "  convert_docx_to_pdf(docx_path,Pdf_Dir)\n",
        "  return docx_path,Pdf_Dir"
      ],
      "metadata": {
        "id": "wTIqVCsP17gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from google.colab import drive\n",
        "import os , random\n",
        "import subprocess\n",
        "from docx import Document\n",
        "from django.utils.text import slugify\n",
        "from docx.shared import Pt\n",
        "\n",
        "Repost_Type_Title = 'Financial Model'\n",
        "Repost_Type = 'Financial_Model'\n",
        "  # Mount Google Drive\n",
        "if not os.path.isdir('/content/drive'):\n",
        "   # If not, mount the drive\n",
        "     drive.mount('/content/drive')\n",
        "else:\n",
        "     print(\"Drive is already mounted.\")\n",
        "\n",
        "\n",
        "def save_academic_paper_with_prompt_Tile(topic, prompt_my,contnet,try_number):\n",
        "  global docx_path,Pdf_Dir\n",
        "\n",
        "\n",
        "  # Define the path to the folder in Google Drive\n",
        "  folder_path = r\"/content/drive/My Drive/ChatGPT_Paper_wrting/\"+f\"{Repost_Type}/Title/\"\n",
        "\n",
        "\n",
        "  Pdf_Dir = folder_path# r\"/content/drive/My Drive/ChatGPT_Paper_wrting/{Repost_Type}/Title/\"\n",
        "\n",
        "  topic = slugify(topic[:21])\n",
        "  docx_path= f\"{folder_path}\"+f\"{Repost_Type}_T_\"+f\"{topic}.docx\"\n",
        "\n",
        "  # Check if the folder exists\n",
        "  if not os.path.exists(folder_path):\n",
        "  # If the folder doesn't exist, create it\n",
        "    os.makedirs(folder_path)\n",
        "\n",
        "\n",
        "  # Replace spaces in the topic with underscores\n",
        "  #topic = topic[:12].replace(\" \", \"_\")\n",
        "  #topic = slugify(topic)\n",
        "\n",
        "  # Define the path to the DOCX file in the folder\n",
        "\n",
        "  # Check if the DOCX file exists\n",
        "  if os.path.isfile(docx_path):\n",
        "\n",
        "    if try_number == 0 :\n",
        "\n",
        "       topic = topic+str(random.randint(0,100))#os.remove(docx_path)\n",
        "       docx_path= f\"{folder_path}\"+f\"{Repost_Type}_T_\"+f\"{topic}.docx\"\n",
        "       if os.path.isfile(docx_path):\n",
        "          try:\n",
        "             os.remove (docx_path.replace('docx','pdf'))\n",
        "             os.remove (docx_path)#\n",
        "\n",
        "          except:\n",
        "             print (\"the file for saving Exist and some error happened\")\n",
        "       doc = Document()\n",
        "\n",
        "    else :\n",
        "\n",
        "    # If the DOCX file exists, open it\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"#+str(random.randint(0,9))+\".docx\"\n",
        "       doc = Document(docx_path)\n",
        "\n",
        "\n",
        "    # Add the generated text to the document\n",
        "    p = doc.add_paragraph()#prompt_my)\n",
        "    # Add the generated text to the document\n",
        "    # Add the generated text to the document\n",
        "    p.style = doc.styles['Subtitle']\n",
        "\n",
        "    font = p.style.font\n",
        "    font.name = 'Arial'\n",
        "    font.size = Pt(15)\n",
        "    p = add_text_with_bold(doc,prompt_my,p)\n",
        "\n",
        "    #p.style = doc.styles['Subtitle']\n",
        "\n",
        "  else:\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"\n",
        "    #print(docx_path)\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "    doc = Document()\n",
        "\n",
        "    # Add the generated text to the document\n",
        "    p = doc.add_paragraph()#prompt_my)\n",
        "    # Add the generated text to the document\n",
        "    # Add the generated text to the document\n",
        "    p.style = doc.styles['Title']\n",
        "\n",
        "\n",
        "    p = add_text_with_bold(doc, f\"{Repost_Type_Title} For:\"+prompt_my,p)\n",
        "    p.style = doc.styles['Title']\n",
        "\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Revert the style of the paragraph back to 'Normal'\n",
        "  p = doc.add_paragraph()#contnet)\n",
        "  p.style = doc.styles['Normal']\n",
        "\n",
        "  p = add_text_with_bold(doc,contnet,p)\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Convert the DOCX file to a PDF\n",
        "  convert_docx_to_pdf(docx_path,Pdf_Dir)\n",
        "  return docx_path,Pdf_Dir\n",
        "\n",
        "def save_academic_paper_with_prompt(topic, prompt_my,contnet,try_number):\n",
        "  global docx_path,Pdf_Dir\n",
        "\n",
        "\n",
        "  # Define the path to the folder in Google Drive\n",
        "  folder_path = r\"/content/drive/My Drive/ChatGPT_Paper_wrting/\"+f\"{Repost_Type}/Prompt/\"\n",
        "\n",
        "\n",
        "  Pdf_Dir = folder_path# r\"/content/drive/My Drive/ChatGPT_Paper_wrting/\"+f\"{Repost_Type}/Prompt/\"\n",
        "  topic = slugify(topic[:21])\n",
        "  docx_path= f\"{folder_path}\"+f\"{Repost_Type}_PR_\"+f\"{topic}.docx\"\n",
        "\n",
        "\n",
        "  # Check if the folder exists\n",
        "  if not os.path.exists(folder_path):\n",
        "  # If the folder doesn't exist, create it\n",
        "    os.makedirs(folder_path)\n",
        "\n",
        "\n",
        "  # Replace spaces in the topic with underscores\n",
        "  #topic = topic[:12].replace(\" \", \"_\")\n",
        "  #topic = slugify(topic)\n",
        "\n",
        "  # Define the path to the DOCX file in the folder\n",
        "\n",
        "\n",
        "    # If the DOCX file exists, open it\n",
        "  if try_number == 0 :\n",
        "       try:\n",
        "          os.remove(docx_path)\n",
        "          os.romove (docx_path.replace('docx','pdf'))\n",
        "       except:\n",
        "          pass\n",
        "\n",
        "  # Check if the DOCX file exists\n",
        "  if os.path.isfile(docx_path):\n",
        "    # If the DOCX file exists, open it\n",
        "        #docx_path = f\"{folder_path}{topic}.docx\"#+str(random.randint(0,9))+\".docx\"\n",
        "    if try_number == 0 :\n",
        "\n",
        "       topic = topic+str(random.randint(0,100))#os.remove(docx_path)\n",
        "       docx_path= f\"{folder_path}\"+f\"{Repost_Type}_PR_\"+f\"{topic}.docx\"\n",
        "       if os.path.isfile(docx_path):\n",
        "          try:\n",
        "             os.remove (docx_path.replace('docx','pdf'))\n",
        "             os.remove (docx_path)#\n",
        "\n",
        "          except:\n",
        "             print (\"the file for saving Exist and some error happened\")\n",
        "       doc = Document()\n",
        "\n",
        "\n",
        "    else :\n",
        "\n",
        "    # If the DOCX file exists, open it\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"#+str(random.randint(0,9))+\".docx\"\n",
        "       doc = Document(docx_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Add the generated text to the document\n",
        "    p = doc.add_paragraph(prompt_my)\n",
        "    # Add the generated text to the document\n",
        "    # Add the generated text to the document\n",
        "    p.style = doc.styles['Subtitle']\n",
        "\n",
        "    font = p.style.font\n",
        "    font.name = 'Arial'\n",
        "    font.size = Pt(15)\n",
        "    p = add_text_with_bold(doc,prompt_my,p)\n",
        "    p.style = doc.styles['Subtitle']\n",
        "\n",
        "  else:\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"\n",
        "    #print(docx_path)\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "    doc = Document()\n",
        "\n",
        "    # Add the generated text to the document\n",
        "    p = doc.add_paragraph()#prompt_my)\n",
        "    # Add the generated text to the document\n",
        "    # Add the generated text to the document\n",
        "    p.style = doc.styles['Title']\n",
        "    p = add_text_with_bold(doc,f\"{Repost_Type_Title} For:\"+ prompt_my,p)\n",
        "\n",
        "    p.style = doc.styles['Title']\n",
        "\n",
        "  #p = add_text_with_bold(doc,prompt_my,p)  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Revert the style of the paragraph back to 'Normal'\n",
        "  p = doc.add_paragraph()#contnet)\n",
        "  p.style = doc.styles['Normal']\n",
        "\n",
        "  p = add_text_with_bold(doc,contnet,p) # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Convert the DOCX file to a PDF\n",
        "  convert_docx_to_pdf(docx_path,Pdf_Dir)\n",
        "  return docx_path,Pdf_Dir\n",
        "\n",
        "#save_academic_paper_with_prompt_Tile('title','**prmpt_mt** is ','contetn',0)\n",
        "#save_academic_paper_with_prompt('title','**prmpt_mt**','content ',0)"
      ],
      "metadata": {
        "id": "FXS5P81E2rId",
        "outputId": "7f0aec7d-53aa-4b5b-ff46-dbef6a15eeb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive is already mounted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# @title\n",
        "# conect to [Mega.z](https://mega.nz/) cloud for storage files based ot this page:\n",
        "\n",
        "https://colab.research.google.com/github/sudo-ken/Mega-to-Google-Drive/blob/master/Transfer_files_from_Mega_to_Google_Drive.ipynb#scrollTo=Vgh1xlQYGZCO"
      ],
      "metadata": {
        "id": "x7XWsP_amNqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# %cd '/content/'\n",
        "# !git clone https://github.com/jeroenmeulenaar/python3-mega.git\n",
        "# !(cd python3-mega; pip install urlobject pycrypto)\n",
        "\n",
        "# import os\n",
        "# os.chdir('python3-mega')\n",
        "# from mega import Mega\n",
        "# os.chdir('../')\n",
        "# m = Mega.from_ephemeral()\n",
        "\n",
        "# !git clone https://github.com/odwyersoftware/mega.py\n",
        "# %cd mega.py\n",
        "# !python setup.py install\n",
        "%cd '/content/'\n",
        "\n",
        "!rm -rf '/content/yoloOnGoogleColab'\n",
        "#!git clone https://github.com/CAR-Driving/yoloOnGoogleColab"
      ],
      "metadata": {
        "id": "L436PiVNmQog",
        "outputId": "6fa8b7ab-58ef-4902-d4e3-01f710bb4412",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# @markdown <center><h3>Input Your Mega ID</h3></center><br>\n",
        "from functools import wraps\n",
        "import errno\n",
        "import os\n",
        "import signal\n",
        "import subprocess\n",
        "import shlex\n",
        "\n",
        "\n",
        "class TimeoutError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "def timeout(seconds=10, error_message=os.strerror(errno.ETIME)):\n",
        "    def decorator(func):\n",
        "        def _handle_timeout(signum, frame):\n",
        "            raise TimeoutError(error_message)\n",
        "\n",
        "        def wrapper(*args, **kwargs):\n",
        "            signal.signal(signal.SIGALRM, _handle_timeout)\n",
        "            signal.alarm(seconds)\n",
        "            try:\n",
        "                result = func(*args, **kwargs)\n",
        "            finally:\n",
        "                signal.alarm(0)\n",
        "            return result\n",
        "\n",
        "        return wraps(func)(wrapper)\n",
        "\n",
        "    return decorator\n",
        "\n",
        "\n",
        "if not os.path.exists(\"/root/.ipython/ocr.py\"):\n",
        "    from subprocess import run\n",
        "    from shlex import split\n",
        "\n",
        "    shellCmd = \"wget -qq https://raw.githubusercontent.com/biplobsd/OneClickRun/master/res/ocr.py \\\n",
        "                    -O /root/.ipython/ocr.py\"\n",
        "    run(split(shellCmd))\n",
        "from ocr import runSh\n",
        "\n",
        "@timeout(10)\n",
        "def runShT(args):\n",
        "    return runSh(args, output=True)\n",
        "\n",
        "\n",
        "# MEGAcmd installing\n",
        "if not os.path.exists(\"/usr/bin/mega-cmd\"):\n",
        "    print(\"Installing MEGA ...\")\n",
        "    runSh('sudo apt-get -y update')\n",
        "    runSh('sudo apt-get -y install libmms0 libc-ares2 libc6 libcrypto++6 libgcc1 libmediainfo0v5 libpcre3 libpcrecpp0v5 libssl1.1 libstdc++6 libzen0v5 zlib1g apt-transport-https')\n",
        "    runSh('sudo curl -sL -o /var/cache/apt/archives/MEGAcmd.deb https://mega.nz/linux/MEGAsync/Debian_9.0/amd64/megacmd-Debian_9.0_amd64.deb', output=True)\n",
        "    runSh('sudo dpkg -i /var/cache/apt/archives/MEGAcmd.deb', output=True)\n",
        "    print(\"MEGA is installed.\")\n",
        "else:\n",
        "    !pkill mega-cmd\n",
        "\n",
        "# INPUT YOUR MEGA ID\n",
        "\n",
        "USERNAME = 'kayeyoc231@llubed.com'  # @param {type:\"string\"}\n",
        "PASSWORD = \"ss123456\"  # @param {type:\"string\"}\n",
        "if not (USERNAME == \"\" or PASSWORD == \"\"):\n",
        "    try:\n",
        "        runShT(f\"mega-login {USERNAME} {PASSWORD}\")\n",
        "        print (\"megazn login has done successfully\")\n",
        "    except TimeoutError:\n",
        "        runSh('mega-whoami', output=True)\n",
        "else:\n",
        "    print(\"Please Input your Mega IDs.\")\n",
        "# @markdown *After signing in, use the above cell(Main Cell) to transfer files from Mega to GDrive using the transfer quota of your Mega Pro Account*"
      ],
      "metadata": {
        "id": "uqYuzvYFoMIM",
        "outputId": "e00c3f9a-2921-4024-e10e-7be9c35040e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Initiating MEGAcmd server in background. Log: /root/.megaCmd/megacmdserver.log]\n",
            "Unable to connect to service: error=2\n",
            "Please ensure mega-cmd-server is running\n",
            "Failed to create socket for registering for state changes\n",
            "megazn login has done successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#!rm -rf '/content/ChatGPT_academic_paper'\n",
        "!mkdir '/content/ChatGPT_academic_paper'\n",
        "%cd '/content/ChatGPT_academic_paper'\n",
        "!echo 't' >> t.txt\n",
        "\n",
        "from subprocess import Popen, PIPE\n",
        "import shlex\n",
        "import errno, os\n",
        "\n",
        "from subprocess import Popen, PIPE\n",
        "import shlex\n",
        "from ocr import runSh\n",
        "import re\n",
        "from distutils.dir_util import copy_tree\n",
        "\n",
        "# copy subdirectory example\n",
        "fromDirectory = '/content/ChatGPT_academic_paper/'\n",
        "toDirectory = '/content/gdrive/My Drive/yolo_car_database/'\n",
        "\n",
        "runSh('mega-cd /' )\n",
        "runSh(' mega-mkdir ChatGPT_academic_paper ')\n",
        "runSh(' mega-ls ')\n",
        "runSh('mega-cd ChatGPT_academic_paper ')\n",
        "\n",
        "# copy_tree(fromDirectory, toDirectory)\n",
        "def uplaod_mega_nz(root,cloude='mega',title1=''):\n",
        "  if (cloude=='mega'):\n",
        "  #  from mega import Mega\n",
        "  #  mega = Mega()\n",
        "  #  email = 'woraqofa@ivyandmarj.com'\n",
        "  #  password = 'feripas800@wgraj.com'\n",
        "  #  m = mega.login(email, password)\n",
        "  #  # login using a temporary anonymous account\n",
        "  #  m = mega.login()\n",
        "  #  quota = m.get_quota()\n",
        "  #  # specify unit output kilo, mega, gig, else bytes will output\n",
        "  #  space = m.get_storage_space(kilo=True)\n",
        "  #  m.create_folder('yolo_car_database/'+title1+'/')\n",
        "  #  folder = m.find('yolo_car_database/'+title1+'/')\n",
        "   # m.upload('myfile.doc', folder[0])\n",
        "  #  run_command('mega-cd ~ && mega-mkdir Yolo_car_database && mega-cd Yolo_car_database && mega-put '+ root+'/* . ')\n",
        "\n",
        "   runSh('mega-cd ChatGPT_academic_paper' + title1 + '/')\n",
        "   runSh('mega-put '+ root+' . ')\n",
        "   runSh(' mega-ls')\n",
        "\n",
        "   for path, subdirs, files in os.walk( root):\n",
        "      for name in files:\n",
        "        print (files)\n",
        "          # m.upload(os.path.join(path, name), folder[0])\n",
        "   # public_exported_web_link = m.export('myfile.doc')\n",
        "   # public_exported_web_link = m.export('my_mega_folder/my_sub_folder_to_share')\n",
        "\n",
        "  if (cloude=='google_drive'):\n",
        "     run_command('mkdir '+root+'/')\n",
        "     for path, subdirs, files in os.walk( root):\n",
        "      for name in files:\n",
        "        # print ('cp -r \"'+os.path.join(path, name)+'\" '+'\"/content/gdrive/My Drive/ChatGPT_academic_paper/' + title1 + '/\"')\n",
        "        # print (os.path.join(path, change_name(name)))\n",
        "        # os.rename(os.path.join(path, name), os.path.join(path, change_name(name)))\n",
        "        run_command('cp -r  \"'+os.path.join(path, name)+'\" '+'\"/content/gdrive/My Drive/ChatGPT_academic_paper/' + title1 + '/\"')\n",
        "     try:\n",
        "        copy_tree(root,'/content/gdrive/My Drive/ChatGPT_academic_paper/' + title1 + '/')\n",
        "     except OSError as e: # this would be \"except OSError, e:\" before Python 2.6\n",
        "        if e.errno != errno.ENOENT: # errno.ENOENT = no such file or directory\n",
        "            # raise #\n",
        "            i=0\n",
        "def change_file_name(root):\n",
        "  for path, subdirs, files in os.walk( root):\n",
        "      for name in files:\n",
        "        print ('filename is: \"'+os.path.join(path, name))\n",
        "        print (os.path.join(path, change_name(name)))\n",
        "        os.rename(os.path.join(path, name), os.path.join(path, change_name(name)))\n",
        "\n",
        "def run_command(cmd):\n",
        "    with Popen(shlex.split(cmd), stdout=PIPE, bufsize=1, universal_newlines=False) as p:\n",
        "        while True:\n",
        "            line = p.stdout.readline()\n",
        "            if not line:\n",
        "                break\n",
        "            print(line)\n",
        "        exit_code = p.poll()\n",
        "    return exit_code\n",
        "def change_name(name):\n",
        "    name_file = ''.join(name)\n",
        "    name_file = name_file.replace(\" \", \"_\")\n",
        "    name_file = name_file.replace(\"'\", \"_\")\n",
        "    name_file = name_file.replace(\"\\n\", \"\")\n",
        "    name_file = name_file.replace(\"\\t\", \"\")\n",
        "    name_file = name_file.replace(\"!\", \"\")\n",
        "    name_file = name_file.replace(\"-\", \"\")\n",
        "    name_file = name_file.replace(\"$\", \"\")\n",
        "    name_file = re.sub(r'[\\\\/*?:\"<>|]',\"\",name_file)\n",
        "    return name_file\n",
        "def MegaZN_upload_file(command):\n",
        "    # command_title=re.split('([^a-zA-Z0-9])',command)\n",
        "    command_title_1 = re.split('([^a-zA-Z0-9])', command)\n",
        "    command_title = ''.join(command_title_1)\n",
        "    command_title=change_name(command_title)\n",
        "\n",
        "\n",
        "    # call_args = ' youtube-dl --match-title ' + ' \"'+command_title_1[0]+ '\" ' + '\"ytsearch10\":'+'\"'+command+ '\" '+\"--external-downloader-args   '-ss 00:00:03 -t 00:03:08' --write-info-json --write-annotation --write-thumbnail --write-sub -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4'\"\n",
        "    #call_args = ' youtube-dl --match-title ' + ' \"'+command_title_1[0]+ '\" ' + '\"ytsearch100\":'+'\"'+command+ '\" '+\"--playlist-end 3  --external-downloader-args   '-ss 00:00:03 -t 00:03:08' --write-info-json --write-annotation --write-thumbnail --write-sub -f 'best[ext=mp4,height<=1080]+best[filesize<100M]' \"\n",
        "\n",
        "    # call_args = call_args.split() # because call takes a list of strings\n",
        "    # print (call_args)\n",
        "    # call(call_args)\n",
        "    # os.chdir(\"/content/yolo_car_database\")\n",
        "    # run_command('cd \"/content/yolo_car_database\"')\n",
        "    # run_command(call_args)\n",
        "    # os.system(\"cp --recursive '/content/yolo_car_database' '/content/gdrive/My Drive/yolo_car_databe\")\n",
        "    # os.system('pwd && ls ')\n",
        "    # copy_tree(fromDirectory, toDirectory)\n",
        "    # p = Popen(shlex.split(call_args), bufsize=1, universal_newlines=True)\n",
        "    run_command('mkdir /content/ChatGPT_academic_paper/'+command_title)\n",
        "\n",
        "    os.chdir( '/content/ChatGPT_academic_paper/'+command_title+'/')\n",
        "    #run_command(call_args)\n",
        "    # copy_tree('/content/yolo_car_database/'+command_title+'/', '/content/gdrive/My Drive/yolo_car_database/'+command_title+'/')\n",
        "    change_file_name('/content/ChatGPT_academic_paper/'+command_title+'/')\n",
        "    uplaod_mega_nz('/content/ChatGPT_academic_paper/'+command_title+'/','mega',command_title)\n",
        "    try:\n",
        "        # call(call_args)\n",
        "        # run_command('mkdir /content/yolo_car_database/'+command_title)\n",
        "        # os.chdir( '/content/yolo_car_database/'+command_title+'/')\n",
        "        # run_command(call_args)\n",
        "        # copy_tree('/content/yolo_car_database/'+command_title+'/', toDirectory)\n",
        "\n",
        "        # print (call_args)\n",
        "        pp=0\n",
        "\n",
        "    except OSError as e: # this would be \"except OSError, e:\" before Python 2.6\n",
        "        if e.errno != errno.ENOENT: # errno.ENOENT = no such file or directory\n",
        "            raise # re-raise exception if a different error occurred\n",
        "\n",
        "    # return p.poll()\n",
        "\n",
        "# !wget https://github.com/spectrico/car-make-model-classifier-yolo3-python/blob/master/labels.txt\n",
        "\n",
        "i=0\n",
        "#for line in open('/content/yoloOnGoogleColab/car_type_label.txt','r').readlines():\n",
        "    #print (line)\n",
        "    #try:\n",
        "      #Youtube_download_video(line)\n",
        "\n",
        "    #except OSError as e: # this would be \"except OSError, e:\" before Python 2.6\n",
        "        #if e.errno != errno.ENOENT: # errno.ENOENT = no such file or directory\n",
        "            #i=1 # re-raise exception if a different error occurred\n",
        "    #i=i+1\n",
        "# !cp '/content/yolo_car_database' \"gdrive/My Drive/yolo_car_databe\""
      ],
      "metadata": {
        "id": "8Fx5M6zXmTAX",
        "outputId": "9d1a756b-5ced-4713-cb56-bf1296748bd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/ChatGPT_academic_paper’: File exists\n",
            "/content/ChatGPT_academic_paper\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!pwd\n",
        "%cd '/content/'\n",
        "from google.colab import drive\n",
        "import os\n",
        "import subprocess\n",
        "from docx import Document\n",
        "from django.utils.text import slugify\n",
        "\n",
        "# Mount Google Drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "def save_academic_paper_with_prompt_megazn(topic, prompt_my,contnet):\n",
        "  # Define the path to the folder in Google Drive\n",
        "  folder_path = r\"/content/ChatGPT_academic_paper/\"\n",
        "\n",
        "  Pdf_Dir= r\"/content/ChatGPT_academic_paper/\"\n",
        "  docx_path= f\"{folder_path}{topic}.docx\"\n",
        "  # Check if the folder exists\n",
        "  if not os.path.exists(folder_path):\n",
        "  # If the folder doesn't exist, create it\n",
        "    os.mkdir(folder_path)\n",
        "\n",
        "\n",
        "  # Replace spaces in the topic with underscores\n",
        "  #topic = topic[:12].replace(\" \", \"_\")\n",
        "  topic = slugify(topic)\n",
        "\n",
        "  # Define the path to the DOCX file in the folder\n",
        "\n",
        "\n",
        "  # Check if the DOCX file exists\n",
        "  if os.path.isfile(docx_path):\n",
        "    # If the DOCX file exists, open it\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"#+str(random.randint(0,9))+\".docx\"\n",
        "    doc = Document(docx_path)\n",
        "  else:\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"\n",
        "    #print(docx_path)\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "    doc = Document()\n",
        "\n",
        "  # Add the generated text to the document\n",
        "  p = doc.add_paragraph(prompt_my)\n",
        "  # Add the generated text to the document\n",
        "  # Add the generated text to the document\n",
        "  p.style = doc.styles['Heading 2']\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Revert the style of the paragraph back to 'Normal'\n",
        "  p = doc.add_paragraph(contnet)\n",
        "  p.style = doc.styles['Normal']\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Convert the DOCX file to a PDF\n",
        "  convert_docx_to_pdf(docx_path,Pdf_Dir)\n",
        "\n",
        "  os.chdir(folder_path)\n",
        "\n",
        "    # copy_tree('/content/yolo_car_database/'+command_title+'/', '/content/gdrive/My Drive/yolo_car_database/'+command_title+'/')\n",
        "\n",
        "  uplaod_mega_nz('/content/ChatGPT_Paper_wrting/')\n",
        "  uplaod_mega_nz('/content/ChatGPT_Paper_wrting/','google_drive')\n",
        "  return docx_path,Pdf_Dir"
      ],
      "metadata": {
        "id": "nv2vAOr8sskq",
        "outputId": "37acfab1-8bc4-44ee-cc27-8c96d4aefba2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ChatGPT_academic_paper\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#save_academic_paper(\"Persian_\"+'topic','\\n**'+'choice_translated_prompt'+'**\\n'+\"choice_translated\")\n",
        "topic = TOPIC[:20].replace(\" \", \"_\")\n",
        "topic = slugify(TOPIC[:-5])\n",
        "docx_path = f\"{topic}.docx\"\n",
        "\n",
        "print(docx_path)"
      ],
      "metadata": {
        "id": "a76qNIRHs_gS",
        "outputId": "3afa6834-6f22-4942-a8d7-0db30461e12f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "empowerher-cinema-revolutionizing-youtube-with-ai-for-women-in.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qQOCu3GyEFf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#I have tried to update the prompt by ChatGPT itself 👇👇"
      ],
      "metadata": {
        "id": "wxqM4h1fw4fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_main_variables(prompts, variable):\n",
        "   main_variables= main_variables_0\n",
        "   for prompt in prompts:\n",
        "       variables = re.findall(r'\\{(\\w+)\\}', prompt)\n",
        "       for var in variables:\n",
        "           if var == 'TOPIC':\n",
        "               main_variables[var] = variable\n",
        "           else:\n",
        "               main_variables[var] = None\n",
        "\n",
        "   return main_variables"
      ],
      "metadata": {
        "id": "Jd711_MyBgje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_main_variables(prompts, variable_para, var_content):\n",
        "    main_variables = main_variables_0\n",
        "\n",
        "    new_prompt = prompts[:]  # Create a deep copy of prompts\n",
        "\n",
        "    for i, prompt in enumerate(prompts):\n",
        "        for var in variable_para:\n",
        "            if var == variable_para :\n",
        "                main_variables[var] = var_content\n",
        "                new_prompt[i] = prompt.replace(var, var_content)\n",
        "        for var, value in main_variables.items():\n",
        "             if var == variable_para:\n",
        "                main_variables[var] = var_content\n",
        "                new_prompt[i] = new_prompt[i].replace('{'+var+'}', \"{\"+f\"{var}\"+'}'+f\" which is :{var_content}\")#f\"{{{variable}}}\")\n",
        "\n",
        "\n",
        "    return main_variables, new_prompt\n",
        "#TOPIC='my test topic'\n",
        "main_variables, prompt_new = extract_main_variables(prompts, 'TOPIC', TOPIC)\n",
        "print (\" topic is :\", TOPIC)\n",
        "print(\"main variable is :\", main_variables)\n",
        "print(\"new_prompt is :\", prompt_new)\n",
        "prompts= prompt_new\n",
        "print(\"prompt is :\", prompts)"
      ],
      "metadata": {
        "id": "VLFUpVSA2Pbr",
        "outputId": "d618a75e-6835-46b6-a923-e96975433e57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " topic is : EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film\n",
            "main variable is : {'TOPIC': 'EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film', 'RESEARCH_DOMAIN': 'Making Pitch deck file for the TOPIC ', 'PARAGRAPH': 'about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin...'}\n",
            "new_prompt is : ['suggest one Business Plans repost Title in less than 15 word, based of This Topic :(EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film) and the description:(about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin...).', '1.What are the key aspects of EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film that need to be addressed in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin...?', '2.Create a mind map of the main elements of EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film and how they are interconnected in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin....', '3.Write down ideas on sticky notes about how to improve EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... Then, group these ideas based on common themes.', '4.Take turns sharing ideas on how to improve EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... Make sure everyone has a chance to contribute.', '5.Think of ways to create the problem in EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... This will help you understand how to solve it.', '6.Apply the SCAMPER method to existing solutions or situations in EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... This will spark new ideas.', '7.Assemble a diverse group of people from various backgrounds and disciplines to tackle EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... This will ensure a more rounded and innovative solution.', '8.Envision a future state where EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film has been solved successfully in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... Starting from this endpoint, work backward to identify the series of events and decisions that led to that future.']\n",
            "prompt is : ['suggest one Business Plans repost Title in less than 15 word, based of This Topic :(EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film) and the description:(about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin...).', '1.What are the key aspects of EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film that need to be addressed in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin...?', '2.Create a mind map of the main elements of EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film and how they are interconnected in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin....', '3.Write down ideas on sticky notes about how to improve EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... Then, group these ideas based on common themes.', '4.Take turns sharing ideas on how to improve EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... Make sure everyone has a chance to contribute.', '5.Think of ways to create the problem in EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... This will help you understand how to solve it.', '6.Apply the SCAMPER method to existing solutions or situations in EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... This will spark new ideas.', '7.Assemble a diverse group of people from various backgrounds and disciplines to tackle EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... This will ensure a more rounded and innovative solution.', '8.Envision a future state where EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film has been solved successfully in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... Starting from this endpoint, work backward to identify the series of events and decisions that led to that future.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "\n",
        "def generate_prompt_from_response(previous_response, main_variables):\n",
        "   # Customize this logic based on your needs\n",
        "   # For simplicity, let's use the last 50 characters of the response as the new prompt\n",
        "   new_prompt = previous_response[-50:]\n",
        "\n",
        "   # Replace the main variables in the new prompt\n",
        "   for var, value in main_variables.items():\n",
        "       if value is not None:\n",
        "           new_prompt = new_prompt.replace(value, f\"{{{var}}}\")\n",
        "\n",
        "   return new_prompt\n",
        "\n",
        "# Example usage\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\"\n",
        "\n",
        "prompts_1 = [\n",
        "f\"Find a research topic for a PhD in the area of '{TOPIC}'\",\n",
        "\n",
        "]\n",
        "#prompts_2 = [\n",
        "#   \"I need to find information on renewable energy for a research paper that will be 1,500 words and must include eight sources.\",\n",
        "#   \"The research paper should cover the latest advancements in renewable energy technology.\"\n",
        "#]\n",
        "\n",
        "#main_variables,prompt_new = extract_main_variables(prompts,'TOPIC',TOPIC)\n",
        "#print(main_variables)\n",
        "\n",
        "#previous_response = \"Previous GPT response\"\n",
        "#new_prompt = generate_prompt_from_response(previous_response, main_variables)\n",
        "#print(new_prompt)\n",
        "#print ( prompts)"
      ],
      "metadata": {
        "id": "NYegFb6aq_h8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Updating the prompt by ChatGPT:👇👇"
      ],
      "metadata": {
        "id": "UgzzXkG9wjbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.get_encoding(encoding_name)\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "num_tokens_from_string(\"tiktoken is great!\", \"cl100k_base\")"
      ],
      "metadata": {
        "id": "oJ1QCUr62rtw",
        "outputId": "5686d01d-d6b2-4e27-eba5-d99c29113c1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt_update_0(prompt, previous_content, main_variables):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   # Replace the TOPIC variable in the prompt\n",
        "   for var, value in main_variables.items():\n",
        "       if var == 'TOPIC' and value is not None:\n",
        "           prompt = prompt.replace(f\"{{{var}}}\", value)\n",
        "\n",
        "   # Construct the instruction for updating the prompt\n",
        "   instruction = f\"Given the previous content:\\n\\n{previous_content}\\n\\nUpdate the prompt: {prompt}\"\n",
        "\n",
        "   # Create the completion with the instruction\n",
        "   completion = client.completions.create(\n",
        "       model=model_engine,\n",
        "       prompt=instruction,\n",
        "       max_tokens=max_tokens,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "\n",
        "   # Extract and return the updated prompt from the response\n",
        "   updated_prompt = completion.choices[0].text.strip()\n",
        "   return updated_prompt"
      ],
      "metadata": {
        "id": "QbOCQqCDB8xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "def generate_prompt_update_a1(prompt_my):\n",
        "  model_engine = \"text-davinci-003\"\n",
        "  max_tokens = 2048\n",
        "\n",
        "  completion = client.completions.create(\n",
        "      model=\"gpt-3.5-turbo-instruct\",\n",
        "      #model=\"curie\"\n",
        "      prompt=prompt_my,\n",
        "      max_tokens=2048,\n",
        "      temperature=0.3,\n",
        "      n=1,\n",
        "      frequency_penalty=0,\n",
        "  )\n",
        "  return completion"
      ],
      "metadata": {
        "id": "WPRw6qJOuaS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import openai\n",
        "from openai import RateLimitError\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   api_key = openai_api# \"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\",\n",
        ")\n",
        "def retry_with_exponential_backoff(\n",
        "   func,\n",
        "   initial_delay: float = 1,\n",
        "   exponential_base: float = 2,\n",
        "   jitter: bool = True,\n",
        "   max_retries: int = 10,\n",
        "   errors: tuple = (RateLimitError,),\n",
        "):\n",
        "   \"\"\"Retry a function with exponential backoff.\"\"\"\n",
        "   def wrapper(*args, **kwargs):\n",
        "       # Initialize variables\n",
        "       num_retries = 0\n",
        "       delay = initial_delay\n",
        "       # Loop until a successful response or max_retries is hit or an exception is raised\n",
        "       while True:\n",
        "           try:\n",
        "               return func(*args, **kwargs)\n",
        "           # Retry on specified errors\n",
        "           except errors as e:\n",
        "               # Increment retries\n",
        "               num_retries += 1\n",
        "               # Check if max retries has been reached\n",
        "               if num_retries > max_retries:\n",
        "                  raise Exception(\n",
        "                      f\"Maximum number of retries ({max_retries}) exceeded.\"\n",
        "                  )\n",
        "               # Increment the delay\n",
        "               delay *= exponential_base * (1 + jitter * random.random())\n",
        "               # Sleep for the delay\n",
        "               time.sleep(delay)\n",
        "           # Raise exceptions for any errors not specified\n",
        "           except Exception as e:\n",
        "               raise e\n",
        "   return wrapper\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "\n",
        "@retry_with_exponential_backoff\n",
        "def generate_prompt_update(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "   print(f\"{num_tokens_from_string(prompt_my,model)} prompt tokens counted by num_tokens_from_messages().\")\n",
        "\n",
        "   completion = client.completions.create(\n",
        "     model=\"gpt-3.5-turbo-instruct\",\n",
        "     prompt=prompt_my,\n",
        "     max_tokens=500,\n",
        "     temperature=0.1,\n",
        "     n=1,\n",
        "     frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "\n",
        "@retry_with_exponential_backoff\n",
        "def generate_academic_paper(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "   print(f\"{num_tokens_from_string(prompt_my,model)} prompt tokens counted by num_tokens_from_messages().\")\n",
        "\n",
        "\n",
        "   completion = client.completion.create(\n",
        "     #model=\"gpt-3.5-turbo-instruct\",\n",
        "     model=\"gpt-3.5-turbo-1106\",\n",
        "     prompt=prompt_my,\n",
        "     max_tokens=2048,\n",
        "     temperature=0.3,\n",
        "     n=1,\n",
        "     frequency_penalty=0,\n",
        "   )\n",
        "   return completion"
      ],
      "metadata": {
        "id": "O2TNMQ8eFl8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def generate_content(prompts, variables, TOPIC, perviuse_content=\"\"):\n",
        "  # Generate content for each variable\n",
        "  variable_contents = {}\n",
        "\n",
        "\n",
        "  main_variables = main_variables_0\n",
        "  for prompt in prompts:\n",
        "      for var in variables:\n",
        "          if var in prompt:\n",
        "              print(f\"\\n---prompt is ----\\n{prompt}\")\n",
        "              #prompt_my = f\"Generate content for the variable '{var}' in the context of the topic '{TOPIC}'. Please consider the result must be in less than 10 words. The prompt is '{prompt}'. Also the more information for understanding better content is '{perviuse_content}'\"\n",
        "\n",
        "              prompt_my = f\"Generate content for the variable '{var}' in the context of the topic '{TOPIC}'. Please consider the result must be sumerized and as variable for chatgpt academic phd writer assistance. The prompt is '{prompt}'. Also the more information for understanding better content is '{perviuse_content}'\"\n",
        "              content = generate_prompt_update_a1(prompt_my)\n",
        "              for choice in content.choices:\n",
        "                print(\"\\n Result is :\"+choice.text)\n",
        "                variable_contents[var] = choice.text\n",
        "              print(f\"variable_contents[{var}] is: {variable_contents[var]}\")\n",
        "\n",
        "              time.sleep(random.randint(22, 40))\n",
        "\n",
        "  # Replace the variables in the prompts with the generated content\n",
        "  prompt_new = []\n",
        "  for prompt in prompts:\n",
        "      for var, content in variable_contents.items():\n",
        "          prompt = prompt.replace(f\"{{{var}}}\", variable_contents[var])\n",
        "      prompt_new.append(prompt)\n",
        "      print(\"\\n --- Updated prompt is :\\n\"+str(prompt_new))\n",
        "  return prompt_new\n",
        "\n",
        "# Define main variables\n",
        "#TOPIC = \"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"\n",
        "\n",
        "# List of variables\n",
        "variables = [\"RESEARCH_DOMAIN\", \"PARAGRAPH\", \"PARAGRAPHS\", \"TOPIC_SENTENCE\", \"LANGUAGE\", \"ABSTRACT_PARAGRAPH\", \"BIBLIOGRAPHY\", \"THEORY1\", \"THEORY2\", \"RESEARCH_QUESTIONS\", \"ACTION\", \"RESULT_PARAGRAPHS\", \"DATE\", \"NUMBER_OF_DAYS_MONTHS_YEARS\"]\n",
        "\n",
        "# List of prompts\n",
        "#prompts = [\"prompt1\", \"prompt2\", \"prompt3\"] # replace with your actual prompts\n",
        "#perviuse_content= \"test\"\n",
        "# Call the function and store the returned prompts\n",
        "#updated_prompts = generate_content(prompts, variables, TOPIC, perviuse_content)\n",
        "#print(\"Updated Prompts:\", updated_prompts)"
      ],
      "metadata": {
        "id": "uI21enmkhb0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def generate_content_2(prompts, variables, TOPIC, perviuse_content=\"\"):\n",
        "  # Generate content for each variable\n",
        "  variable_contents = {}\n",
        "  main_variables = main_variables_0\n",
        "  for prompt in prompts:\n",
        "      for var in variables:\n",
        "          if var in prompt:\n",
        "              print(f\"\\n---prompt is ----\\n{prompt}\")\n",
        "              prompt_my = f\"Generate content for the variable '{var}' in the context of the topic '{TOPIC}'. Please consider the result must be in less than 10 words. The prompt is '{prompt}'. Also the more information for understanding better content is '{perviuse_content}'\"\n",
        "              content = generate_prompt_update_a1(prompt_my)\n",
        "              for choice in content.choices:\n",
        "                print(\"\\n Result is :\"+choice.text)\n",
        "                variable_contents[var] = choice.text\n",
        "              print(f\"variable_contents[{var}] is: {variable_contents[var]}\")\n",
        "\n",
        "              time.sleep(random.randint(22, 40))\n",
        "\n",
        "  main_variables, prompt_new = extract_main_variables(prompts, var, variable_contents[var])\n",
        "\n",
        "  print(\"main variable is :\", main_variables)\n",
        "  print(\"new_prompt is :\", prompt_new)\n",
        "  prompts= prompt_new\n",
        "\n",
        "  # Replace the variables in the prompts with the generated content\n",
        "  prompt_new = []\n",
        "  for prompt in prompts:\n",
        "      for var, content in variable_contents.items():\n",
        "          prompt = prompt.replace(f\"{{{var}}}\", variable_contents[var])\n",
        "      prompt_new.append(prompt)\n",
        "      print(\"\\n --- Updated prompt is :\\n\"+str(prompt_new))\n",
        "  return prompt_new,main_variables\n",
        "\n",
        "# Define main variables\n",
        "#TOPIC = \"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"\n",
        "\n",
        "# List of variables\n",
        "variables = [\"RESEARCH_DOMAIN\", \"PARAGRAPH\", \"PARAGRAPHS\", \"TOPIC_SENTENCE\", \"LANGUAGE\", \"ABSTRACT_PARAGRAPH\", \"BIBLIOGRAPHY\", \"THEORY1\", \"THEORY2\", \"RESEARCH_QUESTIONS\", \"ACTION\", \"RESULT_PARAGRAPHS\", \"DATE\", \"NUMBER_OF_DAYS_MONTHS_YEARS\"]\n",
        "\n",
        "# List of prompts\n",
        "#prompts = [\"prompt1\", \"prompt2\", \"prompt3\"] # replace with your actual prompts\n",
        "#perviuse_content= \"test\"\n",
        "# Call the function and store the returned prompts\n",
        "#updated_prompts = generate_content(prompts, variables, TOPIC, perviuse_content)\n",
        "#print(\"Updated Prompts:\", updated_prompts)"
      ],
      "metadata": {
        "id": "-tAXnnAOkagH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\" #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\"\n",
        "\n",
        "\n",
        "#topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "#client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   #api_key = \"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\",\n",
        "#)\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "# Create a Translator object\n",
        "translator = Translator()\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "def generate_academic_paper_a0(prompt_my):\n",
        "  model_engine = \"text-davinci-003\"\n",
        "  max_tokens = 2048\n",
        "\n",
        "  completion = client.completions.create(\n",
        "      model=\"gpt-3.5-turbo-instruct\",\n",
        "      prompt=prompt_my,\n",
        "      max_tokens=2048,\n",
        "      temperature=0.3,\n",
        "      n=1,\n",
        "      frequency_penalty=0,\n",
        "  )\n",
        "  return completion"
      ],
      "metadata": {
        "id": "44bkCJOHtmuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time,random\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   api_key = openai_api#\"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\",\n",
        ")\n",
        "global k\n",
        "k=0\n",
        "def generate_papers(prompts, perviuse_content, perviuse_try_numner):\n",
        "  choice_text_all=[]\n",
        "  global prompt_Word_Topic,k\n",
        "  prompt_Word_Topic_1 = prompt_Word_Topic\n",
        "\n",
        "\n",
        "  for i in range(perviuse_try_numner, len(prompts), 20):\n",
        "     # Slice the prompts list to get the next 20 prompts\n",
        "     print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "\n",
        "     batch = prompts[i:i+20]\n",
        "     print(\"batch is \",batch)\n",
        "\n",
        "\n",
        "\n",
        "     for prompt in batch:\n",
        "\n",
        "         # Print the prompt\n",
        "         print(\"prompt is \",list({prompt}))\n",
        "\n",
        "         updated_prompts = generate_content(list({prompt}), variables, TOPIC, perviuse_content)\n",
        "         print(\"Updated Prompts:\", updated_prompts)\n",
        "\n",
        "\n",
        "\n",
        "         time.sleep(random.randint(22, 40))\n",
        "         response = generate_academic_paper_a0(updated_prompts)\n",
        "         print(\"\\nGenerated Academic Paper:\")\n",
        "         print(\"========================\\n\")\n",
        "         for choice in response.choices:\n",
        "           print(choice.text)\n",
        "           choice_in_loop = choice.text\n",
        "           choice_text_all.append(choice.text)\n",
        "\n",
        "\n",
        "         #save_academic_paper(topic,'\\n--------**\\n'+updated_prompts+'/n-------**\\n'+choice.text)\n",
        "\n",
        "         if k == 0 :\n",
        "            prompt_Word_Topic_1[0] = choice.text\n",
        "            prompt_Word_Topic_1[0] = prompt_Word_Topic_1[0].replace ( '\"','')\n",
        "            print ('Prompt for topic is',prompt_Word_Topic_1[0]  )\n",
        "\n",
        "            save_academic_paper_with_prompt(TOPIC[:20]+\"_Prompt\",''.join(prompt_Word_Topic_1[k]),\"\",perviuse_try_numner)\n",
        "            save_academic_paper_with_prompt_Tile(TOPIC[:20]+\"_T\",''.join(prompt_Word_Topic_1[k]),\"\",perviuse_try_numner)\n",
        "\n",
        "         else :\n",
        "            save_academic_paper_with_prompt(TOPIC[:20]+\"_Prompt\",'\\n**<<<  ChatGPT Prompt is:\\n'+''.join(updated_prompts)+'\\n>>>**\\n',choice.text,perviuse_try_numner)\n",
        "            save_academic_paper_with_prompt_Tile(TOPIC[:20]+'_T','\\n'+''.join(prompt_Word_Topic_1[k])+'\\n',choice.text,perviuse_try_numner)\n",
        "\n",
        "\n",
        "\n",
        "         save_academic_paper_with_prompt_megazn(TOPIC[:20],'\\n**<<<  ChatGPT Prompt is:\\n'+''.join(updated_prompts)+'\\n>>>**\\n',choice.text)\n",
        "         #save_academic_paper_with_prompt_megazn(TOPIC[:20],'\\n**<<<  ChatGPT Prompt is:\\n'+''.join(updated_prompts)+'\\n>>>**\\n',choice.text, 'google_drive')\n",
        "         if hasattr(choice, 'choices'):\n",
        "             extract_text(choice)\n",
        "\n",
        "         perviuse_content = choice_in_loop\n",
        "         print(\"\\n end of loop\")\n",
        "         print(\"========================\\n\")\n",
        "\n",
        "         time.sleep(random.randint(22, 40))\n",
        "         perviuse_try_numner = perviuse_try_numner+1\n",
        "         k=k+1\n",
        "  return choice_text_all,perviuse_try_numner\n",
        "\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\" #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\""
      ],
      "metadata": {
        "id": "Uf6RCPBz3aqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Final Results 👇🌹🌱"
      ],
      "metadata": {
        "id": "xHPMNDjfToIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from django.utils.text import slugify\n",
        "\n",
        "\n",
        "\n",
        "def main_generate_papers(TOPIC, prompts, perviuse_content, perviuse_try_numner):\n",
        "    if not perviuse_try_numner:\n",
        "        perviuse_try_numner = 0\n",
        "        perviuse_content = ['fist step']\n",
        "\n",
        "    elif (perviuse_try_numner == len(prompts)):\n",
        "        perviuse_try_numner = 0\n",
        "        perviuse_content = ['fist step']\n",
        "\n",
        "    generate_papers(prompts, perviuse_content, perviuse_try_numner)\n",
        "\n",
        "    return perviuse_content, perviuse_try_numner\n",
        "\n",
        "topic = TOPIC_CLASS()\n",
        "\n",
        "if not topic.perviuse_try_numner:\n",
        "    topic.perviuse_try_numner = 0\n",
        "    topic.perviuse_content = ['fist step']\n",
        "\n",
        "elif (topic.perviuse_try_numner == len(prompts)):\n",
        "    topic.perviuse_try_numner = 0\n",
        "    topic.perviuse_content = ['fist step']\n",
        "\n",
        "topic.topic = TOPIC\n",
        "main_generate_papers(topic.topic, prompts, topic.perviuse_content, topic.perviuse_try_numner)"
      ],
      "metadata": {
        "id": "-YbWDEd4WzDq",
        "outputId": "9bf5cd37-12f6-4cd0-e272-411ade0dd515",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I is  0  Len of prompt Is: 9\n",
            "batch is  ['suggest one Business Plans repost Title in less than 15 word, based of This Topic :(EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film) and the description:(about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin...).', '1.What are the key aspects of EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film that need to be addressed in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin...?', '2.Create a mind map of the main elements of EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film and how they are interconnected in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin....', '3.Write down ideas on sticky notes about how to improve EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... Then, group these ideas based on common themes.', '4.Take turns sharing ideas on how to improve EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... Make sure everyone has a chance to contribute.', '5.Think of ways to create the problem in EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... This will help you understand how to solve it.', '6.Apply the SCAMPER method to existing solutions or situations in EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... This will spark new ideas.', '7.Assemble a diverse group of people from various backgrounds and disciplines to tackle EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... This will ensure a more rounded and innovative solution.', '8.Envision a future state where EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film has been solved successfully in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... Starting from this endpoint, work backward to identify the series of events and decisions that led to that future.']\n",
            "prompt is  ['suggest one Business Plans repost Title in less than 15 word, based of This Topic :(EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film) and the description:(about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin...).']\n",
            "\n",
            " --- Updated prompt is :\n",
            "['suggest one Business Plans repost Title in less than 15 word, based of This Topic :(EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film) and the description:(about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin...).']\n",
            "Updated Prompts: ['suggest one Business Plans repost Title in less than 15 word, based of This Topic :(EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film) and the description:(about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin...).']\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "\"Empowering Women in Film: AI-Driven YouTube Channel for Artistic Revolution\"\n",
            "Prompt for topic is \n",
            "\n",
            "Empowering Women in Film: AI-Driven YouTube Channel for Artistic Revolution\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  ['1.What are the key aspects of EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film that need to be addressed in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin...?']\n",
            "\n",
            " --- Updated prompt is :\n",
            "['1.What are the key aspects of EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film that need to be addressed in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin...?']\n",
            "Updated Prompts: ['1.What are the key aspects of EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film that need to be addressed in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin...?']\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "1. Purpose and Mission: The first key aspect to consider when creating an art YouTube channel for empowering women in film is to clearly define the purpose and mission of the channel. This should align with the overall goal of EmpowerHer Cinema, which is to use AI technology to promote and support women in the film industry. The channel should have a clear focus on showcasing and promoting the work of female filmmakers, as well as providing resources and support for women in the industry.\n",
            "\n",
            "2. Content Strategy: The next important aspect to consider is the content strategy for the channel. This should include a mix of different types of content, such as interviews with female filmmakers, behind-the-scenes footage, film reviews, and educational videos. The content should be engaging, informative, and relevant to the target audience.\n",
            "\n",
            "3. Use of AI Technology: As EmpowerHer Cinema utilizes AI technology to create content, it is important to consider how this can be incorporated into the art YouTube channel. This could include using AI to generate video ideas, create thumbnails, or even assist with video editing. It is important to strike a balance between using AI technology and maintaining a human touch in the content.\n",
            "\n",
            "4. Collaboration and Networking: Another key aspect to consider is collaboration and networking with other female filmmakers and industry professionals. This can help to expand the reach of the channel and create a supportive community for women in film. It is important to reach out to other channels and creators who share a similar mission and collaborate on projects or cross-promote each other's content.\n",
            "\n",
            "5. Branding and Marketing: Creating a strong brand and marketing strategy is crucial for the success of the channel. This includes creating a visually appealing channel design, using keywords and tags to optimize searchability, and promoting the channel through social media and other platforms.\n",
            "\n",
            "6. Community Engagement: The success of the channel will also depend on building a strong and engaged community. This can be achieved through actively responding to comments, hosting live Q&A sessions, and creating a sense of inclusivity and support for women in the film industry.\n",
            "\n",
            "7. Consistency and Quality: Finally, it is important to maintain consistency and quality in the content being produced. This means regularly uploading new videos, ensuring high production value, and continuously improving the content based on audience feedback.\n",
            "\n",
            "Overall, creating an art YouTube channel for empowering women in film should align with the key aspects of EmpowerHer Cinema, while also incorporating a unique and creative approach to showcasing and supporting female filmmakers. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  ['2.Create a mind map of the main elements of EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film and how they are interconnected in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin....']\n",
            "\n",
            " --- Updated prompt is :\n",
            "['2.Create a mind map of the main elements of EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film and how they are interconnected in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin....']\n",
            "Updated Prompts: ['2.Create a mind map of the main elements of EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film and how they are interconnected in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin....']\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "Main Elements of EmpowerHer Cinema:\n",
            "\n",
            "1. YouTube Channel: The main platform for EmpowerHer Cinema, where videos will be uploaded and shared with the audience.\n",
            "\n",
            "2. AI Technology: The use of artificial intelligence technology to automatically create content and videos for the channel.\n",
            "\n",
            "3. Women in Film: The target audience of EmpowerHer Cinema, with a focus on empowering and promoting women in the film industry.\n",
            "\n",
            "4. Empowerment: The main goal of the channel, to empower and support women in the film industry through the content and videos created.\n",
            "\n",
            "5. Art: The medium through which EmpowerHer Cinema will convey its message and empower women in film.\n",
            "\n",
            "6. Diversity and Inclusion: A key aspect of EmpowerHer Cinema, promoting diversity and inclusion in the film industry and showcasing the work of women from different backgrounds.\n",
            "\n",
            "7. Collaboration: Working with other women in film and partnering with organizations and brands to amplify the message of EmpowerHer Cinema.\n",
            "\n",
            "8. Education: Providing educational content and resources for women in film to develop their skills and knowledge.\n",
            "\n",
            "9. Community: Building a community of women in film through the channel, connecting and supporting each other.\n",
            "\n",
            "10. Social Media: Using social media platforms to promote and share the content of EmpowerHer Cinema and engage with the audience.\n",
            "\n",
            "Interconnections:\n",
            "\n",
            "1. The YouTube channel is the main platform for EmpowerHer Cinema, where all the elements come together to achieve the goal of empowering women in film.\n",
            "\n",
            "2. AI technology is used to create content and videos for the channel, making it more efficient and accessible.\n",
            "\n",
            "3. The target audience of EmpowerHer Cinema is women in film, and the channel aims to empower and support them through its content.\n",
            "\n",
            "4. The main goal of the channel is to empower women in film, and this is achieved through the use of art as a medium to convey the message.\n",
            "\n",
            "5. Diversity and inclusion are important aspects of EmpowerHer Cinema, and the channel showcases the work of women from different backgrounds to promote these values.\n",
            "\n",
            "6. Collaboration with other women in film and partnering with organizations and brands helps to amplify the message of EmpowerHer Cinema and reach a wider audience.\n",
            "\n",
            "7. Education is provided through the channel to help women in film develop their skills and knowledge.\n",
            "\n",
            "8. The community of women in film is built through the channel, connecting and supporting each other.\n",
            "\n",
            "9. Social media is used to promote and share the content of EmpowerHer Cinema, engaging with the audience and building a larger community.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  ['3.Write down ideas on sticky notes about how to improve EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... Then, group these ideas based on common themes.']\n",
            "\n",
            " --- Updated prompt is :\n",
            "['3.Write down ideas on sticky notes about how to improve EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... Then, group these ideas based on common themes.']\n",
            "Updated Prompts: ['3.Write down ideas on sticky notes about how to improve EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... Then, group these ideas based on common themes.']\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "1. Utilize AI technology to curate and recommend content by and about women in film\n",
            "2. Collaborate with female filmmakers and artists to create original content for the channel\n",
            "3. Offer workshops and tutorials on using AI technology for video editing and content creation\n",
            "4. Create a community for female filmmakers to connect and support each other\n",
            "5. Highlight diverse voices and perspectives in the film industry through curated playlists and featured content\n",
            "6. Partner with organizations and events that support women in film to promote the channel and its content\n",
            "7. Use AI technology to analyze and improve the channel's reach and engagement with its audience\n",
            "8. Offer resources and tools for women in film, such as funding opportunities and networking opportunities\n",
            "9. Incorporate interactive elements, such as live Q&A sessions and polls, to engage with the audience and promote discussion on important issues in the film industry\n",
            "10. Collaborate with other art and media platforms to cross-promote and expand the channel's reach.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  ['4.Take turns sharing ideas on how to improve EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... Make sure everyone has a chance to contribute.']\n",
            "\n",
            " --- Updated prompt is :\n",
            "['4.Take turns sharing ideas on how to improve EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... Make sure everyone has a chance to contribute.']\n",
            "Updated Prompts: ['4.Take turns sharing ideas on how to improve EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... Make sure everyone has a chance to contribute.']\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "1. Collaborate with female filmmakers and content creators: Reach out to women in the film industry and collaborate with them to create content for the channel. This will not only bring diverse perspectives but also help in promoting their work and empowering them.\n",
            "\n",
            "2. Focus on diverse representation: Ensure that the channel features a diverse range of women from different backgrounds, cultures, and experiences. This will not only make the content more inclusive but also provide a platform for underrepresented voices.\n",
            "\n",
            "3. Use AI to curate content: Utilize AI technology to curate content that is relevant and engaging for the audience. This will save time and effort in manually searching for content and also help in discovering new and emerging female filmmakers.\n",
            "\n",
            "4. Host workshops and events: Organize workshops and events that focus on empowering women in the film industry. This could include panel discussions, masterclasses, and networking events. This will not only bring the community together but also provide valuable resources and knowledge for aspiring female filmmakers.\n",
            "\n",
            "5. Create a mentorship program: Set up a mentorship program where established female filmmakers can mentor and guide aspiring filmmakers. This will not only provide valuable guidance but also create a support system for women in the industry.\n",
            "\n",
            "6. Feature behind-the-scenes content: Showcasing the behind-the-scenes process of creating films can be inspiring and educational for aspiring filmmakers. Use AI to create engaging and informative content that gives a glimpse into the filmmaking process.\n",
            "\n",
            "7. Collaborate with film festivals: Partner with film festivals that focus on promoting women in film. This will not only provide a platform for showcasing content but also help in building a community of female filmmakers.\n",
            "\n",
            "8. Engage with the audience: Encourage audience engagement by asking for feedback, suggestions, and ideas for future content. This will not only make the audience feel involved but also help in understanding their preferences and interests.\n",
            "\n",
            "9. Utilize social media: Use social media platforms to promote the channel and reach a wider audience. This could include creating teasers, behind-the-scenes content, and engaging with followers.\n",
            "\n",
            "10. Constantly evolve and adapt: Keep up with the latest trends and technologies in the film industry and adapt accordingly. This will help in staying relevant and providing fresh and engaging content for the audience.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  ['5.Think of ways to create the problem in EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... This will help you understand how to solve it.']\n",
            "\n",
            " --- Updated prompt is :\n",
            "['5.Think of ways to create the problem in EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... This will help you understand how to solve it.']\n",
            "Updated Prompts: ['5.Think of ways to create the problem in EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... This will help you understand how to solve it.']\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "1. Lack of representation: One of the main problems in the film industry is the lack of representation of women, both on and off screen. This can also be seen in the content available on YouTube, where male creators dominate the platform. EmpowerHer Cinema can address this issue by using AI to automatically generate content that showcases the work of female filmmakers and highlights their achievements in the industry.\n",
            "\n",
            "2. Gender bias in film criticism: Women in film often face harsher criticism and scrutiny compared to their male counterparts. This can discourage them from pursuing their passion and can also affect the way their work is perceived by the audience. EmpowerHer Cinema can use AI to analyze and filter out biased comments and reviews, creating a more positive and supportive environment for female filmmakers.\n",
            "\n",
            "3. Limited access to resources: Starting a YouTube channel and creating high-quality content can be expensive and time-consuming. This can be a barrier for women who may not have the same financial resources or support as their male counterparts. EmpowerHer Cinema can use AI to automate the video-making process, making it more accessible and affordable for women to create and share their content.\n",
            "\n",
            "4. Lack of mentorship and networking opportunities: Women in the film industry often face challenges in finding mentors and networking opportunities, which are crucial for career growth. EmpowerHer Cinema can use AI to connect female filmmakers with experienced professionals in the industry, providing them with valuable guidance and networking opportunities.\n",
            "\n",
            "5. Gender stereotypes in content creation: The film industry is often criticized for perpetuating gender stereotypes and limiting the roles and stories of women on screen. EmpowerHer Cinema can use AI to analyze and identify these stereotypes in content and provide suggestions for more diverse and empowering narratives. This can help break the cycle of gender stereotypes in the film industry and promote more inclusive storytelling.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  ['6.Apply the SCAMPER method to existing solutions or situations in EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... This will spark new ideas.']\n",
            "\n",
            " --- Updated prompt is :\n",
            "['6.Apply the SCAMPER method to existing solutions or situations in EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... This will spark new ideas.']\n",
            "Updated Prompts: ['6.Apply the SCAMPER method to existing solutions or situations in EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... This will spark new ideas.']\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "S - Substitute: Instead of using AI for content creation, EmpowerHer Cinema could partner with female filmmakers and content creators to showcase their work and provide a platform for their voices to be heard.\n",
            "\n",
            "C - Combine: EmpowerHer Cinema could combine their AI technology with live events and workshops, where female filmmakers can come together to learn and collaborate.\n",
            "\n",
            "A - Adapt: EmpowerHer Cinema could adapt their AI technology to also include resources and tools for aspiring female filmmakers, such as tutorials, tips and tricks, and networking opportunities.\n",
            "\n",
            "M - Modify: Instead of solely focusing on YouTube, EmpowerHer Cinema could modify their platform to include other social media channels, such as Instagram and TikTok, to reach a wider audience and engage with younger generations.\n",
            "\n",
            "P - Put to another use: EmpowerHer Cinema could use their AI technology to create personalized film recommendations for viewers, based on their interests and preferences.\n",
            "\n",
            "E - Eliminate: EmpowerHer Cinema could eliminate the traditional film festival model and use their AI technology to curate and showcase female-led films on their platform, providing more opportunities for exposure and recognition.\n",
            "\n",
            "R - Reverse: Instead of only featuring female filmmakers and content creators, EmpowerHer Cinema could reverse their focus and also include male allies who support and promote gender equality in the film industry.\n",
            "\n",
            "By applying the SCAMPER method, EmpowerHer Cinema can continue to innovate and evolve their platform to better serve and empower women in the field of cinema.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  ['7.Assemble a diverse group of people from various backgrounds and disciplines to tackle EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... This will ensure a more rounded and innovative solution.']\n",
            "\n",
            " --- Updated prompt is :\n",
            "['7.Assemble a diverse group of people from various backgrounds and disciplines to tackle EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... This will ensure a more rounded and innovative solution.']\n",
            "Updated Prompts: ['7.Assemble a diverse group of people from various backgrounds and disciplines to tackle EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... This will ensure a more rounded and innovative solution.']\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            " The group should include:\n",
            "\n",
            "1. Filmmakers: These individuals will bring their expertise in the film industry and provide insights into the specific needs and challenges faced by women in the field.\n",
            "\n",
            "2. AI experts: As the proposed channel will use AI technology, it is important to have experts in this field who can provide technical knowledge and guidance on how to effectively utilize AI for content creation.\n",
            "\n",
            "3. Gender equality advocates: Including individuals who are passionate about promoting gender equality and empowering women in all industries will bring a valuable perspective to the discussion.\n",
            "\n",
            "4. Content creators: This could include YouTubers, bloggers, and other individuals who have experience in creating content for online platforms. They can provide insights on what type of content resonates with audiences and how to make it engaging.\n",
            "\n",
            "5. Marketing professionals: To ensure the success of the channel, it is important to have individuals who can provide guidance on how to effectively market and promote the content to reach a wider audience.\n",
            "\n",
            "6. Diversity and inclusion experts: These individuals can provide insights on how to ensure the channel is inclusive and representative of diverse voices and perspectives.\n",
            "\n",
            "7. Women in film organizations: Inviting representatives from organizations that support and advocate for women in the film industry will bring valuable insights and connections to the project.\n",
            "\n",
            "8. Social media influencers: Including individuals who have a strong presence on social media and can help promote the channel to a wider audience will be beneficial.\n",
            "\n",
            "9. Educators: Bringing in educators who specialize in film and media studies can provide a valuable academic perspective to the project.\n",
            "\n",
            "10. Women in film professionals: Inviting women who are currently working in the film industry, whether as directors, producers, writers, or other roles, will provide real-life experiences and insights into the challenges faced by women in the field.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  ['8.Envision a future state where EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film has been solved successfully in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... Starting from this endpoint, work backward to identify the series of events and decisions that led to that future.']\n",
            "\n",
            " --- Updated prompt is :\n",
            "['8.Envision a future state where EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film has been solved successfully in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... Starting from this endpoint, work backward to identify the series of events and decisions that led to that future.']\n",
            "Updated Prompts: ['8.Envision a future state where EmpowerHer Cinema: Revolutionizing YouTube with AI for Women in Film has been solved successfully in the context of about creating an art YouTube channel for empowering the women in the field of cinema . this chanel would use the automatic ai content and video makin.... Starting from this endpoint, work backward to identify the series of events and decisions that led to that future.']\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "1. EmpowerHer Cinema is founded by a group of women filmmakers who are passionate about promoting and empowering women in the film industry. They notice a lack of representation and opportunities for women in the industry and want to create a platform to change that.\n",
            "\n",
            "2. The founders conduct research and surveys to understand the challenges faced by women in the film industry. They find that one of the major barriers is the lack of visibility and exposure for female filmmakers, especially on popular platforms like YouTube.\n",
            "\n",
            "3. The team decides to create an art YouTube channel specifically for women in film, where they can showcase their work, share their experiences, and connect with other filmmakers.\n",
            "\n",
            "4. They face a challenge in creating content for the channel as they have limited resources and time. This is when they come up with the idea of using AI to automate the content creation process.\n",
            "\n",
            "5. The team starts working on developing an AI system that can generate video content based on specific keywords and themes. They also incorporate features like voiceovers and subtitles to make the videos more accessible.\n",
            "\n",
            "6. The AI system goes through multiple iterations and tests before it is ready to be used for EmpowerHer Cinema's YouTube channel. The team also hires a diverse group of women to curate and oversee the content generated by the AI.\n",
            "\n",
            "7. The channel is launched and quickly gains popularity among women filmmakers and film enthusiasts. The AI-generated videos are of high quality and cover a wide range of topics related to women in film, from interviews with successful female directors to tutorials on filmmaking techniques.\n",
            "\n",
            "8. As the channel grows, EmpowerHer Cinema partners with other organizations and companies to host workshops, events, and competitions for women in film. The AI system is also constantly updated and improved to cater to the changing needs and trends in the industry.\n",
            "\n",
            "9. The success of EmpowerHer Cinema's YouTube channel leads to an increase in opportunities for women in the film industry. More female filmmakers are getting recognition and opportunities, and the gender gap in the industry starts to close.\n",
            "\n",
            "10. In the future, EmpowerHer Cinema's YouTube channel becomes a go-to platform for anyone interested in women-centric films and female filmmakers. It has revolutionized the way women in film are represented and has played a significant role in empowering and promoting diversity in the industry.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(['fist step'], 0)"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating the sound by OpenAI: 👇👇\n",
        "\n",
        "https://platform.openai.com/docs/guides/text-to-speech"
      ],
      "metadata": {
        "id": "2ctHZTF6wj0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"/content/ChatGPT_academic_paper\"\n",
        "from openai import OpenAI\n",
        "from django.utils.text import slugify\n",
        "\n",
        "\n",
        "client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   api_key = openai_api#\"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\",\n",
        ")\n",
        "\n",
        "response = client.audio.speech.create(\n",
        "    model=\"tts-1\",\n",
        "    voice=\"alloy\",\n",
        "    input=TOPIC#\"Hello world! This is a streaming test.\",\n",
        ")\n",
        "TOPIC_S = slugify(TOPIC)\n",
        "\n",
        "Sound_File=folder_path+f\"{TOPIC[:40]}\"+str(random.randint (0,1000))+\".mp3\"\n",
        "\n",
        "\n",
        "print (\"save folder is: \",Sound_File)#/content/drive/MyDrive/ChatGPT_Paper_wrting/\"+f\"{TOPIC_S}\"+str(random.randint (0,1000))+\".mp3\") #\"/\"+\"output.mp3\"\n",
        "#response.stream_to_file(\"/content/drive/My Drive/ChatGPT_Paper_wrting/\"+f\"{TOPIC_S}\"+str(random.randint (0,1000))+\".mp3\")#\"/\"+\"output.mp3\")\n",
        "\n",
        "response.stream_to_file(Sound_File)\n",
        "print ( 'topic is:',TOPIC)\n",
        "#print (\"save folder is: /content/drive/MyDrive/ChatGPT_Paper_wrting/\"+f\"{TOPIC[:40]}\"+str(random.randint (0,1000))+\".mp3\") #\"/\"+\"output.mp3\""
      ],
      "metadata": {
        "id": "d2YvDx5DwS7H",
        "outputId": "001ed06b-4764-4c50-ebe6-565d443788f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/ChatGPT_academic_paper’: File exists\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-2c9943b1ce6a>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mTOPIC_S\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslugify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTOPIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mSound_File\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34mf\"{TOPIC[:40]}\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".mp3\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'folder_path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from IPython.display import HTML\n",
        "\n",
        "def upload_files_to_transfer_sh(file_paths):\n",
        "  urls = []\n",
        "  html_content = \"<form>\"\n",
        "  for file_path in file_paths:\n",
        "      with open(file_path, 'rb') as file:\n",
        "          response = requests.post('https://transfer.sh/', files={'file': file})\n",
        "          response.raise_for_status()\n",
        "          urls.append(response.text)\n",
        "          html_content += f\"<p>File: {file_path} <br> And Upload URL is: <a href='{response.text}'>{response.text}</a></p>\"\n",
        "  html_content += \"</form>\"\n",
        "  return urls, html_content\n",
        "\n",
        "file_paths = [Sound_File, docx_path, docx_path.replace('docx','pdf')]\n",
        "urls, html_content = upload_files_to_transfer_sh(file_paths)\n",
        "for url in urls:\n",
        "  print(url)\n",
        "HTML(html_content)"
      ],
      "metadata": {
        "id": "JQVNA0T95rgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Emailing the content 👇🐢🌸"
      ],
      "metadata": {
        "id": "bIYfHcTCp9Qn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi-mail"
      ],
      "metadata": {
        "id": "Pku-t3QT_AsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "from fastapi_mail import FastMail, MessageSchema, ConnectionConfig\n",
        "import os\n",
        "import base64\n",
        "import zipfile\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "conf = ConnectionConfig(\n",
        "  MAIL_USERNAME = \"Your_Email\",\n",
        "  MAIL_PASSWORD = \"Your_Email_Password\",\n",
        "  MAIL_FROM = \"Your_Email\",\n",
        "  MAIL_PORT = 587,\n",
        "  MAIL_SERVER = \"smtp.gmail.com\",\n",
        "  MAIL_TLS = True,\n",
        "  MAIL_SSL = False,\n",
        "  USE_CREDENTIALS = True\n",
        ")\n",
        "\n",
        "@app.post(\"/send_email_summary/\")\n",
        "async def send_email_summary(news_content_summary: str, news_data_with_text_df_1_html: str, attachments: list):\n",
        "  # Create a zip file from the attachments\n",
        "  with zipfile.ZipFile('attachments.zip', 'w') as zipf:\n",
        "      for attachment in attachments:\n",
        "          zipf.write(attachment)\n",
        "\n",
        "  # Prepare attachments\n",
        "  with open('attachments.zip', 'rb') as f:\n",
        "      content = f.read()\n",
        "      encoded_content = base64.b64encode(content).decode()\n",
        "      attachments_data = [\n",
        "          {\n",
        "              'ContentType': 'application/zip',\n",
        "              'Filename': 'attachments.zip',\n",
        "              'Base64Content': encoded_content\n",
        "          }\n",
        "      ]\n",
        "\n",
        "  message = MessageSchema(\n",
        "      subject=\"GPT News Summary of Today\",\n",
        "      recipients=[\"Your_Email\"],\n",
        "      body=\"<h3>Here is the result of our code for today.</h3>{}<br><br> \\\n",
        "            <h3>GPT Gent Summary Sources</h3>{}<br><br> \\\n",
        "            <h4> The PDF,DICX and MP3 file has been added at attachment</h4>\".format(news_content_summary, news_data_with_text_df_1_html),\n",
        "      attachments=attachments_data\n",
        "  )\n",
        "\n",
        "  fm = FastMail(conf)\n",
        "  await fm.send_message(message)\n",
        "  return {\"message\": \"Email Sent\"}"
      ],
      "metadata": {
        "id": "n_r7b-Ud_FKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perviuse_content=''\n",
        "news_content_summary = 'Summary of the news'\n",
        "news_data_with_text_df_1_html = 'HTML table of news sources'\n",
        "attachments = [Sound_File, docx_path, docx_path.replace('docx','pdf')]\n",
        "\n",
        "send_email_summary(news_content_summary, news_data_with_text_df_1_html, attachments)"
      ],
      "metadata": {
        "id": "i4QMJkj8AF6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install mailjet_rest\n",
        "\n",
        "\n",
        "from mailjet_rest import Client\n",
        "import os\n",
        "import base64\n",
        "import zipfile\n",
        "\n",
        "def send_email_summary(api_key, api_secret, news_content_summary, news_data_with_text_df_1_html , attachments):\n",
        "  mailjet = Client(auth=(api_key, api_secret), version='v3.1')\n",
        "\n",
        "  # Create a zip file from the attachments\n",
        "  with zipfile.ZipFile('attachments.zip', 'w') as zipf:\n",
        "      for attachment in attachments:\n",
        "          zipf.write(attachment)\n",
        "\n",
        "  # Prepare attachments\n",
        "  attachments_data = []\n",
        "  with open('attachments.zip', 'rb') as f:\n",
        "      content = f.read()\n",
        "      encoded_content = base64.b64encode(content).decode()\n",
        "      attachments_data.append({\n",
        "          'ContentType': 'application/zip',\n",
        "          'Filename': 'attachments.zip',\n",
        "          'Base64Content': encoded_content\n",
        "      })\n",
        "\n",
        "  data = {\n",
        "    'Messages': [\n",
        "      {\n",
        "        \"From\": {\n",
        "          \"Email\": \"easonlai888@gmail.com\",\n",
        "          \"Name\": \"Eason\"\n",
        "        },\n",
        "        \"To\": [\n",
        "          {\n",
        "            \"Email\": \"Your_Email\",\n",
        "            \"Name\": \"Eason\"\n",
        "          }\n",
        "        ],\n",
        "        \"Subject\": \"GPT News Summary of Today\",\n",
        "        \"HTMLPart\": \"<h3>Here is the result of our code for today.</h3>{}<br><br> \\\n",
        "                  <h3>GPT Gent Summary Sources</h3>{}<br><br> \\\n",
        "                  <h4> The PDF,DICX and MP3 file has been added at attachment</h4>\",#.format(news_content_summary, news_data_with_text_df_1_html),\n",
        "        \"Attachments\": attachments_data\n",
        "      }\n",
        "    ]\n",
        "  }\n",
        "  result = mailjet.send.create(data=data)\n",
        "  print(result.status_code)\n",
        "  print(result.json())"
      ],
      "metadata": {
        "id": "lmNpBP9vrrSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = openai_api\n",
        "api_secret = 'PLEASE_ENTER_YOUR_OWNED_MAILJET_API_KEY_SECRET'\n",
        "perviuse_content=''\n",
        "news_content_summary = 'Summary of the news'\n",
        "news_data_with_text_df_1_html = 'HTML table of news sources'\n",
        "attachments = [Sound_File, docx_path, docx_path.replace('docx','pdf')]\n",
        "\n",
        "send_email_summary(api_key, api_secret, perviuse_content, news_data_with_text_df_1_html, attachments)"
      ],
      "metadata": {
        "id": "OZMmRxJyr1QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Only update the Prompt by the help of ChatGPT:👇👇"
      ],
      "metadata": {
        "id": "BAiQz23MlpUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define main variables\n",
        "#TOPIC = \"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"\n",
        "\n",
        "# List of variables\n",
        "variables = [\"RESEARCH_DOMAIN\", \"PARAGRAPH\", \"PARAGRAPHS\", \"TOPIC_SENTENCE\", \"LANGUAGE\", \"ABSTRACT_PARAGRAPH\", \"BIBLIOGRAPHY\", \"THEORY1\", \"THEORY2\", \"RESEARCH_QUESTIONS\", \"ACTION\", \"RESULT_PARAGRAPHS\", \"DATE\", \"NUMBER_OF_DAYS_MONTHS_YEARS\"]\n",
        "\n",
        "# Generate content for each variable\n",
        "variable_contents = {}\n",
        "for prompt in prompts:\n",
        "   for var in variables:\n",
        "       if var in prompt:\n",
        "           prompt = f\"Generate content for the variable '{var}' based on the topic '{TOPIC}'. For this prompt '{prompt}'\"\n",
        "           content= generate_academic_paper(prompt)\n",
        "           for choice in content.choices:\n",
        "               print(choice.text)\n",
        "               variable_contents[var] = choice.text\n",
        "           print(\"variable_contents[var] is: \",variable_contents[var])\n",
        "\n",
        "# Replace the variables in the prompts with the generated content\n",
        "for prompt in prompts:\n",
        "   for var, content in variable_contents.items():\n",
        "       prompt = prompt.replace(f\"{{{var}}}\", content)\n",
        "print(\"Updated Prompt:\", prompt)"
      ],
      "metadata": {
        "id": "kH3LygdiXsPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt_update_a3(prompt, previous_content):\n",
        "    model_engine = \"text-davinci-003\"\n",
        "    max_tokens = 2048\n",
        "\n",
        "    # Construct the instruction for updating the prompt\n",
        "    instruction = f\"Given the previous content:\\n\\n{previous_content}\\n\\nUpdate the prompt: {prompt}\"\n",
        "\n",
        "    # Create the completion with the instruction\n",
        "    completion = client.completions.create(\n",
        "        model=model_engine,\n",
        "        prompt=instruction,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=0.3,\n",
        "        n=1,\n",
        "        frequency_penalty=0,\n",
        "    )\n",
        "\n",
        "    # Extract and return the updated prompt from the response\n",
        "    updated_prompt = completion.choices[0].text.strip()\n",
        "    return updated_prompt\n",
        "# Inside your loop\n",
        "for prompt in prompts:\n",
        "    print(\"Original Prompt:\", prompt)\n",
        "    response = generate_academic_paper_a2(prompt)\n",
        "    previous_content = response.choices[0].text.strip()\n",
        "    updated_prompt = generate_prompt_update_2(prompt, previous_content)\n",
        "    print(\"Updated Prompt:\", updated_prompt)\n",
        "\n",
        "    # Continue with the rest of your processing\n",
        "    # ..."
      ],
      "metadata": {
        "id": "KviSdMwzwqAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# with no translation for become faster answer:👇👇🙏"
      ],
      "metadata": {
        "id": "iuTPp4YYBg2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\"\n",
        "#topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key = openai_api#\"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\",\n",
        ")\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "# Create a Translator object\n",
        "translator = Translator()\n",
        "\n",
        "\n",
        "# Function to generate an academic paper\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "def generate_academic_paper_a2(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   completion = client.completions.create(\n",
        "       model=\"gpt-3.5-turbo-instruct\",\n",
        "       prompt=prompt_my,\n",
        "       max_tokens=2048,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "choice_text_all=[]\n",
        "\n",
        "import time\n",
        "# Function to generate academic papers for given prompts\n",
        "# Function to generate academic papers for given prompts\n",
        "def generate_papers(prompts):\n",
        "   for i in range(0, len(prompts), 20):\n",
        "       # Slice the prompts list to get the next 20 prompts\n",
        "       print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "\n",
        "       batch = prompts[i:i+20]\n",
        "       print(\"batch is \",batch)\n",
        "   #for j in range ( 0, Len(batch)):\n",
        "       # Generate papers for the next 20 prompts\n",
        "       for prompt in batch:\n",
        "      #   for prompt in prompt1:\n",
        "           # Print the prompt\n",
        "           print(\"prompt is \", prompt)\n",
        "           response = generate_academic_paper_a2(prompt)\n",
        "           print(\"\\nGenerated Academic Paper:\")\n",
        "           print(\"========================\\n\")\n",
        "           #print(response)\n",
        "           for choice in response.choices:\n",
        "             print(choice.text)\n",
        "             choice_text_all.append(choice.text)\n",
        "\n",
        "             # Translate the generated text to Persian\n",
        "         #  choice_translated = translate_to_persian(choice.text) #translator.translate(choice.text, dest='fa')\n",
        "         # choice_translated_prompt = translate_to_persian(prompt)#translator.translate(prompt, dest='fa')\n",
        "\n",
        "         #    print(\"\\n-----\\n Translated is \",choice_translated)\n",
        "         #    save_academic_paper(\"Persian_\"+topic,'\\n**'+choice_translated_prompt+'**\\n'+choice_translated)\n",
        "             save_academic_paper(topic,'\\n--------**\\n'+prompt+'/n-------**\\n'+choice.text)\n",
        "             # Recursively call the function for the nested Completion objects\n",
        "             if hasattr(choice, 'choices'):\n",
        "               extract_text(choice)\n",
        "\n",
        "           #generated_text = response.choices[0].text\n",
        "           # Print the generated text\n",
        "           #print(generated_text)\n",
        "           print(\"\\n end of loop\")\n",
        "           print(\"========================\\n\")\n",
        "\n",
        "           #print(\"loop\")\n",
        "       # Wait for a short period of time before sending the next batch of prompts\n",
        "           time.sleep(40)\n",
        "   return choice_text_all#,choice.translated\n",
        "\n",
        "# Generate academic papers for the given prompts\n",
        "generate_papers(prompts)"
      ],
      "metadata": {
        "id": "rl16DSYABo9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SETUP COLAB for run Streamlit\n",
        "!npm install localtunnel\n",
        "!curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "GRn7OkOUjcdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DL Translate\n",
        "A deep learning-based translation library built on Huggingface transformers and Facebook's mBART-Large\n",
        "\n",
        "https://colab.research.google.com/github/xhluca/dl-translate/blob/main/demos/colab_demo.ipynb#scrollTo=qdefSjR_YIiG"
      ],
      "metadata": {
        "id": "_I5yn6CCZdMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q dl-translate"
      ],
      "metadata": {
        "id": "c7-q341UWsr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dl_translate as dlt\n",
        "mt = dlt.TranslationModel('mbart50')"
      ],
      "metadata": {
        "id": "gtQcnXabalaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dl_translate as dlt\n",
        "\n",
        "def translate_to_persian(text):\n",
        "  # Initialize the translation model\n",
        "  #mt = dlt.TranslationModel('mbart50')\n",
        "\n",
        "  # Translate the text\n",
        "  translated = mt.translate(text, source=dlt.lang.ENGLISH, target=dlt.lang.PERSIAN)\n",
        "\n",
        "  return translated"
      ],
      "metadata": {
        "id": "iOX6FGFWaFqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key = openai_api#\"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\",\n",
        ")\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "# Create a Translator object\n",
        "translator = Translator()\n",
        "\n",
        "\n",
        "# Function to generate an academic paper\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=10, max_time=600)\n",
        "def generate_academic_paper_5(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   completion = client.completions.create(\n",
        "       model=\"gpt-3.5-turbo-instruct\",\n",
        "       prompt=prompt_my,\n",
        "       max_tokens=2048,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "choice_text_all=[]\n",
        "\n",
        "import time\n",
        "# Function to generate academic papers for given prompts\n",
        "# Function to generate academic papers for given prompts\n",
        "def generate_papers(prompts):\n",
        "   for i in range(0, len(prompts), 20):\n",
        "       # Slice the prompts list to get the next 20 prompts\n",
        "       print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "       batch = prompts[i:i+10]\n",
        "       print(\"batch is \",batch)\n",
        "       # Generate papers for the next 20 prompts\n",
        "       for prompt in batch:\n",
        "      #   for prompt in prompt1:\n",
        "           # Print the prompt\n",
        "           print(\"prompt is \", prompt)\n",
        "           response = generate_academic_paper(prompt)\n",
        "           print(\"\\nGenerated Academic Paper:\")\n",
        "           print(\"========================\\n\")\n",
        "           #print(response)\n",
        "           for choice in response.choices:\n",
        "             print(choice.text)\n",
        "             choice_text_all.append(choice.text)\n",
        "              # Translate the generated text to Persian\n",
        "             choice_translated = translate_to_persian(choice.text) #translator.translate(choice.text, dest='fa')\n",
        "             choice_translated_prompt = translate_to_persian(prompt)#translator.translate(prompt, dest='fa')\n",
        "\n",
        "             print(\"\\n-----\\n Translated is \",choice_translated)\n",
        "             save_academic_paper(\"Persian_\"+topic,'\\n**'+choice_translated_prompt+'**\\n'+choice_translated)\n",
        "             save_academic_paper(topic,'\\n**'+prompt+'**\\n'+choice.text)\n",
        "             # Recursively call the function for the nested Completion objects\n",
        "             if hasattr(choice, 'choices'):\n",
        "               extract_text(choice)\n",
        "\n",
        "           #generated_text = response.choices[0].text\n",
        "           # Print the generated text\n",
        "           #print(generated_text)\n",
        "           print(\"\\n end of loop\")\n",
        "           print(\"========================\\n\")\n",
        "\n",
        "           #print(\"loop\")\n",
        "       # Wait for a short period of time before sending the next batch of prompts\n",
        "           time.sleep(2)\n",
        "   return choice_text_all,choice.translated\n",
        "\n",
        "# Generate academic papers for the given prompts\n",
        "generate_papers(prompts3)"
      ],
      "metadata": {
        "id": "oVldhSpgEVZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#For solving queta prompt of Openai API;\n",
        "👇👇🌱"
      ],
      "metadata": {
        "id": "GdTvLhAkKLEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "#import openai\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key = openai_api#\"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\",\n",
        ")\n",
        "\n",
        "def retry_with_exponential_backoff(\n",
        "   func,\n",
        "   initial_delay: float = 1,\n",
        "   exponential_base: float = 2,\n",
        "   jitter: bool = True,\n",
        "   max_retries: int = 10,\n",
        "   errors: tuple = (openai.error.RateLimitError,),\n",
        "):\n",
        "   \"\"\"Retry a function with exponential backoff.\"\"\"\n",
        "   def wrapper(*args, **kwargs):\n",
        "       # Initialize variables\n",
        "       num_retries = 0\n",
        "       delay = initial_delay\n",
        "       # Loop until a successful response or max_retries is hit or an exception is raised\n",
        "       while True:\n",
        "           try:\n",
        "               return func(*args, **kwargs)\n",
        "           # Retry on specified errors\n",
        "           except errors as e:\n",
        "               # Increment retries\n",
        "               num_retries += 1\n",
        "               # Check if max retries has been reached\n",
        "               if num_retries > max_retries:\n",
        "                  raise Exception(\n",
        "                      f\"Maximum number of retries ({max_retries}) exceeded.\"\n",
        "                  )\n",
        "               # Increment the delay\n",
        "               delay *= exponential_base * (1 + jitter * random.random())\n",
        "               # Sleep for the delay\n",
        "               time.sleep(delay)\n",
        "           # Raise exceptions for any errors not specified\n",
        "           except Exception as e:\n",
        "               raise e\n",
        "   return wrapper\n",
        "\n",
        "@retry_with_exponential_backoff\n",
        "def generate_academic_paper_0(prompt_my):\n",
        "  model_engine = \"text-davinci-003\"\n",
        "  max_tokens = 2048\n",
        "\n",
        "  completion = client.completions.create(\n",
        "      model=\"gpt-3.5-turbo-instruct\",\n",
        "      prompt=prompt_my,\n",
        "      max_tokens=2048,\n",
        "      temperature=0.3,\n",
        "      n=1,\n",
        "      frequency_penalty=0,\n",
        "  )\n",
        "  return completion"
      ],
      "metadata": {
        "id": "zLWA8i87KXks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vH0Z7EL5LnQc"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "openai.api_key = openai_api#\"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key= openai_api#\"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\",\n",
        ")\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Function to generate an academic paper\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=10, max_time=600)\n",
        "def generate_academic_paper_6(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   completion = client.completions.create(\n",
        "       model=\"gpt-3.5-turbo-instruct\",\n",
        "       prompt=prompt_my,\n",
        "       max_tokens=2048,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "choice_text_all=[]\n",
        "\n",
        "import time\n",
        "# Function to generate academic papers for given prompts\n",
        "# Function to generate academic papers for given prompts\n",
        "def generate_papers(prompts):\n",
        "   for i in range(0, len(prompts), 20):\n",
        "       # Slice the prompts list to get the next 20 prompts\n",
        "       print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "       batch = prompts[i:i+10]\n",
        "       print(\"batch is \",batch)\n",
        "       # Generate papers for the next 20 prompts\n",
        "       for prompt in batch:\n",
        "      #   for prompt in prompt1:\n",
        "           # Print the prompt\n",
        "           print(\"prompt is \", prompt)\n",
        "           response = generate_academic_paper(prompt)\n",
        "           print(\"\\nGenerated Academic Paper:\")\n",
        "           print(\"========================\\n\")\n",
        "           #print(response)\n",
        "           for choice in response.choices:\n",
        "             print(choice.text)\n",
        "             choice_text_all.append(choice.text)\n",
        "             save_academic_paper(TOPIC,'\\n**'+prompt+'**\\n'+choice.text)\n",
        "             # Recursively call the function for the nested Completion objects\n",
        "             if hasattr(choice, 'choices'):\n",
        "               extract_text(choice)\n",
        "\n",
        "           #generated_text = response.choices[0].text\n",
        "           # Print the generated text\n",
        "           #print(generated_text)\n",
        "           print(\"\\n end of loop\")\n",
        "           print(\"========================\\n\")\n",
        "\n",
        "           #print(\"loop\")\n",
        "       # Wait for a short period of time before sending the next batch of prompts\n",
        "           time.sleep(2)\n",
        "   return choice.text_all\n",
        "\n",
        "# Generate academic papers for the given prompts\n",
        "generate_papers(prompts3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJTgcojthnm7"
      },
      "outputs": [],
      "source": [
        "def render_index_page():\n",
        "   html_content = \"\"\"\n",
        "   <!DOCTYPE html>\n",
        "   <html>\n",
        "   <head>\n",
        "      <title>Generate Academic Papers</title>\n",
        "   </head>\n",
        "   <body>\n",
        "      <h1>Generate Academic Papers</h1>\n",
        "      <form method=\"POST\">\n",
        "          <label for=\"topic\">Topic:</label>\n",
        "          <input type=\"text\" id=\"topic\" name=\"topic\" required>\n",
        "          <input type=\"submit\" value=\"Generate\">\n",
        "      </form>\n",
        "   </body>\n",
        "   </html>\n",
        "   \"\"\"\n",
        "   return render_template_string(html_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKhSXALkhpL7"
      },
      "outputs": [],
      "source": [
        "def render_result_page(topic, docx_file, pdf_file, choice_text_all):\n",
        "   html_content = f\"\"\"\n",
        "   <!DOCTYPE html>\n",
        "   <html>\n",
        "   <head>\n",
        "       <title>Result</title>\n",
        "   </head>\n",
        "   <body>\n",
        "       <h1>Result</h1>\n",
        "       <p>Academic papers have been generated for the topic: {topic}</p>\n",
        "       <a href=\"/download/{docx_file}\">Download DOCX</a>\n",
        "       <a href=\"/download/{pdf_file}\">Download PDF</a>\n",
        "       <h2>Generated Text:</h2>\n",
        "       <p>{choice_text_all}</p>\n",
        "   </body>\n",
        "   </html>\n",
        "   \"\"\"\n",
        "   return render_template_string(html_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuTJlSSGgh4E"
      },
      "outputs": [],
      "source": [
        "# app.py\n",
        "\n",
        "from flask import Flask, request, render_template\n",
        "from academic_paper_generator import generate_papers\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def home():\n",
        "  if request.method == 'POST':\n",
        "      topic = request.form.get('topic')\n",
        "      prompts3 = [\n",
        "          f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "          f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "          f\"Identify gaps in the literature on '{topic}'\",\n",
        "          \"Generate 10 academic research questions about Perviuse action\",\n",
        "          f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "      ]\n",
        "      generate_papers(prompts3)\n",
        "      return render_template('result.html', topic=topic)\n",
        "  else:\n",
        "      return render_template('index.html')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  app.run(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}