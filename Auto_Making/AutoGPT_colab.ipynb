{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/So-AI-love/chatgpt-prompts-for-academic-writing/blob/main/Auto_Making/AutoGPT_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Autogpt\n",
        " By this post instruction:👇👇\n",
        "\n",
        "https://drlee.io/step-by-step-auto-gpt-in-google-colab-how-to-make-it-work-for-you-482a9fa6ea8b"
      ],
      "metadata": {
        "id": "luWfJbBIUBlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Significant-Gravitas/Auto-GPT.git -b stable --single-branch\n",
        "%cd Auto-GPT/\n",
        "!pip install -r requirements.txt  # you may have to restart your runtime\n",
        "%cd Auto-GPT/\n",
        "!cp .env.template env.txt    #(edit env.txt and add your keys)\n",
        "# Stop here and add your keys!"
      ],
      "metadata": {
        "id": "N5oZztAdUIrv",
        "outputId": "4fc5d795-b9f0-43d1-815a-f0e6b8d33c94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Auto-GPT'...\n",
            "remote: Enumerating objects: 12692, done.\u001b[K\n",
            "remote: Total 12692 (delta 0), reused 0 (delta 0), pack-reused 12692\u001b[K\n",
            "Receiving objects: 100% (12692/12692), 4.96 MiB | 9.45 MiB/s, done.\n",
            "Resolving deltas: 100% (8588/8588), done.\n",
            "/content/Auto-GPT/Auto-GPT\n",
            "Collecting en-core-web-sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (from -r requirements.txt (line 30))\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting auto-gpt-plugin-template@ git+https://github.com/Significant-Gravitas/Auto-GPT-Plugin-Template@0.1.0 (from -r requirements.txt (line 49))\n",
            "  Cloning https://github.com/Significant-Gravitas/Auto-GPT-Plugin-Template (to revision 0.1.0) to /tmp/pip-install-m7iq_xor/auto-gpt-plugin-template_cc2a4d469adf425b8f8996173f6ef474\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Significant-Gravitas/Auto-GPT-Plugin-Template /tmp/pip-install-m7iq_xor/auto-gpt-plugin-template_cc2a4d469adf425b8f8996173f6ef474\n",
            "  Running command git checkout -q 7612a14c629dc64ad870eee4d05850d60e1dd9ce\n",
            "  Resolved https://github.com/Significant-Gravitas/Auto-GPT-Plugin-Template to commit 7612a14c629dc64ad870eee4d05850d60e1dd9ce\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting vcrpy@ git+https://github.com/Significant-Gravitas/vcrpy.git@master (from -r requirements.txt (line 73))\n",
            "  Cloning https://github.com/Significant-Gravitas/vcrpy.git (to revision master) to /tmp/pip-install-m7iq_xor/vcrpy_9688f6f0b2f6406383d1c4c42b8ab8d7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Significant-Gravitas/vcrpy.git /tmp/pip-install-m7iq_xor/vcrpy_9688f6f0b2f6406383d1c4c42b8ab8d7\n",
            "  Resolved https://github.com/Significant-Gravitas/vcrpy.git to commit bfd15f9d06a516138b673cb481547f3352d9cc43\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m[Errno 2] No such file or directory: 'Auto-GPT/'\n",
            "/content/Auto-GPT/Auto-GPT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the OpenAI API key to the env.txt file\n",
        "!echo \"OPENAI_API_KEY=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\" > env.txt\n",
        "\n",
        "# Add more environment variables as needed\n",
        "!echo \"ANOTHER_VARIABLE=another_value\" >> env.txt"
      ],
      "metadata": {
        "id": "LIQXcppEcv8l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp env.txt .env"
      ],
      "metadata": {
        "id": "eAyxkFDtUYxn",
        "outputId": "c5734687-09b7-4219-f51f-da9b4b4fc4bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-24 08:31:22.844785: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-24 08:31:22.844870: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-24 08:31:22.844907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-24 08:31:22.854953: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-24 08:31:24.273218: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            " \u001b[0m plugins_config.yaml does not exist, creating base config.\n",
            "\u001b[31mContinuous Mode: \u001b[0m ENABLED\n",
            "\u001b[31mWARNING: \u001b[0m Continuous mode is not recommended. It is potentially dangerous and may cause your AI to run forever or carry out actions you would not usually authorise. Use at your own risk.\n",
            "\u001b[33mWARNING: \u001b[0m You do not have access to gpt-4-0314. Setting smart_llm to gpt-3.5-turbo.\n",
            "\u001b[31mLEGAL: \u001b[0m \u001b[0m\n",
            "\u001b[31mLEGAL: \u001b[0m \u001b[36mDISCLAIMER AND INDEMNIFICATION AGREEMENT\u001b[0m\n",
            "\u001b[31mLEGAL: \u001b[0m \u001b[36mPLEASE READ THIS DISCLAIMER AND INDEMNIFICATION AGREEMENT CAREFULLY BEFORE USING THE AUTOGPT SYSTEM. BY USING THE AUTOGPT SYSTEM, YOU AGREE TO BE BOUND BY THIS AGREEMENT.\u001b[0m\n",
            "\u001b[31mLEGAL: \u001b[0m \u001b[0m\n",
            "\u001b[31mLEGAL: \u001b[0m \u001b[36mIntroduction\u001b[0m\n",
            "\u001b[31mLEGAL: \u001b[0m AutoGPT (the \"System\") is a project that connects a GPT-like artificial intelligence system to the internet and allows it to automate tasks. While the System is designed to be useful and efficient, there may be instances where the System could perform actions that may cause harm or have unintended consequences.\u001b[0m\n",
            "\u001b[31mLEGAL: \u001b[0m \u001b[0m\n",
            "\u001b[31mLEGAL: \u001b[0m \u001b[36mNo Liability for Actions of the System\u001b[0m\n",
            "\u001b[31mLEGAL: \u001b[0m The developers, contributors, and maintainers of the AutoGPT project (collectively, the \"Project Parties\") make no warranties or representations, express or implied, about the System's performance, accuracy, reliability, or safety. By using the System, you understand and agree that the Project Parties shall not be liable for any actions taken by the System or any consequences resulting from such actions.\u001b[0m\n",
            "\u001b[31mLEGAL: \u001b[0m \u001b[0m\n",
            "\u001b[31mLEGAL: \u001b[0m \u001b[36mUser Responsibility and Respondeat Superior Liability\u001b[0m\n",
            "\u001b[31mLEGAL: \u001b[0m As a user of the System, you are responsible for supervising and monitoring the actions of the System while it is operating on your\u001b[0m\n",
            "\u001b[31mLEGAL: \u001b[0m behalf. You acknowledge that using the System could expose you to potential liability including but not limited to respondeat superior and you agree to assume all risks and liabilities associated with such potential liability.\u001b[0m\n",
            "\u001b[31mLEGAL: \u001b[0m \u001b[0m\n",
            "\u001b[31mLEGAL: \u001b[0m \u001b[36mIndemnification\u001b[0m\n",
            "\u001b[31mLEGAL: \u001b[0m By using the System, you agree to indemnify, defend, and hold harmless the Project Parties from and against any and all claims, liabilities, damages, losses, or expenses (including reasonable attorneys' fees and costs) arising out of or in connection with your use of the System, including, without limitation, any actions taken by the System on your behalf, any failure to properly supervise or monitor the System, and any resulting harm or unintended consequences.\u001b[0m\n",
            "\u001b[31mLEGAL: \u001b[0m             \u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m \u001b[33mWelcome to Auto-GPT!\u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m \u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m \u001b[0m\n",
            "\u001b[32mWelcome to Auto-GPT! \u001b[0m run with '--help' for more information.\n",
            "\u001b[32mCreate an AI-Assistant: \u001b[0m input '--manual' to enter manual mode.\n",
            " \u001b[0m Asking user via keyboard...\n",
            "\u001b[6n\u001b[?2004h\u001b[?1l\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;94mI want Auto-GPT to\u001b[0m:\u001b[19D\u001b[20C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[20D\u001b[J\u001b[0m\u001b[?7h\u001b[?2004lWARNING: your terminal doesn't support cursor position requests (CPR).\n",
            "\u001b[?2004h\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;94mI want Auto-GPT to\u001b[0m:\u001b[19D\u001b[20C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?25l\u001b[?7l\u001b[20D\u001b[0m\u001b[J\u001b[0;94mI want Auto-GPT to\u001b[0m:\u001b[19D\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l \u001b[0m You interrupted Auto-GPT\n",
            " \u001b[0m Quitting...\n",
            "Exception ignored in atexit callback: <bound method finalize._exitfunc of <class 'weakref.finalize'>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/weakref.py\", line 642, in _exitfunc\n",
            "    @classmethod\n",
            "KeyboardInterrupt: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m autogpt --continuous"
      ],
      "metadata": {
        "id": "vWW4c9P6d0zV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "# %cd ..\n",
        "!./run.sh"
      ],
      "metadata": {
        "id": "VH4EImCTd3eX",
        "outputId": "7ef74d1a-50ac-479a-b30a-ae8b54fb1b34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Auto-GPT\n",
            "All packages are installed.\n",
            "2023-11-24 08:35:57.217908: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-24 08:35:57.217997: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-24 08:35:57.218056: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-24 08:35:57.233550: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-24 08:35:58.749149: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[33mWARNING: \u001b[0m You do not have access to gpt-4-0314. Setting smart_llm to gpt-3.5-turbo.\n",
            "\u001b[32mNEWS: \u001b[0m \u001b[33mWelcome to Auto-GPT!\u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m \u001b[0m\n",
            "\u001b[32mNEWS: \u001b[0m \u001b[0m\n",
            "\u001b[32mWelcome to Auto-GPT! \u001b[0m run with '--help' for more information.\n",
            "\u001b[32mCreate an AI-Assistant: \u001b[0m input '--manual' to enter manual mode.\n",
            " \u001b[0m Asking user via keyboard...\n",
            "\u001b[6n\u001b[?2004h\u001b[?1l\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;94mI want Auto-GPT to\u001b[0m:\u001b[19D\u001b[20C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[20D\u001b[J\u001b[0m\u001b[?7h\u001b[?2004lWARNING: your terminal doesn't support cursor position requests (CPR).\n",
            "\u001b[?2004h\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;94mI want Auto-GPT to\u001b[0m:\u001b[19D\u001b[20C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}