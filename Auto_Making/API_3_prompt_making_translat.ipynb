{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/So-AI-love/chatgpt-prompts-for-academic-writing/blob/main/Auto_Making/API_3_prompt_making_translat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AcaGPT MVP\n",
        "\n",
        "The gosl of this project is Creating something like AutoGPT but in the field of Academic Papers wrting.\n",
        "\n",
        "\n",
        "For example the MVP Lage has been made by this AI free website maker :\n",
        "\n",
        "https://acagpt.site.live/editv2/"
      ],
      "metadata": {
        "id": "qnaAEEnpFyLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The SWOT and ..., analysis of this startup is available at here:\n",
        "\n",
        "![enter image description here][1]\n",
        "\n",
        "Analysis and Feedback on a ChatGPT-based Academic Paper Writing Startup\n",
        "\n",
        "https://venturusai.com/report/3Qj8RT-if-possible-suggest-one-startup-in-the-field-of-chatgpt-for-\n",
        "\n",
        "\n",
        "  [1]: https://i.stack.imgur.com/DH3se.jpg"
      ],
      "metadata": {
        "id": "tvOJqqvAMHMD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHgZHeIxi31Q"
      },
      "source": [
        "## Aromatically wrrie apaper by the ChatGPT and this github prompt instruction:\n",
        "\n",
        "https://github.com/ahmetbersoz/chatgpt-prompts-for-academic-writing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "  # Mount Google Drive\n",
        "if not os.path.isdir('/content/drive'):\n",
        "   # If not, mount the drive\n",
        "     drive.mount('/content/drive')\n",
        "else:\n",
        "     print(\"Drive is already mounted.\")"
      ],
      "metadata": {
        "id": "6GjtEabAJCXo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1017569-5c7a-40af-c8ad-e4d4812223e5"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive is already mounted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt7VN_fmGT3E",
        "outputId": "4657f311-d612-42fd-9bac-01ae9ef5deaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.3.5)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (0.15.0)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.12.0)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
            "Requirement already satisfied: docx2pdf in /usr/local/lib/python3.10/dist-packages (0.1.8)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from docx2pdf) (4.66.1)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.5.0)\n",
            "Requirement already satisfied: django in /usr/local/lib/python3.10/dist-packages (4.2.7)\n",
            "Requirement already satisfied: asgiref<4,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from django) (3.7.2)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from django) (0.4.4)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from asgiref<4,>=3.6.0->django) (4.5.0)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (5.1.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from tenacity) (1.16.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25h+ localtunnel@2.0.2\n",
            "updated 1 package and audited 36 packages in 0.539s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 2 \u001b[93mmoderate\u001b[0m severity vulnerabilities\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n",
            "34.148.118.131\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install backoff\n",
        "!pip install docx2pdf\n",
        "!pip install python-docx\n",
        "!pip install django\n",
        "\n",
        "\n",
        "!pip install tenacity\n",
        "!pip install tiktoken\n",
        "\n",
        "# SETUP COLAB for run Streamlit\n",
        "!npm install localtunnel\n",
        "\n",
        "!pip install -q dl-translate\n",
        "!curl ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install libreoffice\n",
        "#!sudo apt-get install abiword\n",
        "!sudo apt install libreoffice-writer"
      ],
      "metadata": {
        "id": "AUeIF57v21gq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa0aa520-b0ff-45ef-9f0f-240c209f2337"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Connected to cloud.r-pr\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadconte\r                                                                               \rHit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Waiting for headers] [Connected to ppa.launchpadcontent.net (185.125.190.80\r0% [Waiting for headers] [Connected to ppa.launchpadcontent.net (185.125.190.80\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libreoffice is already the newest version (1:7.3.7-0ubuntu0.22.04.3).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " megacmd : Depends: libc-ares2 (>= 1.11.0~rc1) but it is not going to be installed\n",
            "           Depends: libcrypto++6 but it is not installable\n",
            "           Depends: libmediainfo0v5 (>= 0.7.56) but it is not going to be installed\n",
            "           Depends: libssl1.1 (>= 1.1.0) but it is not installable\n",
            "           Depends: libzen0v5 (>= 0.4.31-2~) but it is not going to be installed\n",
            "E: Unmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libreoffice-writer is already the newest version (1:7.3.7-0ubuntu0.22.04.3).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " megacmd : Depends: libc-ares2 (>= 1.11.0~rc1) but it is not going to be installed\n",
            "           Depends: libcrypto++6 but it is not installable\n",
            "           Depends: libmediainfo0v5 (>= 0.7.56) but it is not going to be installed\n",
            "           Depends: libssl1.1 (>= 1.1.0) but it is not installable\n",
            "           Depends: libzen0v5 (>= 0.4.31-2~) but it is not going to be installed\n",
            "\u001b[1;31mE: \u001b[0mUnmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define main variables\n",
        "TOPIC = \"{TOPIC}\"\n",
        "RESEARCH_DOMAIN = \"{RESEARCH_DOMAIN}\"\n",
        "PARAGRAPH = \"{PARAGRAPH}\"\n",
        "PARAGRAPHS = \"{PARAGRAPHS}\"\n",
        "TOPIC_SENTENCE = \"{TOPIC_SENTENCE}\"\n",
        "LANGUAGE = \"{LANGUAGE}\"\n",
        "ABSTRACT_PARAGRAPH = \"{ABSTRACT_PARAGRAPH}\"\n",
        "BIBLIOGRAPHY = \"{BIBLIOGRAPHY}\"\n",
        "THEORY1 = \"{THEORY1}\"\n",
        "THEORY2 = \"{THEORY2}\"\n",
        "RESEARCH_QUESTIONS = \"{RESEARCH_QUESTIONS}\"\n",
        "ACTION = \"{ACTION}\"\n",
        "RESULT_PARAGRAPHS = \"{RESULT_PARAGRAPHS}\"\n",
        "DATE = \"{DATE}\"\n",
        "NUMBER_OF_DAYS_MONTHS_YEARS = \"{NUMBER_OF_DAYS_MONTHS_YEARS}\"\n",
        "\n",
        "main_variables_0 = {\n",
        "       'TOPIC': None,\n",
        "       'RESEARCH_DOMAIN': None,\n",
        "       'PARAGRAPH': None,\n",
        "       'PARAGRAPHS': None,\n",
        "       'TOPIC_SENTENCE': None,\n",
        "       'LANGUAGE': None,\n",
        "       'ABSTRACT_PARAGRAPH': None,\n",
        "       'BIBLIOGRAPHY': None,\n",
        "       'THEORY1': None,\n",
        "       'THEORY2': None,\n",
        "       'RESEARCH_QUESTIONS': None,\n",
        "       'ACTION': None,\n",
        "       'RESULT_PARAGRAPHS': None,\n",
        "       'DATE': None,\n",
        "       'NUMBER_OF_DAYS_MONTHS_YEARS': None\n",
        "   }\n",
        "\n",
        "# List of prompts for generating academic papers\n",
        "prompts = [\n",
        "\n",
        "  # Improving Language\n",
        "  f\"Write a counterargument to the following claim: '{PARAGRAPH}'\",\n",
        "  f\"Rewrite this in an academic voice: '{PARAGRAPH}'\",\n",
        "  f\"Expand these notes: '{PARAGRAPH}'\",\n",
        "  f\"Provide me a list of words and phrases which were repeatedly / more than 3 times used: '{PARAGRAPHS}'\",\n",
        "  f\"Provide me a list of synonyms for '{PARAGRAPH}' and evaluate them in the context of '{PARAGRAPH}'\",\n",
        "  f\"Act as a language expert, proofread my paper on '{TOPIC_SENTENCE}' while putting a focus on grammar and punctuation.\",\n",
        "  f\"In the context of '{RESEARCH_DOMAIN}' translate '{PARAGRAPH}' into the '{LANGUAGE}' language.\",\n",
        "\n",
        "   # Brainstorming\n",
        "   f\"Find a research topic for a PhD in the area of '{TOPIC}'\",\n",
        "   f\"Write a detailed proposal on the following research topic. Make sure it is free from plagiarism. '{PARAGRAPH}'\",\n",
        "   f\"Identify gaps in the literature on '{TOPIC_SENTENCE}'\",\n",
        "   f\"Generate 10 academic research questions about '{PARAGRAPHS}'\",\n",
        "   f\"Generate a list of research hypotheses related to '{TOPIC_SENTENCE}'\",\n",
        "   f\"Identify potential areas for future research in the context of this '{TOPIC_SENTENCE}'\",\n",
        "   f\"Suggest novel applications of '{TOPIC_SENTENCE}' within '{RESEARCH_DOMAIN}'\",\n",
        "\n",
        "   # Title/Topic Sentence\n",
        "   f\"Suggest 5 titles for the following abstract: '{ABSTRACT_PARAGRAPH}'\",\n",
        "   f\"Write a topic sentence for this paragraph: '{PARAGRAPH}'\",\n",
        "\n",
        "   # Keywords\n",
        "   f\"Provide 5 keywords for this: '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Abstract\n",
        "   f\"Generate an abstract for a scientific paper based on this information for: '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Outline\n",
        "   f\"Generate an outline for '{TOPIC_SENTENCE}'\",\n",
        "   f\"I want to write a journal article about '{TOPIC_SENTENCE}'. Give me an outline for the article that I can use as a starting point.\",\n",
        "\n",
        "   # Introduction\n",
        "   f\"Come up with an introduction for the following research topic: '{TOPIC_SENTENCE}'\",\n",
        "\n",
        "   # Literature Review\n",
        "   f\"Conduct a literature review on '{TOPIC_SENTENCE}' and provide review paper references\",\n",
        "   f\"Provide me with references and links to papers in '{PARAGRAPH}'\",\n",
        "   f\"Summarize the scholarly literature including in-text citations on '{PARAGRAPHS}'\",\n",
        "   f\"Write this in standard Harvard referencing '{PARAGRAPH}'\",\n",
        "   f\"Convert this '{BIBLIOGRAPHY}' from MLA to APA style.\",\n",
        "   f\"Compare and contrast '{THEORY1}' and '{THEORY2}' in the context of '{RESEARCH_DOMAIN}'\",\n",
        "\n",
        "   # Methodology\n",
        "   f\"Create objectives and methodology for '{TOPIC_SENTENCE}'\",\n",
        "   f\"Write a detailed methodology for the topic: '{TOPIC_SENTENCE}'\",\n",
        "   f\"Analyze the strengths and weaknesses of this methodology: '{PARAGRAPHS}'\",\n",
        "   f\"Write objectives for this study: '{TOPIC_SENTENCE}'\",\n",
        "   f\"What are the limitations of using '{TOPIC_SENTENCE}' in '{RESEARCH_DOMAIN}'?\",\n",
        "   f\"Create a recipe for the methods used in this '{PARAGRAPHS}'\",\n",
        "   f\"Suggest interdisciplinary approaches to '{TOPIC_SENTENCE}'\",\n",
        "   f\"Explain how qualitative/quantitative research methods can be used to address '{RESEARCH_QUESTIONS}'\",\n",
        "   f\"Recommend best practices for data collection and analysis in '{TOPIC_SENTENCE}'\",\n",
        "\n",
        "   # Experiments\n",
        "   f\"Design an experiment that '{ACTION}'\",\n",
        "\n",
        "   # Results\n",
        "   f\"Write a result section for the following paragraphs. Please write this in the third person. '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Discussion\n",
        "   f\"Discuss this results: '{RESULT_PARAGRAPHS}'\",\n",
        "\n",
        "   # Conclusion\n",
        "   f\"Generate a conclusion for this: '{PARAGRAPHS}'\",\n",
        "   f\"Give recommendations and conclusion for: '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Future Works\n",
        "   f\"Can you suggest 3 directions for future research on this topic: '{PARAGRAPH}'\",\n",
        "\n",
        "   # Plan/Presentation\n",
        "   f\"Develop a research plan for: '{TOPIC_SENTENCE}'\",\n",
        "   f\"Write a schedule for completion in '{TOPIC_SENTENCE}' in NUMBER OF DAYS MONTHS YEARS which is '{NUMBER_OF_DAYS_MONTHS_YEARS}'\",\n",
        "   f\"The deadline for the submission of the first draft is '{DATE}'. Give me a week-by-week breakdown so I can plan my writing better.\",\n",
        "   f\"Write a sensational press release for this research: '{PARAGRAPHS}'\",\n",
        "   f\"Make this more persuasive: '{PARAGRAPH}'\",\n",
        "   f\"Write 3 tweets about this research? '{PARAGRAPHS}'\",\n",
        "]"
      ],
      "metadata": {
        "id": "uPcmAM5Zq5M-"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define main variables\n",
        "#TOPIC = \"Psychological symptoms detection for Iranian men in their 40s studying for a PHD degree\"\n",
        "#RESEARCH_DOMAIN = \"Psychology\"\n",
        "#PARAGRAPH = \"The symptoms include lack of energy for doing work and difficulty focusing the mind on something\"\n",
        "#PARAGRAPHS = \"Historical background showing narcissism, which doesn't accept the information of psychology science but suggests using new technologies for creating cooperation\"\n",
        "#TOPIC_SENTENCE = \"The aim of this study is to investigate the psychological symptoms of Iranian men in their 40s who are studying for a PHD degree\"\n",
        "#LANGUAGE = \"English\"\n",
        "#ABSTRACT_PARAGRAPH = \"This study aims to investigate the psychological symptoms of Iranian men in their 40s who are studying for a PHD degree\"\n",
        "#BIBLIOGRAPHY = \"Masoumeh Zandpour, Jafar Hasani, Carla Sharp\"\n",
        "#THEORY1 = \"Psychological symptoms detection\"\n",
        "#THEORY2 = \"Narcissism\"\n",
        "#RESEARCH_QUESTIONS = \"What are the psychological symptoms of Iranian men in their 40s who are studying for a PHD degree?\"\n",
        "#ACTION = \"Investigate the psychological symptoms of Iranian men in their 40s who are studying for a PHD degree\"\n",
        "#RESULT_PARAGRAPHS = \"The results of the study indicate...\"\n",
        "#DATE = \"11/26/2023\"\n",
        "#NUMBER_OF_DAYS_MONTHS_YEARS = \"2 months\""
      ],
      "metadata": {
        "id": "dMj_71pfRWfL"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define main variables\n",
        "TOPIC = \"{TOPIC}\"\n",
        "RESEARCH_DOMAIN = \"{RESEARCH_DOMAIN}\"\n",
        "PARAGRAPH = \"{PARAGRAPH}\"\n",
        "PARAGRAPHS = \"{PARAGRAPHS}\"\n",
        "TOPIC_SENTENCE = \"{TOPIC_SENTENCE}\"\n",
        "LANGUAGE = \"{LANGUAGE}\"\n",
        "ABSTRACT_PARAGRAPH = \"{ABSTRACT_PARAGRAPH}\"\n",
        "BIBLIOGRAPHY = \"{BIBLIOGRAPHY}\"\n",
        "THEORY1 = \"{THEORY1}\"\n",
        "THEORY2 = \"{THEORY2}\"\n",
        "RESEARCH_QUESTIONS = \"{RESEARCH_QUESTIONS}\"\n",
        "ACTION = \"{ACTION}\"\n",
        "RESULT_PARAGRAPHS = \"{RESULT_PARAGRAPHS}\"\n",
        "DATE = \"{DATE}\"\n",
        "NUMBER_OF_DAYS_MONTHS_YEARS = \"{NUMBER_OF_DAYS_MONTHS_YEARS}\"\n",
        "\n",
        "main_variables_0 = {\n",
        "      'TOPIC': TOPIC,\n",
        "      'RESEARCH_DOMAIN': RESEARCH_DOMAIN,\n",
        "      'PARAGRAPH': PARAGRAPH,\n",
        "      'PARAGRAPHS': PARAGRAPHS,\n",
        "      'TOPIC_SENTENCE': TOPIC_SENTENCE,\n",
        "      'LANGUAGE': LANGUAGE,\n",
        "      'ABSTRACT_PARAGRAPH': ABSTRACT_PARAGRAPH,\n",
        "      'BIBLIOGRAPHY': BIBLIOGRAPHY,\n",
        "      'THEORY1': THEORY1,\n",
        "      'THEORY2': THEORY2,\n",
        "      'RESEARCH_QUESTIONS': RESEARCH_QUESTIONS,\n",
        "      'ACTION': ACTION,\n",
        "      'RESULT_PARAGRAPHS': RESULT_PARAGRAPHS,\n",
        "      'DATE': DATE,\n",
        "      'NUMBER_OF_DAYS_MONTHS_YEARS': NUMBER_OF_DAYS_MONTHS_YEARS\n",
        "  }\n",
        "\n",
        "# List of prompts for generating academic papers\n",
        "prompts = [\n",
        "# Improving Language\n",
        "f\"Write a counterargument to the following claim: '{PARAGRAPH}'\",\n",
        "f\"Rewrite this in an academic voice: '{PARAGRAPH}'\",\n",
        "f\"Expand these notes: '{PARAGRAPH}'\",\n",
        "f\"Provide me a list of words and phrases which were repeatedly / more than 3 times used: '{PARAGRAPHS}'\",\n",
        "f\"Provide me a list of synonyms for '{PARAGRAPH}' and evaluate them in the context of '{PARAGRAPH}'\",\n",
        "f\"Act as a language expert, proofread my paper on '{TOPIC_SENTENCE}' while putting a focus on grammar and punctuation.\",\n",
        "f\"In the context of '{RESEARCH_DOMAIN}' translate '{PARAGRAPH}' into the '{LANGUAGE}' language.\",\n",
        "\n",
        "  # Brainstorming\n",
        "  f\"Find a research topic for a PhD in the area of '{TOPIC}'\",\n",
        "  f\"Write a detailed proposal on the following research topic. Make sure it is free from plagiarism. '{PARAGRAPH}'\",\n",
        "  f\"Identify gaps in the literature on '{TOPIC_SENTENCE}'\",\n",
        "  f\"Generate 10 academic research questions about '{PARAGRAPHS}'\",\n",
        "  f\"Generate a list of research hypotheses related to '{TOPIC_SENTENCE}'\",\n",
        "  f\"Identify potential areas for future research in the context of this '{TOPIC_SENTENCE}'\",\n",
        "  f\"Suggest novel applications of '{TOPIC_SENTENCE}' within '{RESEARCH_DOMAIN}'\",\n",
        "\n",
        "  # Title/Topic Sentence\n",
        "  f\"Suggest 5 titles for the following abstract: '{ABSTRACT_PARAGRAPH}'\",\n",
        "  f\"Write a topic sentence for this paragraph: '{PARAGRAPH}'\",\n",
        "\n",
        "  # Keywords\n",
        "  f\"Provide 5 keywords for this: '{PARAGRAPHS}'\",\n",
        "\n",
        "  # Abstract\n",
        "  f\"Generate an abstract for a scientific paper based on this information for: '{PARAGRAPHS}'\",\n",
        "\n",
        "  # Outline\n",
        "  f\"Generate an outline for '{TOPIC_SENTENCE}'\",\n",
        "  f\"I want to write a journal article about '{TOPIC_SENTENCE}'. Give me an outline for the article that I can use as a starting point.\",\n",
        "\n",
        "  # Introduction\n",
        "  f\"Come up with an introduction for the following research topic: '{TOPIC_SENTENCE}'\",\n",
        "\n",
        "  # Literature Review\n",
        "  f\"Conduct a literature review on '{TOPIC_SENTENCE}' and provide review paper references\",\n",
        "  f\"Provide me with references and links to papers in '{PARAGRAPH}'\",\n",
        "  f\"Summarize the scholarly literature including in-text citations on '{PARAGRAPHS}'\",\n",
        "  f\"Write this in standard Harvard referencing '{PARAGRAPH}'\",\n",
        "  f\"Convert this '{BIBLIOGRAPHY}' from MLA to APA style.\",\n",
        "  f\"Compare and contrast '{THEORY1}' and '{THEORY2}' in the context of '{RESEARCH_DOMAIN}'\",\n",
        "\n",
        "  # Methodology\n",
        "   f\"Create objectives and methodology for '{TOPIC_SENTENCE}'\",\n",
        "   f\"Write a detailed methodology for the topic: '{TOPIC_SENTENCE}'\",\n",
        "   f\"Analyze the strengths and weaknesses of this methodology: '{PARAGRAPHS}'\",\n",
        "   f\"Write objectives for this study: '{TOPIC_SENTENCE}'\",\n",
        "   f\"What are the limitations of using '{TOPIC_SENTENCE}' in '{RESEARCH_DOMAIN}'?\",\n",
        "   f\"Create a recipe for the methods used in this '{PARAGRAPHS}'\",\n",
        "   f\"Suggest interdisciplinary approaches to '{TOPIC_SENTENCE}'\",\n",
        "   f\"Explain how qualitative/quantitative research methods can be used to address '{RESEARCH_QUESTIONS}'\",\n",
        "   f\"Recommend best practices for data collection and analysis in '{TOPIC_SENTENCE}'\",\n",
        "\n",
        "   # Experiments\n",
        "   f\"Design an experiment that '{ACTION}'\",\n",
        "\n",
        "   # Results\n",
        "   f\"Write a result section for the following paragraphs. Please write this in the third person. '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Discussion\n",
        "   f\"Discuss this results: '{RESULT_PARAGRAPHS}'\",\n",
        "\n",
        "   # Conclusion\n",
        "   f\"Generate a conclusion for this: '{PARAGRAPHS}'\",\n",
        "   f\"Give recommendations and conclusion for: '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Future Works\n",
        "   f\"Can you suggest 3 directions for future research on this topic: '{PARAGRAPH}'\",\n",
        "\n",
        "   # Plan/Presentation\n",
        "   f\"Develop a research plan for: '{TOPIC_SENTENCE}'\",\n",
        "   f\"Write a schedule for completion in '{TOPIC_SENTENCE}' in NUMBER OF DAYS MONTHS YEARS which is '{NUMBER_OF_DAYS_MONTHS_YEARS}'\",\n",
        "   f\"The deadline for the submission of the first draft is '{DATE}'. Give me a week-by-week breakdown so I can plan my writing better.\",\n",
        "   f\"Write a sensational press release for this research: '{PARAGRAPHS}'\",\n",
        "   f\"Make this more persuasive: '{PARAGRAPH}'\",\n",
        "   f\"Write 3 tweets about this research? '{PARAGRAPHS}'\",\n",
        "]"
      ],
      "metadata": {
        "id": "ndWVOITXN7Xu"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Goal adding 🙏👇🌸"
      ],
      "metadata": {
        "id": "Jl9PPovDuhlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @title (Please insert your request to be done by this code at below form:👇👇)\n",
        "Question = '\\u0628\\u0631\\u0631\\u0633\\u06CC \\u0631\\u0648\\u0634\\u0647\\u0627\\u06CC \\u0634\\u06A9\\u0633\\u062A\\u0646 \\u062E\\u0634\\u0648\\u0646\\u062A \\u0628\\u0631 \\u0636\\u062F \\u0632\\u0646\\u0627\\u0646 \\u0628\\u0647 \\u0632\\u0628\\u0627\\u0646 \\u0627\\u0646\\u06AF\\u0644\\u06CC\\u0633\\u06CC ' # @param {type:\"string\"}\n",
        "openai_api = \"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\" # @param {type:\"string\"}\n",
        "\n",
        "TOPIC_0 = f\"Analyze the current situation in the Islamic Republic of Iran and the challenges faced by resistance forces. And Identify effective strategies used by resistance movements to navigate challenging political environments.\"\n",
        "TOPIC_0 = f\"Could you provide more insights into the challenges faced by the opposition groups in Iran and how they could overcome these challenges to effectively organize resistance against the Islamic Republic?\"\n",
        "\n",
        "#PASSWORD =  # @param {type:\"string\"}\n",
        "if not (Question == \"\"):\n",
        "\n",
        "    TOPIC  = Question\n",
        "\n",
        "else:\n",
        "    TOPIC  = TOPIC_0\n",
        "\n",
        "    print(\"Please Input your Mega IDs.\")\n",
        "# @markdown *After signing\n",
        "print ('Your question is:',TOPIC)# has done successfully\")\n",
        "\n",
        "main_variables_0 = {\n",
        "   'TOPIC': TOPIC,\n",
        "}\n",
        "\n",
        "prompts = [\n",
        " # Understanding the Issue\n",
        " f\"What are the key aspects of {main_variables_0['TOPIC']} that need to be addressed?\",\n",
        "\n",
        " # Mind Mapping\n",
        " f\"Create a mind map of the main elements of {main_variables_0['TOPIC']} and how they are interconnected.\",\n",
        "\n",
        " # Affinity Diagramming\n",
        " f\"Write down ideas on sticky notes about how to improve {main_variables_0['TOPIC']}. Then, group these ideas based on common themes.\",\n",
        "\n",
        " # Round-Robin Brainstorming\n",
        " f\"Take turns sharing ideas on how to improve {main_variables_0['TOPIC']}. Make sure everyone has a chance to contribute.\",\n",
        "\n",
        " # Reverse Brainstorming\n",
        " f\"Think of ways to create the problem in {main_variables_0['TOPIC']}. This will help you understand how to solve it.\",\n",
        "\n",
        " # SCAMPER\n",
        " f\"Apply the SCAMPER method to existing solutions or situations in {main_variables_0['TOPIC']}. This will spark new ideas.\",\n",
        "\n",
        " # Cross-Functional Brainstorming\n",
        " f\"Assemble a diverse group of people from various backgrounds and disciplines to tackle {main_variables_0['TOPIC']}. This will ensure a more rounded and innovative solution.\",\n",
        "\n",
        " # Future Backwards\n",
        " f\"Envision a future state where {main_variables_0['TOPIC']} has been solved successfully. Starting from this endpoint, work backward to identify the series of events and decisions that led to that future.\"\n",
        "]"
      ],
      "metadata": {
        "id": "rmbkC20f6RWu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c05839d3-3c30-4e2f-f55e-204016d3443b",
        "cellView": "form"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your question is: بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title .\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of changes in the type of violence that continues in the aftermath of violence\"\n",
        "#TOPIC =f\"stop the WarDark Triad and Light Triad in the Middle East: A Critical Examination of their Influence and Impact on Iran\"+TOPIC\n",
        "\n",
        "#TOPIC = f\"If possible read this post ( https://www.geeky-gadgets.com/chatgpt-brainstorming-prompts/ ) and suggest  one python block code 10 prompt in the for on ( prompt=[The suggested prompt based of [var1] ). The prompt must have 10 line and at least three necessary value like TOPIC , FIELD_SUDY,and the third vale is your optional . Also you can have more variable or prompt for doing this post main goal which is brainstorming for one topic based of ChatGPT promptimg. This would be ChatGPT cheat sheet prompting.\"\n",
        "TOPIC = main_variables_0.get('TOPIC', 'Default Value')\n",
        "print ('TOPIC IS :', TOPIC)\n",
        "\n",
        "folder_chatGPT = \"/content/ChatGPT_academic_paper\"\n",
        "#openai_api_0 = \"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\"\n",
        "#openai_api = \"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\"\n",
        "global TOPIC_CLASS\n",
        "class TOPIC_CLASS:\n",
        "    def __init__(self):\n",
        "        self.perviuse_try_numner = 0\n",
        "        self.perviuse_content = ['fist step']\n",
        "        self.topic= TOPIC\n",
        "TP= TOPIC_CLASS()\n",
        "#TOPIC = f\" \""
      ],
      "metadata": {
        "id": "I484Df8ONQVI",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Funstions for saving as PDF and DOCX :\n",
        "👇🌱"
      ],
      "metadata": {
        "id": "lI5PG0BNPrPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install libreoffice\n",
        "#!sudo apt-get install abiword\n",
        "!sudo apt install libreoffice-writer"
      ],
      "metadata": {
        "id": "XDBHbtajP03B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78f6803f-87de-46a5-e032-ec4a3ffc33ab"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Connected to cloud.r-pr\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Waiting for headers] [Connected to ppa.launchpadcontent.net (185.125.190.80\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libreoffice is already the newest version (1:7.3.7-0ubuntu0.22.04.3).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " megacmd : Depends: libc-ares2 (>= 1.11.0~rc1) but it is not going to be installed\n",
            "           Depends: libcrypto++6 but it is not installable\n",
            "           Depends: libmediainfo0v5 (>= 0.7.56) but it is not going to be installed\n",
            "           Depends: libssl1.1 (>= 1.1.0) but it is not installable\n",
            "           Depends: libzen0v5 (>= 0.4.31-2~) but it is not going to be installed\n",
            "E: Unmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libreoffice-writer is already the newest version (1:7.3.7-0ubuntu0.22.04.3).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " megacmd : Depends: libc-ares2 (>= 1.11.0~rc1) but it is not going to be installed\n",
            "           Depends: libcrypto++6 but it is not installable\n",
            "           Depends: libmediainfo0v5 (>= 0.7.56) but it is not going to be installed\n",
            "           Depends: libssl1.1 (>= 1.1.0) but it is not installable\n",
            "           Depends: libzen0v5 (>= 0.4.31-2~) but it is not going to be installed\n",
            "\u001b[1;31mE: \u001b[0mUnmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {
        "id": "W2xiQx_camiB"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "def convert_docx_to_pdf0(docx_path, pdf_path):\n",
        "  subprocess.call(['abiword', '--to=pdf', docx_path, '--to-dir', pdf_path])\n",
        "\n",
        "def convert_docx_to_pdf(docx_path, pdf_path):\n",
        " command = ['libreoffice', '--headless', '--convert-to', 'pdf', '--outdir', pdf_path, docx_path]\n",
        " subprocess.call(command)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "from docx import Document\n",
        "\n",
        "\n",
        "\n",
        "def save_academic_paper(topic, prompt_my):\n",
        " # Define the path to the DOCX file\n",
        " docx_path = f\"/content/{topic}.docx\"\n",
        "\n",
        " # Check if the DOCX file exists\n",
        " if os.path.isfile(docx_path):\n",
        "     # If the DOCX file exists, open it\n",
        "     doc = Document(docx_path)\n",
        " else:\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "     doc = Document()\n",
        "\n",
        " # Add the generated text to the document\n",
        " #print (\"____&&&&&&&&&&\\n\",prompt_my)\n",
        " doc.add_paragraph(prompt_my)\n",
        "\n",
        " # Save the document\n",
        " doc.save(docx_path)\n",
        "\n",
        " # Convert the DOCX file to a PDF\n",
        " convert_docx_to_pdf(docx_path, \"/content/output/\")"
      ],
      "metadata": {
        "id": "uE2pz7Zp4QIZ"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import subprocess\n",
        "from docx import Document\n",
        "from django.utils.text import slugify\n",
        "\n",
        "\n",
        "def save_academic_paper(topic, prompt_my):\n",
        "  # Define the path to the folder in Google Drive\n",
        "  folder_path = r\"/content/drive/My Drive/ChatGPT_Paper_wrting/\"\n",
        "\n",
        "  # Mount Google Drive\n",
        "  if not os.path.isdir('/content/drive'):\n",
        "   # If not, mount the drive\n",
        "     drive.mount('/content/drive')\n",
        "  else:\n",
        "     print(\"Drive is already mounted.\")\n",
        "\n",
        "  Pdf_Dir= r\"/content/drive/My Drive/ChatGPT_Paper_wrting/\"\n",
        "  docx_path= f\"{folder_path}{topic}.docx\"\n",
        "  # Check if the folder exists\n",
        "  if not os.path.exists(folder_path):\n",
        "  # If the folder doesn't exist, create it\n",
        "    os.mkdir(folder_path)\n",
        "\n",
        "\n",
        "  # Replace spaces in the topic with underscores\n",
        "  #topic = topic[:12].replace(\" \", \"_\")\n",
        "  topic = slugify(topic)\n",
        "\n",
        "  # Define the path to the DOCX file in the folder\n",
        "\n",
        "\n",
        "  # Check if the DOCX file exists\n",
        "  if os.path.isfile(docx_path):\n",
        "    # If the DOCX file exists, open it\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"#+str(random.randint(0,9))+\".docx\"\n",
        "    doc = Document(docx_path)\n",
        "  else:\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"\n",
        "    #print(docx_path)\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "    doc = Document()\n",
        "\n",
        "  # Add the generated text to the document\n",
        "  doc.add_paragraph(prompt_my)\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Convert the DOCX file to a PDF\n",
        "  convert_docx_to_pdf(docx_path,Pdf_Dir)"
      ],
      "metadata": {
        "id": "gEC4g9KHOQwh"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import subprocess\n",
        "from docx import Document\n",
        "from django.utils.text import slugify\n",
        "\n",
        "\n",
        "  # Mount Google Drive\n",
        "if not os.path.isdir('/content/drive'):\n",
        "   # If not, mount the drive\n",
        "     drive.mount('/content/drive')\n",
        "else:\n",
        "     print(\"Drive is already mounted.\")\n",
        "\n",
        "\n",
        "def save_academic_paper_with_prompt(topic, prompt_my,contnet):\n",
        "  # Define the path to the folder in Google Drive\n",
        "  folder_path = r\"/content/drive/My Drive/ChatGPT_Paper_wrting/\"\n",
        "\n",
        "\n",
        "  Pdf_Dir= r\"/content/drive/My Drive/ChatGPT_Paper_wrting/\"\n",
        "  docx_path= f\"{folder_path}{topic}.docx\"\n",
        "  # Check if the folder exists\n",
        "  if not os.path.exists(folder_path):\n",
        "  # If the folder doesn't exist, create it\n",
        "    os.mkdir(folder_path)\n",
        "\n",
        "\n",
        "  # Replace spaces in the topic with underscores\n",
        "  #topic = topic[:12].replace(\" \", \"_\")\n",
        "  topic = slugify(topic)\n",
        "\n",
        "  # Define the path to the DOCX file in the folder\n",
        "\n",
        "\n",
        "  # Check if the DOCX file exists\n",
        "  if os.path.isfile(docx_path):\n",
        "    # If the DOCX file exists, open it\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"#+str(random.randint(0,9))+\".docx\"\n",
        "    doc = Document(docx_path)\n",
        "  else:\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"\n",
        "    #print(docx_path)\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "    doc = Document()\n",
        "\n",
        "  # Add the generated text to the document\n",
        "  p = doc.add_paragraph(prompt_my)\n",
        "  # Add the generated text to the document\n",
        "  # Add the generated text to the document\n",
        "  p.style = doc.styles['Heading 3']\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Revert the style of the paragraph back to 'Normal'\n",
        "  p = doc.add_paragraph(contnet)\n",
        "  p.style = doc.styles['Normal']\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Convert the DOCX file to a PDF\n",
        "  convert_docx_to_pdf(docx_path,Pdf_Dir)"
      ],
      "metadata": {
        "id": "iYQv76ernY6l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab3d5cd1-23ca-49a4-f9f7-650e0cc9f8dd"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive is already mounted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# @title\n",
        "# conect to [Mega.z](https://mega.nz/) cloud for storage files based ot this page:\n",
        "\n",
        "https://colab.research.google.com/github/sudo-ken/Mega-to-Google-Drive/blob/master/Transfer_files_from_Mega_to_Google_Drive.ipynb#scrollTo=Vgh1xlQYGZCO"
      ],
      "metadata": {
        "id": "x7XWsP_amNqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube-dl\n",
        "!apt install python3-distutils\n",
        "!pip install mega.py\n",
        "!apt install python3-distutils  -y\n",
        "\n",
        "# %cd '/content/'\n",
        "# !git clone https://github.com/jeroenmeulenaar/python3-mega.git\n",
        "# !(cd python3-mega; pip install urlobject pycrypto)\n",
        "\n",
        "# import os\n",
        "# os.chdir('python3-mega')\n",
        "# from mega import Mega\n",
        "# os.chdir('../')\n",
        "# m = Mega.from_ephemeral()\n",
        "\n",
        "# !git clone https://github.com/odwyersoftware/mega.py\n",
        "# %cd mega.py\n",
        "# !python setup.py install\n",
        "%cd '/content/'\n",
        "\n",
        "!rm -rf '/content/yoloOnGoogleColab'\n",
        "#!git clone https://github.com/CAR-Driving/yoloOnGoogleColab"
      ],
      "metadata": {
        "id": "L436PiVNmQog",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9a4857a-4894-47f8-a2c4-9a1bb551aa9a"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: youtube-dl in /usr/local/lib/python3.10/dist-packages (2021.12.17)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-distutils is already the newest version (3.10.8-1~22.04).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " megacmd : Depends: libc-ares2 (>= 1.11.0~rc1) but it is not going to be installed\n",
            "           Depends: libcrypto++6 but it is not installable\n",
            "           Depends: libmediainfo0v5 (>= 0.7.56) but it is not going to be installed\n",
            "           Depends: libssl1.1 (>= 1.1.0) but it is not installable\n",
            "           Depends: libzen0v5 (>= 0.4.31-2~) but it is not going to be installed\n",
            "\u001b[1;31mE: \u001b[0mUnmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\u001b[0m\n",
            "Requirement already satisfied: mega.py in /usr/local/lib/python3.10/dist-packages (1.0.8)\n",
            "Requirement already satisfied: requests>=0.10 in /usr/local/lib/python3.10/dist-packages (from mega.py) (2.31.0)\n",
            "Requirement already satisfied: pycryptodome<4.0.0,>=3.9.6 in /usr/local/lib/python3.10/dist-packages (from mega.py) (3.19.0)\n",
            "Requirement already satisfied: pathlib==1.0.1 in /usr/local/lib/python3.10/dist-packages (from mega.py) (1.0.1)\n",
            "Requirement already satisfied: tenacity<6.0.0,>=5.1.5 in /usr/local/lib/python3.10/dist-packages (from mega.py) (5.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=0.10->mega.py) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=0.10->mega.py) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=0.10->mega.py) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=0.10->mega.py) (2023.7.22)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from tenacity<6.0.0,>=5.1.5->mega.py) (1.16.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-distutils is already the newest version (3.10.8-1~22.04).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " megacmd : Depends: libc-ares2 (>= 1.11.0~rc1) but it is not going to be installed\n",
            "           Depends: libcrypto++6 but it is not installable\n",
            "           Depends: libmediainfo0v5 (>= 0.7.56) but it is not going to be installed\n",
            "           Depends: libssl1.1 (>= 1.1.0) but it is not installable\n",
            "           Depends: libzen0v5 (>= 0.4.31-2~) but it is not going to be installed\n",
            "\u001b[1;31mE: \u001b[0mUnmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\u001b[0m\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# @markdown <center><h3>Input Your Mega ID</h3></center><br>\n",
        "from functools import wraps\n",
        "import errno\n",
        "import os\n",
        "import signal\n",
        "import subprocess\n",
        "import shlex\n",
        "\n",
        "\n",
        "class TimeoutError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "def timeout(seconds=10, error_message=os.strerror(errno.ETIME)):\n",
        "    def decorator(func):\n",
        "        def _handle_timeout(signum, frame):\n",
        "            raise TimeoutError(error_message)\n",
        "\n",
        "        def wrapper(*args, **kwargs):\n",
        "            signal.signal(signal.SIGALRM, _handle_timeout)\n",
        "            signal.alarm(seconds)\n",
        "            try:\n",
        "                result = func(*args, **kwargs)\n",
        "            finally:\n",
        "                signal.alarm(0)\n",
        "            return result\n",
        "\n",
        "        return wraps(func)(wrapper)\n",
        "\n",
        "    return decorator\n",
        "\n",
        "\n",
        "if not os.path.exists(\"/root/.ipython/ocr.py\"):\n",
        "    from subprocess import run\n",
        "    from shlex import split\n",
        "\n",
        "    shellCmd = \"wget -qq https://raw.githubusercontent.com/biplobsd/OneClickRun/master/res/ocr.py \\\n",
        "                    -O /root/.ipython/ocr.py\"\n",
        "    run(split(shellCmd))\n",
        "from ocr import runSh\n",
        "\n",
        "@timeout(10)\n",
        "def runShT(args):\n",
        "    return runSh(args, output=True)\n",
        "\n",
        "\n",
        "# MEGAcmd installing\n",
        "if not os.path.exists(\"/usr/bin/mega-cmd\"):\n",
        "    print(\"Installing MEGA ...\")\n",
        "    runSh('sudo apt-get -y update')\n",
        "    runSh('sudo apt-get -y install libmms0 libc-ares2 libc6 libcrypto++6 libgcc1 libmediainfo0v5 libpcre3 libpcrecpp0v5 libssl1.1 libstdc++6 libzen0v5 zlib1g apt-transport-https')\n",
        "    runSh('sudo curl -sL -o /var/cache/apt/archives/MEGAcmd.deb https://mega.nz/linux/MEGAsync/Debian_9.0/amd64/megacmd-Debian_9.0_amd64.deb', output=True)\n",
        "    runSh('sudo dpkg -i /var/cache/apt/archives/MEGAcmd.deb', output=True)\n",
        "    print(\"MEGA is installed.\")\n",
        "else:\n",
        "    !pkill mega-cmd\n",
        "\n",
        "# INPUT YOUR MEGA ID\n",
        "\n",
        "USERNAME = 'kayeyoc231@llubed.com'  # @param {type:\"string\"}\n",
        "PASSWORD = \"ss123456\"  # @param {type:\"string\"}\n",
        "if not (USERNAME == \"\" or PASSWORD == \"\"):\n",
        "    try:\n",
        "        runShT(f\"mega-login {USERNAME} {PASSWORD}\")\n",
        "        print (\"megazn login has done successfully\")\n",
        "    except TimeoutError:\n",
        "        runSh('mega-whoami', output=True)\n",
        "else:\n",
        "    print(\"Please Input your Mega IDs.\")\n",
        "# @markdown *After signing in, use the above cell(Main Cell) to transfer files from Mega to GDrive using the transfer quota of your Mega Pro Account*"
      ],
      "metadata": {
        "id": "uqYuzvYFoMIM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a021a247-4ac4-42ab-bedf-a9742d9ab4cf"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Initiating MEGAcmd server in background. Log: /root/.megaCmd/megacmdserver.log]\n",
            "Unable to connect to service: error=2\n",
            "Please ensure mega-cmd-server is running\n",
            "Failed to create socket for registering for state changes\n",
            "megazn login has done successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#!rm -rf '/content/ChatGPT_academic_paper'\n",
        "!mkdir '/content/ChatGPT_academic_paper'\n",
        "%cd '/content/ChatGPT_academic_paper'\n",
        "!echo 't' >> t.txt\n",
        "\n",
        "from subprocess import Popen, PIPE\n",
        "import shlex\n",
        "import errno, os\n",
        "\n",
        "from subprocess import Popen, PIPE\n",
        "import shlex\n",
        "from ocr import runSh\n",
        "import re\n",
        "from distutils.dir_util import copy_tree\n",
        "\n",
        "# copy subdirectory example\n",
        "fromDirectory = '/content/ChatGPT_academic_paper/'\n",
        "toDirectory = '/content/gdrive/My Drive/yolo_car_database/'\n",
        "\n",
        "runSh('mega-cd /' )\n",
        "runSh(' mega-mkdir ChatGPT_academic_paper ')\n",
        "runSh(' mega-ls ')\n",
        "runSh('mega-cd ChatGPT_academic_paper ')\n",
        "\n",
        "# copy_tree(fromDirectory, toDirectory)\n",
        "def uplaod_mega_nz(root,cloude='mega',title1=''):\n",
        "  if (cloude=='mega'):\n",
        "  #  from mega import Mega\n",
        "  #  mega = Mega()\n",
        "  #  email = 'woraqofa@ivyandmarj.com'\n",
        "  #  password = 'feripas800@wgraj.com'\n",
        "  #  m = mega.login(email, password)\n",
        "  #  # login using a temporary anonymous account\n",
        "  #  m = mega.login()\n",
        "  #  quota = m.get_quota()\n",
        "  #  # specify unit output kilo, mega, gig, else bytes will output\n",
        "  #  space = m.get_storage_space(kilo=True)\n",
        "  #  m.create_folder('yolo_car_database/'+title1+'/')\n",
        "  #  folder = m.find('yolo_car_database/'+title1+'/')\n",
        "   # m.upload('myfile.doc', folder[0])\n",
        "  #  run_command('mega-cd ~ && mega-mkdir Yolo_car_database && mega-cd Yolo_car_database && mega-put '+ root+'/* . ')\n",
        "\n",
        "   runSh('mega-cd ChatGPT_academic_paper' + title1 + '/')\n",
        "   runSh('mega-put '+ root+' . ')\n",
        "   runSh(' mega-ls')\n",
        "\n",
        "   for path, subdirs, files in os.walk( root):\n",
        "      for name in files:\n",
        "        print (files)\n",
        "          # m.upload(os.path.join(path, name), folder[0])\n",
        "   # public_exported_web_link = m.export('myfile.doc')\n",
        "   # public_exported_web_link = m.export('my_mega_folder/my_sub_folder_to_share')\n",
        "\n",
        "  if (cloude=='google_drive'):\n",
        "     run_command('mkdir '+root+'/')\n",
        "     for path, subdirs, files in os.walk( root):\n",
        "      for name in files:\n",
        "        # print ('cp -r \"'+os.path.join(path, name)+'\" '+'\"/content/gdrive/My Drive/ChatGPT_academic_paper/' + title1 + '/\"')\n",
        "        # print (os.path.join(path, change_name(name)))\n",
        "        # os.rename(os.path.join(path, name), os.path.join(path, change_name(name)))\n",
        "        run_command('cp -r  \"'+os.path.join(path, name)+'\" '+'\"/content/gdrive/My Drive/ChatGPT_academic_paper/' + title1 + '/\"')\n",
        "     try:\n",
        "        copy_tree(root,'/content/gdrive/My Drive/ChatGPT_academic_paper/' + title1 + '/')\n",
        "     except OSError as e: # this would be \"except OSError, e:\" before Python 2.6\n",
        "        if e.errno != errno.ENOENT: # errno.ENOENT = no such file or directory\n",
        "            # raise #\n",
        "            i=0\n",
        "def change_file_name(root):\n",
        "  for path, subdirs, files in os.walk( root):\n",
        "      for name in files:\n",
        "        print ('filename is: \"'+os.path.join(path, name))\n",
        "        print (os.path.join(path, change_name(name)))\n",
        "        os.rename(os.path.join(path, name), os.path.join(path, change_name(name)))\n",
        "\n",
        "def run_command(cmd):\n",
        "    with Popen(shlex.split(cmd), stdout=PIPE, bufsize=1, universal_newlines=False) as p:\n",
        "        while True:\n",
        "            line = p.stdout.readline()\n",
        "            if not line:\n",
        "                break\n",
        "            print(line)\n",
        "        exit_code = p.poll()\n",
        "    return exit_code\n",
        "def change_name(name):\n",
        "    name_file = ''.join(name)\n",
        "    name_file = name_file.replace(\" \", \"_\")\n",
        "    name_file = name_file.replace(\"'\", \"_\")\n",
        "    name_file = name_file.replace(\"\\n\", \"\")\n",
        "    name_file = name_file.replace(\"\\t\", \"\")\n",
        "    name_file = name_file.replace(\"!\", \"\")\n",
        "    name_file = name_file.replace(\"-\", \"\")\n",
        "    name_file = name_file.replace(\"$\", \"\")\n",
        "    name_file = re.sub(r'[\\\\/*?:\"<>|]',\"\",name_file)\n",
        "    return name_file\n",
        "def MegaZN_upload_file(command):\n",
        "    # command_title=re.split('([^a-zA-Z0-9])',command)\n",
        "    command_title_1 = re.split('([^a-zA-Z0-9])', command)\n",
        "    command_title = ''.join(command_title_1)\n",
        "    command_title=change_name(command_title)\n",
        "\n",
        "\n",
        "    # call_args = ' youtube-dl --match-title ' + ' \"'+command_title_1[0]+ '\" ' + '\"ytsearch10\":'+'\"'+command+ '\" '+\"--external-downloader-args   '-ss 00:00:03 -t 00:03:08' --write-info-json --write-annotation --write-thumbnail --write-sub -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4'\"\n",
        "    #call_args = ' youtube-dl --match-title ' + ' \"'+command_title_1[0]+ '\" ' + '\"ytsearch100\":'+'\"'+command+ '\" '+\"--playlist-end 3  --external-downloader-args   '-ss 00:00:03 -t 00:03:08' --write-info-json --write-annotation --write-thumbnail --write-sub -f 'best[ext=mp4,height<=1080]+best[filesize<100M]' \"\n",
        "\n",
        "    # call_args = call_args.split() # because call takes a list of strings\n",
        "    # print (call_args)\n",
        "    # call(call_args)\n",
        "    # os.chdir(\"/content/yolo_car_database\")\n",
        "    # run_command('cd \"/content/yolo_car_database\"')\n",
        "    # run_command(call_args)\n",
        "    # os.system(\"cp --recursive '/content/yolo_car_database' '/content/gdrive/My Drive/yolo_car_databe\")\n",
        "    # os.system('pwd && ls ')\n",
        "    # copy_tree(fromDirectory, toDirectory)\n",
        "    # p = Popen(shlex.split(call_args), bufsize=1, universal_newlines=True)\n",
        "    run_command('mkdir /content/ChatGPT_academic_paper/'+command_title)\n",
        "\n",
        "    os.chdir( '/content/ChatGPT_academic_paper/'+command_title+'/')\n",
        "    #run_command(call_args)\n",
        "    # copy_tree('/content/yolo_car_database/'+command_title+'/', '/content/gdrive/My Drive/yolo_car_database/'+command_title+'/')\n",
        "    change_file_name('/content/ChatGPT_academic_paper/'+command_title+'/')\n",
        "    uplaod_mega_nz('/content/ChatGPT_academic_paper/'+command_title+'/','mega',command_title)\n",
        "    try:\n",
        "        # call(call_args)\n",
        "        # run_command('mkdir /content/yolo_car_database/'+command_title)\n",
        "        # os.chdir( '/content/yolo_car_database/'+command_title+'/')\n",
        "        # run_command(call_args)\n",
        "        # copy_tree('/content/yolo_car_database/'+command_title+'/', toDirectory)\n",
        "\n",
        "        # print (call_args)\n",
        "        pp=0\n",
        "\n",
        "    except OSError as e: # this would be \"except OSError, e:\" before Python 2.6\n",
        "        if e.errno != errno.ENOENT: # errno.ENOENT = no such file or directory\n",
        "            raise # re-raise exception if a different error occurred\n",
        "\n",
        "    # return p.poll()\n",
        "\n",
        "# !wget https://github.com/spectrico/car-make-model-classifier-yolo3-python/blob/master/labels.txt\n",
        "\n",
        "i=0\n",
        "#for line in open('/content/yoloOnGoogleColab/car_type_label.txt','r').readlines():\n",
        "    #print (line)\n",
        "    #try:\n",
        "      #Youtube_download_video(line)\n",
        "\n",
        "    #except OSError as e: # this would be \"except OSError, e:\" before Python 2.6\n",
        "        #if e.errno != errno.ENOENT: # errno.ENOENT = no such file or directory\n",
        "            #i=1 # re-raise exception if a different error occurred\n",
        "    #i=i+1\n",
        "# !cp '/content/yolo_car_database' \"gdrive/My Drive/yolo_car_databe\""
      ],
      "metadata": {
        "id": "8Fx5M6zXmTAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38a7e07d-5e24-4856-9aaf-c62a7725b297"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/ChatGPT_academic_paper’: File exists\n",
            "/content/ChatGPT_academic_paper\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!pwd\n",
        "%cd '/content/'\n",
        "from google.colab import drive\n",
        "import os\n",
        "import subprocess\n",
        "from docx import Document\n",
        "from django.utils.text import slugify\n",
        "\n",
        "# Mount Google Drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "def save_academic_paper_with_prompt_megazn(topic, prompt_my,contnet):\n",
        "  # Define the path to the folder in Google Drive\n",
        "  folder_path = r\"/content/ChatGPT_academic_paper/\"\n",
        "\n",
        "  Pdf_Dir= r\"/content/ChatGPT_academic_paper/\"\n",
        "  docx_path= f\"{folder_path}{topic}.docx\"\n",
        "  # Check if the folder exists\n",
        "  if not os.path.exists(folder_path):\n",
        "  # If the folder doesn't exist, create it\n",
        "    os.mkdir(folder_path)\n",
        "\n",
        "\n",
        "  # Replace spaces in the topic with underscores\n",
        "  #topic = topic[:12].replace(\" \", \"_\")\n",
        "  topic = slugify(topic)\n",
        "\n",
        "  # Define the path to the DOCX file in the folder\n",
        "\n",
        "\n",
        "  # Check if the DOCX file exists\n",
        "  if os.path.isfile(docx_path):\n",
        "    # If the DOCX file exists, open it\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"#+str(random.randint(0,9))+\".docx\"\n",
        "    doc = Document(docx_path)\n",
        "  else:\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"\n",
        "    #print(docx_path)\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "    doc = Document()\n",
        "\n",
        "  # Add the generated text to the document\n",
        "  p = doc.add_paragraph(prompt_my)\n",
        "  # Add the generated text to the document\n",
        "  # Add the generated text to the document\n",
        "  p.style = doc.styles['Heading 2']\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Revert the style of the paragraph back to 'Normal'\n",
        "  p = doc.add_paragraph(contnet)\n",
        "  p.style = doc.styles['Normal']\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Convert the DOCX file to a PDF\n",
        "  convert_docx_to_pdf(docx_path,Pdf_Dir)\n",
        "\n",
        "  os.chdir(folder_path)\n",
        "\n",
        "    # copy_tree('/content/yolo_car_database/'+command_title+'/', '/content/gdrive/My Drive/yolo_car_database/'+command_title+'/')\n",
        "\n",
        "  uplaod_mega_nz('/content/ChatGPT_Paper_wrting/')\n",
        "  uplaod_mega_nz('/content/ChatGPT_Paper_wrting/','google_drive')"
      ],
      "metadata": {
        "id": "nv2vAOr8sskq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "462501e1-2307-4958-b1de-e6a112128a9e"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ChatGPT_academic_paper\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#save_academic_paper(\"Persian_\"+'topic','\\n**'+'choice_translated_prompt'+'**\\n'+\"choice_translated\")\n",
        "topic = TOPIC[:20].replace(\" \", \"_\")\n",
        "topic = slugify(TOPIC[:-5])\n",
        "docx_path = f\"{topic}.docx\"\n",
        "\n",
        "print(docx_path)"
      ],
      "metadata": {
        "id": "a76qNIRHs_gS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d2738cf-4868-49d7-961d-12fe933c8919"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install googletrans==4.0.0-rc1\n",
        "\n",
        "!pip install httpcore==0.15.0 httpx pymongo googletrans\n",
        "!pip install httpx==0.24.1"
      ],
      "metadata": {
        "id": "qQOCu3GyEFf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "134a3c39-d2dc-4f9f-dbc9-6c2533476034"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: httpcore==0.15.0 in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (0.24.1)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.6.0)\n",
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (0.12.0)\n",
            "Requirement already satisfied: sniffio==1.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (1.3.0)\n",
            "Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (2023.7.22)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore==0.15.0) (3.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore==0.15.0) (1.1.3)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from googletrans) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->googletrans) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->googletrans) (2.0.7)\n",
            "Requirement already satisfied: httpx==0.24.1 in /usr/local/lib/python3.10/dist-packages (0.24.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (2023.7.22)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (0.15.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (1.3.0)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.1) (0.12.0)\n",
            "Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.1) (3.7.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore<0.18.0,>=0.15.0->httpx==0.24.1) (1.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#I have tried to update the prompt by ChatGPT itself 👇👇"
      ],
      "metadata": {
        "id": "wxqM4h1fw4fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_main_variables(prompts, variable):\n",
        "   main_variables= main_variables_0\n",
        "   for prompt in prompts:\n",
        "       variables = re.findall(r'\\{(\\w+)\\}', prompt)\n",
        "       for var in variables:\n",
        "           if var == 'TOPIC':\n",
        "               main_variables[var] = variable\n",
        "           else:\n",
        "               main_variables[var] = None\n",
        "\n",
        "   return main_variables"
      ],
      "metadata": {
        "id": "Jd711_MyBgje"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_main_variables(prompts, variable_para, var_content):\n",
        "    main_variables = main_variables_0\n",
        "\n",
        "    new_prompt = prompts[:]  # Create a deep copy of prompts\n",
        "\n",
        "    for i, prompt in enumerate(prompts):\n",
        "        for var in variable_para:\n",
        "            if var == variable_para :\n",
        "                main_variables[var] = var_content\n",
        "                new_prompt[i] = prompt.replace(var, var_content)\n",
        "        for var, value in main_variables.items():\n",
        "             if var == variable_para:\n",
        "                main_variables[var] = var_content\n",
        "                new_prompt[i] = new_prompt[i].replace('{'+var+'}', \"{\"+f\"{var}\"+'}'+f\" which is :{var_content}\")#f\"{{{variable}}}\")\n",
        "\n",
        "\n",
        "    return main_variables, new_prompt\n",
        "#TOPIC='my test topic'\n",
        "main_variables, prompt_new = extract_main_variables(prompts, 'TOPIC', TOPIC)\n",
        "print (\" topic is :\", TOPIC)\n",
        "print(\"main variable is :\", main_variables)\n",
        "print(\"new_prompt is :\", prompt_new)\n",
        "prompts= prompt_new\n",
        "print(\"prompt is :\", prompts)"
      ],
      "metadata": {
        "id": "VLFUpVSA2Pbr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0beee573-bc90-4359-bb71-f524e95b97d2"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " topic is : بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی \n",
            "main variable is : {'TOPIC': 'بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی '}\n",
            "new_prompt is : ['What are the key aspects of بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی  that need to be addressed?', 'Create a mind map of the main elements of بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی  and how they are interconnected.', 'Write down ideas on sticky notes about how to improve بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی . Then, group these ideas based on common themes.', 'Take turns sharing ideas on how to improve بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی . Make sure everyone has a chance to contribute.', 'Think of ways to create the problem in بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی . This will help you understand how to solve it.', 'Apply the SCAMPER method to existing solutions or situations in بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی . This will spark new ideas.', 'Assemble a diverse group of people from various backgrounds and disciplines to tackle بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی . This will ensure a more rounded and innovative solution.', 'Envision a future state where بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی  has been solved successfully. Starting from this endpoint, work backward to identify the series of events and decisions that led to that future.']\n",
            "prompt is : ['What are the key aspects of بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی  that need to be addressed?', 'Create a mind map of the main elements of بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی  and how they are interconnected.', 'Write down ideas on sticky notes about how to improve بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی . Then, group these ideas based on common themes.', 'Take turns sharing ideas on how to improve بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی . Make sure everyone has a chance to contribute.', 'Think of ways to create the problem in بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی . This will help you understand how to solve it.', 'Apply the SCAMPER method to existing solutions or situations in بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی . This will spark new ideas.', 'Assemble a diverse group of people from various backgrounds and disciplines to tackle بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی . This will ensure a more rounded and innovative solution.', 'Envision a future state where بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی  has been solved successfully. Starting from this endpoint, work backward to identify the series of events and decisions that led to that future.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "\n",
        "def generate_prompt_from_response(previous_response, main_variables):\n",
        "   # Customize this logic based on your needs\n",
        "   # For simplicity, let's use the last 50 characters of the response as the new prompt\n",
        "   new_prompt = previous_response[-50:]\n",
        "\n",
        "   # Replace the main variables in the new prompt\n",
        "   for var, value in main_variables.items():\n",
        "       if value is not None:\n",
        "           new_prompt = new_prompt.replace(value, f\"{{{var}}}\")\n",
        "\n",
        "   return new_prompt\n",
        "\n",
        "# Example usage\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\"\n",
        "\n",
        "prompts_1 = [\n",
        "f\"Find a research topic for a PhD in the area of '{TOPIC}'\",\n",
        "\n",
        "]\n",
        "#prompts_2 = [\n",
        "#   \"I need to find information on renewable energy for a research paper that will be 1,500 words and must include eight sources.\",\n",
        "#   \"The research paper should cover the latest advancements in renewable energy technology.\"\n",
        "#]\n",
        "\n",
        "#main_variables,prompt_new = extract_main_variables(prompts,'TOPIC',TOPIC)\n",
        "#print(main_variables)\n",
        "\n",
        "#previous_response = \"Previous GPT response\"\n",
        "#new_prompt = generate_prompt_from_response(previous_response, main_variables)\n",
        "#print(new_prompt)\n",
        "#print ( prompts)"
      ],
      "metadata": {
        "id": "NYegFb6aq_h8"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Updating the prompt by ChatGPT:👇👇"
      ],
      "metadata": {
        "id": "UgzzXkG9wjbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.get_encoding(encoding_name)\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "num_tokens_from_string(\"tiktoken is great!\", \"cl100k_base\")"
      ],
      "metadata": {
        "id": "oJ1QCUr62rtw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6a5e9aa-8c35-48b4-e1b9-3ebcd11c4c22"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt_update_0(prompt, previous_content, main_variables):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   # Replace the TOPIC variable in the prompt\n",
        "   for var, value in main_variables.items():\n",
        "       if var == 'TOPIC' and value is not None:\n",
        "           prompt = prompt.replace(f\"{{{var}}}\", value)\n",
        "\n",
        "   # Construct the instruction for updating the prompt\n",
        "   instruction = f\"Given the previous content:\\n\\n{previous_content}\\n\\nUpdate the prompt: {prompt}\"\n",
        "\n",
        "   # Create the completion with the instruction\n",
        "   completion = client.completions.create(\n",
        "       model=model_engine,\n",
        "       prompt=instruction,\n",
        "       max_tokens=max_tokens,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "\n",
        "   # Extract and return the updated prompt from the response\n",
        "   updated_prompt = completion.choices[0].text.strip()\n",
        "   return updated_prompt"
      ],
      "metadata": {
        "id": "QbOCQqCDB8xb"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "def generate_prompt_update_a1(prompt_my):\n",
        "  model_engine = \"text-davinci-003\"\n",
        "  max_tokens = 2048\n",
        "\n",
        "  completion = client.completions.create(\n",
        "      model=\"gpt-3.5-turbo-instruct\",\n",
        "      #model=\"curie\"\n",
        "      prompt=prompt_my,\n",
        "      max_tokens=2048,\n",
        "      temperature=0.3,\n",
        "      n=1,\n",
        "      frequency_penalty=0,\n",
        "  )\n",
        "  return completion"
      ],
      "metadata": {
        "id": "WPRw6qJOuaS1"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import openai\n",
        "from openai import RateLimitError\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   api_key = openai_api# \"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\",\n",
        ")\n",
        "def retry_with_exponential_backoff(\n",
        "   func,\n",
        "   initial_delay: float = 1,\n",
        "   exponential_base: float = 2,\n",
        "   jitter: bool = True,\n",
        "   max_retries: int = 10,\n",
        "   errors: tuple = (RateLimitError,),\n",
        "):\n",
        "   \"\"\"Retry a function with exponential backoff.\"\"\"\n",
        "   def wrapper(*args, **kwargs):\n",
        "       # Initialize variables\n",
        "       num_retries = 0\n",
        "       delay = initial_delay\n",
        "       # Loop until a successful response or max_retries is hit or an exception is raised\n",
        "       while True:\n",
        "           try:\n",
        "               return func(*args, **kwargs)\n",
        "           # Retry on specified errors\n",
        "           except errors as e:\n",
        "               # Increment retries\n",
        "               num_retries += 1\n",
        "               # Check if max retries has been reached\n",
        "               if num_retries > max_retries:\n",
        "                  raise Exception(\n",
        "                      f\"Maximum number of retries ({max_retries}) exceeded.\"\n",
        "                  )\n",
        "               # Increment the delay\n",
        "               delay *= exponential_base * (1 + jitter * random.random())\n",
        "               # Sleep for the delay\n",
        "               time.sleep(delay)\n",
        "           # Raise exceptions for any errors not specified\n",
        "           except Exception as e:\n",
        "               raise e\n",
        "   return wrapper\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "\n",
        "@retry_with_exponential_backoff\n",
        "def generate_prompt_update(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "   print(f\"{num_tokens_from_string(prompt_my,model)} prompt tokens counted by num_tokens_from_messages().\")\n",
        "\n",
        "   completion = client.completions.create(\n",
        "     model=\"gpt-3.5-turbo-instruct\",\n",
        "     prompt=prompt_my,\n",
        "     max_tokens=500,\n",
        "     temperature=0.1,\n",
        "     n=1,\n",
        "     frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "\n",
        "@retry_with_exponential_backoff\n",
        "def generate_academic_paper(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "   print(f\"{num_tokens_from_string(prompt_my,model)} prompt tokens counted by num_tokens_from_messages().\")\n",
        "\n",
        "\n",
        "   completion = client.completion.create(\n",
        "     #model=\"gpt-3.5-turbo-instruct\",\n",
        "     model=\"gpt-3.5-turbo-1106\",\n",
        "     prompt=prompt_my,\n",
        "     max_tokens=2048,\n",
        "     temperature=0.3,\n",
        "     n=1,\n",
        "     frequency_penalty=0,\n",
        "   )\n",
        "   return completion"
      ],
      "metadata": {
        "id": "O2TNMQ8eFl8n"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def generate_content(prompts, variables, TOPIC, perviuse_content=\"\"):\n",
        "  # Generate content for each variable\n",
        "  variable_contents = {}\n",
        "\n",
        "\n",
        "  main_variables = main_variables_0\n",
        "  for prompt in prompts:\n",
        "      for var in variables:\n",
        "          if var in prompt:\n",
        "              print(f\"\\n---prompt is ----\\n{prompt}\")\n",
        "              #prompt_my = f\"Generate content for the variable '{var}' in the context of the topic '{TOPIC}'. Please consider the result must be in less than 10 words. The prompt is '{prompt}'. Also the more information for understanding better content is '{perviuse_content}'\"\n",
        "\n",
        "              prompt_my = f\"Generate content for the variable '{var}' in the context of the topic '{TOPIC}'. Please consider the result must be sumerized and as variable for chatgpt academic phd writer assistance. The prompt is '{prompt}'. Also the more information for understanding better content is '{perviuse_content}'\"\n",
        "              content = generate_prompt_update_a1(prompt_my)\n",
        "              for choice in content.choices:\n",
        "                print(\"\\n Result is :\"+choice.text)\n",
        "                variable_contents[var] = choice.text\n",
        "              print(f\"variable_contents[{var}] is: {variable_contents[var]}\")\n",
        "\n",
        "              time.sleep(random.randint(22, 40))\n",
        "\n",
        "  # Replace the variables in the prompts with the generated content\n",
        "  prompt_new = []\n",
        "  for prompt in prompts:\n",
        "      for var, content in variable_contents.items():\n",
        "          prompt = prompt.replace(f\"{{{var}}}\", variable_contents[var])\n",
        "      prompt_new.append(prompt)\n",
        "      print(\"\\n --- Updated prompt is :\\n\"+str(prompt_new))\n",
        "  return prompt_new\n",
        "\n",
        "# Define main variables\n",
        "#TOPIC = \"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"\n",
        "\n",
        "# List of variables\n",
        "variables = [\"RESEARCH_DOMAIN\", \"PARAGRAPH\", \"PARAGRAPHS\", \"TOPIC_SENTENCE\", \"LANGUAGE\", \"ABSTRACT_PARAGRAPH\", \"BIBLIOGRAPHY\", \"THEORY1\", \"THEORY2\", \"RESEARCH_QUESTIONS\", \"ACTION\", \"RESULT_PARAGRAPHS\", \"DATE\", \"NUMBER_OF_DAYS_MONTHS_YEARS\"]\n",
        "\n",
        "# List of prompts\n",
        "#prompts = [\"prompt1\", \"prompt2\", \"prompt3\"] # replace with your actual prompts\n",
        "#perviuse_content= \"test\"\n",
        "# Call the function and store the returned prompts\n",
        "#updated_prompts = generate_content(prompts, variables, TOPIC, perviuse_content)\n",
        "#print(\"Updated Prompts:\", updated_prompts)"
      ],
      "metadata": {
        "id": "uI21enmkhb0n"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def generate_content_2(prompts, variables, TOPIC, perviuse_content=\"\"):\n",
        "  # Generate content for each variable\n",
        "  variable_contents = {}\n",
        "  main_variables = main_variables_0\n",
        "  for prompt in prompts:\n",
        "      for var in variables:\n",
        "          if var in prompt:\n",
        "              print(f\"\\n---prompt is ----\\n{prompt}\")\n",
        "              prompt_my = f\"Generate content for the variable '{var}' in the context of the topic '{TOPIC}'. Please consider the result must be in less than 10 words. The prompt is '{prompt}'. Also the more information for understanding better content is '{perviuse_content}'\"\n",
        "              content = generate_prompt_update_a1(prompt_my)\n",
        "              for choice in content.choices:\n",
        "                print(\"\\n Result is :\"+choice.text)\n",
        "                variable_contents[var] = choice.text\n",
        "              print(f\"variable_contents[{var}] is: {variable_contents[var]}\")\n",
        "\n",
        "              time.sleep(random.randint(22, 40))\n",
        "\n",
        "  main_variables, prompt_new = extract_main_variables(prompts, var, variable_contents[var])\n",
        "\n",
        "  print(\"main variable is :\", main_variables)\n",
        "  print(\"new_prompt is :\", prompt_new)\n",
        "  prompts= prompt_new\n",
        "\n",
        "  # Replace the variables in the prompts with the generated content\n",
        "  prompt_new = []\n",
        "  for prompt in prompts:\n",
        "      for var, content in variable_contents.items():\n",
        "          prompt = prompt.replace(f\"{{{var}}}\", variable_contents[var])\n",
        "      prompt_new.append(prompt)\n",
        "      print(\"\\n --- Updated prompt is :\\n\"+str(prompt_new))\n",
        "  return prompt_new,main_variables\n",
        "\n",
        "# Define main variables\n",
        "#TOPIC = \"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"\n",
        "\n",
        "# List of variables\n",
        "variables = [\"RESEARCH_DOMAIN\", \"PARAGRAPH\", \"PARAGRAPHS\", \"TOPIC_SENTENCE\", \"LANGUAGE\", \"ABSTRACT_PARAGRAPH\", \"BIBLIOGRAPHY\", \"THEORY1\", \"THEORY2\", \"RESEARCH_QUESTIONS\", \"ACTION\", \"RESULT_PARAGRAPHS\", \"DATE\", \"NUMBER_OF_DAYS_MONTHS_YEARS\"]\n",
        "\n",
        "# List of prompts\n",
        "#prompts = [\"prompt1\", \"prompt2\", \"prompt3\"] # replace with your actual prompts\n",
        "#perviuse_content= \"test\"\n",
        "# Call the function and store the returned prompts\n",
        "#updated_prompts = generate_content(prompts, variables, TOPIC, perviuse_content)\n",
        "#print(\"Updated Prompts:\", updated_prompts)"
      ],
      "metadata": {
        "id": "-tAXnnAOkagH"
      },
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\" #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\"\n",
        "\n",
        "\n",
        "#topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "#client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   #api_key = \"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\",\n",
        "#)\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "# Create a Translator object\n",
        "translator = Translator()\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "def generate_academic_paper_a0(prompt_my):\n",
        "  model_engine = \"text-davinci-003\"\n",
        "  max_tokens = 2048\n",
        "\n",
        "  completion = client.completions.create(\n",
        "      model=\"gpt-3.5-turbo-instruct\",\n",
        "      prompt=prompt_my,\n",
        "      max_tokens=2048,\n",
        "      temperature=0.3,\n",
        "      n=1,\n",
        "      frequency_penalty=0,\n",
        "  )\n",
        "  return completion"
      ],
      "metadata": {
        "id": "44bkCJOHtmuJ"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time,random\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   api_key = openai_api#\"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\",\n",
        ")\n",
        "\n",
        "def generate_papers(prompts, perviuse_content, perviuse_try_numner):\n",
        "  choice_text_all=[]\n",
        "\n",
        "  for i in range(perviuse_try_numner, len(prompts), 20):\n",
        "     # Slice the prompts list to get the next 20 prompts\n",
        "     print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "\n",
        "     batch = prompts[i:i+20]\n",
        "     print(\"batch is \",batch)\n",
        "\n",
        "     for prompt in batch:\n",
        "\n",
        "         # Print the prompt\n",
        "         print(\"prompt is \",list({prompt}))\n",
        "\n",
        "         updated_prompts = generate_content(list({prompt}), variables, TOPIC, perviuse_content)\n",
        "         print(\"Updated Prompts:\", updated_prompts)\n",
        "\n",
        "         time.sleep(random.randint(22, 40))\n",
        "         response = generate_academic_paper_a0(updated_prompts)\n",
        "         print(\"\\nGenerated Academic Paper:\")\n",
        "         print(\"========================\\n\")\n",
        "         for choice in response.choices:\n",
        "           print(choice.text)\n",
        "           choice_in_loop = choice.text\n",
        "           choice_text_all.append(choice.text)\n",
        "\n",
        "\n",
        "         #save_academic_paper(topic,'\\n--------**\\n'+updated_prompts+'/n-------**\\n'+choice.text)\n",
        "         save_academic_paper_with_prompt(TOPIC[:20],'\\n**<<<  ChatGPT Prompt is:\\n'+''.join(updated_prompts)+'\\n>>>**\\n',choice.text)\n",
        "\n",
        "         save_academic_paper_with_prompt_megazn(TOPIC[:20],'\\n**<<<  ChatGPT Prompt is:\\n'+''.join(updated_prompts)+'\\n>>>**\\n',choice.text)\n",
        "         #save_academic_paper_with_prompt_megazn(TOPIC[:20],'\\n**<<<  ChatGPT Prompt is:\\n'+''.join(updated_prompts)+'\\n>>>**\\n',choice.text, 'google_drive')\n",
        "         if hasattr(choice, 'choices'):\n",
        "             extract_text(choice)\n",
        "\n",
        "         perviuse_content = choice_in_loop\n",
        "         print(\"\\n end of loop\")\n",
        "         print(\"========================\\n\")\n",
        "\n",
        "         time.sleep(random.randint(22, 40))\n",
        "         perviuse_try_numner = perviuse_try_numner+1\n",
        "  return choice_text_all,perviuse_try_numner\n",
        "\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\" #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\""
      ],
      "metadata": {
        "id": "JHIX17GHsecy"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Final Results 👇🌹🌱"
      ],
      "metadata": {
        "id": "xHPMNDjfToIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from django.utils.text import slugify\n",
        "\n",
        "\n",
        "\n",
        "def main_generate_papers(TOPIC, prompts, perviuse_content, perviuse_try_numner):\n",
        "    if not perviuse_try_numner:\n",
        "        perviuse_try_numner = 0\n",
        "        perviuse_content = ['fist step']\n",
        "\n",
        "    elif (perviuse_try_numner == len(prompts)):\n",
        "        perviuse_try_numner = 0\n",
        "        perviuse_content = ['fist step']\n",
        "\n",
        "    generate_papers(prompts, perviuse_content, perviuse_try_numner)\n",
        "\n",
        "    return perviuse_content, perviuse_try_numner\n",
        "\n",
        "topic = TOPIC_CLASS()\n",
        "\n",
        "if not topic.perviuse_try_numner:\n",
        "    topic.perviuse_try_numner = 0\n",
        "    topic.perviuse_content = ['fist step']\n",
        "\n",
        "elif (topic.perviuse_try_numner == len(prompts)):\n",
        "    topic.perviuse_try_numner = 0\n",
        "    topic.perviuse_content = ['fist step']\n",
        "\n",
        "topic.topic = TOPIC\n",
        "main_generate_papers(topic.topic, prompts, topic.perviuse_content, topic.perviuse_try_numner)"
      ],
      "metadata": {
        "id": "-YbWDEd4WzDq",
        "outputId": "d464eacb-de27-4a40-e64d-5f03661b41c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I is  0  Len of prompt Is: 8\n",
            "batch is  ['What are the key aspects of بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی  that need to be addressed?', 'Create a mind map of the main elements of بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی  and how they are interconnected.', 'Write down ideas on sticky notes about how to improve بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی . Then, group these ideas based on common themes.', 'Take turns sharing ideas on how to improve بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی . Make sure everyone has a chance to contribute.', 'Think of ways to create the problem in بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی . This will help you understand how to solve it.', 'Apply the SCAMPER method to existing solutions or situations in بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی . This will spark new ideas.', 'Assemble a diverse group of people from various backgrounds and disciplines to tackle بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی . This will ensure a more rounded and innovative solution.', 'Envision a future state where بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی  has been solved successfully. Starting from this endpoint, work backward to identify the series of events and decisions that led to that future.']\n",
            "prompt is  ['What are the key aspects of بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی  that need to be addressed?']\n",
            "\n",
            " --- Updated prompt is :\n",
            "['What are the key aspects of بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی  that need to be addressed?']\n",
            "Updated Prompts: ['What are the key aspects of بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی  that need to be addressed?']\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:backoff:Backing off generate_academic_paper_a0(...) for 0.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-Q07LrlRkXw9wIcYieiZ4OMrT on requests per day (RPD): Limit 200, Used 200, Requested 1. Please try again in 7m12s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "INFO:backoff:Backing off generate_academic_paper_a0(...) for 1.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-Q07LrlRkXw9wIcYieiZ4OMrT on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "INFO:backoff:Backing off generate_academic_paper_a0(...) for 0.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-Q07LrlRkXw9wIcYieiZ4OMrT on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "INFO:backoff:Backing off generate_academic_paper_a0(...) for 2.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-Q07LrlRkXw9wIcYieiZ4OMrT on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "INFO:backoff:Backing off generate_academic_paper_a0(...) for 14.6s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-Q07LrlRkXw9wIcYieiZ4OMrT on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "INFO:backoff:Backing off generate_academic_paper_a0(...) for 27.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-Q07LrlRkXw9wIcYieiZ4OMrT on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "INFO:backoff:Backing off generate_academic_paper_a0(...) for 9.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-Q07LrlRkXw9wIcYieiZ4OMrT on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "INFO:backoff:Backing off generate_academic_paper_a0(...) for 25.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-Q07LrlRkXw9wIcYieiZ4OMrT on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "INFO:backoff:Backing off generate_academic_paper_a0(...) for 168.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-Q07LrlRkXw9wIcYieiZ4OMrT on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "1. Definition of Violence Against Women: The first key aspect of the topic is to clearly define what constitutes violence against women. This can include physical, sexual, psychological, and economic violence, as well as other forms of abuse and discrimination.\n",
            "\n",
            "2. Prevalence and Impact: It is important to examine the prevalence of violence against women and its impact on individuals, families, and society as a whole. This includes understanding the root causes and underlying factors that contribute to this issue.\n",
            "\n",
            "3. Cultural and Social Context: The cultural and social context in which violence against women occurs must be taken into consideration. This includes examining societal attitudes, beliefs, and norms that perpetuate and justify violence against women.\n",
            "\n",
            "4. Legal Framework: The legal framework for addressing violence against women, including laws, policies, and procedures, should be evaluated. This includes looking at the effectiveness of existing laws and identifying any gaps or loopholes that need to be addressed.\n",
            "\n",
            "5. Support Services: It is important to assess the availability and accessibility of support services for survivors of violence against women. This includes shelters, hotlines, counseling, and legal aid services.\n",
            "\n",
            "6. Prevention Strategies: Examining prevention strategies is crucial in breaking the cycle of violence against women. This can include education and awareness programs, as well as addressing underlying issues such as gender inequality and toxic masculinity.\n",
            "\n",
            "7. Role of Media: The role of media in perpetuating or challenging stereotypes and attitudes towards violence against women should also be examined. This includes analyzing the portrayal of women in media and the impact it has on societal perceptions.\n",
            "\n",
            "8. International Efforts: It is important to consider the global efforts and initiatives in addressing violence against women, such as the United Nations' Sustainable Development Goals and the Convention on the Elimination of all Forms of Discrimination Against Women (CEDAW).\n",
            "\n",
            "9. Challenges and Barriers: The challenges and barriers in addressing violence against women, such as lack of resources, political will, and cultural resistance, should be identified and addressed.\n",
            "\n",
            "10. Future Directions: Finally, it is important to discuss potential solutions and recommendations for addressing violence against women in the future. This can include policy changes, education and awareness campaigns, and strengthening support services for survivors.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  ['Create a mind map of the main elements of بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی  and how they are interconnected.']\n",
            "\n",
            " --- Updated prompt is :\n",
            "['Create a mind map of the main elements of بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی  and how they are interconnected.']\n",
            "Updated Prompts: ['Create a mind map of the main elements of بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی  and how they are interconnected.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off generate_academic_paper_a0(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-Q07LrlRkXw9wIcYieiZ4OMrT on requests per day (RPD): Limit 200, Used 200, Requested 1. Please try again in 7m12s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "INFO:backoff:Backing off generate_academic_paper_a0(...) for 0.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-Q07LrlRkXw9wIcYieiZ4OMrT on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "INFO:backoff:Backing off generate_academic_paper_a0(...) for 3.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-Q07LrlRkXw9wIcYieiZ4OMrT on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "INFO:backoff:Backing off generate_academic_paper_a0(...) for 5.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-Q07LrlRkXw9wIcYieiZ4OMrT on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "INFO:backoff:Backing off generate_academic_paper_a0(...) for 10.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-Q07LrlRkXw9wIcYieiZ4OMrT on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "INFO:backoff:Backing off generate_academic_paper_a0(...) for 4.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-Q07LrlRkXw9wIcYieiZ4OMrT on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "INFO:backoff:Backing off generate_academic_paper_a0(...) for 25.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-Q07LrlRkXw9wIcYieiZ4OMrT on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "INFO:backoff:Backing off generate_academic_paper_a0(...) for 19.0s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-Q07LrlRkXw9wIcYieiZ4OMrT on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "INFO:backoff:Backing off generate_academic_paper_a0(...) for 35.1s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-Q07LrlRkXw9wIcYieiZ4OMrT on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "INFO:backoff:Backing off generate_academic_paper_a0(...) for 110.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-Q07LrlRkXw9wIcYieiZ4OMrT on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "INFO:backoff:Backing off generate_academic_paper_a0(...) for 356.2s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-Q07LrlRkXw9wIcYieiZ4OMrT on requests per day (RPD): Limit 200, Used 200, Requested 1. Please try again in 7m12s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "Main Elements:\n",
            "1. Violence against women\n",
            "2. Methods of breaking violence\n",
            "3. Interconnectedness of methods\n",
            "\n",
            "1. Violence against women\n",
            "- Physical violence\n",
            "- Sexual violence\n",
            "- Emotional/psychological violence\n",
            "- Economic violence\n",
            "- Cultural violence\n",
            "- Structural violence\n",
            "\n",
            "2. Methods of breaking violence\n",
            "- Legal interventions\n",
            "- Education and awareness\n",
            "- Counseling and therapy\n",
            "- Economic empowerment\n",
            "- Community support and resources\n",
            "- Cultural and social change\n",
            "- Self-defense and safety planning\n",
            "\n",
            "3. Interconnectedness of methods\n",
            "- Legal interventions can provide protection and consequences for perpetrators of violence, but may not address underlying issues or prevent future violence.\n",
            "- Education and awareness can help change societal attitudes and beliefs about violence against women, but may not be effective without legal and structural support.\n",
            "- Counseling and therapy can address trauma and help survivors heal, but may not be accessible or culturally appropriate for all women.\n",
            "- Economic empowerment can provide financial independence and reduce vulnerability to violence, but may not be possible for all women.\n",
            "- Community support and resources can provide a network of support for survivors, but may not be available in all communities.\n",
            "- Cultural and social change can challenge traditional gender roles and norms that perpetuate violence, but may face resistance and take time to achieve.\n",
            "- Self-defense and safety planning can help women protect themselves in dangerous situations, but may not be a long-term solution to ending violence.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  ['Write down ideas on sticky notes about how to improve بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی . Then, group these ideas based on common themes.']\n",
            "\n",
            " --- Updated prompt is :\n",
            "['Write down ideas on sticky notes about how to improve بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی . Then, group these ideas based on common themes.']\n",
            "Updated Prompts: ['Write down ideas on sticky notes about how to improve بررسی روشهای شکستن خشونت بر ضد زنان به زبان انگلیسی . Then, group these ideas based on common themes.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off generate_academic_paper_a0(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-Q07LrlRkXw9wIcYieiZ4OMrT on requests per day (RPD): Limit 200, Used 200, Requested 1. Please try again in 7m12s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "INFO:backoff:Backing off generate_academic_paper_a0(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-Q07LrlRkXw9wIcYieiZ4OMrT on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating the sound by OpenAI: 👇👇\n",
        "\n",
        "https://platform.openai.com/docs/guides/text-to-speech"
      ],
      "metadata": {
        "id": "2ctHZTF6wj0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!mkdir \"/content/ChatGPT_academic_paper\"\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   api_key = openai_api#\"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\",\n",
        ")\n",
        "\n",
        "response = client.audio.speech.create(\n",
        "    model=\"tts-1\",\n",
        "    voice=\"alloy\",\n",
        "    input=TOPIC#\"Hello world! This is a streaming test.\",\n",
        ")\n",
        "from django.utils.text import slugify\n",
        "\n",
        "TOPIC_S= slugify(TOPIC)\n",
        "response.stream_to_file(\"/content/drive/My Drive/ChatGPT_Paper_wrting/\"+TOPIC_S+\".mp3\")#\"/content/drive/MyDrive/ChatGPT_Paper_wrting/\"+\"output.mp3\")"
      ],
      "metadata": {
        "id": "d2YvDx5DwS7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Only update the Prompt by the help of ChatGPT:👇👇"
      ],
      "metadata": {
        "id": "BAiQz23MlpUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define main variables\n",
        "#TOPIC = \"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"\n",
        "\n",
        "# List of variables\n",
        "variables = [\"RESEARCH_DOMAIN\", \"PARAGRAPH\", \"PARAGRAPHS\", \"TOPIC_SENTENCE\", \"LANGUAGE\", \"ABSTRACT_PARAGRAPH\", \"BIBLIOGRAPHY\", \"THEORY1\", \"THEORY2\", \"RESEARCH_QUESTIONS\", \"ACTION\", \"RESULT_PARAGRAPHS\", \"DATE\", \"NUMBER_OF_DAYS_MONTHS_YEARS\"]\n",
        "\n",
        "# Generate content for each variable\n",
        "variable_contents = {}\n",
        "for prompt in prompts:\n",
        "   for var in variables:\n",
        "       if var in prompt:\n",
        "           prompt = f\"Generate content for the variable '{var}' based on the topic '{TOPIC}'. For this prompt '{prompt}'\"\n",
        "           content= generate_academic_paper(prompt)\n",
        "           for choice in content.choices:\n",
        "               print(choice.text)\n",
        "               variable_contents[var] = choice.text\n",
        "           print(\"variable_contents[var] is: \",variable_contents[var])\n",
        "\n",
        "# Replace the variables in the prompts with the generated content\n",
        "for prompt in prompts:\n",
        "   for var, content in variable_contents.items():\n",
        "       prompt = prompt.replace(f\"{{{var}}}\", content)\n",
        "print(\"Updated Prompt:\", prompt)"
      ],
      "metadata": {
        "id": "kH3LygdiXsPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt_update_a3(prompt, previous_content):\n",
        "    model_engine = \"text-davinci-003\"\n",
        "    max_tokens = 2048\n",
        "\n",
        "    # Construct the instruction for updating the prompt\n",
        "    instruction = f\"Given the previous content:\\n\\n{previous_content}\\n\\nUpdate the prompt: {prompt}\"\n",
        "\n",
        "    # Create the completion with the instruction\n",
        "    completion = client.completions.create(\n",
        "        model=model_engine,\n",
        "        prompt=instruction,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=0.3,\n",
        "        n=1,\n",
        "        frequency_penalty=0,\n",
        "    )\n",
        "\n",
        "    # Extract and return the updated prompt from the response\n",
        "    updated_prompt = completion.choices[0].text.strip()\n",
        "    return updated_prompt\n",
        "# Inside your loop\n",
        "for prompt in prompts:\n",
        "    print(\"Original Prompt:\", prompt)\n",
        "    response = generate_academic_paper_a2(prompt)\n",
        "    previous_content = response.choices[0].text.strip()\n",
        "    updated_prompt = generate_prompt_update_2(prompt, previous_content)\n",
        "    print(\"Updated Prompt:\", updated_prompt)\n",
        "\n",
        "    # Continue with the rest of your processing\n",
        "    # ..."
      ],
      "metadata": {
        "id": "KviSdMwzwqAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# with no translation for become faster answer:👇👇🙏"
      ],
      "metadata": {
        "id": "iuTPp4YYBg2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\"\n",
        "#topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key = openai_api#\"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\",\n",
        ")\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "# Create a Translator object\n",
        "translator = Translator()\n",
        "\n",
        "\n",
        "# Function to generate an academic paper\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "def generate_academic_paper_a2(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   completion = client.completions.create(\n",
        "       model=\"gpt-3.5-turbo-instruct\",\n",
        "       prompt=prompt_my,\n",
        "       max_tokens=2048,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "choice_text_all=[]\n",
        "\n",
        "import time\n",
        "# Function to generate academic papers for given prompts\n",
        "# Function to generate academic papers for given prompts\n",
        "def generate_papers(prompts):\n",
        "   for i in range(0, len(prompts), 20):\n",
        "       # Slice the prompts list to get the next 20 prompts\n",
        "       print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "\n",
        "       batch = prompts[i:i+20]\n",
        "       print(\"batch is \",batch)\n",
        "   #for j in range ( 0, Len(batch)):\n",
        "       # Generate papers for the next 20 prompts\n",
        "       for prompt in batch:\n",
        "      #   for prompt in prompt1:\n",
        "           # Print the prompt\n",
        "           print(\"prompt is \", prompt)\n",
        "           response = generate_academic_paper_a2(prompt)\n",
        "           print(\"\\nGenerated Academic Paper:\")\n",
        "           print(\"========================\\n\")\n",
        "           #print(response)\n",
        "           for choice in response.choices:\n",
        "             print(choice.text)\n",
        "             choice_text_all.append(choice.text)\n",
        "\n",
        "             # Translate the generated text to Persian\n",
        "         #  choice_translated = translate_to_persian(choice.text) #translator.translate(choice.text, dest='fa')\n",
        "         # choice_translated_prompt = translate_to_persian(prompt)#translator.translate(prompt, dest='fa')\n",
        "\n",
        "         #    print(\"\\n-----\\n Translated is \",choice_translated)\n",
        "         #    save_academic_paper(\"Persian_\"+topic,'\\n**'+choice_translated_prompt+'**\\n'+choice_translated)\n",
        "             save_academic_paper(topic,'\\n--------**\\n'+prompt+'/n-------**\\n'+choice.text)\n",
        "             # Recursively call the function for the nested Completion objects\n",
        "             if hasattr(choice, 'choices'):\n",
        "               extract_text(choice)\n",
        "\n",
        "           #generated_text = response.choices[0].text\n",
        "           # Print the generated text\n",
        "           #print(generated_text)\n",
        "           print(\"\\n end of loop\")\n",
        "           print(\"========================\\n\")\n",
        "\n",
        "           #print(\"loop\")\n",
        "       # Wait for a short period of time before sending the next batch of prompts\n",
        "           time.sleep(40)\n",
        "   return choice_text_all#,choice.translated\n",
        "\n",
        "# Generate academic papers for the given prompts\n",
        "generate_papers(prompts)"
      ],
      "metadata": {
        "id": "rl16DSYABo9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SETUP COLAB for run Streamlit\n",
        "!npm install localtunnel\n",
        "!curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "GRn7OkOUjcdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DL Translate\n",
        "A deep learning-based translation library built on Huggingface transformers and Facebook's mBART-Large\n",
        "\n",
        "https://colab.research.google.com/github/xhluca/dl-translate/blob/main/demos/colab_demo.ipynb#scrollTo=qdefSjR_YIiG"
      ],
      "metadata": {
        "id": "_I5yn6CCZdMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q dl-translate"
      ],
      "metadata": {
        "id": "c7-q341UWsr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dl_translate as dlt\n",
        "mt = dlt.TranslationModel('mbart50')"
      ],
      "metadata": {
        "id": "gtQcnXabalaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dl_translate as dlt\n",
        "\n",
        "def translate_to_persian(text):\n",
        "  # Initialize the translation model\n",
        "  #mt = dlt.TranslationModel('mbart50')\n",
        "\n",
        "  # Translate the text\n",
        "  translated = mt.translate(text, source=dlt.lang.ENGLISH, target=dlt.lang.PERSIAN)\n",
        "\n",
        "  return translated"
      ],
      "metadata": {
        "id": "iOX6FGFWaFqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key = openai_api#\"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\",\n",
        ")\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "# Create a Translator object\n",
        "translator = Translator()\n",
        "\n",
        "\n",
        "# Function to generate an academic paper\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=10, max_time=600)\n",
        "def generate_academic_paper_5(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   completion = client.completions.create(\n",
        "       model=\"gpt-3.5-turbo-instruct\",\n",
        "       prompt=prompt_my,\n",
        "       max_tokens=2048,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "choice_text_all=[]\n",
        "\n",
        "import time\n",
        "# Function to generate academic papers for given prompts\n",
        "# Function to generate academic papers for given prompts\n",
        "def generate_papers(prompts):\n",
        "   for i in range(0, len(prompts), 20):\n",
        "       # Slice the prompts list to get the next 20 prompts\n",
        "       print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "       batch = prompts[i:i+10]\n",
        "       print(\"batch is \",batch)\n",
        "       # Generate papers for the next 20 prompts\n",
        "       for prompt in batch:\n",
        "      #   for prompt in prompt1:\n",
        "           # Print the prompt\n",
        "           print(\"prompt is \", prompt)\n",
        "           response = generate_academic_paper(prompt)\n",
        "           print(\"\\nGenerated Academic Paper:\")\n",
        "           print(\"========================\\n\")\n",
        "           #print(response)\n",
        "           for choice in response.choices:\n",
        "             print(choice.text)\n",
        "             choice_text_all.append(choice.text)\n",
        "              # Translate the generated text to Persian\n",
        "             choice_translated = translate_to_persian(choice.text) #translator.translate(choice.text, dest='fa')\n",
        "             choice_translated_prompt = translate_to_persian(prompt)#translator.translate(prompt, dest='fa')\n",
        "\n",
        "             print(\"\\n-----\\n Translated is \",choice_translated)\n",
        "             save_academic_paper(\"Persian_\"+topic,'\\n**'+choice_translated_prompt+'**\\n'+choice_translated)\n",
        "             save_academic_paper(topic,'\\n**'+prompt+'**\\n'+choice.text)\n",
        "             # Recursively call the function for the nested Completion objects\n",
        "             if hasattr(choice, 'choices'):\n",
        "               extract_text(choice)\n",
        "\n",
        "           #generated_text = response.choices[0].text\n",
        "           # Print the generated text\n",
        "           #print(generated_text)\n",
        "           print(\"\\n end of loop\")\n",
        "           print(\"========================\\n\")\n",
        "\n",
        "           #print(\"loop\")\n",
        "       # Wait for a short period of time before sending the next batch of prompts\n",
        "           time.sleep(2)\n",
        "   return choice_text_all,choice.translated\n",
        "\n",
        "# Generate academic papers for the given prompts\n",
        "generate_papers(prompts3)"
      ],
      "metadata": {
        "id": "oVldhSpgEVZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#For solving queta prompt of Openai API;\n",
        "👇👇🌱"
      ],
      "metadata": {
        "id": "GdTvLhAkKLEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "#import openai\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key = openai_api#\"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\",\n",
        ")\n",
        "\n",
        "def retry_with_exponential_backoff(\n",
        "   func,\n",
        "   initial_delay: float = 1,\n",
        "   exponential_base: float = 2,\n",
        "   jitter: bool = True,\n",
        "   max_retries: int = 10,\n",
        "   errors: tuple = (openai.error.RateLimitError,),\n",
        "):\n",
        "   \"\"\"Retry a function with exponential backoff.\"\"\"\n",
        "   def wrapper(*args, **kwargs):\n",
        "       # Initialize variables\n",
        "       num_retries = 0\n",
        "       delay = initial_delay\n",
        "       # Loop until a successful response or max_retries is hit or an exception is raised\n",
        "       while True:\n",
        "           try:\n",
        "               return func(*args, **kwargs)\n",
        "           # Retry on specified errors\n",
        "           except errors as e:\n",
        "               # Increment retries\n",
        "               num_retries += 1\n",
        "               # Check if max retries has been reached\n",
        "               if num_retries > max_retries:\n",
        "                  raise Exception(\n",
        "                      f\"Maximum number of retries ({max_retries}) exceeded.\"\n",
        "                  )\n",
        "               # Increment the delay\n",
        "               delay *= exponential_base * (1 + jitter * random.random())\n",
        "               # Sleep for the delay\n",
        "               time.sleep(delay)\n",
        "           # Raise exceptions for any errors not specified\n",
        "           except Exception as e:\n",
        "               raise e\n",
        "   return wrapper\n",
        "\n",
        "@retry_with_exponential_backoff\n",
        "def generate_academic_paper_0(prompt_my):\n",
        "  model_engine = \"text-davinci-003\"\n",
        "  max_tokens = 2048\n",
        "\n",
        "  completion = client.completions.create(\n",
        "      model=\"gpt-3.5-turbo-instruct\",\n",
        "      prompt=prompt_my,\n",
        "      max_tokens=2048,\n",
        "      temperature=0.3,\n",
        "      n=1,\n",
        "      frequency_penalty=0,\n",
        "  )\n",
        "  return completion"
      ],
      "metadata": {
        "id": "zLWA8i87KXks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vH0Z7EL5LnQc"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "openai.api_key = openai_api#\"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key= openai_api#\"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\",\n",
        ")\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Function to generate an academic paper\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=10, max_time=600)\n",
        "def generate_academic_paper_6(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   completion = client.completions.create(\n",
        "       model=\"gpt-3.5-turbo-instruct\",\n",
        "       prompt=prompt_my,\n",
        "       max_tokens=2048,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "choice_text_all=[]\n",
        "\n",
        "import time\n",
        "# Function to generate academic papers for given prompts\n",
        "# Function to generate academic papers for given prompts\n",
        "def generate_papers(prompts):\n",
        "   for i in range(0, len(prompts), 20):\n",
        "       # Slice the prompts list to get the next 20 prompts\n",
        "       print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "       batch = prompts[i:i+10]\n",
        "       print(\"batch is \",batch)\n",
        "       # Generate papers for the next 20 prompts\n",
        "       for prompt in batch:\n",
        "      #   for prompt in prompt1:\n",
        "           # Print the prompt\n",
        "           print(\"prompt is \", prompt)\n",
        "           response = generate_academic_paper(prompt)\n",
        "           print(\"\\nGenerated Academic Paper:\")\n",
        "           print(\"========================\\n\")\n",
        "           #print(response)\n",
        "           for choice in response.choices:\n",
        "             print(choice.text)\n",
        "             choice_text_all.append(choice.text)\n",
        "             save_academic_paper(TOPIC,'\\n**'+prompt+'**\\n'+choice.text)\n",
        "             # Recursively call the function for the nested Completion objects\n",
        "             if hasattr(choice, 'choices'):\n",
        "               extract_text(choice)\n",
        "\n",
        "           #generated_text = response.choices[0].text\n",
        "           # Print the generated text\n",
        "           #print(generated_text)\n",
        "           print(\"\\n end of loop\")\n",
        "           print(\"========================\\n\")\n",
        "\n",
        "           #print(\"loop\")\n",
        "       # Wait for a short period of time before sending the next batch of prompts\n",
        "           time.sleep(2)\n",
        "   return choice.text_all\n",
        "\n",
        "# Generate academic papers for the given prompts\n",
        "generate_papers(prompts3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJTgcojthnm7"
      },
      "outputs": [],
      "source": [
        "def render_index_page():\n",
        "   html_content = \"\"\"\n",
        "   <!DOCTYPE html>\n",
        "   <html>\n",
        "   <head>\n",
        "      <title>Generate Academic Papers</title>\n",
        "   </head>\n",
        "   <body>\n",
        "      <h1>Generate Academic Papers</h1>\n",
        "      <form method=\"POST\">\n",
        "          <label for=\"topic\">Topic:</label>\n",
        "          <input type=\"text\" id=\"topic\" name=\"topic\" required>\n",
        "          <input type=\"submit\" value=\"Generate\">\n",
        "      </form>\n",
        "   </body>\n",
        "   </html>\n",
        "   \"\"\"\n",
        "   return render_template_string(html_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKhSXALkhpL7"
      },
      "outputs": [],
      "source": [
        "def render_result_page(topic, docx_file, pdf_file, choice_text_all):\n",
        "   html_content = f\"\"\"\n",
        "   <!DOCTYPE html>\n",
        "   <html>\n",
        "   <head>\n",
        "       <title>Result</title>\n",
        "   </head>\n",
        "   <body>\n",
        "       <h1>Result</h1>\n",
        "       <p>Academic papers have been generated for the topic: {topic}</p>\n",
        "       <a href=\"/download/{docx_file}\">Download DOCX</a>\n",
        "       <a href=\"/download/{pdf_file}\">Download PDF</a>\n",
        "       <h2>Generated Text:</h2>\n",
        "       <p>{choice_text_all}</p>\n",
        "   </body>\n",
        "   </html>\n",
        "   \"\"\"\n",
        "   return render_template_string(html_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuTJlSSGgh4E"
      },
      "outputs": [],
      "source": [
        "# app.py\n",
        "\n",
        "from flask import Flask, request, render_template\n",
        "from academic_paper_generator import generate_papers\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def home():\n",
        "  if request.method == 'POST':\n",
        "      topic = request.form.get('topic')\n",
        "      prompts3 = [\n",
        "          f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "          f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "          f\"Identify gaps in the literature on '{topic}'\",\n",
        "          \"Generate 10 academic research questions about Perviuse action\",\n",
        "          f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "      ]\n",
        "      generate_papers(prompts3)\n",
        "      return render_template('result.html', topic=topic)\n",
        "  else:\n",
        "      return render_template('index.html')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  app.run(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}