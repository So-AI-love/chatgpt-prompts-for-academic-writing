{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/So-AI-love/chatgpt-prompts-for-academic-writing/blob/main/Auto_Making/Academic_Papers_Writing_translat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHgZHeIxi31Q"
      },
      "source": [
        "## Aromatically wrrie apaper by the ChatGPT and this github prompt instruction:\n",
        "\n",
        "https://github.com/ahmetbersoz/chatgpt-prompts-for-academic-writing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt7VN_fmGT3E",
        "outputId": "3d087fad-f5f1-44c2-fada-4dffa3a25ac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.3.5-py3-none-any.whl (220 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/220.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.4/220.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m220.8/220.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Collecting httpcore (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.1 openai-1.3.5\n",
            "Collecting backoff\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: backoff\n",
            "Successfully installed backoff-2.2.1\n",
            "Collecting docx2pdf\n",
            "  Downloading docx2pdf-0.1.8-py3-none-any.whl (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from docx2pdf) (4.66.1)\n",
            "Installing collected packages: docx2pdf\n",
            "Successfully installed docx2pdf-0.1.8\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.5.0)\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install backoff\n",
        "!pip install docx2pdf\n",
        "!pip install python-docx\n",
        "\n",
        "# SETUP COLAB for run Streamlit\n",
        "!npm install localtunnel\n",
        "\n",
        "!pip install -q dl-translate\n",
        "!curl ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install libreoffice\n",
        "#!sudo apt-get install abiword\n",
        "!sudo apt install libreoffice-writer"
      ],
      "metadata": {
        "id": "AUeIF57v21gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c4VOgN2lpk4"
      },
      "outputs": [],
      "source": [
        "\n",
        "topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "\n",
        "\n",
        "prompts = [\n",
        "# Improving Language\n",
        "f\"Write a counterargument to the following claim: '{topic}'\",\n",
        "f\"Rewrite this in an academic voice: '{topic}'\",\n",
        "f\"Expand these notes: '{topic}'\",\n",
        "f\"Provide me a list of words and phrases which were repeatedly / more than 3 times used: '{topic}'\",\n",
        "f\"Provide me a list of synonyms for '{topic}' and evaluate them in the context of '{topic}'\",\n",
        "f\"Act as a language expert, proofread my paper on '{topic}' while putting a focus on grammar and punctuation.\",\n",
        "f\"In the context of '{topic}' translate '{topic}' into the '{topic}' language.\",\n",
        "\n",
        "# Brainstorming\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research topic. Make Sure it is free from plagiarism. '{topic}'\",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "f\"Generate 10 academic research questions about '{topic}'\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\",\n",
        "f\"Identify potential areas for future research in the context of this '{topic}'\",\n",
        "f\"Suggest novel applications of '{topic}' within '{topic}'\",\n",
        "\n",
        "# Title/Topic Sentence\n",
        "f\"Suggest 5 titles for the following abstract: '{topic}'\",\n",
        "f\"Write a topic sentences for this paragraph: '{topic}'\",\n",
        "\n",
        "# Keywords\n",
        "f\"Provide 5 keywords for this: '{topic}'\",\n",
        "\n",
        "# Abstract\n",
        "f\"Generate an abstract for a scientific paper based on this information for: '{topic}'\",\n",
        "\n",
        "# Outline\n",
        "f\"Generate an outline for '{topic}'\",\n",
        "f\"I want to write a journal article about '{topic}'. give me an outline for the article that I can use as a starting point.\",\n",
        "\n",
        "# Introduction\n",
        "f\"Come up with an introduction for the following research topic: '{topic}'\",\n",
        "\n",
        "# Literature Review\n",
        "f\"Conduct a literature review on '{topic}' and provide review paper references\",\n",
        "f\"Provide me with references and links to papers in '{topic}'\",\n",
        "f\"Summarize the scholarly literature including in-text citations on '{topic}'\",\n",
        "f\"Write this in standard Harvard referencing '{topic}'\",\n",
        "f\"Convert this '{topic}' from MLA to APA style.\",\n",
        "f\"Compare and contrast '{topic}' and '{topic}' in the context of '{topic}'\",\n",
        "\n",
        "# Methodology\n",
        "f\"Create objectives and methodology for '{topic}'\",\n",
        "f\"Write a detailed methodology for the topic: '{topic}'\",\n",
        "f\"Analyze the strengths and weaknesses of this methodology: '{topic}'\",\n",
        "f\"Write objectives for this study: '{topic}'\",\n",
        "f\"What are the limitations of using '{topic}' in '{topic}'?\",\n",
        "f\"Create a recipe for the methods used in this '{topic}'\",\n",
        "f\"Suggest interdisciplinary approaches to '{topic}'\",\n",
        "f\"Explain how qualitative/quantitative research methods can be used to address '{topic}'\",\n",
        "f\"Recommend best practices for data collection and analysis in '{topic}'\",\n",
        "\n",
        "# Experiments\n",
        "f\"Design an experiment that '{topic}'\",\n",
        "\n",
        "# Results\n",
        "f\"Write a result section for the following paragraphs. Please write this in the third person. '{topic}'\",\n",
        "\n",
        "# Discussion\n",
        "f\"Discuss this results: '{topic}'\",\n",
        "\n",
        "# Conclusion\n",
        "f\"Generate a conclusion for this: '{topic}'\",\n",
        "f\"Give recommendations and conclusion for: '{topic}'\",\n",
        "\n",
        "# Future Works\n",
        "f\"Can you suggest 3 directions for future research on this topic: '{topic}'\",\n",
        "\n",
        "# Plan/Presentation\n",
        "f\"Develop a research plan for: '{topic}'\",\n",
        "f\"Write a schedule for completion in '{topic}' in '{topic}'\",\n",
        "f\"The deadline for the submission of the first draft is '{topic}'. give me a week-by-week breakdown so I can plan my writing better.\",\n",
        "f\"Write a sensational press release for this research: '{topic}'\",\n",
        "f\"Make this more persuasive: '{topic}'\",\n",
        "f\"Write 3 tweets about this research? '{topic}'\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define main variables\n",
        "TOPIC = \"{TOPIC}\"\n",
        "RESEARCH_DOMAIN = \"{RESEARCH_DOMAIN}\"\n",
        "PARAGRAPH = \"{PARAGRAPH}\"\n",
        "PARAGRAPHS = \"{PARAGRAPHS}\"\n",
        "TOPIC_SENTENCE = \"{TOPIC_SENTENCE}\"\n",
        "LANGUAGE = \"{LANGUAGE}\"\n",
        "ABSTRACT_PARAGRAPH = \"{ABSTRACT_PARAGRAPH}\"\n",
        "BIBLIOGRAPHY = \"{BIBLIOGRAPHY}\"\n",
        "THEORY1 = \"{THEORY1}\"\n",
        "THEORY2 = \"{THEORY2}\"\n",
        "RESEARCH_QUESTIONS = \"{RESEARCH_QUESTIONS}\"\n",
        "ACTION = \"{ACTION}\"\n",
        "RESULT_PARAGRAPHS = \"{RESULT_PARAGRAPHS}\"\n",
        "DATE = \"{DATE}\"\n",
        "NUMBER_OF_DAYS_MONTHS_YEARS = \"{NUMBER_OF_DAYS_MONTHS_YEARS}\"\n",
        "\n",
        "# List of prompts for generating academic papers\n",
        "prompts = [\n",
        "\n",
        "  # Improving Language\n",
        "  f\"Write a counterargument to the following claim: '{PARAGRAPH}'\",\n",
        "  f\"Rewrite this in an academic voice: '{PARAGRAPH}'\",\n",
        "  f\"Expand these notes: '{PARAGRAPH}'\",\n",
        "  f\"Provide me a list of words and phrases which were repeatedly / more than 3 times used: '{PARAGRAPHS}'\",\n",
        "  f\"Provide me a list of synonyms for '{PARAGRAPH}' and evaluate them in the context of '{PARAGRAPH}'\",\n",
        "  f\"Act as a language expert, proofread my paper on '{TOPIC_SENTENCE}' while putting a focus on grammar and punctuation.\",\n",
        "  f\"In the context of '{RESEARCH_DOMAIN}' translate '{PARAGRAPH}' into the '{LANGUAGE}' language.\",\n",
        "\n",
        "   # Brainstorming\n",
        "   f\"Find a research topic for a PhD in the area of '{TOPIC}'\",\n",
        "   f\"Write a detailed proposal on the following research topic. Make sure it is free from plagiarism. '{PARAGRAPH}'\",\n",
        "   f\"Identify gaps in the literature on '{TOPIC_SENTENCE}'\",\n",
        "   f\"Generate 10 academic research questions about '{PARAGRAPHS}'\",\n",
        "   f\"Generate a list of research hypotheses related to '{TOPIC_SENTENCE}'\",\n",
        "   f\"Identify potential areas for future research in the context of this '{TOPIC_SENTENCE}'\",\n",
        "   f\"Suggest novel applications of '{TOPIC_SENTENCE}' within '{RESEARCH_DOMAIN}'\",\n",
        "\n",
        "   # Title/Topic Sentence\n",
        "   f\"Suggest 5 titles for the following abstract: '{ABSTRACT_PARAGRAPH}'\",\n",
        "   f\"Write a topic sentence for this paragraph: '{PARAGRAPH}'\",\n",
        "\n",
        "   # Keywords\n",
        "   f\"Provide 5 keywords for this: '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Abstract\n",
        "   f\"Generate an abstract for a scientific paper based on this information for: '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Outline\n",
        "   f\"Generate an outline for '{TOPIC_SENTENCE}'\",\n",
        "   f\"I want to write a journal article about '{TOPIC_SENTENCE}'. Give me an outline for the article that I can use as a starting point.\",\n",
        "\n",
        "   # Introduction\n",
        "   f\"Come up with an introduction for the following research topic: '{TOPIC_SENTENCE}'\",\n",
        "\n",
        "   # Literature Review\n",
        "   f\"Conduct a literature review on '{TOPIC_SENTENCE}' and provide review paper references\",\n",
        "   f\"Provide me with references and links to papers in '{PARAGRAPH}'\",\n",
        "   f\"Summarize the scholarly literature including in-text citations on '{PARAGRAPHS}'\",\n",
        "   f\"Write this in standard Harvard referencing '{PARAGRAPH}'\",\n",
        "   f\"Convert this '{BIBLIOGRAPHY}' from MLA to APA style.\",\n",
        "   f\"Compare and contrast '{THEORY1}' and '{THEORY2}' in the context of '{RESEARCH_DOMAIN}'\",\n",
        "\n",
        "   # Methodology\n",
        "   f\"Create objectives and methodology for '{TOPIC_SENTENCE}'\",\n",
        "   f\"Write a detailed methodology for the topic: '{TOPIC_SENTENCE}'\",\n",
        "   f\"Analyze the strengths and weaknesses of this methodology: '{PARAGRAPHS}'\",\n",
        "   f\"Write objectives for this study: '{TOPIC_SENTENCE}'\",\n",
        "   f\"What are the limitations of using '{TOPIC_SENTENCE}' in '{RESEARCH_DOMAIN}'?\",\n",
        "   f\"Create a recipe for the methods used in this '{PARAGRAPHS}'\",\n",
        "   f\"Suggest interdisciplinary approaches to '{TOPIC_SENTENCE}'\",\n",
        "   f\"Explain how qualitative/quantitative research methods can be used to address '{RESEARCH_QUESTIONS}'\",\n",
        "   f\"Recommend best practices for data collection and analysis in '{TOPIC_SENTENCE}'\",\n",
        "\n",
        "   # Experiments\n",
        "   f\"Design an experiment that '{ACTION}'\",\n",
        "\n",
        "   # Results\n",
        "   f\"Write a result section for the following paragraphs. Please write this in the third person. '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Discussion\n",
        "   f\"Discuss this results: '{RESULT_PARAGRAPHS}'\",\n",
        "\n",
        "   # Conclusion\n",
        "   f\"Generate a conclusion for this: '{PARAGRAPHS}'\",\n",
        "   f\"Give recommendations and conclusion for: '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Future Works\n",
        "   f\"Can you suggest 3 directions for future research on this topic: '{PARAGRAPH}'\",\n",
        "\n",
        "   # Plan/Presentation\n",
        "   f\"Develop a research plan for: '{TOPIC_SENTENCE}'\",\n",
        "   f\"Write a schedule for completion in '{TOPIC_SENTENCE}' in NUMBER OF DAYS MONTHS YEARS which is '{NUMBER_OF_DAYS_MONTHS_YEARS}'\",\n",
        "   f\"The deadline for the submission of the first draft is '{DATE}'. Give me a week-by-week breakdown so I can plan my writing better.\",\n",
        "   f\"Write a sensational press release for this research: '{PARAGRAPHS}'\",\n",
        "   f\"Make this more persuasive: '{PARAGRAPH}'\",\n",
        "   f\"Write 3 tweets about this research? '{PARAGRAPHS}'\",\n",
        "]"
      ],
      "metadata": {
        "id": "uPcmAM5Zq5M-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\""
      ],
      "metadata": {
        "id": "I484Df8ONQVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Funstions for saving as PDF and DOCX :\n",
        "üëáüå±"
      ],
      "metadata": {
        "id": "lI5PG0BNPrPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install libreoffice\n",
        "#!sudo apt-get install abiword\n",
        "!sudo apt install libreoffice-writer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDBHbtajP03B",
        "outputId": "ec06be67-da73-4775-bf61-d4395d1bf6ff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Waiting for headers] [C\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Connecting to ppa.launc\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Connected to ppa.launchpadcontent.net (185.125.190.80\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,284 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,520 kB]\n",
            "Fetched 2,923 kB in 1s (2,161 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libreoffice is already the newest version (1:7.3.7-0ubuntu0.22.04.3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libreoffice-writer is already the newest version (1:7.3.7-0ubuntu0.22.04.3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "W2xiQx_camiB"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "def convert_docx_to_pdf0(docx_path, pdf_path):\n",
        "  subprocess.call(['abiword', '--to=pdf', docx_path, '--to-dir', pdf_path])\n",
        "\n",
        "def convert_docx_to_pdf(docx_path, pdf_path):\n",
        " command = ['libreoffice', '--headless', '--convert-to', 'pdf', '--outdir', pdf_path, docx_path]\n",
        " subprocess.call(command)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "from docx import Document\n",
        "\n",
        "\n",
        "\n",
        "def save_academic_paper(topic, prompt_my):\n",
        " # Define the path to the DOCX file\n",
        " docx_path = f\"/content/{topic}.docx\"\n",
        "\n",
        " # Check if the DOCX file exists\n",
        " if os.path.isfile(docx_path):\n",
        "     # If the DOCX file exists, open it\n",
        "     doc = Document(docx_path)\n",
        " else:\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "     doc = Document()\n",
        "\n",
        " # Add the generated text to the document\n",
        " #print (\"____&&&&&&&&&&\\n\",prompt_my)\n",
        " doc.add_paragraph(prompt_my)\n",
        "\n",
        " # Save the document\n",
        " doc.save(docx_path)\n",
        "\n",
        " # Convert the DOCX file to a PDF\n",
        " convert_docx_to_pdf(docx_path, \"/content/output/\")"
      ],
      "metadata": {
        "id": "uE2pz7Zp4QIZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import subprocess\n",
        "from docx import Document\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def save_academic_paper(topic, prompt_my):\n",
        "  # Define the path to the folder in Google Drive\n",
        "  folder_path = f\"/content/drive/My Drive/ChatGPT_Paper_wrting/\"\n",
        "\n",
        "  # Check if the folder exists\n",
        "  if not os.path.exists(folder_path):\n",
        "     # If the folder doesn't exist, create it\n",
        "     os.mkdir(folder_path)\n",
        "\n",
        "  # Define the path to the DOCX file in the folder\n",
        "  docx_path = f\"{folder_path}{topic}.docx\"\n",
        "\n",
        "  Pdf_Dir= f\"/content/drive/My Drive/ChatGPT_Paper_wrting\"\n",
        "\n",
        "  # Check if the DOCX file exists\n",
        "  if os.path.isfile(docx_path):\n",
        "     # If the DOCX file exists, open it\n",
        "     docx_path = f\"{folder_path}{topic}_\"+random.randint(0,9)+\".docx\"\n",
        "\n",
        "     doc = Document(docx_path)\n",
        "  else:\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "     doc = Document()\n",
        "\n",
        "  # Add the generated text to the document\n",
        "  doc.add_paragraph(prompt_my)\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Convert the DOCX file to a PDF\n",
        "  convert_docx_to_pdf(docx_path,Pdf_Dir)"
      ],
      "metadata": {
        "id": "gEC4g9KHOQwh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32a6b7bf-e9cf-44b2-e290-e5909c7e13f0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save_academic_paper(\"Persian_\"+'topic','\\n**'+'choice_translated_prompt'+'**\\n'+\"choice_translated\")"
      ],
      "metadata": {
        "id": "a76qNIRHs_gS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install googletrans==4.0.0-rc1\n",
        "\n",
        "!pip install httpcore==0.15.0 httpx pymongo googletrans\n",
        "!pip install httpx==0.24.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQOCu3GyEFf1",
        "outputId": "942d7048-36d6-4cc7-d8d8-a48394f0aeff"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting httpcore==0.15.0\n",
            "  Downloading httpcore-0.15.0-py3-none-any.whl (68 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/68.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m30.7/68.4 kB\u001b[0m \u001b[31m745.3 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m68.4/68.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Collecting pymongo\n",
            "  Downloading pymongo-4.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m677.1/677.1 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting googletrans\n",
            "  Downloading googletrans-3.0.0.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting h11<0.13,>=0.11 (from httpcore==0.15.0)\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio==1.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (1.3.0)\n",
            "Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (2023.7.22)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore==0.15.0) (3.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore==0.15.0) (1.1.3)\n",
            "INFO: pip is looking at multiple versions of httpx to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting httpx\n",
            "  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hstspreload (from httpx)\n",
            "  Downloading hstspreload-2023.1.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==3.* (from httpx)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna>=2.8 (from anyio==3.*->httpcore==0.15.0)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3 (from httpx)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting googletrans\n",
            "  Downloading googletrans-2.4.0.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from googletrans) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->googletrans) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->googletrans) (2.0.7)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-2.4.0-py3-none-any.whl size=15762 sha256=8d511e07e563f89dc66df1a3cf28103f5e661855000851e311a78008d1061a93\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/5f/60/c4738a8b36085696062052befbbfb65fc94d2286fb17015856\n",
            "Successfully built googletrans\n",
            "Installing collected packages: h11, dnspython, pymongo, httpcore, googletrans, httpx\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.14.0\n",
            "    Uninstalling h11-0.14.0:\n",
            "      Successfully uninstalled h11-0.14.0\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.2\n",
            "    Uninstalling httpcore-1.0.2:\n",
            "      Successfully uninstalled httpcore-1.0.2\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.25.2\n",
            "    Uninstalling httpx-0.25.2:\n",
            "      Successfully uninstalled httpx-0.25.2\n",
            "Successfully installed dnspython-2.4.2 googletrans-2.4.0 h11-0.12.0 httpcore-0.15.0 httpx-0.25.1 pymongo-4.6.0\n",
            "Collecting httpx==0.24.1\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (2023.7.22)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (0.15.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (1.3.0)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.1) (0.12.0)\n",
            "Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.1) (3.7.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore<0.18.0,>=0.15.0->httpx==0.24.1) (1.1.3)\n",
            "Installing collected packages: httpx\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.25.1\n",
            "    Uninstalling httpx-0.25.1:\n",
            "      Successfully uninstalled httpx-0.25.1\n",
            "Successfully installed httpx-0.24.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# with no translation for become faster answer:üëáüëáüôè"
      ],
      "metadata": {
        "id": "iuTPp4YYBg2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\"\n",
        "#topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key = \"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\",\n",
        ")\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "# Create a Translator object\n",
        "translator = Translator()\n",
        "\n",
        "\n",
        "# Function to generate an academic paper\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "def generate_academic_paper_a(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   completion = client.completions.create(\n",
        "       model=\"gpt-3.5-turbo-instruct\",\n",
        "       prompt=prompt_my,\n",
        "       max_tokens=2048,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "choice_text_all=[]\n",
        "\n",
        "import time\n",
        "# Function to generate academic papers for given prompts\n",
        "# Function to generate academic papers for given prompts\n",
        "def generate_papers(prompts):\n",
        "   for i in range(0, len(prompts), 20):\n",
        "       # Slice the prompts list to get the next 20 prompts\n",
        "       print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "\n",
        "       batch = prompts[i:i+20]\n",
        "       print(\"batch is \",batch)\n",
        "   #for j in range ( 0, Len(batch)):\n",
        "       # Generate papers for the next 20 prompts\n",
        "       for prompt in batch:\n",
        "      #   for prompt in prompt1:\n",
        "           # Print the prompt\n",
        "           print(\"prompt is \", prompt)\n",
        "           response = generate_academic_paper(prompt)\n",
        "           print(\"\\nGenerated Academic Paper:\")\n",
        "           print(\"========================\\n\")\n",
        "           #print(response)\n",
        "           for choice in response.choices:\n",
        "             print(choice.text)\n",
        "             choice_text_all.append(choice.text)\n",
        "\n",
        "             # Translate the generated text to Persian\n",
        "         #  choice_translated = translate_to_persian(choice.text) #translator.translate(choice.text, dest='fa')\n",
        "         # choice_translated_prompt = translate_to_persian(prompt)#translator.translate(prompt, dest='fa')\n",
        "\n",
        "         #    print(\"\\n-----\\n Translated is \",choice_translated)\n",
        "         #    save_academic_paper(\"Persian_\"+topic,'\\n**'+choice_translated_prompt+'**\\n'+choice_translated)\n",
        "             save_academic_paper(topic,'\\n--------**\\n'+prompt+'/n-------**\\n'+choice.text)\n",
        "             # Recursively call the function for the nested Completion objects\n",
        "             if hasattr(choice, 'choices'):\n",
        "               extract_text(choice)\n",
        "\n",
        "           #generated_text = response.choices[0].text\n",
        "           # Print the generated text\n",
        "           #print(generated_text)\n",
        "           print(\"\\n end of loop\")\n",
        "           print(\"========================\\n\")\n",
        "\n",
        "           #print(\"loop\")\n",
        "       # Wait for a short period of time before sending the next batch of prompts\n",
        "           time.sleep(40)\n",
        "   return choice_text_all#,choice.translated\n",
        "\n",
        "# Generate academic papers for the given prompts\n",
        "generate_papers(prompts)"
      ],
      "metadata": {
        "id": "rl16DSYABo9E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "62c3bda7-e9d8-4562-ecda-29c121aeb01a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I is  0  Len of prompt Is: 48\n",
            "batch is  [\"Write a counterargument to the following claim: '{PARAGRAPH}'\", \"Rewrite this in an academic voice: '{PARAGRAPH}'\", \"Expand these notes: '{PARAGRAPH}'\", \"Provide me a list of words and phrases which were repeatedly / more than 3 times used: '{PARAGRAPHS}'\", \"Provide me a list of synonyms for '{PARAGRAPH}' and evaluate them in the context of '{PARAGRAPH}'\", \"Act as a language expert, proofread my paper on '{TOPIC_SENTENCE}' while putting a focus on grammar and punctuation.\", \"In the context of '{RESEARCH_DOMAIN}' translate '{PARAGRAPH}' into the '{LANGUAGE}' language.\", \"Find a research topic for a PhD in the area of '{TOPIC}'\", \"Write a detailed proposal on the following research topic. Make sure it is free from plagiarism. '{PARAGRAPH}'\", \"Identify gaps in the literature on '{TOPIC_SENTENCE}'\", \"Generate 10 academic research questions about '{PARAGRAPHS}'\", \"Generate a list of research hypotheses related to '{TOPIC_SENTENCE}'\", \"Identify potential areas for future research in the context of this '{TOPIC_SENTENCE}'\", \"Suggest novel applications of '{TOPIC_SENTENCE}' within '{RESEARCH_DOMAIN}'\", \"Suggest 5 titles for the following abstract: '{ABSTRACT_PARAGRAPH}'\", \"Write a topic sentence for this paragraph: '{PARAGRAPH}'\", \"Provide 5 keywords for this: '{PARAGRAPHS}'\", \"Generate an abstract for a scientific paper based on this information for: '{PARAGRAPHS}'\", \"Generate an outline for '{TOPIC_SENTENCE}'\", \"I want to write a journal article about '{TOPIC_SENTENCE}'. Give me an outline for the article that I can use as a starting point.\"]\n",
            "prompt is  Write a counterargument to the following claim: '{PARAGRAPH}'\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "Claim: \"Social media has had a positive impact on society by connecting people from all over the world and promoting cultural exchange.\"\n",
            "\n",
            "Counterargument: While it is true that social media has connected people from different parts of the world and allowed for cultural exchange, it has also had negative effects on society. One of the main issues with social media is the spread of misinformation and fake news. With the rise of social media, anyone can share information without fact-checking, leading to the spread of false information and conspiracy theories. This has resulted in a polarized society and has caused harm to individuals and communities. Additionally, social media has also been linked to mental health issues such as anxiety and depression, as people constantly compare their lives to the curated and often unrealistic versions presented on social media. Therefore, while social media may have some positive impacts, it is important to acknowledge and address the negative effects it has on society.\n",
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  Rewrite this in an academic voice: '{PARAGRAPH}'\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "The aforementioned paragraph can be rephrased in an academic tone as follows:\n",
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  Expand these notes: '{PARAGRAPH}'\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "A paragraph is a group of sentences that are related and express a single main idea or topic. It is typically composed of at least three sentences, but can be longer depending on the complexity of the topic being discussed. A well-written paragraph should have a clear topic sentence that introduces the main idea, followed by supporting sentences that provide evidence or explanation for the main idea. The final sentence in a paragraph is often a concluding sentence that summarizes the main point or transitions to the next paragraph. Paragraphs are an essential part of writing, as they help to organize and structure ideas in a coherent and logical manner. They also make it easier for readers to follow and understand the writer's thoughts and arguments. In academic writing, paragraphs are often used to present evidence, analysis, and conclusions, while in creative writing, they can be used to create a flow and rhythm in the narrative. Overall, paragraphs play a crucial role in effective communication and are a fundamental building block of written language.\n",
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  Provide me a list of words and phrases which were repeatedly / more than 3 times used: '{PARAGRAPHS}'\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "1. Repeatedly\n",
            "2. More than 3 times\n",
            "3. List\n",
            "4. Words\n",
            "5. Phrases\n",
            "6. Used\n",
            "7. Frequently\n",
            "8. Often\n",
            "9. Recurring\n",
            "10. Continuously\n",
            "11. Repetitive\n",
            "12. Duplicated\n",
            "13. Reiterated\n",
            "14. Reoccurred\n",
            "15. Persistently\n",
            "16. Regularly\n",
            "17. Frequently mentioned\n",
            "18. Commonly used\n",
            "19. Over and over\n",
            "20. Again and again\n",
            "21. Multiple times\n",
            "22. On a regular basis\n",
            "23. Incessantly\n",
            "24. Non-stop\n",
            "25. Continually\n",
            "26. Time and time again\n",
            "27. Ad nauseam\n",
            "28. In repetition\n",
            "29. In a loop\n",
            "30. In succession\n",
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  Provide me a list of synonyms for '{PARAGRAPH}' and evaluate them in the context of '{PARAGRAPH}'\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "1. Passage - This synonym is closely related to the word \"paragraph\" as it also refers to a section of written text. However, \"passage\" may be used to describe a longer and more substantial piece of writing, while \"paragraph\" typically refers to a shorter section.\n",
            "\n",
            "2. Section - Like \"paragraph,\" this word refers to a distinct part of a larger whole. However, \"section\" may also be used to describe physical divisions, such as sections in a book or sections of a building.\n",
            "\n",
            "3. Segment - This synonym is similar to \"section\" and \"paragraph\" in that it refers to a distinct part of something. However, \"segment\" may also imply a division or separation, rather than just a part of a whole.\n",
            "\n",
            "4. Block - While \"paragraph\" refers to a section of written text, \"block\" can also refer to a physical chunk or mass. In the context of a paragraph, \"block\" may suggest a solid and cohesive unit of writing.\n",
            "\n",
            "5. Chunk - Similar to \"block,\" this synonym may imply a solid and substantial piece of writing. However, \"chunk\" may also have a slightly informal or colloquial connotation.\n",
            "\n",
            "6. Portion - This word can be used to describe a part or section of something, including a paragraph. However, \"portion\" may also imply a specific amount or quantity.\n",
            "\n",
            "7. Division - This synonym may be used to describe a section or part of a larger whole. However, \"division\" may also suggest a clear separation or distinction between different parts.\n",
            "\n",
            "8. Segment - Like \"segment,\" this word may imply a division or separation. However, \"segment\" may also suggest a smaller and more specific part of something.\n",
            "\n",
            "9. Clause - This word is often used in the context of grammar and refers to a group of words that contains a subject and a verb. In the context of a paragraph, \"clause\" may imply a distinct and self-contained idea or thought.\n",
            "\n",
            "10. Unit - This synonym may suggest a distinct and cohesive part of something. In the context of a paragraph, \"unit\" may imply that the paragraph is an essential and integral part of a larger piece of writing.\n",
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  Act as a language expert, proofread my paper on '{TOPIC_SENTENCE}' while putting a focus on grammar and punctuation.\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "As a language expert, I have carefully proofread your paper on '{TOPIC_SENTENCE}' and have focused on improving the grammar and punctuation. After thorough examination, I have made the following corrections and suggestions:\n",
            "\n",
            "- In the first paragraph, the use of \"it's\" should be changed to \"its\" as it is possessive and not a contraction.\n",
            "- In the second paragraph, the sentence \"This is because it is a complex topic\" can be rephrased as \"This is due to its complexity\" for better clarity and conciseness.\n",
            "- In the third paragraph, the use of \"their\" should be changed to \"its\" as the subject is singular.\n",
            "- In the fourth paragraph, the sentence \"This is why it is important to have a strong understanding of grammar and punctuation\" can be improved by adding a comma after \"why\" to create a pause and improve the flow of the sentence.\n",
            "- In the fifth paragraph, the use of \"there\" should be changed to \"their\" as it is referring to the students' understanding.\n",
            "- In the sixth paragraph, the sentence \"It is essential to proofread your paper before submitting it\" can be rephrased as \"Proofreading your paper before submission is essential\" to make it more active and direct.\n",
            "- In the seventh paragraph, the use of \"it\" should be changed to \"its\" as it is referring to the paper's quality.\n",
            "- In the eighth paragraph, the sentence \"This will ensure that your paper is free from any grammatical or punctuation errors\" can be improved by adding \"of\" after \"free\" to make it grammatically correct.\n",
            "- In the ninth paragraph, the use of \"their\" should be changed to \"its\" as it is referring to the paper's overall quality.\n",
            "- In the tenth paragraph, the sentence \"Having a strong understanding of grammar and punctuation is crucial for any writer\" can be rephrased as \"A strong understanding of grammar and punctuation is crucial for all writers\" for better clarity and impact.\n",
            "\n",
            "Overall, your paper on '{TOPIC_SENTENCE}' is well-written and informative. However, paying attention to grammar and punctuation can greatly enhance the quality of your writing. I hope my suggestions will be helpful in further improving your paper. Keep up the good work!\n",
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  In the context of '{RESEARCH_DOMAIN}' translate '{PARAGRAPH}' into the '{LANGUAGE}' language.\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "En el contexto de '{RESEARCH_DOMAIN}', traduzca '{PARAGRAPH}' al idioma '{LANGUAGE}'.\n",
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  Find a research topic for a PhD in the area of '{TOPIC}'\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "\"Exploring the Impact of Artificial Intelligence on Human Resource Management Practices in the Digital Age\"\n",
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  Write a detailed proposal on the following research topic. Make sure it is free from plagiarism. '{PARAGRAPH}'\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "Title: The Impact of Social Media on Mental Health in Adolescents\n",
            "\n",
            "Introduction:\n",
            "Social media has become an integral part of our daily lives, especially for adolescents. With the rise of various social media platforms, adolescents are constantly exposed to a virtual world that is filled with information, opinions, and interactions. While social media has its benefits, it has also been linked to negative effects on mental health, particularly in adolescents. This research proposal aims to investigate the impact of social media on mental health in adolescents and identify potential solutions to mitigate its negative effects.\n",
            "\n",
            "Background:\n",
            "Adolescence is a critical stage of development where individuals are more vulnerable to external influences. With the widespread use of social media, adolescents are constantly exposed to unrealistic beauty standards, cyberbullying, and the pressure to present a perfect image of themselves online. This can lead to feelings of inadequacy, low self-esteem, and anxiety, which can have a detrimental effect on their mental health.\n",
            "\n",
            "Research Questions:\n",
            "1. How does social media usage affect the mental health of adolescents?\n",
            "2. What are the common mental health issues faced by adolescents due to social media usage?\n",
            "3. What are the factors that contribute to the negative impact of social media on mental health in adolescents?\n",
            "4. Are there any differences in the impact of social media on mental health between genders?\n",
            "5. What are the potential solutions to mitigate the negative effects of social media on mental health in adolescents?\n",
            "\n",
            "Methodology:\n",
            "This research will be conducted using a mixed-method approach, combining both quantitative and qualitative methods. A survey will be distributed to a sample of adolescents aged 13-18 years to gather quantitative data on their social media usage and its impact on their mental health. The survey will also include questions on their demographics and any pre-existing mental health conditions. Additionally, in-depth interviews will be conducted with a smaller sample of adolescents to gather qualitative data on their experiences with social media and its impact on their mental health. The data collected will be analyzed using statistical methods and thematic analysis.\n",
            "\n",
            "Significance:\n",
            "This research is significant as it will contribute to the existing literature on the impact of social media on mental health in adolescents. The findings of this study can help raise awareness about the negative effects of social media on mental health and provide insights into potential solutions to mitigate these effects. This research can also be used to inform parents, educators, and mental health professionals on the importance of monitoring social media usage in adolescents and providing support to those who may be struggling with their mental health due to social media.\n",
            "\n",
            "Ethical Considerations:\n",
            "This research will adhere to ethical guidelines, and all participants will be required to give informed consent before participating. Confidentiality and anonymity will be maintained throughout the study, and participants will have the right to withdraw from the study at any time.\n",
            "\n",
            "Conclusion:\n",
            "In conclusion, this research proposal aims to investigate the impact of social media on mental health in adolescents. By understanding the negative effects of social media on mental health, we can work towards finding solutions to mitigate these effects and promote a healthier relationship with social media among adolescents. This research has the potential to make a significant contribution to the field of mental health and help improve the well-being of adolescents in the digital age. \n",
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  Identify gaps in the literature on '{TOPIC_SENTENCE}'\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "1. Lack of recent studies: Many of the existing literature on '{TOPIC_SENTENCE}' are outdated and do not reflect current trends and developments in the field. This highlights the need for more recent studies to provide up-to-date information and insights.\n",
            "\n",
            "2. Limited geographical scope: Most of the literature on '{TOPIC_SENTENCE}' focuses on a specific region or country, neglecting the experiences and perspectives of other regions. This limits the generalizability of findings and hinders a comprehensive understanding of the topic.\n",
            "\n",
            "3. Insufficient diversity in study samples: Many studies on '{TOPIC_SENTENCE}' have been conducted on a narrow sample of participants, often limited to a specific demographic or population. This can lead to biased or incomplete conclusions and overlook the experiences of marginalized or underrepresented groups.\n",
            "\n",
            "4. Lack of interdisciplinary approach: '{TOPIC_SENTENCE}' is a complex and multifaceted topic that requires an interdisciplinary approach to fully understand it. However, the existing literature often lacks collaboration between different disciplines, resulting in a limited understanding of the topic.\n",
            "\n",
            "5. Inadequate theoretical frameworks: Some of the literature on '{TOPIC_SENTENCE}' lacks a strong theoretical foundation, making it difficult to interpret and apply the findings. This highlights the need for more studies that are grounded in robust theoretical frameworks.\n",
            "\n",
            "6. Limited focus on practical implications: While there is a significant body of literature on '{TOPIC_SENTENCE}', many studies fail to provide practical implications or recommendations for real-world applications. This gap hinders the translation of research findings into actionable strategies.\n",
            "\n",
            "7. Neglect of marginalized voices: The existing literature on '{TOPIC_SENTENCE}' often overlooks the perspectives and experiences of marginalized groups, such as women, minorities, and individuals from low-income backgrounds. This gap highlights the need for more inclusive and diverse research in this area.\n",
            "\n",
            "8. Limited attention to emerging technologies: With the rapid advancement of technology, there is a lack of literature on the impact of new and emerging technologies on '{TOPIC_SENTENCE}'. This gap needs to be addressed to keep up with the constantly evolving landscape of the topic.\n",
            "\n",
            "9. Inadequate focus on long-term effects: Many studies on '{TOPIC_SENTENCE}' have a short-term focus, neglecting the long-term effects and implications of the topic. This gap highlights the need for more longitudinal studies to understand the lasting impact of '{TOPIC_SENTENCE}'.\n",
            "\n",
            "10. Lack of comparative studies: There is a lack of comparative studies that examine the similarities and differences in '{TOPIC_SENTENCE}' across different cultures, countries, or regions. This gap limits our understanding of the topic and the potential cultural influences on it.\n",
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  Generate 10 academic research questions about '{PARAGRAPHS}'\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "1. What are the potential impacts of {PARAGRAPHS} on the mental health of individuals?\n",
            "2. How does {PARAGRAPHS} affect the productivity and efficiency of employees in the workplace?\n",
            "3. What are the underlying factors that contribute to the prevalence of {PARAGRAPHS} in modern society?\n",
            "4. How does the media portrayal of {PARAGRAPHS} influence public perception and understanding of the issue?\n",
            "5. What are the long-term consequences of {PARAGRAPHS} on the environment and sustainability?\n",
            "6. How do cultural and societal norms contribute to the perpetuation of {PARAGRAPHS}?\n",
            "7. What are the most effective strategies for addressing and preventing {PARAGRAPHS} in communities?\n",
            "8. How does socioeconomic status impact the likelihood of individuals experiencing {PARAGRAPHS}?\n",
            "9. What are the ethical implications of conducting research on {PARAGRAPHS} and its effects on vulnerable populations?\n",
            "10. How do government policies and interventions impact the prevalence and severity of {PARAGRAPHS} in different regions?\n",
            "\n",
            " end of loop\n",
            "========================\n",
            "\n",
            "prompt is  Generate a list of research hypotheses related to '{TOPIC_SENTENCE}'\n",
            "\n",
            "Generated Academic Paper:\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "1. The use of social media has a significant impact on individuals' mental health.\n",
            "2. Increased screen time is associated with higher levels of anxiety and depression.\n",
            "3. Social media addiction is linked to decreased self-esteem and body image issues.\n",
            "4. The constant comparison on social media leads to higher levels of stress and dissatisfaction.\n",
            "5. The type of content consumed on social media affects individuals' emotional well-being.\n",
            "6. The frequency of social media use is correlated with individuals' level of loneliness.\n",
            "7. The use of social media can lead to a decrease in face-to-face social interactions.\n",
            "8. Social media use is associated with a decrease in academic performance and productivity.\n",
            "9. The pressure to maintain a perfect online image contributes to increased levels of stress and anxiety.\n",
            "10. The use of social media can lead to a decrease in overall life satisfaction.\n",
            "11. The influence of social media on body image is stronger among adolescents and young adults.\n",
            "12. The use of social media can lead to a decrease in real-life empathy and emotional intelligence.\n",
            "13. Social media use is linked to an increase in cyberbullying and online harassment.\n",
            "14. The use of social media can have a negative impact on sleep quality and quantity.\n",
            "15. The constant exposure to curated and edited images on social media can lead to unrealistic beauty standards and body dissatisfaction.\n",
            "\n",
            " end of loop\n",
            "========================\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-838112992903>\u001b[0m in \u001b[0;36m<cell line: 102>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;31m# Generate academic papers for the given prompts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m \u001b[0mgenerate_papers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-838112992903>\u001b[0m in \u001b[0;36mgenerate_papers\u001b[0;34m(prompts)\u001b[0m\n\u001b[1;32m     96\u001b[0m            \u001b[0;31m#print(\"loop\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m        \u001b[0;31m# Wait for a short period of time before sending the next batch of prompts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m            \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mchoice_text_all\u001b[0m\u001b[0;31m#,choice.translated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SETUP COLAB for run Streamlit\n",
        "!npm install localtunnel\n",
        "!curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "GRn7OkOUjcdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#I have tried to update the prompt by ChatGPT itself üëáüëá"
      ],
      "metadata": {
        "id": "wxqM4h1fw4fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_main_variables(prompts, variable):\n",
        "   main_variables = {\n",
        "       'TOPIC': None,\n",
        "       'RESEARCH_DOMAIN': None,\n",
        "       'PARAGRAPH': None,\n",
        "       'PARAGRAPHS': None,\n",
        "       'TOPIC_SENTENCE': None,\n",
        "       'LANGUAGE': None,\n",
        "       'ABSTRACT_PARAGRAPH': None,\n",
        "       'BIBLIOGRAPHY': None,\n",
        "       'THEORY1': None,\n",
        "       'THEORY2': None,\n",
        "       'RESEARCH_QUESTIONS': None,\n",
        "       'ACTION': None,\n",
        "       'RESULT_PARAGRAPHS': None,\n",
        "       'DATE': None,\n",
        "       'NUMBER_OF_DAYS_MONTHS_YEARS': None\n",
        "   }\n",
        "\n",
        "   for prompt in prompts:\n",
        "       variables = re.findall(r'\\{(\\w+)\\}', prompt)\n",
        "       for var in variables:\n",
        "           if var == 'TOPIC':\n",
        "               main_variables[var] = variable\n",
        "           else:\n",
        "               main_variables[var] = None\n",
        "\n",
        "   return main_variables"
      ],
      "metadata": {
        "id": "Jd711_MyBgje"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "\n",
        "def generate_prompt_from_response(previous_response, main_variables):\n",
        "   # Customize this logic based on your needs\n",
        "   # For simplicity, let's use the last 50 characters of the response as the new prompt\n",
        "   new_prompt = previous_response[-50:]\n",
        "\n",
        "   # Replace the main variables in the new prompt\n",
        "   for var, value in main_variables.items():\n",
        "       if value is not None:\n",
        "           new_prompt = new_prompt.replace(value, f\"{{{var}}}\")\n",
        "\n",
        "   return new_prompt\n",
        "\n",
        "# Example usage\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\"\n",
        "\n",
        "prompts_1 = [\n",
        "f\"Find a research topic for a PhD in the area of '{TOPIC}'\",\n",
        "\n",
        "]\n",
        "#prompts_2 = [\n",
        "#   \"I need to find information on renewable energy for a research paper that will be 1,500 words and must include eight sources.\",\n",
        "#   \"The research paper should cover the latest advancements in renewable energy technology.\"\n",
        "#]\n",
        "\n",
        "main_variables = extract_main_variables(prompts,TOPIC)\n",
        "print(main_variables)\n",
        "\n",
        "previous_response = \"Previous GPT response\"\n",
        "new_prompt = generate_prompt_from_response(previous_response, main_variables)\n",
        "print(new_prompt)\n",
        "print ( prompts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYegFb6aq_h8",
        "outputId": "88af1ca3-c9c0-464a-8ec8-d4bad6a1e67b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'TOPIC': 'Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power', 'RESEARCH_DOMAIN': None, 'PARAGRAPH': None, 'PARAGRAPHS': None, 'TOPIC_SENTENCE': None, 'LANGUAGE': None, 'ABSTRACT_PARAGRAPH': None, 'BIBLIOGRAPHY': None, 'THEORY1': None, 'THEORY2': None, 'RESEARCH_QUESTIONS': None, 'ACTION': None, 'RESULT_PARAGRAPHS': None, 'DATE': None, 'NUMBER_OF_DAYS_MONTHS_YEARS': None}\n",
            "Previous GPT response\n",
            "[\"Write a counterargument to the following claim: '{PARAGRAPH}'\", \"Rewrite this in an academic voice: '{PARAGRAPH}'\", \"Expand these notes: '{PARAGRAPH}'\", \"Provide me a list of words and phrases which were repeatedly / more than 3 times used: '{PARAGRAPHS}'\", \"Provide me a list of synonyms for '{PARAGRAPH}' and evaluate them in the context of '{PARAGRAPH}'\", \"Act as a language expert, proofread my paper on '{TOPIC_SENTENCE}' while putting a focus on grammar and punctuation.\", \"In the context of '{RESEARCH_DOMAIN}' translate '{PARAGRAPH}' into the '{LANGUAGE}' language.\", \"Find a research topic for a PhD in the area of '{TOPIC}'\", \"Write a detailed proposal on the following research topic. Make sure it is free from plagiarism. '{PARAGRAPH}'\", \"Identify gaps in the literature on '{TOPIC_SENTENCE}'\", \"Generate 10 academic research questions about '{PARAGRAPHS}'\", \"Generate a list of research hypotheses related to '{TOPIC_SENTENCE}'\", \"Identify potential areas for future research in the context of this '{TOPIC_SENTENCE}'\", \"Suggest novel applications of '{TOPIC_SENTENCE}' within '{RESEARCH_DOMAIN}'\", \"Suggest 5 titles for the following abstract: '{ABSTRACT_PARAGRAPH}'\", \"Write a topic sentence for this paragraph: '{PARAGRAPH}'\", \"Provide 5 keywords for this: '{PARAGRAPHS}'\", \"Generate an abstract for a scientific paper based on this information for: '{PARAGRAPHS}'\", \"Generate an outline for '{TOPIC_SENTENCE}'\", \"I want to write a journal article about '{TOPIC_SENTENCE}'. Give me an outline for the article that I can use as a starting point.\", \"Come up with an introduction for the following research topic: '{TOPIC_SENTENCE}'\", \"Conduct a literature review on '{TOPIC_SENTENCE}' and provide review paper references\", \"Provide me with references and links to papers in '{PARAGRAPH}'\", \"Summarize the scholarly literature including in-text citations on '{PARAGRAPHS}'\", \"Write this in standard Harvard referencing '{PARAGRAPH}'\", \"Convert this '{BIBLIOGRAPHY}' from MLA to APA style.\", \"Compare and contrast '{THEORY1}' and '{THEORY2}' in the context of '{RESEARCH_DOMAIN}'\", \"Create objectives and methodology for '{TOPIC_SENTENCE}'\", \"Write a detailed methodology for the topic: '{TOPIC_SENTENCE}'\", \"Analyze the strengths and weaknesses of this methodology: '{PARAGRAPHS}'\", \"Write objectives for this study: '{TOPIC_SENTENCE}'\", \"What are the limitations of using '{TOPIC_SENTENCE}' in '{RESEARCH_DOMAIN}'?\", \"Create a recipe for the methods used in this '{PARAGRAPHS}'\", \"Suggest interdisciplinary approaches to '{TOPIC_SENTENCE}'\", \"Explain how qualitative/quantitative research methods can be used to address '{RESEARCH_QUESTIONS}'\", \"Recommend best practices for data collection and analysis in '{TOPIC_SENTENCE}'\", \"Design an experiment that '{ACTION}'\", \"Write a result section for the following paragraphs. Please write this in the third person. '{PARAGRAPHS}'\", \"Discuss this results: '{RESULT_PARAGRAPHS}'\", \"Generate a conclusion for this: '{PARAGRAPHS}'\", \"Give recommendations and conclusion for: '{PARAGRAPHS}'\", \"Can you suggest 3 directions for future research on this topic: '{PARAGRAPH}'\", \"Develop a research plan for: '{TOPIC_SENTENCE}'\", \"Write a schedule for completion in '{TOPIC_SENTENCE}' in NUMBER OF DAYS MONTHS YEARS which is '{NUMBER_OF_DAYS_MONTHS_YEARS}'\", \"The deadline for the submission of the first draft is '{DATE}'. Give me a week-by-week breakdown so I can plan my writing better.\", \"Write a sensational press release for this research: '{PARAGRAPHS}'\", \"Make this more persuasive: '{PARAGRAPH}'\", \"Write 3 tweets about this research? '{PARAGRAPHS}'\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Updating the prompt by ChatGPT:üëáüëá"
      ],
      "metadata": {
        "id": "UgzzXkG9wjbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt_update_0(prompt, previous_content, main_variables):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   # Replace the TOPIC variable in the prompt\n",
        "   for var, value in main_variables.items():\n",
        "       if var == 'TOPIC' and value is not None:\n",
        "           prompt = prompt.replace(f\"{{{var}}}\", value)\n",
        "\n",
        "   # Construct the instruction for updating the prompt\n",
        "   instruction = f\"Given the previous content:\\n\\n{previous_content}\\n\\nUpdate the prompt: {prompt}\"\n",
        "\n",
        "   # Create the completion with the instruction\n",
        "   completion = client.completions.create(\n",
        "       model=model_engine,\n",
        "       prompt=instruction,\n",
        "       max_tokens=max_tokens,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "\n",
        "   # Extract and return the updated prompt from the response\n",
        "   updated_prompt = completion.choices[0].text.strip()\n",
        "   return updated_prompt"
      ],
      "metadata": {
        "id": "QbOCQqCDB8xb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "def generate_prompt_update_1(prompt_my):\n",
        "  model_engine = \"text-davinci-003\"\n",
        "  max_tokens = 2048\n",
        "\n",
        "  completion = client.completions.create(\n",
        "      model=\"gpt-3.5-turbo-instruct\",\n",
        "      prompt=prompt_my,\n",
        "      max_tokens=2048,\n",
        "      temperature=0.3,\n",
        "      n=1,\n",
        "      frequency_penalty=0,\n",
        "  )\n",
        "  return completion"
      ],
      "metadata": {
        "id": "WPRw6qJOuaS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import openai\n",
        "from openai import RateLimitError\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   api_key = \"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\",\n",
        ")\n",
        "def retry_with_exponential_backoff(\n",
        "   func,\n",
        "   initial_delay: float = 1,\n",
        "   exponential_base: float = 2,\n",
        "   jitter: bool = True,\n",
        "   max_retries: int = 10,\n",
        "   errors: tuple = (RateLimitError,),\n",
        "):\n",
        "   \"\"\"Retry a function with exponential backoff.\"\"\"\n",
        "   def wrapper(*args, **kwargs):\n",
        "       # Initialize variables\n",
        "       num_retries = 0\n",
        "       delay = initial_delay\n",
        "       # Loop until a successful response or max_retries is hit or an exception is raised\n",
        "       while True:\n",
        "           try:\n",
        "               return func(*args, **kwargs)\n",
        "           # Retry on specified errors\n",
        "           except errors as e:\n",
        "               # Increment retries\n",
        "               num_retries += 1\n",
        "               # Check if max retries has been reached\n",
        "               if num_retries > max_retries:\n",
        "                  raise Exception(\n",
        "                      f\"Maximum number of retries ({max_retries}) exceeded.\"\n",
        "                  )\n",
        "               # Increment the delay\n",
        "               delay *= exponential_base * (1 + jitter * random.random())\n",
        "               # Sleep for the delay\n",
        "               time.sleep(delay)\n",
        "           # Raise exceptions for any errors not specified\n",
        "           except Exception as e:\n",
        "               raise e\n",
        "   return wrapper\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "\n",
        "@retry_with_exponential_backoff\n",
        "def generate_prompt_update(prompt_my):\n",
        " model_engine = \"text-davinci-003\"\n",
        " max_tokens = 2048\n",
        "\n",
        " completion = client.completions.create(\n",
        "     model=\"gpt-3.5-turbo-instruct\",\n",
        "     prompt=prompt_my,\n",
        "     max_tokens=1024,\n",
        "     temperature=0.1,\n",
        "     n=1,\n",
        "     frequency_penalty=0,\n",
        " )\n",
        " return completion\n",
        "\n",
        "\n",
        "@retry_with_exponential_backoff\n",
        "def generate_academic_paper(prompt_my):\n",
        " model_engine = \"text-davinci-003\"\n",
        " max_tokens = 2048\n",
        "\n",
        " completion = client.completion.create(\n",
        "     model=\"gpt-3.5-turbo-instruct\",\n",
        "     prompt=prompt_my,\n",
        "     max_tokens=2048,\n",
        "     temperature=0.3,\n",
        "     n=1,\n",
        "     frequency_penalty=0,\n",
        " )\n",
        " return completion"
      ],
      "metadata": {
        "id": "O2TNMQ8eFl8n"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate_content(prompts, variables, TOPIC, perviuse_content=\"\"):\n",
        "  # Generate content for each variable\n",
        "  variable_contents = {}\n",
        "\n",
        "  for prompt in prompts:\n",
        "      for var in variables:\n",
        "          if var in prompt:\n",
        "              print(f\"\\n---prompt is ----\\n{prompt}\")\n",
        "              prompt_my = f\"Generate content for the variable '{var}' in the context of the topic '{TOPIC}'. Please consider the result must be in less than 10 words. The prompt is '{prompt}'. Also the more information for understanding better content is '{perviuse_content}'\"\n",
        "              content = generate_prompt_update(prompt_my)\n",
        "              for choice in content.choices:\n",
        "                print(\"\\n Result is :\"+choice.text)\n",
        "                variable_contents[var] = choice.text\n",
        "              print(f\"variable_contents[{var}] is: {variable_contents[var]}\")\n",
        "\n",
        "  # Replace the variables in the prompts with the generated content\n",
        "  prompt_new = []\n",
        "  for prompt in prompts:\n",
        "      for var, content in variable_contents.items():\n",
        "          prompt = prompt.replace(f\"{{{var}}}\", variable_contents[var])\n",
        "      prompt_new.append(prompt)\n",
        "      print(\"\\n --- Updated prompt is :\\n\"+str(prompt_new))\n",
        "  return prompt_new\n",
        "\n",
        "# Define main variables\n",
        "#TOPIC = \"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"\n",
        "\n",
        "# List of variables\n",
        "variables = [\"RESEARCH_DOMAIN\", \"PARAGRAPH\", \"PARAGRAPHS\", \"TOPIC_SENTENCE\", \"LANGUAGE\", \"ABSTRACT_PARAGRAPH\", \"BIBLIOGRAPHY\", \"THEORY1\", \"THEORY2\", \"RESEARCH_QUESTIONS\", \"ACTION\", \"RESULT_PARAGRAPHS\", \"DATE\", \"NUMBER_OF_DAYS_MONTHS_YEARS\"]\n",
        "\n",
        "# List of prompts\n",
        "#prompts = [\"prompt1\", \"prompt2\", \"prompt3\"] # replace with your actual prompts\n",
        "#perviuse_content= \"test\"\n",
        "# Call the function and store the returned prompts\n",
        "#updated_prompts = generate_content(prompts, variables, TOPIC, perviuse_content)\n",
        "#print(\"Updated Prompts:\", updated_prompts)"
      ],
      "metadata": {
        "id": "uI21enmkhb0n"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\" #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\"\n",
        "\n",
        "\n",
        "#topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "#client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   #api_key = \"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\",\n",
        "#)\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "# Create a Translator object\n",
        "translator = Translator()\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "def generate_academic_paper_0(prompt_my):\n",
        "  model_engine = \"text-davinci-003\"\n",
        "  max_tokens = 2048\n",
        "\n",
        "  completion = client.completions.create(\n",
        "      model=\"gpt-3.5-turbo-instruct\",\n",
        "      prompt=prompt_my,\n",
        "      max_tokens=2048,\n",
        "      temperature=0.3,\n",
        "      n=1,\n",
        "      frequency_penalty=0,\n",
        "  )\n",
        "  return completion"
      ],
      "metadata": {
        "id": "44bkCJOHtmuJ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time,random\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   api_key = \"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\",\n",
        ")\n",
        "\n",
        "def generate_papers(prompts, perviuse_content):\n",
        "  choice_text_all=[]\n",
        "  for i in range(0, len(prompts), 20):\n",
        "     # Slice the prompts list to get the next 20 prompts\n",
        "     print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "\n",
        "     batch = prompts[i:i+20]\n",
        "     print(\"batch is \",batch)\n",
        "\n",
        "     for prompt in batch:\n",
        "         # Print the prompt\n",
        "         print(\"prompt is \",list({prompt}))\n",
        "\n",
        "         updated_prompts = generate_content(list({prompt}), variables, TOPIC, perviuse_content)\n",
        "         print(\"Updated Prompts:\", updated_prompts)\n",
        "\n",
        "         #time.sleep(random.randint(20, 40))\n",
        "         response = generate_academic_paper(updated_prompts)\n",
        "         print(\"\\nGenerated Academic Paper:\")\n",
        "         print(\"========================\\n\")\n",
        "         for choice in response.choices:\n",
        "           print(choice.text)\n",
        "           choice_in_loop = choice.text\n",
        "           choice_text_all.append(choice.text)\n",
        "\n",
        "\n",
        "         #save_academic_paper(topic,'\\n--------**\\n'+updated_prompts+'/n-------**\\n'+choice.text)\n",
        "         save_academic_paper(TOPIC,'\\n--------**\\n'+''.join(updated_prompts)+'/n-------**\\n'+choice.text)\n",
        "         if hasattr(choice, 'choices'):\n",
        "             extract_text(choice)\n",
        "\n",
        "         perviuse_content = choice_in_loop\n",
        "         print(\"\\n end of loop\")\n",
        "         print(\"========================\\n\")\n",
        "\n",
        "         #time.sleep(random.randint(20, 40))\n",
        "  return choice_text_all\n",
        "\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\" #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\"\n",
        "\n",
        "# Generate academic papers for the given prompts\n",
        "perviuse_content=['fist step']\n",
        "generate_papers(prompts, perviuse_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHIX17GHsecy",
        "outputId": "1b1b0f2b-afaa-4dc7-d6fc-3f19067bc88b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I is  0  Len of prompt Is: 48\n",
            "batch is  [\"Write a counterargument to the following claim: '{PARAGRAPH}'\", \"Rewrite this in an academic voice: '{PARAGRAPH}'\", \"Expand these notes: '{PARAGRAPH}'\", \"Provide me a list of words and phrases which were repeatedly / more than 3 times used: '{PARAGRAPHS}'\", \"Provide me a list of synonyms for '{PARAGRAPH}' and evaluate them in the context of '{PARAGRAPH}'\", \"Act as a language expert, proofread my paper on '{TOPIC_SENTENCE}' while putting a focus on grammar and punctuation.\", \"In the context of '{RESEARCH_DOMAIN}' translate '{PARAGRAPH}' into the '{LANGUAGE}' language.\", \"Find a research topic for a PhD in the area of '{TOPIC}'\", \"Write a detailed proposal on the following research topic. Make sure it is free from plagiarism. '{PARAGRAPH}'\", \"Identify gaps in the literature on '{TOPIC_SENTENCE}'\", \"Generate 10 academic research questions about '{PARAGRAPHS}'\", \"Generate a list of research hypotheses related to '{TOPIC_SENTENCE}'\", \"Identify potential areas for future research in the context of this '{TOPIC_SENTENCE}'\", \"Suggest novel applications of '{TOPIC_SENTENCE}' within '{RESEARCH_DOMAIN}'\", \"Suggest 5 titles for the following abstract: '{ABSTRACT_PARAGRAPH}'\", \"Write a topic sentence for this paragraph: '{PARAGRAPH}'\", \"Provide 5 keywords for this: '{PARAGRAPHS}'\", \"Generate an abstract for a scientific paper based on this information for: '{PARAGRAPHS}'\", \"Generate an outline for '{TOPIC_SENTENCE}'\", \"I want to write a journal article about '{TOPIC_SENTENCE}'. Give me an outline for the article that I can use as a starting point.\"]\n",
            "prompt is  [\"Write a counterargument to the following claim: '{PARAGRAPH}'\"]\n",
            "\n",
            "---prompt is ----\n",
            "Write a counterargument to the following claim: '{PARAGRAPH}'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define main variables\n",
        "#TOPIC = \"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"\n",
        "\n",
        "# List of variables\n",
        "variables = [\"RESEARCH_DOMAIN\", \"PARAGRAPH\", \"PARAGRAPHS\", \"TOPIC_SENTENCE\", \"LANGUAGE\", \"ABSTRACT_PARAGRAPH\", \"BIBLIOGRAPHY\", \"THEORY1\", \"THEORY2\", \"RESEARCH_QUESTIONS\", \"ACTION\", \"RESULT_PARAGRAPHS\", \"DATE\", \"NUMBER_OF_DAYS_MONTHS_YEARS\"]\n",
        "\n",
        "# Generate content for each variable\n",
        "variable_contents = {}\n",
        "for prompt in prompts:\n",
        "   for var in variables:\n",
        "       if var in prompt:\n",
        "           prompt = f\"Generate content for the variable '{var}' based on the topic '{TOPIC}'. For this prompt '{prompt}'\"\n",
        "           content= generate_academic_paper(prompt)\n",
        "           for choice in content.choices:\n",
        "               print(choice.text)\n",
        "               variable_contents[var] = choice.text\n",
        "           print(\"variable_contents[var] is: \",variable_contents[var])\n",
        "\n",
        "# Replace the variables in the prompts with the generated content\n",
        "for prompt in prompts:\n",
        "   for var, content in variable_contents.items():\n",
        "       prompt = prompt.replace(f\"{{{var}}}\", content)\n",
        "print(\"Updated Prompt:\", prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kH3LygdiXsPg",
        "outputId": "d3f6714d-a1bc-48dc-bf74-d1fe9ee9c407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "While it is true that the Iranian Women's Movement has been facing challenges in increasing compassion and maintaining relationships due to the fatigue of compassion in light triad personality, it is important to consider that this is not the only factor at play. There are other external factors that contribute to the difficulties faced by the movement, such as societal norms and cultural expectations.\n",
            "\n",
            "One could argue that the fatigue of compassion in light triad personality is a result of the constant struggle and oppression faced by Iranian women. The movement has been fighting for their rights and equality for decades, and this constant battle can lead to exhaustion and burnout. It is unfair to solely blame the movement for the lack of compassion, as they are constantly facing resistance and backlash from those who do not support their cause.\n",
            "\n",
            "Furthermore, it is important to acknowledge that the fatigue of compassion in light triad personality is not limited to just the Iranian Women's Movement. It is a common issue faced by activists and advocates all over the world. The constant emotional labor and stress of fighting for a cause can take a toll on anyone, regardless of their personality traits.\n",
            "\n",
            "It is also worth noting that the Iranian Women's Movement has made significant progress in increasing compassion and building strong relationships within their community. They have created safe spaces for women to come together and support each other, and have also been actively involved in various humanitarian efforts. These actions demonstrate their commitment to compassion and empathy, despite the challenges they face.\n",
            "\n",
            "In conclusion, while the fatigue of compassion in light triad personality may be a valid concern, it is important to consider the larger context and external factors that contribute to it. The Iranian Women's Movement should not be solely blamed for the lack of compassion, but rather supported and encouraged in their efforts to bring about positive change in their society.\n",
            "variable_contents[var] is:  \n",
            "\n",
            "While it is true that the Iranian Women's Movement has been facing challenges in increasing compassion and maintaining relationships due to the fatigue of compassion in light triad personality, it is important to consider that this is not the only factor at play. There are other external factors that contribute to the difficulties faced by the movement, such as societal norms and cultural expectations.\n",
            "\n",
            "One could argue that the fatigue of compassion in light triad personality is a result of the constant struggle and oppression faced by Iranian women. The movement has been fighting for their rights and equality for decades, and this constant battle can lead to exhaustion and burnout. It is unfair to solely blame the movement for the lack of compassion, as they are constantly facing resistance and backlash from those who do not support their cause.\n",
            "\n",
            "Furthermore, it is important to acknowledge that the fatigue of compassion in light triad personality is not limited to just the Iranian Women's Movement. It is a common issue faced by activists and advocates all over the world. The constant emotional labor and stress of fighting for a cause can take a toll on anyone, regardless of their personality traits.\n",
            "\n",
            "It is also worth noting that the Iranian Women's Movement has made significant progress in increasing compassion and building strong relationships within their community. They have created safe spaces for women to come together and support each other, and have also been actively involved in various humanitarian efforts. These actions demonstrate their commitment to compassion and empathy, despite the challenges they face.\n",
            "\n",
            "In conclusion, while the fatigue of compassion in light triad personality may be a valid concern, it is important to consider the larger context and external factors that contribute to it. The Iranian Women's Movement should not be solely blamed for the lack of compassion, but rather supported and encouraged in their efforts to bring about positive change in their society.\n",
            "\n",
            "\n",
            "In recent years, the Iranian Women's Movement has gained significant attention and momentum, with a strong focus on promoting gender equality and challenging traditional gender roles. However, despite their efforts, many women in this movement have reported experiencing high levels of compassion fatigue. This phenomenon, characterized by emotional exhaustion, depersonalization, and reduced personal accomplishment, can have detrimental effects on individuals and their relationships. In light of this, it is crucial to explore strategies that can increase compassion within the Iranian Women's Movement and its relationship with the fatigue of compassion, particularly in the context of the Light Triad Personality.\n",
            "\n",
            "One potential strategy for increasing compassion within the Iranian Women's Movement is through the cultivation of self-compassion. This involves treating oneself with kindness and understanding, especially in the face of challenges and setbacks. By fostering self-compassion, individuals can better manage their own emotional well-being and avoid burnout. This, in turn, can lead to a more compassionate and supportive environment within the movement.\n",
            "\n",
            "Another important strategy is the development of empathy and perspective-taking skills. Empathy allows individuals to understand and share the feelings of others, while perspective-taking enables one to see a situation from another's point of view. By honing these skills, members of the Iranian Women's Movement can better understand the struggles and experiences of their fellow activists, leading to increased compassion and support for one another.\n",
            "\n",
            "Furthermore, it is essential to address the issue of burnout within the movement. This can be achieved through the implementation of self-care practices, such as setting boundaries, taking breaks, and seeking support from others. By prioritizing self-care, individuals can prevent compassion fatigue and maintain their emotional well-being, allowing them to continue their activism with renewed energy and compassion.\n",
            "\n",
            "In the context of the Light Triad Personality, which comprises traits of compassion, empathy, and altruism, it is crucial to recognize and nurture these qualities within individuals. By acknowledging and valuing these traits, individuals can feel a sense of purpose and fulfillment in their activism, leading to increased compassion and motivation to continue their efforts.\n",
            "\n",
            "In conclusion, the Iranian Women's Movement is a vital force in promoting gender equality and challenging traditional gender roles. However, the issue of compassion fatigue must be addressed to ensure the sustainability and effectiveness of this movement. By implementing strategies such as cultivating self-compassion, developing empathy and perspective-taking skills, and prioritizing self-care, individuals can increase compassion within the movement and its relationship with the fatigue of compassion, ultimately leading to a more resilient and compassionate movement.\n",
            "variable_contents[var] is:  \n",
            "\n",
            "In recent years, the Iranian Women's Movement has gained significant attention and momentum, with a strong focus on promoting gender equality and challenging traditional gender roles. However, despite their efforts, many women in this movement have reported experiencing high levels of compassion fatigue. This phenomenon, characterized by emotional exhaustion, depersonalization, and reduced personal accomplishment, can have detrimental effects on individuals and their relationships. In light of this, it is crucial to explore strategies that can increase compassion within the Iranian Women's Movement and its relationship with the fatigue of compassion, particularly in the context of the Light Triad Personality.\n",
            "\n",
            "One potential strategy for increasing compassion within the Iranian Women's Movement is through the cultivation of self-compassion. This involves treating oneself with kindness and understanding, especially in the face of challenges and setbacks. By fostering self-compassion, individuals can better manage their own emotional well-being and avoid burnout. This, in turn, can lead to a more compassionate and supportive environment within the movement.\n",
            "\n",
            "Another important strategy is the development of empathy and perspective-taking skills. Empathy allows individuals to understand and share the feelings of others, while perspective-taking enables one to see a situation from another's point of view. By honing these skills, members of the Iranian Women's Movement can better understand the struggles and experiences of their fellow activists, leading to increased compassion and support for one another.\n",
            "\n",
            "Furthermore, it is essential to address the issue of burnout within the movement. This can be achieved through the implementation of self-care practices, such as setting boundaries, taking breaks, and seeking support from others. By prioritizing self-care, individuals can prevent compassion fatigue and maintain their emotional well-being, allowing them to continue their activism with renewed energy and compassion.\n",
            "\n",
            "In the context of the Light Triad Personality, which comprises traits of compassion, empathy, and altruism, it is crucial to recognize and nurture these qualities within individuals. By acknowledging and valuing these traits, individuals can feel a sense of purpose and fulfillment in their activism, leading to increased compassion and motivation to continue their efforts.\n",
            "\n",
            "In conclusion, the Iranian Women's Movement is a vital force in promoting gender equality and challenging traditional gender roles. However, the issue of compassion fatigue must be addressed to ensure the sustainability and effectiveness of this movement. By implementing strategies such as cultivating self-compassion, developing empathy and perspective-taking skills, and prioritizing self-care, individuals can increase compassion within the movement and its relationship with the fatigue of compassion, ultimately leading to a more resilient and compassionate movement.\n",
            "\n",
            "\n",
            "The Iranian Women's Movement has been a powerful force for change in the country, advocating for gender equality and women's rights. However, as with any movement, there are challenges that must be addressed in order to sustain its momentum and effectiveness. One of these challenges is the fatigue of compassion, which can occur when individuals become overwhelmed by the constant need to fight against injustice and oppression.\n",
            "\n",
            "In light of this, it is crucial for the Iranian Women's Movement to implement strategies that can increase compassion within its members and supporters. This not only helps to prevent burnout and fatigue, but also strengthens the movement as a whole. One effective strategy is to promote self-care and self-compassion among activists. This involves encouraging individuals to prioritize their own well-being and to practice self-compassion when facing difficult situations.\n",
            "\n",
            "Another important strategy is to foster a sense of community and support within the movement. This can be achieved through regular meetings, workshops, and events where members can come together to share their experiences, offer support, and build strong relationships. By creating a sense of belonging and solidarity, individuals are more likely to feel motivated and energized to continue their activism.\n",
            "\n",
            "In addition, the Iranian Women's Movement can also benefit from incorporating the concept of the light triad personality into its approach. The light triad personality consists of three traits: compassion, empathy, and altruism. By promoting these traits within the movement, individuals can develop a deeper understanding and connection with others, leading to a stronger sense of compassion and empathy.\n",
            "\n",
            "It is also important for the movement to address any internal conflicts and divisions that may arise. By promoting open communication and conflict resolution, individuals can work through their differences and maintain a united front. This not only strengthens the movement, but also sets a positive example for society.\n",
            "\n",
            "In conclusion, the Iranian Women's Movement has the potential to create lasting change in the country, but it must also prioritize the well-being and compassion of its members. By implementing these strategies, the movement can continue to thrive and make a positive impact on the lives of Iranian women. \n",
            "variable_contents[var] is:  \n",
            "\n",
            "The Iranian Women's Movement has been a powerful force for change in the country, advocating for gender equality and women's rights. However, as with any movement, there are challenges that must be addressed in order to sustain its momentum and effectiveness. One of these challenges is the fatigue of compassion, which can occur when individuals become overwhelmed by the constant need to fight against injustice and oppression.\n",
            "\n",
            "In light of this, it is crucial for the Iranian Women's Movement to implement strategies that can increase compassion within its members and supporters. This not only helps to prevent burnout and fatigue, but also strengthens the movement as a whole. One effective strategy is to promote self-care and self-compassion among activists. This involves encouraging individuals to prioritize their own well-being and to practice self-compassion when facing difficult situations.\n",
            "\n",
            "Another important strategy is to foster a sense of community and support within the movement. This can be achieved through regular meetings, workshops, and events where members can come together to share their experiences, offer support, and build strong relationships. By creating a sense of belonging and solidarity, individuals are more likely to feel motivated and energized to continue their activism.\n",
            "\n",
            "In addition, the Iranian Women's Movement can also benefit from incorporating the concept of the light triad personality into its approach. The light triad personality consists of three traits: compassion, empathy, and altruism. By promoting these traits within the movement, individuals can develop a deeper understanding and connection with others, leading to a stronger sense of compassion and empathy.\n",
            "\n",
            "It is also important for the movement to address any internal conflicts and divisions that may arise. By promoting open communication and conflict resolution, individuals can work through their differences and maintain a united front. This not only strengthens the movement, but also sets a positive example for society.\n",
            "\n",
            "In conclusion, the Iranian Women's Movement has the potential to create lasting change in the country, but it must also prioritize the well-being and compassion of its members. By implementing these strategies, the movement can continue to thrive and make a positive impact on the lives of Iranian women. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off generate_academic_paper(...) for 0.4s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-SDI1YMmM2lE1FsZOy1sRCzwk on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "INFO:backoff:Backing off generate_academic_paper(...) for 1.8s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-SDI1YMmM2lE1FsZOy1sRCzwk on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "- Compassion\n",
            "- Iranian Women Movement\n",
            "- Strategies\n",
            "- Increase\n",
            "- Fatigue\n",
            "- Relationship\n",
            "- Light Triad Personality\n",
            "- Empathy\n",
            "- Understanding\n",
            "- Support\n",
            "- Unity\n",
            "- Empowerment\n",
            "- Kindness\n",
            "- Humanity\n",
            "- Activism\n",
            "- Advocacy\n",
            "- Equality\n",
            "- Inclusivity\n",
            "- Resilience\n",
            "- Strength\n",
            "- Solidarity\n",
            "- Community\n",
            "- Compassionate Action\n",
            "- Emotional Intelligence\n",
            "- Self-Care\n",
            "- Burnout\n",
            "- Mental Health\n",
            "- Boundaries\n",
            "- Self-Reflection\n",
            "- Mindfulness\n",
            "- Communication\n",
            "- Collaboration\n",
            "- Education\n",
            "- Awareness\n",
            "- Social Change\n",
            "- Cultural Shift\n",
            "- Gender Equality\n",
            "- Intersectionality\n",
            "- Feminism\n",
            "- Social Justice\n",
            "- Human Rights\n",
            "- Compassionate Leadership\n",
            "- Role Models\n",
            "- Inspire\n",
            "- Motivate\n",
            "- Impact\n",
            "- Transformation\n",
            "- Progress\n",
            "- Growth\n",
            "- Empathetic Listening\n",
            "- Understanding Others\n",
            "- Compassionate Dialogue\n",
            "- Compassionate Relationships\n",
            "- Compassionate Society\n",
            "variable_contents[var] is:  \n",
            "\n",
            "- Compassion\n",
            "- Iranian Women Movement\n",
            "- Strategies\n",
            "- Increase\n",
            "- Fatigue\n",
            "- Relationship\n",
            "- Light Triad Personality\n",
            "- Empathy\n",
            "- Understanding\n",
            "- Support\n",
            "- Unity\n",
            "- Empowerment\n",
            "- Kindness\n",
            "- Humanity\n",
            "- Activism\n",
            "- Advocacy\n",
            "- Equality\n",
            "- Inclusivity\n",
            "- Resilience\n",
            "- Strength\n",
            "- Solidarity\n",
            "- Community\n",
            "- Compassionate Action\n",
            "- Emotional Intelligence\n",
            "- Self-Care\n",
            "- Burnout\n",
            "- Mental Health\n",
            "- Boundaries\n",
            "- Self-Reflection\n",
            "- Mindfulness\n",
            "- Communication\n",
            "- Collaboration\n",
            "- Education\n",
            "- Awareness\n",
            "- Social Change\n",
            "- Cultural Shift\n",
            "- Gender Equality\n",
            "- Intersectionality\n",
            "- Feminism\n",
            "- Social Justice\n",
            "- Human Rights\n",
            "- Compassionate Leadership\n",
            "- Role Models\n",
            "- Inspire\n",
            "- Motivate\n",
            "- Impact\n",
            "- Transformation\n",
            "- Progress\n",
            "- Growth\n",
            "- Empathetic Listening\n",
            "- Understanding Others\n",
            "- Compassionate Dialogue\n",
            "- Compassionate Relationships\n",
            "- Compassionate Society\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off generate_academic_paper(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-SDI1YMmM2lE1FsZOy1sRCzwk on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "INFO:backoff:Backing off generate_academic_paper(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-SDI1YMmM2lE1FsZOy1sRCzwk on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "INFO:backoff:Backing off generate_academic_paper(...) for 0.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-SDI1YMmM2lE1FsZOy1sRCzwk on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "INFO:backoff:Backing off generate_academic_paper(...) for 3.5s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-SDI1YMmM2lE1FsZOy1sRCzwk on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Compassion\n",
            "2. Iranian women movement\n",
            "3. Strategies\n",
            "4. Increase\n",
            "5. Relationship\n",
            "6. Fatigue\n",
            "7. Light triad personality\n",
            "8. Empathy\n",
            "9. Understanding\n",
            "10. Support\n",
            "11. Unity\n",
            "12. Empowerment\n",
            "13. Advocacy\n",
            "14. Kindness\n",
            "15. Resilience\n",
            "16. Community\n",
            "17. Collaboration\n",
            "18. Education\n",
            "19. Awareness\n",
            "20. Self-care\n",
            "21. Compassionate leadership\n",
            "22. Inclusivity\n",
            "23. Mindfulness\n",
            "24. Social change\n",
            "25. Compassionate action\n",
            "26. Emotional intelligence\n",
            "27. Compassionate communication\n",
            "28. Self-reflection\n",
            "29. Boundaries\n",
            "30. Gratitude\n",
            "variable_contents[var] is:  \n",
            "\n",
            "1. Compassion\n",
            "2. Iranian women movement\n",
            "3. Strategies\n",
            "4. Increase\n",
            "5. Relationship\n",
            "6. Fatigue\n",
            "7. Light triad personality\n",
            "8. Empathy\n",
            "9. Understanding\n",
            "10. Support\n",
            "11. Unity\n",
            "12. Empowerment\n",
            "13. Advocacy\n",
            "14. Kindness\n",
            "15. Resilience\n",
            "16. Community\n",
            "17. Collaboration\n",
            "18. Education\n",
            "19. Awareness\n",
            "20. Self-care\n",
            "21. Compassionate leadership\n",
            "22. Inclusivity\n",
            "23. Mindfulness\n",
            "24. Social change\n",
            "25. Compassionate action\n",
            "26. Emotional intelligence\n",
            "27. Compassionate communication\n",
            "28. Self-reflection\n",
            "29. Boundaries\n",
            "30. Gratitude\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off generate_academic_paper(...) for 0.7s (openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for organization org-SDI1YMmM2lE1FsZOy1sRCzwk on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    869\u001b[0m             )\n\u001b[0;32m--> 870\u001b[0;31m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPStatusError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# thrown on 4xx and 5xx status code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPStatusError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/completions'\nFor more information check: https://httpstatuses.com/429",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    869\u001b[0m             )\n\u001b[0;32m--> 870\u001b[0;31m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPStatusError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# thrown on 4xx and 5xx status code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPStatusError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/completions'\nFor more information check: https://httpstatuses.com/429",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-fdca256805a1>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m            \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Generate content for the variable '{var}' based on the topic '{TOPIC}'. For this prompt '{prompt}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m            \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_academic_paper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mchoice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/backoff/_sync.py\u001b[0m in \u001b[0;36mretry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mexception\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0mmax_tries_exceeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtries\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_tries_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-95a2250a6500>\u001b[0m in \u001b[0;36mgenerate_academic_paper\u001b[0;34m(prompt_my)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0mmax_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   completion = client.completions.create(\n\u001b[0m\u001b[1;32m     40\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo-instruct\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt_my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     ) -> Completion | Stream[Completion]:\n\u001b[0;32m--> 559\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    560\u001b[0m             \u001b[0;34m\"/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1061\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         )\n\u001b[0;32m-> 1063\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 842\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    843\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPStatusError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# thrown on 4xx and 5xx status code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m    874\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    934\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPStatusError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# thrown on 4xx and 5xx status code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m    874\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0;31m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;31m# different thread if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m         return self._request(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt_update_2(prompt, previous_content):\n",
        "    model_engine = \"text-davinci-003\"\n",
        "    max_tokens = 2048\n",
        "\n",
        "    # Construct the instruction for updating the prompt\n",
        "    instruction = f\"Given the previous content:\\n\\n{previous_content}\\n\\nUpdate the prompt: {prompt}\"\n",
        "\n",
        "    # Create the completion with the instruction\n",
        "    completion = client.completions.create(\n",
        "        model=model_engine,\n",
        "        prompt=instruction,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=0.3,\n",
        "        n=1,\n",
        "        frequency_penalty=0,\n",
        "    )\n",
        "\n",
        "    # Extract and return the updated prompt from the response\n",
        "    updated_prompt = completion.choices[0].text.strip()\n",
        "    return updated_prompt\n",
        "# Inside your loop\n",
        "for prompt in prompts:\n",
        "    print(\"Original Prompt:\", prompt)\n",
        "    response = generate_academic_paper_3(prompt)\n",
        "    previous_content = response.choices[0].text.strip()\n",
        "    updated_prompt = generate_prompt_update_2(prompt, previous_content)\n",
        "    print(\"Updated Prompt:\", updated_prompt)\n",
        "\n",
        "    # Continue with the rest of your processing\n",
        "    # ..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "id": "KviSdMwzwqAy",
        "outputId": "3df83b4a-b2a4-42e4-eaf8-e7172388b38c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Prompt: Write a counterargument to the following claim: '{PARAGRAPH}'\n",
            "Updated Prompt: Claim: \"Social media has a negative impact on the quality of relationships between people.\"\n",
            "\n",
            "Counterargument: While it is true that social media can have a negative impact on relationships, it is not the only factor that affects the quality of relationships between people. Other factors such as communication skills, trust, and shared values can also have a significant impact on the quality of relationships. Additionally, social media can also have positive effects on relationships, such as providing a platform for long-distance communication and allowing people to stay connected with friends and family. It is important to recognize the various factors that influence relationships rather than focusing solely on the potential negative effects of social media.\n",
            "Original Prompt: Rewrite this in an academic voice: '{PARAGRAPH}'\n",
            "Updated Prompt: The aforementioned paragraph should be reformulated in an academic voice as follows: The evidence presented in this paragraph indicates that a certain phenomenon is occurring. Further research is necessary to understand the full implications of this phenomenon and to develop strategies for addressing it.\n",
            "Original Prompt: Expand these notes: '{PARAGRAPH}'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-1a39abff3445>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_academic_paper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprevious_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mupdated_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_prompt_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Updated Prompt:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdated_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-1a39abff3445>\u001b[0m in \u001b[0;36mgenerate_prompt_update\u001b[0;34m(prompt, previous_content)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Create the completion with the instruction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     completion = client.completions.create(\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_engine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstruction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     ) -> Completion | Stream[Completion]:\n\u001b[0;32m--> 559\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    560\u001b[0m             \u001b[0;34m\"/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1061\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         )\n\u001b[0;32m-> 1063\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 842\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    843\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_auth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m             log.debug(\n\u001b[1;32m    868\u001b[0m                 \u001b[0;34m'HTTP Request: %s %s \"%i %s\"'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason_phrase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_request_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    902\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    930\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    964\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    216\u001b[0m         )\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionNotAvailable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0;31m# The ConnectionNotAvailable exception is a special case, that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mConnectionNotAvailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"http11.response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     82\u001b[0m                     \u001b[0mreason_phrase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m     85\u001b[0m                 trace.return_value = (\n\u001b[1;32m     86\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    178\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1257\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1259\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DL Translate\n",
        "A deep learning-based translation library built on Huggingface transformers and Facebook's mBART-Large\n",
        "\n",
        "https://colab.research.google.com/github/xhluca/dl-translate/blob/main/demos/colab_demo.ipynb#scrollTo=qdefSjR_YIiG"
      ],
      "metadata": {
        "id": "_I5yn6CCZdMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q dl-translate"
      ],
      "metadata": {
        "id": "c7-q341UWsr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dl_translate as dlt\n",
        "mt = dlt.TranslationModel('mbart50')"
      ],
      "metadata": {
        "id": "gtQcnXabalaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dl_translate as dlt\n",
        "\n",
        "def translate_to_persian(text):\n",
        "  # Initialize the translation model\n",
        "  #mt = dlt.TranslationModel('mbart50')\n",
        "\n",
        "  # Translate the text\n",
        "  translated = mt.translate(text, source=dlt.lang.ENGLISH, target=dlt.lang.PERSIAN)\n",
        "\n",
        "  return translated"
      ],
      "metadata": {
        "id": "iOX6FGFWaFqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key = \"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\",\n",
        ")\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "# Create a Translator object\n",
        "translator = Translator()\n",
        "\n",
        "\n",
        "# Function to generate an academic paper\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=10, max_time=600)\n",
        "def generate_academic_paper_5(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   completion = client.completions.create(\n",
        "       model=\"gpt-3.5-turbo-instruct\",\n",
        "       prompt=prompt_my,\n",
        "       max_tokens=2048,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "choice_text_all=[]\n",
        "\n",
        "import time\n",
        "# Function to generate academic papers for given prompts\n",
        "# Function to generate academic papers for given prompts\n",
        "def generate_papers(prompts):\n",
        "   for i in range(0, len(prompts), 20):\n",
        "       # Slice the prompts list to get the next 20 prompts\n",
        "       print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "       batch = prompts[i:i+10]\n",
        "       print(\"batch is \",batch)\n",
        "       # Generate papers for the next 20 prompts\n",
        "       for prompt in batch:\n",
        "      #   for prompt in prompt1:\n",
        "           # Print the prompt\n",
        "           print(\"prompt is \", prompt)\n",
        "           response = generate_academic_paper(prompt)\n",
        "           print(\"\\nGenerated Academic Paper:\")\n",
        "           print(\"========================\\n\")\n",
        "           #print(response)\n",
        "           for choice in response.choices:\n",
        "             print(choice.text)\n",
        "             choice_text_all.append(choice.text)\n",
        "              # Translate the generated text to Persian\n",
        "             choice_translated = translate_to_persian(choice.text) #translator.translate(choice.text, dest='fa')\n",
        "             choice_translated_prompt = translate_to_persian(prompt)#translator.translate(prompt, dest='fa')\n",
        "\n",
        "             print(\"\\n-----\\n Translated is \",choice_translated)\n",
        "             save_academic_paper(\"Persian_\"+topic,'\\n**'+choice_translated_prompt+'**\\n'+choice_translated)\n",
        "             save_academic_paper(topic,'\\n**'+prompt+'**\\n'+choice.text)\n",
        "             # Recursively call the function for the nested Completion objects\n",
        "             if hasattr(choice, 'choices'):\n",
        "               extract_text(choice)\n",
        "\n",
        "           #generated_text = response.choices[0].text\n",
        "           # Print the generated text\n",
        "           #print(generated_text)\n",
        "           print(\"\\n end of loop\")\n",
        "           print(\"========================\\n\")\n",
        "\n",
        "           #print(\"loop\")\n",
        "       # Wait for a short period of time before sending the next batch of prompts\n",
        "           time.sleep(2)\n",
        "   return choice_text_all,choice.translated\n",
        "\n",
        "# Generate academic papers for the given prompts\n",
        "generate_papers(prompts3)"
      ],
      "metadata": {
        "id": "oVldhSpgEVZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#For solving queta prompt of Openai API;\n",
        "üëáüëáüå±"
      ],
      "metadata": {
        "id": "GdTvLhAkKLEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade openai"
      ],
      "metadata": {
        "id": "iDlM4w-DMHVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "#import openai\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key = \"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\",\n",
        ")\n",
        "\n",
        "def retry_with_exponential_backoff(\n",
        "   func,\n",
        "   initial_delay: float = 1,\n",
        "   exponential_base: float = 2,\n",
        "   jitter: bool = True,\n",
        "   max_retries: int = 10,\n",
        "   errors: tuple = (openai.error.RateLimitError,),\n",
        "):\n",
        "   \"\"\"Retry a function with exponential backoff.\"\"\"\n",
        "   def wrapper(*args, **kwargs):\n",
        "       # Initialize variables\n",
        "       num_retries = 0\n",
        "       delay = initial_delay\n",
        "       # Loop until a successful response or max_retries is hit or an exception is raised\n",
        "       while True:\n",
        "           try:\n",
        "               return func(*args, **kwargs)\n",
        "           # Retry on specified errors\n",
        "           except errors as e:\n",
        "               # Increment retries\n",
        "               num_retries += 1\n",
        "               # Check if max retries has been reached\n",
        "               if num_retries > max_retries:\n",
        "                  raise Exception(\n",
        "                      f\"Maximum number of retries ({max_retries}) exceeded.\"\n",
        "                  )\n",
        "               # Increment the delay\n",
        "               delay *= exponential_base * (1 + jitter * random.random())\n",
        "               # Sleep for the delay\n",
        "               time.sleep(delay)\n",
        "           # Raise exceptions for any errors not specified\n",
        "           except Exception as e:\n",
        "               raise e\n",
        "   return wrapper\n",
        "\n",
        "@retry_with_exponential_backoff\n",
        "def generate_academic_paper_0(prompt_my):\n",
        "  model_engine = \"text-davinci-003\"\n",
        "  max_tokens = 2048\n",
        "\n",
        "  completion = client.completions.create(\n",
        "      model=\"gpt-3.5-turbo-instruct\",\n",
        "      prompt=prompt_my,\n",
        "      max_tokens=2048,\n",
        "      temperature=0.3,\n",
        "      n=1,\n",
        "      frequency_penalty=0,\n",
        "  )\n",
        "  return completion"
      ],
      "metadata": {
        "id": "zLWA8i87KXks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vH0Z7EL5LnQc"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key=\"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\",\n",
        ")\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Function to generate an academic paper\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=10, max_time=600)\n",
        "def generate_academic_paper_6(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   completion = client.completions.create(\n",
        "       model=\"gpt-3.5-turbo-instruct\",\n",
        "       prompt=prompt_my,\n",
        "       max_tokens=2048,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "choice_text_all=[]\n",
        "\n",
        "import time\n",
        "# Function to generate academic papers for given prompts\n",
        "# Function to generate academic papers for given prompts\n",
        "def generate_papers(prompts):\n",
        "   for i in range(0, len(prompts), 20):\n",
        "       # Slice the prompts list to get the next 20 prompts\n",
        "       print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "       batch = prompts[i:i+10]\n",
        "       print(\"batch is \",batch)\n",
        "       # Generate papers for the next 20 prompts\n",
        "       for prompt in batch:\n",
        "      #   for prompt in prompt1:\n",
        "           # Print the prompt\n",
        "           print(\"prompt is \", prompt)\n",
        "           response = generate_academic_paper(prompt)\n",
        "           print(\"\\nGenerated Academic Paper:\")\n",
        "           print(\"========================\\n\")\n",
        "           #print(response)\n",
        "           for choice in response.choices:\n",
        "             print(choice.text)\n",
        "             choice_text_all.append(choice.text)\n",
        "             save_academic_paper(TOPIC,'\\n**'+prompt+'**\\n'+choice.text)\n",
        "             # Recursively call the function for the nested Completion objects\n",
        "             if hasattr(choice, 'choices'):\n",
        "               extract_text(choice)\n",
        "\n",
        "           #generated_text = response.choices[0].text\n",
        "           # Print the generated text\n",
        "           #print(generated_text)\n",
        "           print(\"\\n end of loop\")\n",
        "           print(\"========================\\n\")\n",
        "\n",
        "           #print(\"loop\")\n",
        "       # Wait for a short period of time before sending the next batch of prompts\n",
        "           time.sleep(2)\n",
        "   return choice.text_all\n",
        "\n",
        "# Generate academic papers for the given prompts\n",
        "generate_papers(prompts3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJTgcojthnm7"
      },
      "outputs": [],
      "source": [
        "def render_index_page():\n",
        "   html_content = \"\"\"\n",
        "   <!DOCTYPE html>\n",
        "   <html>\n",
        "   <head>\n",
        "      <title>Generate Academic Papers</title>\n",
        "   </head>\n",
        "   <body>\n",
        "      <h1>Generate Academic Papers</h1>\n",
        "      <form method=\"POST\">\n",
        "          <label for=\"topic\">Topic:</label>\n",
        "          <input type=\"text\" id=\"topic\" name=\"topic\" required>\n",
        "          <input type=\"submit\" value=\"Generate\">\n",
        "      </form>\n",
        "   </body>\n",
        "   </html>\n",
        "   \"\"\"\n",
        "   return render_template_string(html_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKhSXALkhpL7"
      },
      "outputs": [],
      "source": [
        "def render_result_page(topic, docx_file, pdf_file, choice_text_all):\n",
        "   html_content = f\"\"\"\n",
        "   <!DOCTYPE html>\n",
        "   <html>\n",
        "   <head>\n",
        "       <title>Result</title>\n",
        "   </head>\n",
        "   <body>\n",
        "       <h1>Result</h1>\n",
        "       <p>Academic papers have been generated for the topic: {topic}</p>\n",
        "       <a href=\"/download/{docx_file}\">Download DOCX</a>\n",
        "       <a href=\"/download/{pdf_file}\">Download PDF</a>\n",
        "       <h2>Generated Text:</h2>\n",
        "       <p>{choice_text_all}</p>\n",
        "   </body>\n",
        "   </html>\n",
        "   \"\"\"\n",
        "   return render_template_string(html_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuTJlSSGgh4E"
      },
      "outputs": [],
      "source": [
        "# app.py\n",
        "\n",
        "from flask import Flask, request, render_template\n",
        "from academic_paper_generator import generate_papers\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def home():\n",
        "  if request.method == 'POST':\n",
        "      topic = request.form.get('topic')\n",
        "      prompts3 = [\n",
        "          f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "          f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "          f\"Identify gaps in the literature on '{topic}'\",\n",
        "          \"Generate 10 academic research questions about Perviuse action\",\n",
        "          f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "      ]\n",
        "      generate_papers(prompts3)\n",
        "      return render_template('result.html', topic=topic)\n",
        "  else:\n",
        "      return render_template('index.html')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  app.run(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOi1fTQ3VWUo"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key=\"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\",\n",
        ")\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "\"Find a research topic for a PhD in the area of '{TOPIC}'\",\n",
        "\"Write a detailed proposal on the following research '{TOPIC}'. Make Sure it is free from plagiarism. \",\n",
        "\"Identify gaps in the literature on '{TOPIC SENTENCE}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "\"Generate a list of research hypotheses related to '{TOPIC}'\"\n",
        "]\n",
        "\n",
        "# Function to generate an academic paper\n",
        "\n",
        "def generate_academic_paper(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   completion = client.completions.create(\n",
        "     model=\"gpt-3.5-turbo-instruct\",\n",
        "     prompt=prompt_my,#\"Say this is a test\",\n",
        "     max_tokens=2048,\n",
        "     temperature=0.3,\n",
        "     n=1,\n",
        "     #top_p=1,\n",
        "     frequency_penalty=0,\n",
        "     #presence_penalty=0\n",
        "     )\n",
        "   return completion\n",
        "import time\n",
        "# Function to generate academic papers for given prompts\n",
        "# Function to generate academic papers for given prompts\n",
        "def generate_papers(prompts):\n",
        "   for i in range(0, len(prompts), 20):\n",
        "       # Slice the prompts list to get the next 20 prompts\n",
        "       print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "       batch = prompts[i:i+10]\n",
        "       print(\"batch is \",batch)\n",
        "       # Generate papers for the next 20 prompts\n",
        "       for prompt in batch:\n",
        "      #   for prompt in prompt1:\n",
        "           # Print the prompt\n",
        "           print(\"prompt is \", prompt)\n",
        "           response = generate_academic_paper_0(prompt)\n",
        "           print(\"\\nGenerated Academic Paper:\")\n",
        "           print(\"========================\\n\")\n",
        "           #print(response)\n",
        "           for choice in response.choices:\n",
        "             print(choice.text)\n",
        "             # Recursively call the function for the nested Completion objects\n",
        "             if hasattr(choice, 'choices'):\n",
        "               extract_text(choice)\n",
        "\n",
        "           #generated_text = response.choices[0].text\n",
        "           # Print the generated text\n",
        "           #print(generated_text)\n",
        "           print(\"\\n end of loop\")\n",
        "           print(\"========================\\n\")\n",
        "\n",
        "           #print(\"loop\")\n",
        "       # Wait for a short period of time before sending the next batch of prompts\n",
        "           time.sleep(2)\n",
        "\n",
        "# Generate academic papers for the given prompts\n",
        "generate_papers(prompts3)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}